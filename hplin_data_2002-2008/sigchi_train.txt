Scott R. Klemmer:Michael Thomsen:Ethan Phelps-Goodman:Robert Lee:James A. Landay	To form a deep understanding of the present; we need to ?nd and engage history. We present an informal history capture and retrieval mechanism for collaborative, early-stage information design. This history system is implemented in the context of the Designers' Outpost, a wall-scale, tangible interface for collaborative web site design. The interface elements in this history system are designed to be ?uid and comfortable for early-phase design. As demonstrated by an informal lab study with six professional designers, this history system enhances the design process itself, and provides new opportunities for reasoning about the design of complex artifacts	Where do web sites come from?: capturing and interacting with design history	NA:NA:NA:NA:NA	2018
Holger Schnädelbach:Boriana Koleva:Martin Flintham:Mike Fraser:Shahram Izadi:Paul Chandler:Malcolm Foster:Steve Benford:Chris Greenhalgh:Tom Rodden	The augurscope is a portable mixed reality interface for outdoors. A tripod-mounted display is wheeled to different locations and rotated and tilted to view a virtual environment that is aligned with the physical background. Video from an onboard camera is embedded into this virtual environment. Our design encompasses physical form, interaction and the combination of a GPS receiver, electronic compass, accelerometer and rotary encoder for tracking. An initial application involves the public exploring a medieval castle from the site of its modern replacement. Analysis of use reveals problems with lighting, movement and relating virtual and physical viewpoints, and shows how environmental factors and physical form affect interaction. We suggest that problems might be accommodated by carefully constructing virtual and physical content	The augurscope: a mixed reality interface for outdoors	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Shumin Zhai:Alison Sue:Johnny Accot	In a ten-session experiment, six participants practiced typing with an expanding rehearsal method on an optimized virtual keyboard. Based on a large amount of in-situ performance data, this paper reports the following findings. First, the Fitts-digraph movement efficiency model of virtual keyboards is revised. The format and parameters of Fitts' law used previously in virtual keyboards research were incorrect. Second, performance limit predictions of various layouts are calculated with the new model. Third, learning with expanding rehearsal intervals for maximum memory benefits is effective, but many improvements of the training algorithm used can be made in the future. Finally, increased visual load when typing previously practiced text did not significantly change users' performance at this stage of learning, but typing unpracticed text did have a performance effect, suggesting a certain degree of text specific learning when typing on virtual keyboards	Movement model, hits distribution and learning in virtual keyboarding	NA:NA:NA	2018
Poika Isokoski:Mika Käki	Small hand-held touchpads can be used to replace stylus-based digitizing tablets when the use of a stylus is not convenient. In text entry tasks where the writing surface is held in a hand the error rate becomes a problem. The small size of strokes compared to the width of the fingertip and the additional imprecision caused by the interaction of the pad and finger movements make input very imprecise. We describe a new improved clock-face based stroke system for entering numbers with a touchpad. In a 20-session user study with 6 users we found slightly better throughput of successfully entered numbers with the proposed new system. This advantage was mainly due to lower error rate with the new system. User preference similarly slightly favored the new system over an earlier straightforward proposal based on the clock metaphor	Comparison of two touchpad-based methods for numeric entry	NA:NA	2018
Brad A. Myers:Rishi Bhatnagar:Jeffrey Nichols:Choon Hong Peck:Dave Kong:Robert Miller:A. Chris Long	It is difficult to interact with computer displays that are across the room. A popular approach is to use laser pointers tracked by a camera, but interaction techniques using laser pointers tend to be imprecise, error-prone, and slow. Although many previous papers discuss laser pointer interaction techniques, none seem to have performed user studies to help inform the design. This paper reports on two studies of laser pointer interactions that answer some of the questions related to interacting with objects using a laser pointer. The first experiment evaluates various parameters of laser pointers. For example, the time to acquire a target is about 1 second, and the jitter due to hand unsteadiness is about ±8 pixels, which can be reduced to about ±2 to ±4 pixels by filtering. We compared 7 different ways to hold various kinds of laser pointers, and found that a laser pointer built into a PalmOS device was the most stable. The second experiment compared 4 different ways to select objects on a large projected display. We found that tapping directly on a wall-size SmartBoard was the fastest and most accurate method, followed by a new interaction technique that copies the area of interest from the big screen to a handheld. Third in speed was the conventional mouse, and the laser pointer came in last, with a time almost twice as long as tapping on the SmartBoard	Interacting at a distance: measuring the performance of laser pointers and other devices	NA:NA:NA:NA:NA:NA:NA	2018
Atsushi Fukayama:Takehiko Ohno:Naoki Mukawa:Minako Sawaki:Norihiro Hagita	We propose a gaze movement model that enables an embodied interface agent to convey different impressions to users. Managing one's own impression to influence the behaviors of others plays an important role in human communications. To create a new application area which involves agents in this kind of social interaction, interface agents that manage their impressions are required. For this purpose, we build the gaze movement model based on three gaze parameters picked from a large number of psychological studies: amount of gaze, mean duration of gaze, and gaze points while averted. In this paper, we introduce the gaze movement model and gaze parameters. We then present an experiment in which subjects evaluated the impressions created by nine gaze patterns produced by altering the gaze parameters. The results indicate that reproducible relations exist between the gaze parameters and impressions, which shows the validity of the model	Messages embedded in gaze of interface agents --- impression management with agent's gaze	NA:NA:NA:NA:NA	2018
Milton Chen	Eye contact is a natural and often essential element in the language of visual communication. Unfortunately, perceiving eye contact is difficult in most video-conferencing systems and hence limits their effectiveness. We conducted experiments to determine how accurately people perceive eye contact. We discovered that the sensitivity to eye contact is asymmetric, in that we are an order of magnitude less sensitive to eye contact when people look below our eyes than when they look to the left, right, or above our eyes. Additional experiments support a theory that people are prone to perceive eye contact, that is, we will think that someone is making eye contact with us unless we are certain that the person is not looking into our eyes. These experimental results suggest parameters for the design of videoconferencing systems. As a demonstration, we were able to construct from commodity components a simple dyadic videoconferencing prototype that supports eye contact	Leveraging the asymmetric sensitivity of eye contact for videoconference	NA	2018
Michael McGuffin:Ravin Balakrishnan	There exist several user interface widgets that dynamically grow in size in response to the user's focus of attention. Some of these, such as icons in toolbars, expand to facilitate their selection - allowing for a reduced initial size in an attempt to optimize screen space use. However, selection performance may be degraded by this decreased initial widget size. We describe an experiment which explores the effects of varying parameters of expansion techniques in a selection task. Our results suggest that Fitts' law can model and predict performance in such tasks. They also indicate that performance is governed by the target's final size, not its initial one. Further, performance is dependent on the target's final size even when the target only begins expanding as late as after 90% of the movement towards the target has already been completed. These results indicate that expanding widgets can be used without sacrificing performance	Acquisition of expanding targets	NA:NA	2018
Ken Hinckley:Edward Cutrell:Steve Bathiche:Tim Muss	We propose a formal experimental paradigm designed to help evaluate scrolling interaction techniques. Such a method is needed by interaction designers to quantify scrolling performance, thereby providing a tool to evaluate and improve upon new techniques. We systematically vary the scrolling distance as well as the required tolerance of scrolling. Distance and tolerance are the parameters of Fitts' Law, which traditionally has been applied to the evaluation of pointing devices in tasks involving rapid, aimed movement to visible targets. Scrolling involves acquisition of targets well beyond the edges of the screen, yet Fitts' Law models our experimental data very wellWe apply our paradigm to the IBM ScrollPoint and the IntelliMouse Wheel. Our experimental approach reveals a crossover effect in performance versus distance, with the Wheel performing best at short distances but the ScrollPoint performing best at long distances. We also demonstrate that the performance of the Wheel can be significantly improved using an acceleration algorithm. These results show that our approach yields a practical and rigorous method for the evaluation of scrolling techniques.	Quantitative analysis of scrolling techniques	NA:NA:NA:NA	2018
Johnny Accot:Shumin Zhai	Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces	More than dotting the i's --- foundations for crossing-based interfaces	NA:NA	2018
Chris Quintana:Joseph Krajcik:Elliot Soloway	A challenge for HCI researchers and designers involves developing software tools for learners to support them in mindfully doing and learning complex new work practices. Such "learner-centered" tools incorporate scaffolds-software features that address the cognitive obstacles learners face so they can engage in the work in an educationally productive manner. However, designers still lack specific scaffolding design guidelines for developing effective scaffolded tools. The HCI contribution of this paper is a set of scaffolding guidelines distilled from an empirical case study. The study evaluated Symphony, a scaffolded environment for high school students learning science inquiry. The study evaluated the "effects with" the Symphony scaffolds, which described how students worked with the scaffolds to do their science work. The scaffolds were evaluated using several usability and learner-centered criteria, and the resulting information was correlated with structural characteristics of the scaffolds to distill a set of structural scaffolding guidelines	A Case Study to Distill Structural Scaffolding Guidelines for Scaffolded Software Environments	NA:NA:NA	2018
A. J. Bernheim Brush:David Bargeron:Jonathan Grudin:Anoop Gupta	Notification and shared annotations go hand-in-hand. Notification of activity in a shared document system is known to support awareness and improve asynchronous collaboration, but few studies have examined user needs and explored design tradeoffs. We examined large-scale use of notifications in a commercial system and found it lacking. We designed and deployed enhancements to the system, then conducted a field study to gauge their effect. We found that providing more information in notification messages, supporting multiple communication channels through which notifications can be received, and allowing customization of notification messages are particularly important. Overall awareness of annotation activity on software specifications increased with our enhancements	Notification for shared annotation of digital documents	NA:NA:NA:NA	2018
James M. Hudson:Jim Christensen:Wendy A. Kellogg:Thomas Erickson	Many CSCW projects dealing with individual availability and interruption filtering achieve only limited success. Perhaps this is because designers of such systems have limited evidence to draw upon; most data on interruption management is at least a decade old. This study uses an empirical sampling method and qualitative interviews to examine attitudes toward availability and interruption. Specifically, we analyze how corporate research managers spend their time and look at how their attitudes toward interruption relate to their various activities. Attitudes toward interruption are marked by a complex tension between wanting to avoid interruption and appreciating its usefulness. We conclude by discussing the implications of these findings for design, suggesting that the notion of socially translucent systems may be a fruitful approach	"I'd be overwhelmed, but it's just one more thing to do": availability and interruption in research management	NA:NA:NA:NA	2018
Jeffrey S. Pierce:Randy Pausch	When creating techniques for manipulating objects at a distance in immersive virtual environments, researchers have primarily focused on increasing selection range, placement range, and placement accuracy. This focus has led researchers to create and formally study a series of "arm-extension" techniques, which dynamically scale the user's arm to allow him to manipulate distant objects. Researchers have also developed representation-based techniques, which allow users to manipulate a distant object by manipulating a copy of it in a handheld representation. However, researchers have not yet formally established the relative value of these techniques. In this paper we present a formal study comparing Voodoo Dolls, a best-practice representation-based technique, with HOMER, a best-practice arm-extension technique. We found that the Voodoo Dolls technique, which provides better feedback by allowing users to view a manipulated object both up close and at a distance, allowed users to both position and orient objects more accurately. Our results suggest that researchers should focus on improving feedback for 3D manipulation techniques	Comparing voodoo dolls and HOMER: exploring the importance of feedback in virtual environments	NA:NA	2018
Jun Rekimoto	This paper introduces a new sensor architecture for making interactive surfaces that are sensitive to human hand and finger gestures. This sensor recognizes multiple hand positions and shapes and calculates the distance between the hand and the surface by using capacitive sensing and a mesh-shaped antenna. In contrast to camera-based gesture recognition systems, all sensing elements can be integrated within the surface, and this method does not suffer from lighting and occlusion problems. This paper describes the sensor architecture, as well as two working prototype systems: a table-size system and a tablet-size system. It also describes several interaction techniques that would be difficult to perform without using this architecture	SmartSkin: an infrastructure for freehand manipulation on interactive surfaces	NA	2018
Tovi Grossman:Ravin Balakrishnan:Gordon Kurtenbach:George Fitzmaurice:Azam Khan:Bill Buxton	Previous systems have explored the challenges of designing an interface for automotive styling which combine the metaphor of 2D drawing using physical tape with the simultaneous creation and management of a corresponding virtual 3D model. These systems have been limited to only 2D planar curves while typically the principal characteristic curves of an automotive design are three dimensional and non-planar. We present a system which addresses this limitation. Our system allows a designer to construct these non-planar 3D curves by drawing a series of 2D curves using the 2D tape drawing technique and interaction style. These results are generally applicable to the interface design of 3D modeling applications and also to the design of arm's length interaction on large scale display systems	Creating principal 3D curves with digital tape drawing	NA:NA:NA:NA:NA:NA	2018
Eva Jettmar:Clifford Nass	This study examines the effects of interface adaptation on user performance in HCI and CMC. No studies to date have explored the psychological effects of a combination of software performance monitoring and adaptation. This combination is the focus of the present study. Two competing possible effects of adaptive interfaces are presented: 1) Social facilitation, according to which users with high task confidence should perform better, and users with low task confidence should perform less well because their performance is monitored by the interface; and 2) "choking", according to which users with high task confidence should perform less well, and users with low task confidence should perform better because the interface adapts to their performance. A 2 (adaptive vs. non-adaptive) x 2 (high user task confidence vs. low task confidence) x 2 (HCI vs. CMC) laboratory experiment was conducted. Results indicate that for CMC, the social facilitation explanation holds true, while results for HCI were consistent with the "choking" explanation. Implications for the theory and design of adaptive interfaces are discussed	Adaptive testing: effects on user performance	NA:NA	2018
Nathan Bos:Judy Olson:Darren Gergle:Gary Olson:Zach Wright	When virtual teams need to establish trust at a distance, it is advantageous for them to use rich media to communicate. We studied the emergence of trust in a social dilemma game in four different communication situations: face-to-face, video, audio, and text chat. All three of the richer conditions were significant improvements over text chat. Video and audio conferencing groups were nearly as good as face-to-face, but both did show some evidence of what we term delayed trust (slower progress toward full cooperation) and fragile trust (vulnerability to opportunistic behavior)	Effects of four computer-mediated communications channels on trust development	NA:NA:NA:NA:NA	2018
Jun Zheng:Elizabeth Veinott:Nathan Bos:Judith S. Olson:Gary M. Olson	Computer-mediated communication (CMC) is thought to be inadequate when one needs to establish trust. If, however, people meet before using CMC, they trust each other, trust being established through touch. Here we show that if participants do not meet beforehand but rather engage in various getting-acquainted activities over a network, trust is much higher than if they do nothing beforehand, nearly as good as a prior meeting. Using text-chat to get acquainted is nearly as good as meeting, and even just seeing a picture is better than nothing	Trust without touch: jumpstarting long-distance trust with initial social activities	NA:NA:NA:NA:NA	2018
Bonnie John:Alonso Vera:Michael Matessa:Michael Freed:Roger Remington	CPM-GOMS is a modeling method that combines the task decomposition of a GOMS analysis with a model of human resource usage at the level of cognitive, perceptual, and motor operations. CPM-GOMS models have made accurate predictions about skilled user behavior in routine tasks, but developing such models is tedious and error-prone. We describe a process for automatically generating CPM-GOMS models from a hierarchical task decomposition expressed in a cognitive modeling tool called Apex. Resource scheduling in Apex automates the difficult task of interleaving the cognitive, perceptual, and motor resources underlying common task operators (e.g. mouse move-and-click). Apex's UI automatically generates PERT charts, which allow modelers to visualize a model's complex parallel behavior. Because interleaving and visualization is now automated, it is feasible to construct arbitrarily long sequences of behavior. To demonstrate the process, we present a model of automated teller interactions in Apex and discuss implications for user modeling	Automating CPM-GOMS	NA:NA:NA:NA:NA	2018
Stacey D. Scott:Neal Lesh:Gunnar W. Klau	Scheduling, routing, and layout tasks are examples of hard optimization problems with broad application in industry. Past research in this area has focused on algorithmic issues. However, this approach neglects many important human-computer interaction issues that must be addressed to provide people with practical solutions to optimization problems. Automatic methods do not leverage human expertise and can only find solutions that are optimal with regard to an invariably over-simplified problem description. Furthermore, users must understand the generated solutions in order to implement, justify, or modify them. Interactive optimization helps address these issues but has not previously been studied in detail. This paper describes experiments on an interactive optimization system that explore the most appropriate way to combine the respective strengths of people and computers. Our results show that users can successfully identify promising areas of the search space as well as manage the amount of computational effort expended on different subproblems	Investigating human-computer optimization	NA:NA:NA	2018
Joanna McGrenere:Ronald M. Baecker:Kellogg S. Booth	This study examines a novel interface design for heavily-featured productivity software. The design includes two interfaces between which the user can easily toggle: (1) an interface personalized by the user containing desired features only, and (2) the default interface with all the standard features. This design was prototyped as a front-end to a commercial word processor and evaluated in a comprehensive field study. The study tested the effects of different interface designs on users' satisfaction and their perceived ability to navigate, control, and learn the software. There were two conditions: a commercial word processor with adaptive menus and our two-interface prototype with adaptable menus for the same word processor. Results showed that participants were better able to navigate through the menus and toolbars and were better able to learn with our prototype. There were also significant differences in satisfaction and control with our design	An evaluation of a multiple interface design solution for bloated software	NA:NA:NA	2018
James D. Herbsleb:David L. Atkins:David G. Boyer:Mark Handel:Thomas A. Finholt	We report on our experiences of introducing an instant messaging and group chat application into geographically distributed workgroups. We describe a number of issues we encountered, including privacy concerns, individual versus group training, and focusing on teams or individuals. The perception of the tool's utility was a complex issue, depending both on users' views of the importance of informal communication, and their perceptions of the nature of cross-site communication issues. Finally, we conclude with a discussion of critical mass, which is related to the features each user actually uses. More generally, we encountered a dilemma that imposes serious challenges for user-centered design of groupware systems	Introducing instant messaging and chat in the workplace	NA:NA:NA:NA:NA	2018
Ellen Isaacs:Alan Walendowski:Dipti Ranganthan	There have been many attempts to support awareness and lightweight interactions using video and audio, but few have been built on widely available infrastructure. Text-based systems have become more popular, but few support awareness, opportunistic conversations, and mobility, three important elements of distributed collaboration. We built on the popularity of text-based Instant Messengers (IM) by building a mobile IM called Hubbub that tries to provide all three, notably through the use of earcons. In a 5.5-month use study, we found that Hubbub helped people feel connected to colleagues in other locations and supported opportunistic interactions. The sounds provided effective awareness cues, although some found them annoying. It was more important to support graceful transitions between multiple fixed locations than to support wireless access, although both were useful	Hubbub: a sound-enhanced mobile instant messenger that supports awareness and opportunistic interactions	NA:NA:NA	2018
Amy Voida:Wendy C. Newstetter:Elizabeth D. Mynatt	We discuss findings from observation, interviews, and textual analysis of instant messaging use in a university research lab setting. We propose a method for characterizing the tensions that permeate instant messaging texts and that expose the collision between conventions of verbal and written communication. Given this method, we suggest a design space for exploring potential design choices in instant messaging clients. Finally, we recommend an analysis of communicative conventions as a fruitful lens through which designers might anticipate or circumvent design tensions in emergent computer-mediated communication technologies	When conventions collide: the tensions of instant messaging attributed	NA:NA:NA	2018
Mary Czerwinski:Desney S. Tan:George G. Robertson	Published reports suggest that males significantly outperform females in navigating virtual environments. A novel navigation technique reported in CHI 2001, when combined with a large display and wide field of view, appeared to reduce that gender bias. That work has been extended with two navigation studies in order to understand the finding under carefully controlled conditions. The first study replicated the finding that a wide field of view coupled with a large display benefits both male and female users and reduces gender bias. The second study suggested that wide fields of view on a large display were useful to females despite a more densely populated virtual world. Implications for design of virtual worlds and large displays are discussed. Specifically, women take a wider field of view to achieve similar virtual environment navigation performance to men	Women take a wider view	NA:NA:NA	2018
Andy Cockburn:Bruce McKenzie	User interfaces can improve task performance by exploiting the powerful human capabilities for spatial cognition. This opportunity has been demonstrated by many prior experiments. It is tempting to believe that providing greater spatial flexibility-by moving from flat 2D to 3D user interfaces-will further enhance user performance. This paper describes an experiment that investigates the effectiveness of spatial memory in real-world physical models and in equivalent computer-based virtual systems. The different models vary the user's freedom to use depth and perspective in spatial arrangements of images representing web pages. Results show that the subjects' performance deteriorated in both the physical and virtual systems as their freedom to locate items in the third dimension increased. Subjective measures reinforce the performance measures, indicating that users found interfaces with higher dimensions more 'cluttered' and less efficient	Evaluating the effectiveness of spatial memory in 2D and 3D physical and virtual environments	NA:NA	2018
Brian D. Ehret	A theoretical account is presented on how locations of interface objects are learned and how the mechanisms underlying location learning interact with the representativeness of object labels. The account is embodied in a computational cognitive model built within the ACT-R/PM cognitive architecture [1, 2] and is supported by point-of-gaze and performance data collected in empirical research. The model interacts with the same software under the same experimental task conditions as study participants and replicates both performance and the finer-grained point-of-gaze data. Drawing from the data and model, location learning is characterized as a process that occurs as a by-product of interaction such that, without specific intent to do so, users can gradually learn the locations of the interface objects to which they attend. Characteristics of the user interface shape this learning process, however, by constraining the set of possible strategies for interaction. Locations are learned more quickly when the least-effortful strategy available in the interface explicitly requires retrieval of location knowledge	Learning where to look: location learning in graphical user interfaces	NA	2018
Steven M. Drucker:Asta Glatzer:Steven De Mar:Curtis Wong	In this paper, we describe an interface for browsing and skipping digital video content in a consumer setting; that is, sitting and watching television from a couch using a standard remote control. We compare this interface with two other interfaces that are in common use today and found that subjective satisfaction was statistically better with the new interface. Performance metrics however, like time to task completion and number of clicks were worse.	SmartSkip: consumer level browsing and skipping of digital video content	NA:NA:NA:NA	2018
Abigail J. Sellen:Rachel Murphy:Kate L. Shaw	We report on a diary study of how and why knowledge workers use the World Wide Web. By examining in detail a complete two-day set of Web activities from each of 24 people, we construct a framework with which to describe the different tasks knowledge workers undertake. By looking at the characteristics of each type of activity, we can see how certain activities are unsuited to particular kinds of technologies (e.g., mobile devices); how Web tools might be incrementally improved; and how we might better support knowledge workers' Web tasks in the future	How knowledge workers use the web	NA:NA:NA	2018
David Martin:Mark Rouncefield:Ian Sommerville	This paper presents patterns of cooperative interaction derived from ethnographic studies of cooperative work as devices for generalisation, re-use and design. These patterns consist of examples of similar social and interactional phenomena found in different studies that serve as resources for defining and envisaging design concepts, and potential work process and technical solutions. We outline new pattern examples and demonstrate their use in application to a complex setting: e-government in local government planning	Applying patterns of cooperative interaction to work (re)design: e-government and planning	NA:NA:NA	2018
Jeffrey Heer:Ed H. Chi	Understanding user behaviors on Web sites enables site owners to make sites more usable, ultimately helping users to achieve their goals more quickly. Accordingly, researchers have devised methods for categorizing user sessions in hopes of revealing user interests. These techniques build user profiles by combining users' navigation paths with other data features, such as page viewing time, hyperlink structure, and page content. Previously, we have presented complex techniques of combining many of these data features to cluster user profiles. In this paper, we introduce a user study and a systematic evaluation of these different data features and their associated weighting schemes. We present the results of our study, including accuracy measures for a number of clustering approaches, and offer recommendations for Web analysts. While further investigation over more sites is needed to definitively settle on a robust scheme, we have characterized this analytic space	Separating the swarm: categorization methods for user sessions on the web	NA:NA	2018
Bongwon Suh:Allison Woodruff:Ruth Rosenholtz:Alyssa Glass	We present an overview+detail document interface that draws on perceptual principles to help users work with documents. Central to our approach is the use of improved document overviews. Our approach also includes novel highlighting in the full representation of documents, as well as techniques to help users smoothly transition from the overview to the full representation of the document. We present a specific implementation of our design for Web browsing. We also present a qualitative user study that indicates that our perceptual design principles are effective and that users prefer our interface to traditional "find" and highlighting techniques. Our user study additionally reveals interesting tasks and strategies supported in our framework that have implications for overview+detail document interfaces in general	Popout prism: adding perceptual principles to overview+detail document interfaces	NA:NA:NA:NA	2018
Patrick Baudisch:Nathaniel Good:Victoria Bellotti:Pamela Schraedley	Users working with documents that are too large and detailed to fit on the user's screen (e.g. chip designs) have the choice between zooming or applying appropriate visualization techniques. In this paper, we present a comparison of three such techniques. The first, focus plus context screens, are wall-size low-resolution displays with an embedded high-resolution display region. This technique is compared with overview plus detail and zooming/panning. We interviewed fourteen visual surveillance and design professionals from different areas (graphic design, chip design, air traffic control, etc.) in order to create a repre sentative sample of tasks to be used in two experimental comparison studies. In the first experiment, subjects using focus plus context screens to extract information from large static documents completed the two experimental tasks on average 21% and 36% faster than when they used the other interfaces. In the second experiment, focus plus context screens allowed subjects to reduce their error rate in a driving simulation to less than one third of the error rate of the competing overview plus detail setup	Keeping things in context: a comparative evaluation of focus plus context screens, overviews, and zooming	NA:NA:NA:NA	2018
Carl Gutwin	Fisheye views allow people to see both a focus region and the surrounding context in the same window. However, the magnification effects of the fisheye lens can cause several problems for users. One of these is focus-targeting, where a user moves the focus to a new location. Magnification makes focus-targeting difficult because objects appear to move as the focus point approaches them. This paper examines how the distortion of a fisheye view affects focus-targeting performance, and present a technique called speed-coupled flattening (SCF) as a way to improve focus targeting in distortion-oriented views. SCF dynamically reduces the distortion level of a fisheye based on pointer velocity and acceleration. In an experiment, the technique resulted in significant reductions in both targeting time and targeting errors. By adjusting distortion based on the user's activity, we can improve usability without requiring the user to manipulate any additional view controls	Improving focus targeting in interactive fisheye views	NA	2018
Steve Whittaker:Julia Hirschberg:Brian Amento:Litza Stark:Michiel Bacchiani:Philip Isenhour:Larry Stead:Gary Zamchick:Aaron Rosenberg	Increasing amounts of public, corporate, and private speech data are now available on-line. These are limited in their usefulness, however, by the lack of tools to permit their browsing and search. The goal of our research is to provide tools to overcome the inherent difficulties of speech access, by supporting visual scanning, search, and information extraction. We describe a novel principle for the design of UIs to speech data: What You See Is Almost What You Hear (WYSIAWYH). In WYSIAWYH, automatic speech recognition (ASR) generates a transcript of the speech data. The transcript is then used as a visual analogue to that underlying data. A graphical user interface allows users to visually scan, read, annotate and search these transcripts. Users can also use the transcript to access and play specific regions of the underlying message. We first summarize previous studies of voicemail usage that motivated the WYSIAWYH principle, and describe a voicemail UI, SCANMail, that embodies WYSIAWYH. We report on a laboratory experiment and a two-month field trial evaluation. SCANMail outperformed a state of the art voicemail system on core voicemail tasks. This was attributable to SCANMail's support for visual scanning, search and information extraction. While the ASR transcripts contain errors, they nevertheless improve the efficiency of voicemail processing. Transcripts either provide enough information for users to extract key points or to navigate to important regions of the underlying speech, which they can then play directly	SCANMail: a voicemail interface that makes speech browsable, readable and searchable	NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Bernhard Suhm:Josh Bers:Dan McCarthy:Barbara Freeman:David Getty:Katherine Godfrey:Pat Peterson	This paper presents a field study that compares natural language call routing with standard touch-tone menus. Call routing is the task of getting callers to the right place in the call center, which could be the appropriate live agent or automated service. Natural language call routing lets callers describe the reason for their call in their own words, instead of presenting them with a list of menu options to select from using the telephone touch-tone keypad. The field study was conducted in a call center of a large telecommunication service provider. Results show that with natural language call routing, more callers respond to the main routing prompt, more callers are routed to a specific destination (instead of defaulting to a general operator who may have to transfer them), and more callers are routed to the correct agent. Our survey data show that callers overwhelmingly prefer natural language call routing over standard touch-tone menus. Furthermore, natural language call routing can also deliver significant cost savings to call centers	A comparative study of speech in the call center: natural language call routing vs. touch-tone menus	NA:NA:NA:NA:NA:NA:NA	2018
Antti Pirhonen:Stephen Brewster:Christopher Holguin	This paper discusses the use of gesture and non-speech audio as ways to improve the user interface of a mobile music player. Their key advantages mean that users could use a player without having to look at its controls when on the move. Two very different evaluations of the player took place: one based on a standard usability experiment (comparing the new player to a standard design) and the other a video analysis of the player in use. Both of these showed significant usability improvements for the gesture/audio-based interface over a standard visual/pen-based display. The similarities and differences in the results produced by the two studies are discussed	Gestural and audio metaphors as a means of control for mobile devices	NA:NA:NA	2018
Jaime Montemayor:Allison Druin:Allison Farber:Sante Simms:Wayne Churaman:Allison D'Amour	Physical interactive environments can come in many forms: museum installations, amusement parks, experimental theaters, and more. Programming these environments has historically been done by adults, and children, as the visiting participants, have been offered few pre-created choices to explore. Given these creative limitations, the goal of our research has been to develop programming tools for physical interactive environments that are appropriate for use by young children (ages 4-6). We have explored numerous design approaches over the past two years. Recently we began focusing on a "physical programming" approach and developed a wizard-of-oz prototype for young children. This paper presents the motivation for this research, the evolution of our programming approach, and our recent explorations with children	Physical programming: designing tools for children to create physical interactive environments	NA:NA:NA:NA:NA:NA	2018
James Lin:Michael Thomsen:James A. Landay	Informal, sketch-based design tools closely match the work practices of user interface designers. Current tools, however, are limited in the size and complexity of interaction that can be specified. We have created an advanced sketch-based visual language that allows for easy prototyping of large, complex interactive designs. In its current embodiment in the denim web design tool, the visual language allows designers to sketch reusable components for recurring page elements, such as navigation bars, as well as conditionals to illustrate and test transitions that depend on a user's input. Designers can also specify sites that accept richer user input than simple clicking. Our informal evaluation shows that these features allow designers with little programming experience to quickly create prototypes of large, complex web sites while still working inside an informal, sketch-based environment	A visual language for sketching large and complex interactive designs	NA:NA:NA	2018
Loren Terveen:Jessica McMackin:Brian Amento:Will Hill	Many applications require users to specify preferences. We support users in this task by letting them define preferences relative to their personal history or that of other users. We implement this idea using a graphical technique called control shadows, which we have implemented on both a desktop computer and on a cell phone with a small, grayscale display. An empirical study compared user performance on the graphical interface and a text table interface with identical functionality. On the desktop, users completed their tasks more quickly and effectively and strongly preferred the graphical interface. On the cell phone, there was no significant difference between the graphical and table interfaces. Finally, personal history proved useful in specifying preferences, but history of other users was not helpful	Specifying preferences based on user history	NA:NA:NA:NA	2018
Andrew T. Fiore:Scott Lee Tiernan:Marc A. Smith	In this paper we describe an evaluation of behavioral descriptors generated from an analysis of a large collection of Usenet newsgroup messages. The metrics describe aspects of newsgroup authors' behavior over time; such information can aid in filtering, sorting, and recommending content from public discussion spaces like newsgroups. To assess the value of a variety of these behavioral descriptors, we compared 22 participants' subjective evaluations of authors whose messages they read to behavioral metrics describing the same authors. We found that many metrics, particularly the longevity and frequency of participation, the number of newsgroups to which authors contribute messages, and the amount they contribute to each thread, correlate highly with readers' subjective evaluations of the authors	Observed behavior and perceived value of authors in usenet newsgroups: bridging the gap	NA:NA:NA	2018
Dave Snowdon:Antonietta Grasso	Recommender systems selectively circulate information enriched with comments and feedback based on people's experience. These systems filter information in a semi-automatic and high-quality way in order to support a community during their work or leisure practices. However recommender systems are usually separate tools that require a degree of effort to be used, both when receiving information and to insert new feedback. In this paper we present our informal experiences with the use of multiple user interfaces (interactive large screen, email, paper and PDA) as means to improve the diffusion of information through an organizational unit and to improve access to information stored within an existing recommender system	Diffusing information in organizational settings: learning from experience	NA:NA	2018
Robert J. K. Jacob:Hiroshi Ishii:Gian Pangaro:James Patten	The task of organizing information is typically performed either by physically manipulating note cards or sticky notes or by arranging icons on a computer with a graphical user interface. We present a new tangible interface platform for manipulating discrete pieces of abstract information, which attempts to combine the benefits of each of these two alternatives into a single system. We developed interaction techniques and an example application for organizing conference papers. We assessed the effectiveness of our system by experimentally comparing it to both graphical and paper interfaces. The results suggest that our tangible interface can provide a more effective means of organizing, grouping, and manipulating data than either physical operations or graphical computer interaction alone	A tangible interface for organizing information using a grid	NA:NA:NA:NA	2018
Ehud Sharlin:Yuichi Itoh:Benjamin Watson:Yoshifumi Kitamura:Steve Sutphen:Lili Liu	Assessments of spatial, constructional ability are used widely in cognitive research and in clinical diagnosis of disease or injury. Some believe that three-dimensional (3D) forms of these assessments would be particularly sensitive, but difficulties with consistency in administration and scoring have limited their use. We describe Cognitive Cubes, a novel computerized tool for 3D constructional assessment that increases consistency and promises improvements in flexibility, reliability, sensitivity and control. Cognitive Cubes makes use of ActiveCube, a novel tangible user interface for describing 3D shape. In testing, Cognitive Cubes was sensitive to differences in cognitive ability and task, and correlated well to a standard paper-and-pencil 3D spatial assessment	Cognitive cubes: a tangible user interface for cognitive assessment	NA:NA:NA:NA:NA:NA	2018
Ben Piper:Carlo Ratti:Hiroshi Ishii	This paper describes a novel system for the real-time computational analysis of landscape models. Users of the system - called Illuminating Clay - alter the topography of a clay landscape model while the changing geometry is captured in real-time by a ceiling-mounted laser scanner. A depth image of the model serves as an input to a library of landscape analysis functions. The results of this analysis are projected back into the workspace and registered with the surfaces of the model.We describe a scenario for which this kind of tool has been developed and we review past work that has taken a similar approach. We describe our system architecture and highlight specific technical issues in its implementation.We conclude with a discussion of the benefits of the system in combining the tangible immediacy of physical models with the dynamic capabilities of computational simulations.	Illuminating clay: a 3-D tangible interface for landscape analysis	NA:NA:NA	2018
Michelle E. Bayles	A common medium for advertising on the Internet is the use of banner ads. This study investigates recall and recognition of animated banner advertisements in an attempt to identify design guidelines. It was hypothesized that animation would increase recall and recognition of novel ads by increasing user awareness. No significant relationships were found between the use of animation and ability to recall and recognize banner ads. Results indicate that animation does not enhance user memory of online banner advertisements.	Designing online banner advertisements: should we animate?	NA	2018
Melody Y. Ivory:Marti A. Hearst	We are creating an interactive tool to help non-professional web site builders create high quality designs. We have previously reported that quantitative measures of web page structure can predict whether a site will be highly or poorly rated by experts, with accuracies ranging from 67--80%. In this paper we extend that work in several ways. First, we compute a much larger set of measures (157 versus 11), over a much larger collection of pages (5300 vs. 1900), achieving much higher overall accuracy (94% on average) when contrasting good, average, and poor pages. Second, we introduce new classes of measures that can make assessments at the site level and according to page type (home page, content page, etc.). Finally, we create statistical profiles of good sites, and apply them to an existing design, showing how that design can be changed to better match high-quality designs	Statistical profiles of highly-rated web sites	NA:NA	2018
Shelly Farnham:Lili Cheng:Linda Stone:Melora Zaner-Godsey:Christopher Hibbeln:Karen Syrjala:Ann Marie Clark:Janet Abrams	To address the needs of cancer patients and their caregivers, Microsoft Research and the Fred Hutchinson Cancer Research Center developed HutchWorld, an online community environment, to provide computer-mediated social and informational support. In a controlled clinical study, we deployed HutchWorld to bone marrow transplant patients and their caregivers and assessed the impact of Internet access and HutchWorld on their quality of life. We found that Internet access and the use of HutchWorld helped to buffer study participants against reductions in life satisfaction and social support following the transplant procedure. In particular, participants used the Internet to seek out support from family and friends	HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers	NA:NA:NA:NA:NA:NA:NA:NA	2018
Michael J. Muller:Kenneth Carey	This paper provides a description of designers' work practices in a software company. We describe a participatory analysis of the diversity of working relations and roles of designers of IBM's Lotus software products. Designers are an example of a minority discipline - that is, a discipline whose members are often isolated in their work teams among coworkers with different training, backgrounds, and career paths. We explore differences between the practices of designers of Lotus software products and the published reports of design practices in group settings	Design as a minority discipline in a software company: toward requirements for a community of practice	NA:NA	2018
Sean Uberoi Kelly:Christopher Sung:Shelly Farnham	Web sites face difficult challenges in supporting successful communities. In this paper we discuss 2 operating web sites, identically designed but with different and distinct audiences. These sites collect user data from site activity and feed it back to the user community in novel ways. The sites are highly active and growing, and have fostered socially conscious, easily navigable and comprehensible on-line communities with little cost and maintenance. The practice of user data collection and re-purposing we describe works particularly well in highly contextual or information /resource-driven communities. These sites also integrate custom content authoring tools and track their use. The authoring tools were designed to quickly grow a specialized "knowledge base" of content created by users and published to a larger audience. A status system encourages the participation of users to contribute to this knowledge base, while increasing social awareness and responsibility in areas of high user interaction. All user activity, communications, and feedback are tracked. Then data is compiled and re-incorporated into scalable solutions for better navigability, content filtering, and presentation of contents to a larger audience. This practice creates a uniquely high quality of interaction within web communities	Designing for improved social responsibility, user participation and content in on-line communities	NA:NA:NA	2018
Peter Tolmie:James Pycock:Tim Diggins:Allan MacLean:Alain Karsenty	In this paper, we seek to contribute to the Ubiquitous Computing agenda by focusing on one of its earliest, but most difficult, design ambitions - making technology "invisible in use". We draw on field studies of domestic life as this domain is becoming increasingly important for new technologies and challenges many of the assumptions we take for granted in the design of technologies for the workplace. We use some examples of domestic routines to identify a number of insights into what it means for features of activities to be "unremarkable". We conclude by using these insights to critique some of the current emphases in Ubiquitous Computing research, and suggest how we might better understand the HCI issues of what will be required to develop technologies that really are "invisible in use"	Unremarkable computing	NA:NA:NA:NA:NA	2018
David R. McGee:Philip R. Cohen:R. Matthews Wesson:Sheilah Horman	In command posts, officers maintain situational awareness using paper maps, Post-it notes, and hand-written annotations. They do so because paper is robust to failure, it is portable, it offers a flexible means of capturing information, it has ultra-high resolution, and it readily supports face-to-face collaboration. We report herein on an evaluation comparing maps and Post-its with a tangible multimodal system called Rasa. Rasa augments these paper tools with sensors, enabling it to recognize the multimodal language (both written and spoken) that naturally occurs on them. In this study, we found that not only do users prefer Rasa to paper alone, they find it as easy or easier to use than paper tools. Moreover, Rasa introduces no discernible overhead in its operation other than error repair, yet grants the benefits inherent in digital systems. Finally, subjects confirmed that by combining physical and computational tools, Rasa is resistant to computational failure	Comparing paper and tangible, multimodal tools	NA:NA:NA:NA	2018
Victoria Bellotti:Maribeth Back:W. Keith Edwards:Rebecca E. Grinter:Austin Henderson:Cristina Lopes	This paper borrows ideas from social science to inform the design of novel "sensing" user-interfaces for computing technology. Specifically, we present five design challenges inspired by analysis of human-human communication that are mundanely addressed by traditional graphical user interface designs (GUIs). Although classic GUI conventions allow us to finesse these questions, recent research into innovative interaction techniques such as 'Ubiquitous Computing' and 'Tangible Interfaces' has begun to expose the interaction challenges and problems they pose. By making them explicit we open a discourse on how an approach similar to that used by social scientists in studying human-human interaction might inform the design of novel interaction mechanisms that can be used to handle human-computer communication accomplishments	Making sense of sensing systems: five questions for designers and researchers	NA:NA:NA:NA:NA:NA	2018
George Robertson:Kim Cameron:Mary Czerwinski:Daniel Robbins	We describe a new information structure composed of multiple intersecting hierarchies, which we call Polyarchies. Visualizing polyarchies enables use of novel views for discovery of relationships which are very difficult using existing hierarchy visualization tools. This paper will describe the visualization design and system architecture challenges as well as our current solutions. A Mid-Tier Cache architecture is used as a "polyarchy server" which supports a novel web-based polyarchy visualization technique, called Visual Pivot. A series of five user studies guided iterative design of Visual Pivot	Polyarchy visualization: visualizing multiple intersecting hierarchies	NA:NA:NA:NA	2018
Paul M. Aoki:Rebecca E. Grinter:Amy Hurst:Margaret H. Szymanski:James D. Thornton:Allison Woodruff	In addition to providing information to individual visitors, electronic guidebooks have the potential to facilitate social interaction between visitors and their companions. However, many systems impede visitor interaction. By contrast, our electronic guidebook, Sotto Voce, has social interaction as a primary design goal. The system enables visitors to share audio information - specifically, they can hear each other's guidebook activity using a technologically mediated audio eavesdropping mechanism. We conducted a study of visitors using Sotto Voce while touring a historic house. The results indicate that visitors are able to use the system effectively, both as a conversational resource and as an information appliance. More surprisingly, our results suggest that the technologically mediated audio often cohered the visitors' conversation and activity to a far greater degree than audio delivered through the open air	Sotto voce: exploring the interplay of conversation and mobile audio spaces	NA:NA:NA:NA:NA:NA	2018
Alex S. Taylor:Richard Harper	In this paper, we present an overview of the data collected from an ethnographic study of teenagers and their use of mobile phones. Through the data, we suggest that teenagers use their phones to participate in social practices that closely resemble forms of ritualised gift-giving. Such practices, we claim, shape the way teenagers understand and thus use their phones. We go onto show that this insight into everyday, phone-mediated activities has practical implications for mobile phone design. Using an example, we describe how teenagers' gift-giving practices can inform design, providing an initial means to conceptualise future emerging technologies	Age-old practices in the 'new world': a study of gift-giving between teenage mobile phone users	NA:NA	2018
Carlos Jensen:John Davis:Shelly Farnham	In this paper, we examine what types of reputation information users find valuable when selecting someone to interact with in online environments. In an online experiment, we asked users to imagine that they were looking for a partner for a social chat. We found that similarity to the user and ratings from the user's friends were the most valuable pieces of reputation information when selecting chat partners. The context in which reputations were used (social chat, game or newsgroup) affected the self-reported utility of the pieces of reputation information	Finding others online: reputation systems for social online spaces	NA:NA:NA	2018
David Pinelle:Carl Gutwin	Discount usability evaluation methods have recently been introduced as a way to assess groupware systems. However, one criticism of these techniques is that they do not make use of information about users and their work contexts. To address this problem, we developed groupware walkthrough, a new usability inspection technique for groupware. The technique is a substantive modification of cognitive walkthrough to include consideration for the complexities of teamwork. The two components of groupware walkthrough are a task model for identifying and analysing real-world collaborative tasks, and a walkthrough process for assessing a system's support for those tasks. Groupware walkthrough is a low-cost technique that can identify collaboration-specific usability problems and can find problems that would not be revealed through other inspection methods	Groupware walkthrough: adding context to groupware usability evaluation	NA:NA	2018
Marilyn Hughes Blackmon:Peter G. Polson:Muneo Kitajima:Clayton Lewis	This paper proposes a transformation of the Cognitive Walkthrough (CW), a theory-based usability inspection method that has proven useful in designing applications that support use by exploration. The new Cognitive Walkthrough for the Web (CWW) is superior for evaluating how well websites support users' navigation and information search tasks. The CWW uses Latent Semantic Analysis to objectively estimate the degree of semantic similarity (information scent) between representative user goal statements (100-200 words) and heading/link texts on each web page. Using an actual website, the paper shows how the CWW identifies three types of problems in web page designs. Three experiments test CWW predictions of users' success rates in accomplishing goals, verifying the value of CWW for identifying these usability problems	Cognitive walkthrough for the web	NA:NA:NA:NA	2018
Ka-Ping Yee	The small size of handheld computers provides theconvenience of mobility at the expense of reduced screen space for display and interaction. Prior research has identified the value of spatially aware displays, in which a position-tracked display provides a window on a larger virtual workspace. This paper builds on that work by suggesting two-handed interaction techniques combining pen input with spatially aware displays. Enabling simultaneous navigation and manipulation yields the ability to create and edit objects larger than the screen and to drag and drop in 3-D. Four prototypes of the Peephole Display hardware were built, and several Peephole-augmented applications were written, including a drawing program, map viewer, and calendar. Multiple applications can be embedded into a personal information space anchored to the user's physical reference frame. A usability study with 24 participants shows that the Peephole technique can be more effective than current methods for navigating information on handheld computers.	Peephole displays: pen interaction on spatially aware handheld computers	NA	2018
Tom Rodden:Steve Benford	This paper considers how we may realize future ubiquitous domestic environments. Building upon previous work on how buildings evolve by Stewart Brand, we suggest the need to broaden existing considerations of interactive design for domestic environments. We identify a number of classes of research activity and the issues associated with these. We then consider the ways in which current buildings undergo continual change. In doing so we outline the stakeholders involved, the representations used and the way change is managed. We contrast our understanding of how buildings change with research activities before identifying new challenges that will need to be addressed by those involved in designing ubiquitous technologies for domestic environments.	The evolution of buildings and implications for the design of ubiquitous domestic environments	NA:NA	2018
Hilary Hutchinson:Wendy Mackay:Bo Westerlund:Benjamin B. Bederson:Allison Druin:Catherine Plaisant:Michel Beaudouin-Lafon:Stéphane Conversy:Helen Evans:Heiko Hansen:Nicolas Roussel:Björn Eiderbäck	We describe a new method for use in the process of co-designing technologies with users called technology probes. Technology probes are simple, flexible, adaptable technologies with three interdisciplinary goals: the social science goal of understanding the needs and desires of users in a real-world setting, the engineering goal of field-testing the technology, and the design goal of inspiring users and researchers to think about new technologies. We present the results of designing and deploying two technology probes, the messageProbe and the videoProbe, with diverse families in France, Sweden, and the U.S. We conclude with our plans for creating new technologies for and with families based on our experiences.	Technology probes: inspiring design for and with families	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Sri Kurniawan:Alasdair King:David Gareth Evans:Paul Blenkhorn	The paper reports on two development cycles of a joystick-operated full-screen magnifier for visually impaired users. In the first cycle of evaluation, seven visually impaired computer users evaluated the system in comprehension-based sessions using text documents. After considering feedback from these evaluators, a second version of the system was produced and evaluated by a further six visually impaired users. The second evaluation was conducted using information-seeking tasks using Web pages. In both evaluations, the 'thinking aloud protocol' was used. This study makes several contributions to the field. First, it is perhaps the first published study investigating the use of a joystick as an absolute and relative pointing device to control a screen magnifier. Second, the present study revealed that for most of the visually impaired users who participated in the study the joystick had good spatial, cognitive and ergonomic attributes, even for those who had never before used a joystick.	Design and user evaluation of a joystick-operated full-screen magnifier	NA:NA:NA:NA	2018
Julie A. Jacko:Ingrid U. Scott:Francois Sainfort:Leon Barnard:Paula J. Edwards:V. Kathlene Emery:Thitima Kongnakorn:Kevin P. Moloney:Brynley S. Zorich	This study examines the effects of multimodal feedback on the performance of older adults with different visual abilities. Older adults possessing normal vision (n=29) and those who have been diagnosed with Age-Related Macular Degeneration (n=30) performed a series of drag-and-drop tasks under varying forms of feedback. User performance was assessed with measures of feedback exposure times and accuracy. Results indicated that for some cases, non-visual (e.g. auditory or haptic) and multimodal (bi- and trimodal) feedback forms demonstrated significant performance gains over the visual feedback form, for both AMD and normally sighted users. In addition to visual acuity, effects of manual dexterity and computer experience are considered.	Older adults and visual impairment: what do exposure times and accuracy tell us about performance gains associated with multimodal feedback?	NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Faustina Hwang:Simeon Keates:Patrick Langdon:P. John Clarkson	Although a number of studies have reported that force feedback gravity wells can improve performance in "point-and-click" tasks, there have been few studies addressing issues surrounding the use of gravity wells for multiple on-screen targets. This paper investigates the performance of users, both with and without motion-impairments, in a "point-and-click" task when an undesired haptic distractor is present. The importance of distractor location is studied explicitly. Results showed that gravity wells can still improve times and error rates, even on occasions when the cursor is pulled into a distractor. The greatest improvement is seen for the most impaired users. In addition to traditional measures such as time and errors, performance is studied in terms of measures of cursor movement along a path. Two cursor measures, angular distribution and temporal components, are proposed and their ability to explain performance differences is explored.	Multiple haptic targets for motion-impaired computer users	NA:NA:NA:NA	2018
Elaine M. Huang:Elizabeth D. Mynatt	The majority of systems using public displays to foster awareness have focused on providing information across remote locations or among people who are loosely connected and lack awareness of each other's activities or interests. We have, however, identified many potential benefits for an awareness system that displays information within a small, co-located group in which the members already possess some awareness of each other's activities. By using "Semi-Public Displays," public displays scoped for small groups, we can make certain types of information visible in the environment, promoting collaboration and providing lightweight information about group activity. Compared to designing for large, loosely connected groups, designing for Semi-Public Displays mitigates typically problematic issues in sustaining relevant content for the display and minimizing privacy concerns. We are using these applications to support and enhance the interactions and information that group members utilize to maintain awareness and collaborate.	Semi-public displays for small, co-located groups	NA:NA	2018
Tom Rodden:Yvonne Rogers:John Halloran:Ian Taylor	This paper describes the design and deployment of a novel interactional workspace, intended to provide more effective support for face-to-face consultations between two parties. We focus on the initial consultations between customer and agent that take place during the development of complex products. Findings from an ethnographic study of the existing use of technological systems show the interaction during such consultations to be disjointed and not well supported. As an alternative approach, we developed a novel arrangement of multiple displays intended to promote shoulder-to-shoulder collaboration using a variety of interlinked representations and visualizations. The resulting interactional workspace was used by a travel company as part of a large international trade show attended by the general public. The many consultations that took place between agents and customers were quite different, proving to be more equitable, open, fluid and congenial.	Designing novel interactional workspaces to support face to face consultations	NA:NA:NA:NA	2018
Kent O'Hara:Mark Perry:Simon Lewis	Advances in display technology are creating more opportunities for situating displays in our environment. While these displays share some common design principles with display-based interaction at the desktop PC, situated displays also have unique characteristics and values that raise particular design considerations and challenges. In order to further understand situated display design we present a field study of RoomWizard, an interactive room reservation display appliance designed to be mounted outside meeting rooms. The findings illustrate important ways that individual and social behaviours were oriented around the persistent situated displays. These observed behaviours are discussed in relation to particular design characteristics of RoomWizard. We conclude by highlighting more general themes supporting the design of other situated display technologies.	Social coordination around a situated display appliance	NA:NA:NA	2018
Arthur Tang:Charles Owen:Frank Biocca:Weimin Mou	Although there has been much speculation about the potential of Augmented Reality (AR), there are very few empirical studies about its effectiveness. This paper describes an experiment that tested the relative effectiveness of AR instructions in an assembly task. Task information was displayed in user's field of view and registered with the workspace as 3D objects to explicitly demonstrate the exact execution of a procedure step. Three instructional media were compared with the AR system: a printed manual, computer assisted instruction (CAI) using a monitor-based display, and CAI utilizing a head-mounted display. Results indicate that overlaying 3D instructions on the actual work pieces reduced the error rate for an assembly task by 82%, particularly diminishing cumulative errors - errors due to previous assembly mistakes. Measurement of mental effort indicated decreased mental effort in the AR condition, suggesting some of the mental calculation of the assembly task is offloaded to the system.	Comparative effectiveness of augmented reality in object assembly	NA:NA:NA:NA	2018
Yutaka Yamauchi:Jack Whalen:Daniel G. Bobrow	Service technicians in the field often come across difficult service problems that are new to them. They have a large number of resources that they can draw on to deal with such problems, including both people and documents. We have undertaken a detailed study of technicians' everyday work, and have discovered two distinct types of information use, reflecting two different problem-solving practices. The less frequently used problem-solving practice is instruction following, where technicians follow company-documented Repair Analysis Procedures (RAPs). The second, more common practice is gleaning, where the information is gathered from many sources -- including other technicians and informal tips, which are documents written by technicians describing their invented solutions to hard service problems. Our observations show how the informational and interface affordances of the system for accessing the tips support their easy incorporation into the gleaning approach for problem solving in difficult cases. We also recommend ways that RAPs can be augmented to provide affordances for gleaning, and more effective instruction following.	Information use of service technicians in difficult cases	NA:NA:NA	2018
Scott R. Klemmer:Jamey Graham:Gregory J. Wolff:James A. Landay	Our contextual inquiry into the practices of oral historians unearthed a curious incongruity. While oral historians consider interview recordings a central historical artifact, these recordings sit unused after a written transcript is produced. We hypothesized that this is largely because books are more usable than recordings. Therefore, we created Books with Voices: bar-code augmented paper transcripts enabling fast, random access to digital video interviews on a PDA. We present quantitative results of an evaluation of this tangible interface with 13 participants. They found this lightweight, structured access to original recordings to offer substantial benefits with minimal overhead. Oral historians found a level of emotion in the video not available in the printed transcript. The video also helped readers clarify the text and observe nonverbal cues.	Books with voices: paper transcripts as a physical interface to oral histories	NA:NA:NA:NA	2018
Shumin Zhai:Per-Ola Kristensson	We propose a method for computer-based speed writing, SHARK (shorthand aided rapid keyboarding), which augments stylus keyboarding with shorthand gesturing. SHARK defines a shorthand symbol for each word according to its movement pattern on an optimized stylus keyboard. The key principles for the SHARK design include high efficiency stemmed from layout optimization, duality of gesturing and stylus tapping, scale and location independent writing, Zipf's law, and skill transfer from tapping to shorthand writing due to pattern consistency. We developed a SHARK system based on a classic handwriting recognition algorithm. A user study demonstrated the feasibility of the SHARK method.	Shorthand writing on stylus keyboard	NA:NA	2018
Pär-Anders Albinsson:Shumin Zhai	Bare hand pointing on touch screens both benefits and suffers from the nature of direct input. This work explores techniques to overcome its limitations. Our goal is to design interaction tools allowing pixel level pointing in a fast and efficient manner. Based on several cycles of iterative design and testing, we propose two techniques: Cross-Keys that uses discrete taps on virtual keys integrated with a crosshair cursor, and an analog Precision-Handle that uses a leverage (gain) effect to amplify movement precision from the user's finger tip to the end cursor. We conducted a formal experiment with these two techniques, in addition to the previously known Zoom-Pointing and Take-Off as baseline anchors. Both subjective and performance measurements indicate that Precision-Handle and Cross-Keys complement existing techniques for touch screen interaction.	High precision touch screen interaction	NA:NA	2018
R. William Soukoreff:I. Scott MacKenzie	We describe and identify shortcomings in two statistics recently introduced to measure accuracy in text entry evaluations: the minimum string distance (MSD) error rate and keystrokes per character (KSPC). To overcome the weaknesses, a new framework for error analysis is developed and demonstrated. It combines the analysis of the presented text, input stream (keystrokes), and transcribed text. New statistics include a unified total error rate, combining two constituent error rates: the corrected error rate (errors committed but corrected) and the not corrected error rate (errors left in the transcribed text). The framework includes other measures including error correction efficiency, participant conscientiousness, utilised bandwidth, and wasted bandwidth. A text entry study demonstrating the new methodology is described.	Metrics for text entry research: an evaluation of MSD and KSPC, and a new unified error metric	NA:NA	2018
Jens Riegelsberger:M. Angela Sasse:John D. McCarthy	Designing for trust in technology-mediated interaction is an increasing concern in CHI. In advertising, images of people have long been used to create positive attitudes to products or trust in brands. However, the evidence as to whether placing photographs of people on e-commerce web sites has the intended effect has been mixed. This paper reports a study that examined the effect of adding such photographs to 12 existing e-commerce sites, whose reputation had been established through customer ratings. In an experiment with 115 participants, trust was measured using methods that induced financial risk, adapted from experimental economics. Averaging across sites, neither the presence of a photo, nor trustworthiness of the person depicted, had a significant effect. However, the presence of photos reduced participants' ability to identify vendors with good and bad reputations -- the perceived trustworthiness of poorly performing vendors was increased, whereas that of vendors with good reputation was decreased. This result advocates caution when using photos on e-commerce sites to boost trustworthiness, and demonstrates the need for further research into interpersonal cues and on-line trust.	Shiny happy people building trust?: photos on e-commerce websites and consumer trust	NA:NA:NA	2018
Leysia Palen:Paul Dourish	Although privacy is broadly recognized as a dominant concern for the development of novel interactive technologies, our ability to reason analytically about privacy in real settings is limited. A lack of conceptual interpretive frameworks makes it difficult to unpack interrelated privacy issues in settings where information technology is also present. Building on theory developed by social psychologist Irwin Altman, we outline a model of privacy as a dynamic, dialectic process. We discuss three tensions that govern interpersonal privacy management in everyday life, and use these to explore select technology case studies drawn from the research literature. These suggest new ways for thinking about privacy in socio-technical environments as a practical matter.	Unpacking "privacy" for a networked world	NA:NA	2018
Nathaniel S. Good:Aaron Krekelberg	P2P file sharing systems such as Gnutella, Freenet, and KaZaA, while primarily intended for sharing multimedia files, frequently allow other types of information to be shared. This raises serious concerns about the extent to which users may unknowingly be sharing private or personal information.In this paper, we report on a cognitive walkthrough and a laboratory user study of the KaZaA file sharing user interface. The majority of the users in our study were unable to tell what files they were sharing, and sometimes incorrectly assumed they were not sharing any files when in fact they were sharing all files on their hard drive. An analysis of the KaZaA network suggested that a large number of users appeared to be unwittingly sharing personal and private files, and that some users were indeed taking advantage of this and downloading files containing ostensibly private information.	Usability and privacy: a study of Kazaa P2P file-sharing	NA:NA	2018
Benjamin B. Bederson:Bongshin Lee:Robert M. Sherman:Paul S. Herrnson:Richard G. Niemi	With recent troubles in U.S. elections, there has been a nationwide push to update voting systems. Municipalities are investing heavily in electronic voting systems, many of which use a touch screen. These systems offer the promise of faster and more accurate voting, but the current reality is that they are fraught with usability and systemic problems. This paper surveys issues relating to usability of electronic voting systems and reports on a series of studies, including one with 415 voters using new systems that the State of Maryland purchased. Our analysis shows these systems work well, but have several problems, and many voters have concerns about them.	Electronic voting system usability issues	NA:NA:NA:NA:NA	2018
Lynne Coventry:Antonella De Angeli:Graham Johnson	This paper describes some of the consumer-driven usability research conducted by NCR Self Service Strategic Solutions in the development of an understanding of usability and user acceptance of leading-edge biometrics verification techniques. We discuss biometric techniques in general and focus upon the usability phases and issues, associated with iris verification technology at the Automated Teller Machine (ATM) user interface. The paper concludes with a review of some of the major research issues encountered, and an outline of future work in the area.	Usability and biometric verification at the ATM interface	NA:NA:NA	2018
F. Wai-ling Ho-Ching:Jennifer Mankoff:James A. Landay	We developed two visual displays for providing awareness of environmental audio to deaf individuals. Based on fieldwork with deaf and hearing participants, we focused on supporting awareness of non-speech audio sounds such as ringing phones and knocking in a work environment. Unlike past work, our designs support both monitoring and notification of sounds, support discovery of new sounds, and do not require a priori knowledge of sounds to be detected. Our Spectrograph design shows pitch and amplitude, while our Positional Ripples design shows amplitude and location of sounds. A controlled experiment involving deaf participants found neither display to be significantly distracting. However, users preferred the Positional Ripples display and found that display easier to monitor (notification sounds were detected with 90% success in a laboratory setting). The Spectrograph display also supported successful detection in most cases, and was well received when deployed in the field.	Can you see what i hear?: the design and evaluation of a peripheral sound display for the deaf	NA:NA:NA	2018
Jennifer Mankoff:Anind K. Dey:Gary Hsieh:Julie Kientz:Scott Lederer:Morgan Ames	We present a technique for evaluating the usability and effectiveness of ambient displays. Ambient displays are abstract and aesthetic peripheral displays portraying non-critical information on the periphery of a user's attention. Although many innovative displays have been published, little existing work has focused on their evaluation, in part because evaluation of ambient displays is difficult and costly. We adapted a low-cost evaluation technique, heuristic evaluation, for use with ambient displays. With the help of ambient display designers, we defined a modified set of heuristics. We compared the performance of Nielsen's heuristics and our heuristics on two ambient displays. Evaluators using our heuristics found more, severe problems than evaluators using Nielsen's heuristics. Additionally, when using our heuristics, 3-5 evaluators were able to identify 40--60% of known usability issues. This implies that heuristic evaluation is an effective technique for identifying usability issues with ambient displays.	Heuristic evaluation of ambient displays	NA:NA:NA:NA:NA:NA	2018
Shumin Zhai:Stéphane Conversy:Michel Beaudouin-Lafon:Yves Guiard	McGuffin and Balakrishnan (M&B) have recently reported evidence that target expansion during a reaching movement reduces pointing time even if the expansion occurs as late as in the last 10% of the distance to be covered by the cursor. While M&B massed their static and expanding targets in separate blocks of trials, thus making expansion predictable for participants, we replicated their experiment with one new condition in which the target could unpredictably expand, shrink, or stay unchanged. Our results show that target expansion occurring as late as in M&B's experiment enhances pointing performance in the absence of expectation. We discuss these findings in terms of the basic human processes that underlie target-acquisition movements, and we address the implications for user interface design by introducing a revised design for the Mac OS X Dock.	Human on-line response to target expansion	NA:NA:NA:NA	2018
Tovi Grossman:Ravin Balakrishnan:Karan Singh	Current interfaces for manipulating curves typically use a standard point cursor to indirectly adjust curve parameters. We present an interface for far more direct manipulation of curves using a specialized high degree-of-freedom curve input device, called ShapeTape. This device allows us to directly control the shape and position of a virtual curve widget. We describe the design and implementation of a variety of interaction techniques that use this curve widget to create and manipulate other virtual curves in 2D and 3D space. The input device is also used to sense a set of user gestures for invoking commands and tools. The result is an effective alternate user interface for curve manipulation that can be used in 2D and 3D graphics applications.	An interface for creating and manipulating curves using a high degree-of-freedom curve input device	NA:NA:NA	2018
Johnny Accot:Shumin Zhai	We investigate bivariate pointing in light of the recent progress in the modeling of univariate pointing. Unlike previous studies, we focus on the effect of target shape (width and height ratio) on pointing performance, particularly when such a ratio is between 1 and 2. Results showed unequal impact of amplitude and directional constraints, with the former dominating the latter. Investigating models based on the notion of weighted Lp norm, we found that our empirical findings were best captured by an Euclidean model with one free weight. This model significantly outperforms the best model to date.	Refining Fitts' law models for bivariate pointing	NA:NA	2018
Carl Gutwin:Amy Skopik	Fisheye views use distortion to provide both local detail and global context in a single continuous view. However, the distorted presentation can make it more difficult to interact with the data; it is therefore not clear whether fisheye views are good choices for interactive tasks. To investigate this question, we tested the effects of magnification and representation on user performance in a basic pointing activity called steering - where a user moves a pointer along a predefined path in the workspace. We looked specifically at magnified steering, where the entire path does not fit into one view. We tested three types of fisheye at several levels of distortion, and also compared the fisheyes with two non-distorting techniques. We found that increasing distortion did not reduce steering performance, and that the fisheyes were faster than the non-distorting techniques. Our results show that in situations where magnification is required, distortion-oriented views can be effective representations for interactive tasks.	Fisheyes are good for large steering tasks	NA:NA	2018
Desney S. Tan:Mary Czerwinski:George Robertson	Previous research reported interesting gender effects involving specific benefits for females navigating with wider fields of view on large displays. However, it was not clear what was driving the 3D navigation performance gains, and whether or not the effect was more tightly coupled to gender or to spatial abilities. The study we report in this paper replicates and extends previous work, demonstrating that the gender-specific navigation benefits come from the presence of optical flow cues, which are better afforded by wider fields of view on large displays. The study also indicates that the effect may indeed be tied to gender, as opposed to spatial abilities. Together, the findings provide a significant contribution to the HCI community, as we provide strong recommendations for the design and presentation of 3D environments, backed by empirical data. Additionally, these recommendations reliably benefit females, without an accompanying detriment to male navigation performance.	Women go with the (optical) flow	NA:NA:NA	2018
Desney S. Tan:Darren Gergle:Peter Scupelli:Randy Pausch	Large wall-sized displays are becoming prevalent. Although researchers have articulated qualitative benefits of group work on large displays, little work has been done to quantify the benefits for individual users. We ran two studies comparing the performance of users working on a large projected wall display to that of users working on a standard desktop monitor. In these studies, we held the visual angle constant by adjusting the viewing distance to each of the displays. Results from the first study indicate that although there was no significant difference in performance on a reading comprehension task, users performed about 26% better on a spatial orientation task done on the large display. Results from the second study suggest that the large display affords a greater sense of presence, allowing users to treat the spatial task as an egocentric rather than an exocentric rotation. We discuss future work to extend our findings and formulate design principles for computer interfaces and physical workspaces.	With similar visual angles, larger displays improve spatial performance	NA:NA:NA:NA	2018
Daniel Fallman	We argue that HCI has emerged as a design-oriented field of research, directed at large towards innovation, design, and construction of new kinds of information and interaction technology. But the understanding of such an attitude to research in terms of philosophical, theoretical, and methodological underpinnings seems however relatively poor within the field. This paper intends to specifically address what design 'is' and how it is related to HCI. First, three candidate accounts from design theory of what design 'is' are introduced; the conservative, the romantic, and the pragmatic. By examining the role of sketching in design, it is found that the designer becomes involved in a necessary dialogue, from which the design problem and its solution are worked out simultaneously as a closely coupled pair. In conclusion, it is proposed that we need to acknowledge, first, the role of design in HCI conduct, and second, the difference between the knowledge-generating Design-oriented Research and the artifact-generating conduct of Research-oriented Design.	Design-oriented human-computer interaction	NA	2018
William W. Gaver:Jacob Beaver:Steve Benford	Ambiguity is usually considered anathema in Human Computer Interaction. We argue, in contrast, that it is a resource for design that can be used to encourage close personal engagement with systems. We illustrate this with examples from contemporary arts and design practice, and distinguish three broad classes of ambiguity according to where uncertainty is located in the interpretative relationship linking person and artefact. Ambiguity of information finds its source in the artefact itself, ambiguity of context in the sociocultural discourses that are used to interpret it, and ambiguity of relationship in the interpretative and evaluative stance of the individual. For each of these categories, we describe tactics for emphasising ambiguity that may help designers and other practitioners understand and craft its use.	Ambiguity as a resource for design	NA:NA:NA	2018
Kristina Höök:Phoebe Sengers:Gerd Andersson	HCI evaluation methods are useful for improving the design of interactive systems, yet they may be rejected by nontraditional technology disciplines such as media art. We have developed a two-tiered evaluation model that responds to the concerns of interactive artists and have used it to improve the design of an interactive artwork, the Influencing Machine, exploring issues in affective computing. The method was interpretive, focusing on giving the artists a grounded feeling for how the machine was interpreted and their message was communicated. We describe the resulting design of the Influencing Machine and the reactions of users. The study itself is part of the art piece - together these activities achieve the goal of the artists: to provoke our cultural notions of whether a machine can "have emotions".	Sense and sensibility: evaluation and interactive art	NA:NA:NA	2018
Anthony J. Hornof:Tim Halverson	This research investigates the cognitive strategies and eye movements that people use to search for a known item in a hierarchical computer display. Computational cognitive models were built to simulate the visual-perceptual and oculomotor processing required to search hierarchical and nonhierarchical displays. Eye movement data were collected and compared on over a dozen measures with the "a priori" predictions of the models. Though it is well accepted that hierarchical layouts are easier to search than nonhierarchical layouts, the underlying cognitive basis for this design heuristic has not yet been established. This work combines cognitive modeling and eye tracking to explain this and numerous other visual design guidelines. This research also demonstrates the power of cognitive modeling for predicting, explaining, and interpreting eye movement data, and how to use eye tracking data to confirm and disconfirm modeling details.	Cognitive strategies and eye movements for searching hierarchical computer displays	NA:NA	2018
Scott Hudson:James Fogarty:Christopher Atkeson:Daniel Avrahami:Jodi Forlizzi:Sara Kiesler:Johnny Lee:Jie Yang	A person seeking someone else's attention is normally able to quickly assess how interruptible they are. This assessment allows for behavior we perceive as natural, socially appropriate, or simply polite. On the other hand, today's computer systems are almost entirely oblivious to the human world they operate in, and typically have no way to take into account the interruptibility of the user. This paper presents a Wizard of Oz study exploring whether, and how, robust sensor-based predictions of interruptibility might be constructed, which sensors might be most useful to such predictions, and how simple such sensors might be.The study simulates a range of possible sensors through human coding of audio and video recordings. Experience sampling is used to simultaneously collect randomly distributed self-reports of interruptibility. Based on these simulated sensors, we construct statistical models predicting human interruptibility and compare their predictions with the collected self-report data. The results of these models, although covering a demographically limited sample, are very promising, with the overall accuracy of several models reaching about 78%. Additionally, a model tuned to avoiding unwanted interruptions does so for 90% of its predictions, while retaining 75% overall accuracy.	Predicting human interruptibility with sensors: a Wizard of Oz feasibility study	NA:NA:NA:NA:NA:NA:NA:NA	2018
Dario D. Salvucci:Frank J. Lee	Cognitive modeling has evolved into a powerful tool for understanding and predicting user behavior. Higher-level modeling frameworks such as GOMS and its variants facilitate fast and easy model development but are sometimes limited in their ability to model detailed user behavior. Lower-level cognitive architectures such as EPIC, ACT-R, and Soar allow for greater precision and direct interaction with real-world systems but require significant modeling training and expertise. In this paper we present a modeling framework, ACT-Simple, that aims to combine the advantages of both approaches to cognitive modeling. ACT-Simple embodies a "compilation" approach in which a simple description language is compiled down to a core lower-level architecture (namely ACT-R). We present theoretical justification and empirical validation of the usefulness of the approach and framework.	Simple cognitive modeling in a complex cognitive architecture	NA:NA	2018
Batya Friedman:Peter H. Kahn, Jr.:Jennifer Hagman	In this study, we investigated people's relationships with AIBO, a robotic pet, through 6,438 spontaneous postings in online AIBO discussion forums. Results showed that AIBO psychologically engaged this group of participants, particularly by drawing forth conceptions of technological essences (75%), life-like essences (49%), mental states (60%), and social rapport (59%). However, participants seldom attributed moral standing to AIBO (e.g., that AIBO deserves respect, has rights, or can be held morally accountable for action). Our discussion focuses on how robotic pets (now and in the future) may (a) challenge traditional boundaries (e.g. between who or what can possess feelings), (b) extend our conceptions of self, companionship, and community, and (c) begin to replace interactions with live pets. We also discuss a concern that people in general, and children in particular, may fall prey to accepting robotic pets without the moral responsibilities (and moral developmental outcomes) that real, reciprocal companionship and cooperation involves. This research contributes to a growing literature on the human-robotic relationship.	Hardware companions?: what online AIBO discussion forums reveal about the human-robotic relationship	NA:NA:NA	2018
Nicole Shechtman:Leonard M. Horowitz	How is interacting with computer programs different from interacting with people? One answer in the literature is that these two types of interactions are similar. The present study challenges this perspective with a laboratory experiment grounded in the principles of Interpersonal Theory, a psychological approach to interpersonal dynamics. Participants had a text-based, structured conversation with a computer that gave scripted conversational responses. The main manipulation was whether participants were told that they were interacting with a computer program or a person in the room next door. Discourse analyses revealed a key difference in participants' behavior -- when participants believed they were talking to a person, they showed many more of the kinds of behaviors associated with establishing the interpersonal nature of a relationship. This finding has important implications for the design of technologies intended to take on social roles or characteristics.	Media inequality in conversation: how people behave differently when interacting with computers and people	NA:NA	2018
Kwan Min Lee:Clifford Nass	This study examines the interaction effect between user factors and media factors on feelings of social presence which are critical in the design of virtual reality systems and human computer interfaces. Both Experiment 1 and Experiment 2 show that matching synthesized voice personality to user personality positively affects users' (especially extrovert users') feelings of social presence. Experiment 2 also reveals that users feel a stronger sense of social presence when the personality of synthesized voice matches the personality of textual content than when those two are mismatched. In both experiments, extrovert voice induces a stronger sense of presence than introvert voice. These results provide strong evidence for human's automatic social responses to artificial representations possessing humanistic properties such as language and personality. Finally, we discuss various applications of these findings in the design of human computer interfaces, as well as in the study of presence.	Designing social presence of social actors in human computer interaction	NA:NA	2018
W. Keith Edwards:Victoria Bellotti:Anind K. Dey:Mark W. Newman	Infrastructure software comprises code libraries or runtime processes that support the development or operation of application software. A particular infrastructure system may support certain styles of application, and may even determine the features of applications built using it. This poses a challenge: although we have good techniques for designing and evaluating interactive applications, our techniques for designing and evaluating infrastructure intended to support these applications are much less well formed. In this paper, we reflect on case studies of two infrastructure systems for interactive applications. We look at how traditional user-centered techniques, while appropriate for application design and evaluation, fail to properly support infrastructure design and evaluation. We present a set of lessons from our experience, and conclude with suggestions for better user-centered design and evaluation of infrastructure software.	The challenges of user-centered design and evaluation for infrastructure	NA:NA:NA:NA	2018
Aaron Wilson:Margaret Burnett:Laura Beckwith:Orion Granatir:Ledah Casburn:Curtis Cook:Mike Durham:Gregg Rothermel	Despite their ability to help with program correctness, assertions have been notoriously unpopular--even with professional programmers. End-user programmers seem even less likely to appreciate the value of assertions; yet end-user programs suffer from serious correctness problems that assertions could help detect. This leads to the following question: can end users be enticed to enter assertions? To investigate this question, we have devised a curiosity-centered approach to eliciting assertions from end users, built on a surprise-explain-reward strategy. Our follow-up work with end-user participants shows that the approach is effective in encouraging end users to enter assertions that help them find errors.	Harnessing curiosity to increase correctness in end-user programming	NA:NA:NA:NA:NA:NA:NA:NA	2018
Brian P. Bailey:Joseph A. Konstan	DEMAIS is an informal design tool that we claim helps a multimedia designer explore and communicate temporal and interactive (behavioral) design ideas better than existing tools. This paper seeks to empirically validate our claim. We report on an evaluation comparing DEMAIS to pencil and paper and Authorware for the exploration and communication of behavior in early multimedia design. The main results are that (i) DEMAIS was better than Authorware for both exploring and communicating behavior, (ii) DEMAIS was better than pencil and paper for communicating behavior, and (iii) DEMAIS was able to capture most of a designer's behavioral design ideas. Our results show that DEMAIS bridges the early investment/communication gap that exists among current multimedia design tools.	Are informal tools better?: comparing DEMAIS, pencil and paper, and authorware for early multimedia design	NA:NA	2018
Kathleen Luchini:Chris Quintana:Elliot Soloway	Our project explores the benefits and challenges of using handheld computers to support learners in creating concept maps (a type of visual outline). By synthesizing research on small user interfaces with guidelines for building desktop learning tools, we identified potential challenges to using handhelds for complex learning tasks and developed new design guidelines to address these issues. We applied these guidelines to the design of Pocket PiCoMap, a learner-centered concept mapping tool for handheld Pocket PCs. As part of a 9-month classroom study, students used both the handheld Pocket PiCoMap and a comparable desktop concept mapping tool called PiViT. The goal of this comparison between handheld and desktop tools was to better understand how the different form factors of these computers impact students' work processes and products. Our results suggest that students can successfully complete complex learning activities using handheld tools, and that specialized supports (called scaffolds) can be used to help students create better concept maps. This study also identifies several areas where handheld learning tools need further improvements, such as helping students organize their work within the confines of small handheld screens, and we discuss ways in which scaffolds might be used to improve future handheld learning tools.	Pocket PiCoMap: a case study in designing and assessing a handheld concept mapping tool for learners	NA:NA:NA	2018
Anne Kaikkonen:Virpi Roto	The Internet has been a great success in the fixed world, whereas WAP (Wireless Application Protocol), the mobile Internet, has not fulfilled its promise. However, now the analysts have started to believe in a rise of the mobile Internet again. WAP 2.0, with XHTML Mobile Profile as its standard language, will enable sites to function both in the fixed and wireless worlds. In this paper, we analyze different ways to navigate XHTML sites with mobile phones and base our analysis on two usability evaluations with a total of 30 subjects from various countries. The results show that due to limitations of mobile devices (the limited display size, pointing methods, and bandwidth), not all navigation guidelines of the fixed Internet are applicable to the mobile Internet. It is important for developers to realize the effect of these limitations in order to build usable XHTML sites also for mobile use.	Navigating in a mobile XHTML application	NA:NA	2018
Erica Newcomb:Toni Pashley:John Stasko	Although PDAs typically run applications in a "stand-alone" mode, they are increasingly equipped with wireless communications, which makes them useful in new domains. This capability for more powerful information exchange with larger information systems presents a new situated context for PDA applications, and provides new design and usability evaluation challenges.In this work we examine how grocery shopping could be aided by a mobile shopping application that consumers access via a PDA while in a store. The interactive relationship between the physical space of the store and the human activity of shopping are crucial when designing for this application. To better understand this interaction, we studied people's grocery shopping habits, designed and evaluated prototypes, and performed usability tests within the shopping environment. This paper reveals our design process for this problem and a framework for designing and evaluating situated applications for mobile handhelds.	Mobile computing in the retail arena	NA:NA:NA	2018
Victoria Bellotti:Nicolas Ducheneaut:Mark Howard:Ian Smith	Email has come to play a central role in task management, yet email tool features have remained relatively static in recent years, lagging behind users? evolving practices. The Taskmaster system narrows this gap by recasting email as task management and embedding task-centric resources directly in the client. In this paper, we describe the field research that inspired Taskmaster and the principles behind its design. We then describe how user studies conducted with ?live? email data over a two-week period revealed the value of a task-centric approach to email system design and its potential benefits for overloaded users.	Taking email to task: the design and evaluation of a task management centered email tool	NA:NA:NA:NA	2018
Victor Kaptelinin	Virtual environments based on the desktop metaphor provide limited support for creating and managing project-specific work contexts. The paper discusses existing approaches to supporting higher-level user activities and presents a system named UMEA (User-Monitoring Environment for Activities). The design of the system is informed by activity theory. The system: (a) organizes resources into project-related pools consisting of documents, folders, URLs, and contacts, (b) monitors user activities, (c) automatically adds new resources to pools associated with active projects, and (d) provides personal information management tools linked to individual projects. An empirical evaluation of the system is reported.	UMEA: translating interaction histories into project contexts	NA	2018
Gina Danielle Venolia:Carman Neustaedter	It has been proposed that email clients could be improved if they presented messages grouped into conversations. An email conversation is the tree of related messages that arises from the use of the reply operation. We propose two models of conversation. The first model characterizes a conversation as a chronological sequence of messages; the second as a tree based on the reply relationship. We show how existing email clients and prior research projects implicitly support each model to a greater or lesser degree depending on their design, but none fully supports both models simultaneously. We present a mixed-model visualization that simultaneously presents sequence and reply relationships among the messages of a conversation, making both visible at a glance. We describe the integration of the visualization into a working prototype email client. A usability study indicates that the system meets our usability goals and verifies that the visualization fully conveys both types of relationships within the messages of an email conversation.	Understanding sequence and reply relationships within email conversations: a mixed-model visualization	NA:NA	2018
George W. Furnas:Yan Qu	This paper introduces new interactive ways to create, manipulate and analyze shapes, even when those shapes do not have simple algebraic generators. This is made possible by using pixel-pattern rewrites to compute directly with bitmap representations. Such rewrites also permit the definition of functionality maps, bitmaps that specify the spatial scope of application functionality, and organic-widgets, implemented right in the pixels to have arbitrary form, integrated with the shape needs of the applications. Together these features should increase our capabilities for working with rich spatial domains.	Using pixel rewrites for shape-rich interaction	NA:NA	2018
Jodi Forlizzi:Johnny Lee:Scott Hudson	Kinetic (dynamic) typography has demonstrated the ability to add significant emotive content and appeal to expressive text, allowing some of the qualities normally found in film and the spoken word to be added to static text. Kinetic typography has been widely and successfully used in film title sequences as well as television and computer-based advertising. However, its communicative abilities have not been widely studied, and its potential has rarely been exploited outside these areas. This is partly due to the difficulty in creating kinetic typography with current tools, often requiring hours of work to animate a single sentence.In this paper, we present the Kinedit system, a basic authoring tool that takes initial steps toward remedying this situation and hence promoting exploration of the communicative potential of kinetic typography for personal communication. Kinedit is informed by systematic study and characterization of a corpus of examples, and iterative involvement and validation by designers throughout the development process. We describe the tool and its underlying technology, usage experiences, lessons learned, and next steps.	The kinedit system: affective messages using dynamic texts	NA:NA:NA	2018
David Bargeron:Tomer Moscovich	Annotating paper documents with a pen is a familiar and indispensable activity across a wide variety of work and educational settings. Recent developments in pen-based computing promise to bring this experience to digital documents. However, digital documents are more flexible than their paper counterparts. When a digital document is edited, or displayed on different devices, its layout adapts to the new situation. Freeform digital ink annotations made on such a document must likewise adapt, or "reflow." But their unconstrained nature yields only vague guidelines for how these annotations should be transformed. Few systems have considered this issue, and still fewer have addressed it from a user's point of view. This paper reports the results of a study of user expectations for reflowing digital ink annotations. We explore user reaction to reflow in common cases, how sensitive users are to reflow errors, and how important it is that personal style survive reflow. Our findings can help designers and system builders support freeform annotation more effectively.	Reflowing digital ink annotations	NA:NA	2018
Suresh K. Bhavnani:Bichakjian K. Christopher:Timothy M. Johnson:Roderick J. Little:Frederick A. Peck:Jennifer L. Schwartz:Victor J. Strecher	Current search tools on the Web, such as general-purpose search engines (e.g. Google) and domain-specific portals (e.g. MEDLINEplus), do not provide search procedures that guide users to form appropriately ordered sub-goals. The lack of such procedural knowledge often leads users searching in unfamiliar domains to retrieve incomplete information. In critical domains such as in healthcare, such ineffective searches can have dangerous consequences. To address this situation, we developed a new type of domain portal called a Strategy Hub. Strategy Hubs provide the critical search procedures and associated high-quality links that enable users to find comprehensive and accurate information. This paper describes how we collaborated with skin cancer physicians to systematically identify generalizeable search procedures to find comprehensive information about melanoma, and how these search procedures were made available through the Strategy Hub for healthcare. A pilot study suggests that this approach can improve the efficacy, efficiency, and satisfaction of even expert searchers. We conclude with insights on how to refine the design of the Strategy Hub, and how it can be used to provide search procedures across domains.	Strategy hubs: next-generation domain portals with search procedures	NA:NA:NA:NA:NA:NA:NA	2018
Ka-Ping Yee:Kirsten Swearingen:Kevin Li:Marti Hearst	There are currently two dominant interface types for searching and browsing large image collections: keyword-based search, and searching by overall similarity to sample images. We present an alternative based on enabling users to navigate along conceptual dimensions that describe the images. The interface makes use of hierarchical faceted metadata and dynamically generated query previews. A usability study, in which 32 art history students explored a collection of 35,000 fine arts images, compares this approach to a standard image search interface. Despite the unfamiliarity and power of the interface (attributes that often lead to rejection of new search interfaces), the study results show that 90% of the participants preferred the metadata approach overall, 97% said that it helped them learn more about the collection, 75% found it more flexible, and 72% found it easier to use than a standard baseline system. These results indicate that a category-based approach is a successful way to provide access to image collections.	Faceted metadata for image search and browsing	NA:NA:NA:NA	2018
Kerry Rodden:Kenneth R. Wood	In this paper we present and discuss the findings of a study that investigated how people manage their collections of digital photographs. The six-month, 13-participant study included interviews, questionnaires, and analysis of usage statistics gathered from an instrumented digital photograph management tool called Shoebox. Alongside simple browsing features such as folders, thumbnails and timelines, Shoebox has some advanced multimedia features: content-based image retrieval and speech recognition applied to voice annotations. Our results suggest that participants found their digital photos much easier to manage than their non-digital ones, but that this advantage was almost entirely due to the simple browsing features. The advanced features were not used very often and their perceived utility was low. These results should help to inform the design of improved tools for managing personal digital photographs.	How do people manage their digital photographs?	NA:NA	2018
Yoshifumi Kitamura:Yoshihisa Yamaguchi:Imamizu Hiroshi:Fumio Kishino:Mitsuo Kawato	In this paper, we propose a new technique based on recent neuroimaging studies as a tool for the assessment of interactive systems. For this purpose, we analyze the mental process that takes place while human subjects learn to use new tools by using two different approaches. One is an experiment on task performance based on the conventional direct testing method of a user interface, and the other is an indirect method based on recent neuroimaging studies that indirectly estimate the process of interaction through the observation of the human brain activities. The results obtained from the direct experiment on performance evaluation are compared with those from the indirect analysis of the human brain activity, which is measured by a non-invasive neuroimaging measuring method. The process of acquisition of internal models while subjects learn to use new tools is also discussed.	Things happening in the brain while humans learn to use new tools	NA:NA:NA:NA:NA	2018
Paul M. Aoki:Matthew Romaine:Margaret H. Szymanski:James D. Thornton:Daniel Wilson:Allison Woodruff	This paper presents a mobile audio space intended for use by gelled social groups. In face-to-face interactions in such social groups, conversational floors change frequently, e.g., two participants split off to form a new conversational floor, a participant moves from one conversational floor to another, etc. To date, audio spaces have provided little support for such dynamic regroupings of participants, either requiring that the participants explicitly specify with whom they wish to talk or simply presenting all participants as though they are in a single floor. By contrast, the audio space described here monitors participant behavior to identify conversational floors as they emerge. The system dynamically modifies the audio delivered to each participant to enhance the salience of the participants with whom they are currently conversing. We report a user study of the system, focusing on conversation analytic results.	The mad hatter's cocktail party: a social mobile audio space supporting multiple simultaneous conversations	NA:NA:NA:NA:NA:NA	2018
Sara Berg:Alex S. Taylor:Richard Harper	In this paper, we demonstrate how ethnographic fieldwork studies can be used to inform the design of third generation mobile phones. We draw on a field study of teenage mobile phone users and, specifically, their participation in gift-giving practices to design the user interface and form of a concept mobile phone. The concept device is designed to support teenagers' social practices through a novel multimedia messaging system and the augmentation of the phone's address book. We report on the process adopted to design the concept and briefly describe preliminary reactions from potential users. To conclude the paper, we comment on the lessons we have learnt in applying ethnographic findings to design.	Mobile phones for the next generation: device designs for teenagers	NA:NA:NA	2018
Rebecca Grinter:Margery Eldridge	Texting--using a mobile phone to send text messages--has become a form of mass communication. Building on studies that described how British teenagers have incorporated text messaging into their lives, we examine the purposes and nature of the conversations themselves. We also present findings that suggest that teenagers do not have many simultaneous multiple conversations via text messaging; end most text messaging conversations by switching to another medium; and, that, despite popular beliefs, communicate with surprisingly few friends via their mobile phones. Finally we describe how and what words they shorten in their text messages.	Wan2tlk?: everyday text messaging	NA:NA	2018
Jerry Fails:Dan Olsen	Cameras provide an appealing new input medium for interaction. The creation of camera-based interfaces is outside the skill-set of most programmers and completely beyond the skills of most interface designers. Image Processing with Crayons is a tool for creating new camera-based interfaces using a simple painting metaphor. A transparent layers model is used to present the designer with all of the necessary information. Traditional machine learning algorithms have been modified to accommodate the rapid response time required of an interactive design tool.	A design tool for camera-based interaction	NA:NA	2018
Yong Rui:Anoop Gupta:Jonathan Grudin	Our goal is to help automate the capture and broadcast of lectures to remote audiences. There are two inter-related components to the design of such systems. The technology component includes the hardware (e.g., video cameras) and associated software (e.g., speaker-tracking). The aesthetic component embodies the rules and idioms that human videographers follow to make a video visually engaging. We present a lecture room automation system and a substantial number of new video-production rules obtained from professional videographers who critiqued it. We also describe rules for a variety of lecture room environments differing in the numbers and types of cameras. We further discuss gaps between what professional videographers do and what is technologically feasible today.	Videography for telepresentations	NA:NA:NA	2018
Milton Chen	Audio is presented ahead of video in some videoconferencing systems since audio requires less time to process. Audio could be delayed to synchronize with video to achieve lip synchronization; however, the overall audio latency might then become unacceptable. We built a videoconferencing system to achieve lip synchronization with minimal perceived audio latency. Instead of adding a fixed audio delay, our system time-stretches the audio at the beginning of each utterance until the audio is synchronized with the video. We conducted user studies and found that (1) audio could lead video by roughly 50 msec and still be perceived as synchronized; (2) audio could lead video by 300 msec and still be perceived as synchronized if the audio was time-stretched to synchronization within a short period; and (3) our algorithm appears to strike a favorable balance between minimizing audio latency and supporting lip synchronization.	A low-latency lip-synchronized videoconferencing system	NA	2018
Stephen Brewster:Joanna Lumsden:Marek Bell:Malcolm Hall:Stuart Tasker	Mobile and wearable computers present input/output prob-lems due to limited screen space and interaction techniques. When mobile, users typically focus their visual attention on navigating their environment - making visually demanding interface designs hard to operate. This paper presents two multimodal interaction techniques designed to overcome these problems and allow truly mobile, 'eyes-free' device use. The first is a 3D audio radial pie menu that uses head gestures for selecting items. An evaluation of a range of different audio designs showed that egocentric sounds re-duced task completion time, perceived annoyance, and al-lowed users to walk closer to their preferred walking speed. The second is a sonically enhanced 2D gesture recognition system for use on a belt-mounted PDA. An evaluation of the system with and without audio feedback showed users' ges-tures were more accurate when dynamically guided by au-dio-feedback. These novel interaction techniques demon-strate effective alternatives to visual-centric interface de-signs on mobile devices.	Multimodal 'eyes-free' interaction techniques for wearable devices	NA:NA:NA:NA:NA	2018
Patrick Baudisch:Ruth Rosenholtz	As users pan and zoom, display content can disappear into off-screen space, particularly on small-screen devices. The clipping of locations, such as relevant places on a map, can make spatial cognition tasks harder. Halo is a visualization technique that supports spatial cognition by showing users the location of off-screen objects. Halo accomplishes this by surrounding off-screen objects with rings that are just large enough to reach into the border region of the display window. From the portion of the ring that is visible on-screen, users can infer the off-screen location of the object at the center of the ring. We report the results of a user study comparing Halo with an arrow-based visualization technique with respect to four types of map-based route planning tasks. When using the Halo interface, users completed tasks 16-33% faster, while there were no significant differences in error rate for three out of four tasks in our study.	Halo: a technique for visualizing off-screen objects	NA:NA	2018
Betsy Beier:Misha W. Vaughan	A multi-leveled framework for user interface design guidelines of Web applications is presented. User interface design guidelines tend to provide information that is either too general, so that it is difficult to apply to a specific case, or too specific, so that a wide range of products is not supported. The framework presented is unique in that it provides a bridge between the two extremes. It has been dubbed the 'Bull's-Eye' due to its five layers, represented as concentric circles. The center of the Bull's-Eye is the Component layer, followed by Page Templates, Page Flows, Interface Models and Patterns, and Overarching Features and Principles. To support this approach, requirements were gathered from user interface designers, product managers, UI developers, and product developers. Also, usability testing of the guidelines occurred on several levels, from broad guideline tests to more specific product tests. The guidelines and lessons learned are intended to serve as examples for others seeking to design families of Web applications or Web sites.	The bull's-eye: a framework for web application user interface design guidelines	NA:NA	2018
Marilyn Hughes Blackmon:Muneo Kitajima:Peter G. Polson	Methods for identifying usability problems in web page designs should ideally also provide practical methods for repairing the problems found. Blackmon et al. [2] proved the usefulness of the Cognitive Walkthrough for the Web (CWW) for identifying three types of problems that interfere with users' navigation and information search tasks. Extending that work, this paper reports a series of two experiments that develop and prove the effectiveness of both full-scale and quick-fix CWW repair methods. CWW repairs, like CWW problem identification, use Latent Semantic Analysis (LSA) to objectively estimate the degree of semantic similarity (information scent) between representative user goal statements (100-200 words) and heading/link texts on each web page. In addition to proving the effectiveness of CWW repairs, the experiments reported here replicate CWW predictions that users will face serious difficulties if web developers fail to repair the usability problems that CWW identifies in web page designs [2].	Repairing usability problems identified by the cognitive walkthrough for the web	NA:NA:NA	2018
Ed H. Chi:Adam Rosien:Gesara Supattanasiri:Amanda Williams:Christiaan Royer:Celia Chow:Erica Robles:Brinda Dalal:Julie Chen:Steve Cousins	According to usability experts, the top user issue for Web sites is difficult navigation. We have been developing auto-mated usability tools for several years, and here we describe a prototype service called InfoScent™ Bloodhound Simula-tor, a push-button navigation analysis system, which auto-matically analyzes the information cues on a Web site to produce a usability report. We further build upon previous algorithms to create a method called Information Scent Absorption Rate, which measures the navigability of a site by computing the probability of users reaching the desired destinations on the site. Lastly, we present a user study involving 244 subjects over 1385 user sessions that show how Bloodhound correlates with real users surfing for in-formation on four Web sites. The hope is that, by using a simulation of user surfing behavior, we can reduce the need for human labor during usability testing, thus dramatically lower testing costs, and ultimately improving user experience. The Bloodhound Project is unique in that we apply a concrete HCI theory directly to a real-world prob-lem. The lack of empirically validated HCI theoretical model has plagued the development of our field, and this is a step toward that direction.	The bloodhound project: automating discovery of web usability issues using the InfoScentπ simulator	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Susan R. Fussell:Leslie D. Setlock:Robert E. Kraut	This study assessed the value of two video configurations-a head-mounted camera with eye tracking capability and a scene camera providing a view of the work environment-on remote collaboration on physical (3D) tasks. Pairs of participants performed five robot construction tasks in five media conditions: side-by-side, audio-only, head-mounted camera, scene camera, and scene plus head cameras. Task completion times were shortest in the side-by-side condition, and shorter with the scene camera than in the audio-only condition. Participants rated their work quality highest when side-by-side, intermediate with the scene camera, and worst in the audio-only and head-camera conditions. Similarly, helpers' self-rated ability to assist workers and pairs' communication efficiency were highest in the side-by-side condition, but significantly higher with the scene camera than in the audio-only condition. The results demonstrate the value of a shared view of the work environment for remote collaboration on physical tasks.	Effects of head-mounted and scene-oriented video systems on remote collaboration on physical tasks	NA:NA:NA	2018
Roel Vertegaal:Ivo Weevers:Changuk Sohn:Chris Cheung	GAZE-2 is a novel group video conferencing system that uses eye-controlled camera direction to ensure parallax-free transmission of eye contact. To convey eye contact, GAZE-2 employs a video tunnel that allows placement of cameras behind participant images on the screen. To avoid parallax, GAZE-2 automatically directs the cameras in this video tunnel using an eye tracker, selecting a single camera closest to where the user is looking for broadcast. Images of users are displayed in a virtual meeting room, and rotated towards the participant each user looks at. This way, eye contact can be conveyed to any number of users with only a single video stream per user. We empirically evaluated whether eye contact perception is affected by automated camera direction, which causes angular shifts in the transmitted images. Findings suggest camera shifts do not affect eye contact perception, and are not considered highly distractive.	GAZE-2: conveying eye contact in group video conferencing using eye-controlled camera direction	NA:NA:NA:NA	2018
Maia Garau:Mel Slater:Vinoba Vinayagamoorthy:Andrea Brogni:Anthony Steed:M. Angela Sasse	This paper presents an experiment designed to investigate the impact of scommunication in an immersive virtual environment.Participants were paired by gender and were randomly assigned to a CAVE-like system or a head-mounted display. Both were represented by a humanoid avatar in the shared 3D environment. The visual appearance of the avatars was either basic and genderless (like a "match-stick" figure), or more photorealistic and gender-specific. Similarly, eye gaze behavior was either random or inferred from voice, to reflect different levels of behavioral realism.Our comparative analysis of 48 post-experiment questionnaires confirms earlier findings from non-immersive studies using semi-photorealistic avatars, where inferred gaze significantly outperformed random gaze. However responses to the lower-realism avatar are adversely affected by inferred gaze, revealing a significant interaction effect between appearance and behavior. We discuss the importance of aligning visual and behavioral realism for increased avatar effectiveness.	The impact of avatar realism and eye gaze control on perceived quality of communication in a shared immersive virtual environment	NA:NA:NA:NA:NA:NA	2018
Rafael Ballagas:Meredith Ringel:Maureen Stone:Jan Borchers	The iStuff toolkit of physical devices, and the flexible software infrastructure to support it, were designed to simplify the exploration of novel interaction techniques in the post-desktop era of multiple users, devices, systems and applications collaborating in an interactive environment. The toolkit leverages an existing interactive workspace in-frastructure, making it lightweight and platform independent. The supporting software framework includes a dynamically configurable intermediary to simplify the mapping of devices to applications. We describe the iStuff architecture and provide several examples of iStuff, organized into a design space of ubiquitous computing interaction components. The main contribution is a physical toolkit for distributed, heterogeneous environments with run-time retargetable device data flow. We conclude with some insights and experiences derived from using this toolkit and framework to prototype experimental interaction techniques for ubiquitous computing environments.	iStuff: a physical user interface toolkit for ubiquitous computing environments	NA:NA:NA:NA	2018
Andrew Wilson:Steven Shafer	The XWand is a novel wireless sensor package that enables styles of natural interaction with intelligent environments. For example, a user may point the wand at a device and control it using simple gestures. The XWand system leverages the intelligence of the environment to best determine the user's intention. We detail the hardware device, signal processing algorithms to recover position and orientation, gesture recognition techniques, a multimodal (wand and speech) computational architecture and a preliminary user study examining pointing performance under conditions of tracking availability and audio feedback.	XWand: UI for intelligent spaces	NA:NA	2018
Katherine M. Everitt:Scott R. Klemmer:Robert Lee:James A. Landay	A tension exists between designers' comfort with physical artifacts and the need for effective remote collaboration: physical objects live in one place. Previous research and technologies to support remote collaboration have focused on shared electronic media. Current technologies force distributed teams to choose between the physical tools they prefer and the electronic communication mechanisms available. We present Distributed Designers' Outpost, a remote collaboration system based on The Designers' Outpost, a collaborative web site design tool that employs physical Post-it notes as interaction primitives. We extended the system for synchronous remote collaboration and introduced two awareness mechanisms: transient ink input for gestures and a blue shadow of the remote collaborator for presence. We informally evaluated this system with six professional designers. Designers were excited by the prospect of physical remote collaboration but found some coordination challenges in the interaction with shared artifacts.	Two worlds apart: bridging the gap between physical and virtual media for distributed design collaboration	NA:NA:NA:NA	2018
Florian Mueller:Stefan Agamanolis:Rosalind Picard	An Exertion Interface is an interface that deliberately requires intense physical effort. Exertion Interfaces have applications in "Sports over a Distance", potentially capitalizing on the power of traditional physical sports in supporting social bonding. We designed, developed, and evaluated an Exertion Interface that allows people who are miles apart to play a physically exhausting ball game together. Players interact through a life-size video-conference screen using a regular soccer ball as an input device. The Exertion Interface users said that they got to know the other player better, had more fun, became better friends, and were happier with the transmitted audio and video quality, in comparison to those who played the same game using a non-exertion keyboard interface. These results suggest that an Exertion Interface, as compared to a traditional interface, offers increased opportunities for connecting people socially, especially when they have never met before.	Exertion interfaces: sports over a distance for social bonding and fun	NA:NA:NA	2018
Martin Flintham:Steve Benford:Rob Anastasi:Terry Hemmings:Andy Crabtree:Chris Greenhalgh:Nick Tandavanitj:Matt Adams:Ju Row-Farr	We describe two games in which online participants collaborated with mobile participants on the city streets. In the first, the players were online and professional performers were on the streets. The second reversed this relationship. Analysis of these experiences yields new insights into the nature of context. We show how context is more socially than technically constructed. We show how players exploited (and resolved conflicts between) multiple indications of context including GPS, GPS error, audio talk, ambient audio, timing, local knowledge and trust. We recommend not overly relying on GPS, extensively using audio, and extending interfaces to represent GPS error.	Where on-line meets on the streets: experiences with mobile mixed reality games	NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Barry Brown:Ian MacColl:Matthew Chalmers:Areti Galani:Cliff Randell:Anthony Steed	Museums attract increasing numbers of online visitors along with their conventional physical visitors. This paper presents a study of a mixed reality system that allows web, virtual reality and physical visitors to share a museum visit together in real time. Our system allows visitors to share their location and orientation, communicate over a voice channel, and jointly navigate around a shared information space. Results from a study of 34 users of the system show that visiting with the system was highly interactive and retained many of the attractions of a traditional shared exhibition visit. Specifically, users could navigate together, collaborate around objects and discuss exhibits. These findings have implications for non-museum settings, in particular how location awareness is a powerful resource for collaboration, and how 'hybrid objects' can support collaboration at-a-distance.	Lessons from the lighthouse: collaboration in a shared mixed reality system	NA:NA:NA:NA:NA:NA	2018
Dan Cosley:Shyong K. Lam:Istvan Albert:Joseph A. Konstan:John Riedl	Recommender systems use people's opinions about items in an information domain to help people choose other items. These systems have succeeded in domains as diverse as movies, news articles, Web pages, and wines. The psychological literature on conformity suggests that in the course of helping people make choices, these systems probably affect users' opinions of the items. If opinions are influenced by recommendations, they might be less valuable for making recommendations for other users. Further, manipulators who seek to make the system generate artificially high or low recommendations might benefit if their efforts influence users to change the opinions they contribute to the recommender. We study two aspects of recommender system interfaces that may affect users' opinions: the rating scale and the display of predictions at the time users rate items. We find that users rate fairly consistently across rating scales. Users can be manipulated, though, tending to rate toward the prediction the system shows, whether the prediction is accurate or not. However, users can detect systems that manipulate predictions. We discuss how designers of recommender systems might react to these findings.	Is seeing believing?: how recommender system interfaces affect users' opinions	NA:NA:NA:NA:NA	2018
Stephen S. Intille:Ling Bao:Emmanuel Munguia Tapia:John Rondoni	Ubiquitous, context-aware computer systems may ultimately enable computer applications that naturally and usefully respond to a user's everyday activity. Although new algorithms that can automatically detect context from wearable and environmental sensor systems show promise, many of the most flexible and robust systems use probabilistic detection algorithms that require extensive libraries of training data with labeled examples. In this paper, we describe the need for such training data and some challenges we have identified when trying to collect it while testing three context-detection systems for ubiquitous computing and mobile applications.	Acquiring in situ training data for context-aware ubiquitous computing applications	NA:NA:NA:NA	2018
Effie Lai-Chong Law:Ebba Thora Hvannberg	User effect in terms of influencing the validity and reliability of results derived from standard usability tests has been studied with different approaches during the last decade, but inconsistent findings were obtained. User effect is further complicated by other confounding variables. With the use of various computational models, we analyze the extent of user effect in a relatively complex arrangement of international usability tests in which four different European countries were involved. We explore five aspects of user effect, including optimality of sample size, evaluator effect, effect of heterogeneous subgroups, performance of task variants, and efficiency of problem discovery. Some implications for future research are drawn.	Analysis of combinatorial user effect in international usability tests	NA:NA	2018
Perttu Hämäläinen:Mikko Lindholm:Ari Nykänen:Johanna Höysniemi	This paper describes Animaatiokone, an installation for experimenting and learning about stop-motion animation. Located in a movie theater, it allows people to create clay animation while waiting for a movie. Collaboration between users is supported, for example, by sharing of clay actors. The installation's user interface allows even beginners to create and edit animation with help of automatic onion-skinning and simple controls developed through iterative testing and prototyping. In test use, the installation has been popular and hundreds of animations have been created and made available via the installation's homepage http://www.animaatiokone.net	Animaatiokone: an installation for creating clay animation	NA:NA:NA:NA	2018
m. c. schraefel:Gareth V. Hughes:Hugo R. Mills:Graham Smith:Terry R. Payne:Jeremy Frey	The UK e-Science programme is relying on the evolution of the paper lab book into a pervasive data gathering lab system. To date take up of existing commercial or research lab book replacement systems has not been great. In this paper, we reconsider both the role of the lab book in the experimental cycle, as well as its affective and experiential properties as an artefact, in order to design an e-Science lab book that will be acceptable to the scientists who will use it. To this end we combined and extended existing design analysis models in order to assess the artefact functionally and experientially. We present the approach we developed, the prototype we designed based on our analysis, and the results of the formative study we performed of the artefact in real use. We show that our design elicitation method strongly contributed to the success of our prototype's take up.	Breaking the book: translating the chemistry lab book into a pervasive computing lab environment	NA:NA:NA:NA:NA:NA	2018
Anind K. Dey:Raffay Hamid:Chris Beckmann:Ian Li:Daniel Hsu	Context-aware applications are applications that implicitly take their context of use into account by adapting to changes in a user's activities and environments. No one has more intimate knowledge about these activities and environments than end-users themselves. Currently there is no support for end-users to build context-aware applications for these dynamic settings. To address this issue, we present a CAPpella, a programming by demonstration Context-Aware Prototyping environment intended for end-users. Users "program" their desired context-aware behavior (situation and associated action) in situ, without writing any code, by demonstrating it to a CAPpella and by annotating the relevant portions of the demonstration. Using a meeting and medicine-taking scenario, we illustrate how a user can demonstrate different behaviors to a CAPpella. We describe a CAPpella's underlying system to explain how it supports users in building behaviors and present a study of 14 end-users to illustrate its feasibility and usability.	a CAPpella: programming by demonstration of context-aware applications	NA:NA:NA:NA:NA	2018
Masanori Sugimoto:Kazuhiro Hosoi:Hiromichi Hashizume	In this paper, a system called Caretta that integrates personal and shared spaces to support face-to-face collaboration is described. We use PDAs and a multiple-input sensing board for personal and shared spaces, respectively. Users of Caretta can discuss and negotiate with each other in the shared space by manipulating physical objects, while they individually examine their ideas in their own personal spaces. Caretta allows users to participate in group activities interchangeably and seamlessly using both these spaces. Caretta is applicable to various collaborative tasks. In this paper, it supports users in urban planning tasks. User studies of Caretta demonstrated that it allowed users to collaborate in a flexible fashion: users could work individually in their personal spaces at their own pace, cooperatively work together in the shared space, and smoothly transition between both of the spaces.	Caretta: a system for supporting face-to-face collaboration by integrating personal and shared spaces	NA:NA:NA	2018
Diane J. Schiano:Sheryl M. Ehrlich:Kyle Sheridan	Facial affect (or emotion) recognition is a central issue for many VMC and naturalistic computing applications. Most computational models assume "categorical perception" of facial affect, in which a benign illusion promotes robust recognition of emotional expressions even under severe degradation conditions, including temporal compression. However, this applied interest in human facial affect perception is coming at a time when the evidence for categorical perception is being challenged in the basic research literature, largely on methodological grounds. The research presented here systematically addresses the classic evidence for categorical perception of facial affect, using high-quality digital imaging and display technologies and improved research methods. In doing so, it illustrates a fruitful convergence of basic and applied research. The evidence does NOT support categorical perception of facial affect, which in turn underlines the importance of preserving high-fidelity motion information in portraying emotion. This research provides new human behavioral data on facial affect perception, and underscores the importance of careful consideration of facial affect compression methods.	Categorical imperative NOT: facial affect is perceived continuously	NA:NA:NA	2018
Robert C. Miller:Alisa M. Marshall	In current text editors, the find & replace command offers only two options: replace one match at a time prompting for confirmation, or replace all matches at once without any confirmation. Both approaches are prone to errors. This paper explores a third way: cluster-based find & replace, in which the matches are clustered by similarity and whole clusters can be replaced at once. We hypothesized that cluster-based find & replace would make find & replace tasks both faster and more accurate, but initial user studies suggest that clustering may improve speed on some tasks but not accuracy. Users also prefer using a perfect-selection strategy for find & replace, rather than an interleaved decision-action strategy.	Cluster-based find and replace	NA:NA	2018
John D. Lee:Joshua D. Hoffman:Elizabeth Hayes	As computers and other information technology move into cars and trucks, distraction-related crashes are likely to become an important problem. This paper begins to address this problem by examining how alert strategy (graded and single-stage) and alert modality (haptic and auditory) affect how well collision warning systems mitigate distraction and direct drivers attention to the car ahead when it unexpectedly brakes. We conducted two experiments in which drivers interacted with an in-vehicle email system and a collision warning system signaled a braking lead vehicle. The first experiment showed that graded alerts led to a greater safety margin and a lower rate of inappropriate responses to nuisance warnings. A second experiment focused on attitudes toward the collision warning system and found that graded alerts were more trusted than single stage alerts and that haptic alerts, a vibrating seat in these experiments, were perceived as less annoying and more appropriate. Graded haptic alerts offer a promising approach to developing context aware computing in a safety-critical application.	Collision warning design to mitigate driver distraction	NA:NA:NA	2018
Melanie Tory:Torsten Moller:M. Stella Atkins:Arthur E. Kirkpatrick	We compare 2D/3D combination displays to displays with 2D and 3D views alone. Combination displays we consider are: orientation icon (i.e., side-by-side), in-place methods (e.g., clip planes), and a new method called ExoVis. We specifically analyze performance differences (i.e., time and accuracy) for 3D orientation and relative position tasks. Empirical results show that 3D displays are effective for approximate navigation and relative positioning whereas 2D/3D combination displays (orientation icon and ExoVis) are useful for precise orientation and position tasks. Combination 2D/3D displays had as good or better performance as 2D displays. Clip planes were not effective for a 3D orientation task, but may be useful when only one slice is needed.	Combining 2D and 3D views for orientation and relative position tasks	NA:NA:NA:NA	2018
Daniel Wigdor:Ravin Balakrishnan	The numeric keypads on mobile phones generally consist of 12 keys (0-9, *, #). Ambiguity arises when the 36-character alpha-numeric English alphabet is mapped onto this smaller number of keys. In this paper, we first present a taxonomy of the various techniques for resolving this ambiguity, dividing them into techniques that use consecutive actions to first select a character grouping and then a character from within that grouping, and those that use concurrent actions to achieve the same end. We then present the design and implementation of a chording approach to text entry that uses concurrent key presses. We conducted a controlled experiment that compared this chording technique to one-handed and two-handed versions of the commonly used MultiTap technique. The results show that the concurrent chording technique significantly outperforms both versions of the consecutive action MultiTap technique.	A comparison of consecutive and concurrent input text entry techniques for mobile phones	NA:NA	2018
Leah Findlater:Joanna McGrenere	Software applications continue to grow in terms of the number of features they offer, making personalization increasingly important. Research has shown that most users prefer the control afforded by an adaptable approach to personalization rather than a system-controlled adaptive approach. No study, however, has compared the efficiency of the two approaches. In a controlled lab study with 27 subjects we compared the measured and perceived efficiency of three menu conditions: static, adaptable and adaptive. Each was implemented as a split menu, in which the top four items remained static, were adaptable by the subject, or adapted according to the subject's frequently and recently used items. The static menu was found to be significantly faster than the adaptive menu, and the adaptable menu was found to be significantly faster than the adaptive menu under certain conditions. The majority of users preferred the adaptable menu overall. Implications for interface design are discussed.	A comparison of static, adaptive, and adaptable menus	NA:NA	2018
David E. Kieras:Thomas P. Santoro	This paper presents the lessons learned when a computational GOMS modeling tool was used to evaluate user interface concepts and team structure designs for a new class of military shipboard workstations. The lessons are both encouraging and cautionary: For example, computational GOMS models scaled well to a large and complex task involving teams of users. Interruptability and working memory constructs had to be added to conventional GOMS model concepts. However, two surprises emerged: First, the non-psychological aspects of the model construction were the practical bottleneck. Second, user testing data in this domain were difficult to collect and lacked definition, meaning that the model provided a better characterization of the design details than the user testing data. Included in these lessons are recommendations for future model applications and modeling methodology development.	Computational GOMS modeling of a complex team task: lessons learned	NA:NA	2018
Ragnar Bade:Stefan Schlechtweg:Silvia Miksch	In modern intensive care units (ICUs), the medical staff has to monitor a huge amount of high-dimensional and time-oriented data, which needs to be visualized user- and task-specifically to ease diagnosis and treatment planning. Available visual representations, like diagrams or charts neglect the implicit information as well as a-priory or associated knowledge about the data and its meaning (for example, 38.5°C (101.3°F) is moderate fever and 41°C (105.8°F) is critical fever). Another challenge is to provide appropriate interaction techniques to explore and navigate the data and its temporal dimensions. In this context one major challenge is to connect time-oriented data and information to a coherent interactive visualization. In this paper we present different interactive visualization techniques which enable the users to reveal the data at several levels of detail and abstraction, ranging from a broad overview to the fine structure. We will also introduce a time visualization and navigation technique that connects overview+detail, pan+zoom, and focus+context features to one powerful time-browser.	Connecting time-oriented data and information to a coherent interactive visualization	NA:NA:NA	2018
Victor M. González:Gloria Mark	Most current designs of information technology are based on the notion of supporting distinct tasks such as document production, email usage, and voice communication. In this paper we present empirical results that suggest that people organize their work in terms of much larger and thematically connected units of work. We present results of fieldwork observation of information workers in three different roles: analysts, software developers, and managers. We discovered that all of these types of workers experience a high level of discontinuity in the execution of their activities. People average about three minutes on a task and somewhat more than two minutes using any electronic tool or paper document before switching tasks. We introduce the concept of working spheres to explain the inherent way in which individuals conceptualize and organize their basic units of work. People worked in an average of ten different working spheres. Working spheres are also fragmented; people spend about 12 minutes in a working sphere before they switch to another. We argue that design of information technology needs to support people's continual switching between working spheres.	"Constant, constant, multi-tasking craziness": managing multiple working spheres	NA:NA	2018
Alonso Vera:Andrew Howes:Michael McCurdy:Richard L. Lewis	In this paper we report a new approach to generating predictions about skilled interactive cognition. The approach, which we call Cognitive Constraint Modeling, takes as input a description of the constraints on a task environment, on user strategies, and on the human cognitive architecture and generates as output a prediction of the time course of interaction. In the Cognitive Constraint Models that we have built this is achieved by encoding the assumptions inherent in CPM-GOMS as a set of constraints and reasoning about them using finite domain constraint satisfaction.	A constraint satisfaction approach to predicting skilled interactive cognition	NA:NA:NA:NA	2018
Jeffrey T. Hancock:Jennifer Thom-Santelli:Thompson Ritchie	Social psychology has demonstrated that lying is an important, and frequent, part of everyday social interactions. As communication technologies become more ubiquitous in our daily interactions, an important question for developers is to determine how the design of these technologies affects lying behavior. The present research reports the results of a diary study, in which participants recorded all of their social interactions and lies for seven days. The data reveal that participants lied most on the telephone and least in email, and that lying rates in face-to-face and instant messaging interactions were approximately equal. This pattern of results suggests that the design features of communication technologies (e.g., synchronicity, recordability, and copresence) affect lying behavior in important ways, and that these features must be considered by both designers and users when issues of deception and trust arise. The implications for designing applications that increase, decrease or detect deception are discussed.	Deception and design: the impact of communication technology on lying behavior	NA:NA:NA	2018
Kathleen Luchini:Chris Quintana:Elliot Soloway	Handheld computers are mobile, flexible devices that can provide real-time, one-to-one support for students from within the context of their learning activities. This paper describes the design of three learner-centered handheld tools used as part of a nine-month classroom study involving thirty-three eighth grade students. A review of related work identifies some of the challenges of building educational software within the constraints of handheld screens, and two broad design guidelines are synthesized to help address these challenges. The first design guideline focuses on decomposing the learning activity to identify salient tasks and the type of supports (or scaffolds) students need to engage in these tasks, then building separate handheld workspaces to support each task. The second guideline focuses on methods for implementing scaffolds within these task-based workspaces while preserving the usability of the overall handheld software.	Design guidelines for learner-centered handheld tools	NA:NA:NA	2018
David Vronay:Shuo Wang	We present a new user interface for the common morphing tool found in animation packages. Previously this interface has been based on the features of the underlying algorithm, with little regard to how artists actually use this feature. By careful design and analysis of a user study, we were able to design a novel user interface that greatly enhances the usability of the morphing tool for animation. Our improvements come in three areas: First, we replicate the artists' own ad-hoc annotation language and interaction techniques in the user interface. Second, we make the user experience more fluid and editable, to support exploration and iteration. Finally, we use the artists' morph expectations to redesign the morph algorithm itself to be more predictable. We conclude by discussing how our user study technique could help other interface design tasks.	Designing a compelling user interface for morphing	NA:NA	2018
Andrew J. Ko:Brad A. Myers	Debugging is still among the most common and costly of programming activities. One reason is that current debugging tools do not directly support the inquisitive nature of the activity. Interrogative Debugging is a new debugging paradigm in which programmers can ask why did and even why didn't questions directly about their program's runtime failures. The Whyline is a prototype Interrogative Debugging interface for the Alice programming environment that visualizes answers in terms of runtime events directly relevant to a programmer's question. Comparisons of identical debugging scenarios from user tests with and without the Whyline showed that the Whyline reduced debugging time by nearly a factor of 8, and helped programmers complete 40% more tasks.	Designing the whyline: a debugging interface for asking questions about program behavior	NA:NA	2018
Rachid Hourizi:Peter Johnson	In this paper we propose an account of human/computer awareness for use in the (re)design of complex human/computer interaction, before empirically testing its utility. Specifically, having situated our work in the wider field of human/computer awareness research, we address the well-reported phenomenon of "situation awareness" breakdowns in the aviation domain. We assert the need for an explanatory and predictive model of the phenomenon if the frequency of such breakdowns is to be reduced and propose such a model. We then go on to investigate the utility of our model as a guide for design through the discussion of a recent experiment involving manipulations of an animated warning signal on a simulated cockpit control panel. Our results show initial support both for the model and for our assertion of its utility. We conclude that our composite view of awareness yields practical benefit in the design of human computer awareness support.	Designing to support awareness: a predictive, composite model	NA:NA	2018
Chia Shen:Frédéric D. Vernier:Clifton Forlines:Meredith Ringel	DiamondSpin is a toolkit for the efficient prototyping of and experimentation with multi-person, concurrent interfaces for interactive shared displays. In this paper, we identify the fundamental functionality that tabletop user interfaces should embody, then present the toolkit's architecture and API. DiamondSpin provides a novel real-time polar to Cartesian transformation engine that has enabled new, around-the-table interaction metaphors to be implemented. DiamondSpin allows arbitrary document positioning and orientation on a tabletop surface. Polygonal tabletop layouts such as rectangular, octagonal, and circular tabletops can easily be constructed. DiamondSpin also supports multiple work areas within the same digital tabletop. Multi-user operations are offered through multi-threaded input event streams, multiple active objects, and multiple concurrent menus. We also discuss insights on tabletop interaction issues we have observed from a set of applications built with DiamondSpin.	DiamondSpin: an extensible toolkit for around-the-table interaction	NA:NA:NA:NA	2018
Mary Czerwinski:Eric Horvitz:Susan Wilhite	We report on a diary study of the activities of information workers aimed at characterizing how people interleave multiple tasks amidst interruptions. The week-long study revealed the type and complexity of activities performed, the nature of the interruptions experienced, and the difficulty of shifting among numerous tasks. We present key findings from the diary study and discuss implications of the findings. Finally, we describe promising directions in the design of software tools for task management, motivated by the findings.	A diary study of task switching and interruptions	NA:NA:NA	2018
Hideaki Kuzuoka:Keiichi Yamazaki:Akiko Yamazaki:Jun'ichi Kosaka:Yasuko Suga:Christian Heath	The aim of our study is to investigate systems for supporting remote instruction via a mobile robot. In the real world, instructions are typically given through words and body orientations such as head movements, which make it possible to project others' actions. Projectability is an important resource in organizing multiple actions among multiple participants in co-ordination with one another. It can likewise be said that in the case of robot-human collaboration, it is necessary to design a robot's head so that a local participant can project the robot's (and remote person's) actions. GestureMan is a robot that is designed to support such projectability properties. It is argued that a remote controlled mobile robot, designed as a communication medium, makes relevant dual ecologies: ecology at a remote (robot operator's) site and at a local participant's (robot's) site. In order to design a robot as a viable communication medium, it is essential to consider how these ecologies can be mediated and supported.	Dual ecologies of robot as communication media: thoughts on coordinating orientations and projectability	NA:NA:NA:NA:NA:NA	2018
Susan R. Fussell:Sara Kiesler:Leslie D. Setlock:Peter Scupelli:Suzanne Weisband	We present a study of the effects of instant messaging (IM) on individuals' management of work across multiple collaborative projects. Groups of four participants completed four web design tasks. Each participant worked on two tasks, each task with a different partner who was either co-located or remote, connected via IM. In one condition, each participant had one co-located and one remote partner. In a second condition, both partners were remote. We examined communication, division of labor, and task performance as a function of condition. The results indicated that nearly all participants divided their time unequally between projects, but less unequally in the remote/remote condition. In the co-located/remote condition, participants favored the task with the co-located partner. The results show that the effects of IM differ depending on people's multiple tasks are distributed across space. We propose a new IM interface that promotes awareness of multiple collaborators on multiple tasks.	Effects of instant messaging on the management of multiple project trajectories	NA:NA:NA:NA:NA	2018
Tim Harter:Sander Vroegindeweij:Erik Geelhoed:Meera Manahan:Parthasarathy Ranganathan	The utility of a handheld device is often constrained by the battery life, particularly with recent usage patterns where the device is likely to be powered on at all times. The display component in these devices is a major consumer of battery energy and reducing its energy consumption can significantly enhance its utility. This primary research explores the impact of emerging technologies that provide energy-saving display modifications on perceived ease of use, quality, and overall user acceptance, and seeks to understand the tradeoffs between energy reduction and user acceptance for future interfaces. For our study, twelve handheld users reviewed energy-adaptive and standard display interfaces during five scenarios representing frequently performed tasks. The results show good acceptance of energy-aware user interfaces. While displays for tasks involving notifications and menus were deemed acceptable, primarily due to enhanced contrast levels, displays for longer tasks involving greater informational context need additional work.	Energy-aware user interfaces: an evaluation of user acceptance	NA:NA:NA:NA:NA	2018
James Fogarty:Scott E. Hudson:Jennifer Lai	Current systems often create socially awkward interruptions or unduly demand attention because they have no way of knowing if a person is busy and should not be interrupted. Previous work has examined the feasibility of using sensors and statistical models to estimate human interruptibility in an office environment, but left open some questions about the robustness of such an approach. This paper examines several dimensions of robustness in sensor-based statistical models of human interruptibility. We show that real sensors can be constructed with sufficient accuracy to drive the predictive models. We also create statistical models for a much broader group of people than was studied in prior work. Finally, we examine the effects of training data quantity on the accuracy of these models and consider tradeoffs associated with different combinations of sensors. As a whole, our analyses demonstrate that sensor-based statistical models of human interruptibility can provide robust estimates for a variety of office workers in a range of circumstances, and can do so with accuracy as good as or better than people. Integrating these models into systems could support a variety of advances in human computer interaction and computer-mediated communication.	Examining the robustness of sensor-based statistical models of human interruptibility	NA:NA:NA	2018
JJ Cadiz:Attila Narin:Gavin Jancke:Anoop Gupta:Michael Boyle	Industry trends suggest that the PC and telephone user experiences will converge over the next several years. This convergence raises important questions for the HCI community: how should the PC-phone user experience be designed, and how does PC-phone technology affect work practices? This paper focuses on the first question and provides some initial data on the second question. We describe a PC-phone prototype we built called Enhanced Telephony, and we report data from an eight month field deployment of Enhanced Telephony within our company where over 7,000 people installed the prototype. Results indicate that PC-phone software is a promising technology for the workplace and that the most valuable features may be those that help people manage their incoming calls.	Exploring PC-telephone convergence with the enhanced telephony prototype	NA:NA:NA:NA:NA	2018
Eric Paulos:Elizabeth Goodman	As humans we live and interact across a wildly diverse set of physical spaces. We each formulate our own personal meaning of place using a myriad of observable cues such as public-private, large-small, daytime-nighttime, loud-quiet, and crowded-empty. Not surprisingly, it is the people with which we share such spaces that dominate our perception of place. Sometimes these people are friends, family and colleagues. More often, and particularly in public urban spaces we inhabit, the individuals who affect us are ones that we repeatedly observe and yet do not directly interact with - our Familiar Strangers. This paper explores our often ignored yet real relationships with Familiar Strangers. We describe several experiments and studies that led to designs for both a personal, body-worn, wireless device and a mobile phone based application that extend the Familiar Stranger relationship while respecting the delicate, yet important, constraints of our feelings and affinities with strangers in pubic places.	The familiar stranger: anxiety, comfort, and play in public places	NA:NA	2018
Dan R. Olsen, Jr.:Stephen Bart Wood	A goal of human-robot interaction is to allow one user to operate multiple robots simultaneously. In such a scenario the robots provide leverage to the user's attention. The number of such robots that can be operated is called the fan-out of a human-robot team. Robots that have high neglect tolerance and lower interaction time will achieve higher fan-out. We define an equation that relates fan-out to a robot's activity time and its interaction time. We describe how to measure activity time and fan-out. We then use the fan-out equation to compute interaction effort. We can use this interaction effort as a measure of the effectiveness of a human-robot interaction design. We describe experiments that validate the fan-out equation and its use as a metric for improving human-robot interaction.	Fan-out: measuring human control of multiple robots	NA:NA	2018
Anatole Lécuyer:Jean-Marie Burkhardt:Laurent Etienne	We present a new interaction technique to simulate textures in desktop applications without a haptic interface. The proposed technique consists in modifying the motion of the cursor on the computer screen - i.e. the Control/Display ratio. Assuming that the image displayed on the screen corresponds to a top view of the texture, an acceleration (or deceleration) of the cursor indicates a negative (or positive) slope of the texture. Experimental evaluations showed that participants could successfully identify macroscopic textures such as bumps and holes, by simply using the variations of the motion of the cursor. Furthermore, the participants were able to draw the different profiles of bumps and holes which were simulated, correctly. These results suggest that our technique enabled the participants to successfully conjure a mental image of the topography of the macroscopic textures. Applications for this technique are: the feeling of images (pictures, drawings) or GUI components (windows' edges, buttons), the improvement of navigation, or the visualization of scientific data.	Feeling bumps and holes without a haptic interface: the perception of pseudo-haptic textures	NA:NA:NA	2018
Antti Oulasvirta	Human-computer interaction (HCI) is undergoing a paradigm change towards interaction that is contextually adapted to rich use situations taking place "beyond the desktop". Currently, however, there are only few successful applications of context-adapted HCI, arguably because use scenarios have not been based on holistic understanding of the society, users, and use situations. A humanistic research strategy, utilized at the Helsinki Institute for Information Technology, aims to structure the innovation and evaluation of scenarios for future technologies. Population trends and motivational needs are analyzed to recognize psycho-socially relevant design opportunities. Ethnography, ethnomethodology, bodystorming, and computer simulations of use situations are conducted to understand use situations. The goal of design is to empower users by supporting their autonomy and control. Three design cases illustrate the approach. The paper showcases an emerging framework for informed innovation of use potentials.	Finding meaningful uses for context-aware technologies: the humanistic research strategy	NA	2018
Patrick Baudisch:John Pruitt:Steve Ball	The hardware-inspired volume user interface model that is in use across all of today's operating systems is the source of several usability issues. One of them is that restoring the volume of a muted application can require an inappropriately long troubleshooting process: in addition to manipulating the application's volume and mute controls, users may also have to visit the system's volume control panel to find and adjust additional controls there. The "flat" volume control model presented in this paper eliminates this and other problems by hiding the hardware-oriented volume model from the user. Using the flat model, users use one slider per application to indicate how loud they want the respective applications to play; the slider then internally adjusts all hardware volume variables necessary to obtain the requested output. By offering a single point of control for each application, the flat model simplifies controlling application volume and restoring muted applications. In our studies, participants completed all four volume control and mixing tasks faster and with less error when using the flat model than when using the existing hardware-oriented volume control model. Participants also indicated a subjective preference for the flat model over the existing model.	Flat volume control: improving usability by hiding the volume control hierarchy in the user interface	NA:NA:NA	2018
Carsten Schwesig:Ivan Poupyrev:Eijiro Mori	Gummi is an interaction technique and device concept based on physical deformation of a handheld device. The device consists of several layers of flexible electronic components, including sensors measuring deformation of the device. Users interact with this device by a combination of bending and 2D position control. Gummi explores physical interaction techniques and screen interfaces for such a device. Its graphical user interface facilitates a wide range of interaction tasks, focused on browsing of visual information. We implemented both hardware and software prototypes to explore and evaluate the proposed interaction techniques.Our evaluations have shown that users can grasp Gummi's key interaction principles within minutes. Gummi demonstrates promising possibilities for new interaction techniques and devices based on flexible electronic components.	Gummi: a bendable computer	NA:NA:NA	2018
Piotr D. Adamczyk:Brian P. Bailey	User attention is a scarce resource, and users are susceptible to interruption overload. Systems do not reason about the effects of interrupting a user during a task sequence. In this study, we measure effects of interrupting a user at different moments within task execution in terms of task performance, emotional state, and social attribution. Task models were developed using event perception techniques, and the resulting models were used to identify interruption timings based on a user's predicted cognitive load. Our results show that different interruption moments have different impacts on user emotional state and positive social attribution, and suggest that a system could enable a user to maintain a high level of awareness while mitigating the disruptive effects of interruption. We discuss implications of these results for the design of an attention manager.	If not now, when?: the effects of interruption at different moments within task execution	NA:NA	2018
Elaine M. Huang:Daniel M. Russell:Alison E. Sue	Instant messaging (IM) in the workplace has proven to be a valuable tool for facilitating informal communication. Its benefits, however, are generally limited to times when users are in front of their computers. Because so much work takes place while people are mobile within their workplace, we sought to extend the benefits of IM beyond people's personal machines and into publicly accessible groupware. We first conducted a study of large display groupware applications (LDGAs) to understand the affordances that large displays offer for groupware, and the factors surrounding their adoption. We developed the IM Here system for shared IM on large displays using the lessons learned from the study. In this paper, we present the findings of our LDGA study, the design of IM Here and the preliminary results of our evaluation of IM as a public resource for workgroups.	IM here: public instant messaging on large, shared displays for workgroup interactions	NA:NA:NA	2018
T. J. Robertson:Shrinu Prabhakararao:Margaret Burnett:Curtis Cook:Joseph R. Ruthruff:Laura Beckwith:Amit Phalgune	Although researchers have begun to explicitly support end-user programmers' debugging by providing information to help them find bugs, there is little research addressing the proper mechanism to alert the user to this information. The choice of alerting mechanism can be important, because as previous research has shown, different interruption styles have different potential advantages and disadvantages. To explore impacts of interruptions in the end-user debugging domain, this paper describes an empirical comparison of two interruption styles that have been used to alert end-user programmers to debugging information. Our results show that negotiated-style interruptions were superior to immediate-style interruptions in several issues of importance to end-user debugging, and further suggest that a reason for this superiority may be that immediate-style interruptions encourage different debugging strategies.	Impact of interruption style on end-user debugging	NA:NA:NA:NA:NA:NA:NA	2018
Sunil Vemuri:Philip DeCamp:Walter Bender:Chris Schmandt	Despite the ready availability of digital recording technology and the continually decreasing cost of digital storage, browsing audio recordings remains a tedious task. This paper presents evidence in support of a system designed to assist with information comprehension and retrieval tasks from a large collection of recorded speech. Two techniques are employed to assist users with these tasks. First, a speech recognizer creates necessarily error-laden transcripts of the recorded speech. Second, audio playback is time-compressed using the SOLAFS technique. When used together, subjects are able to perform comprehension tasks with more speed and accuracy.	Improving speech playback using time-compression and speech recognition	NA:NA:NA:NA	2018
Kimiko Ryokai:Stefan Marti:Hiroshi Ishii	We introduce I/O Brush, a new drawing tool aimed at young children, ages four and up, to explore colors, textures, and movements found in everyday materials by "picking up" and drawing with them. I/O Brush looks like a regular physical paintbrush but has a small video camera with lights and touch sensors embedded inside. Outside of the drawing canvas, the brush can pick up color, texture, and movement of a brushed surface. On the canvas, children can draw with the special "ink" they just picked up from their immediate environment. In our preliminary study with kindergarteners, we found that children not only produced complex works of art using I/O Brush, but they also engaged in explicit talk about patterns and features available in their environment. I/O Brush invites children to explore the transformation from concrete and familiar raw material into abstract concepts about patterns of colors, textures and movements.	I/O brush: drawing with everyday objects as ink	NA:NA:NA	2018
Julie A. Jacko:Leon Barnard:Thitima Kongnakorn:Kevin P. Moloney:Paula J. Edwards:V. Kathlene Emery:Francois Sainfort	This study examines the effects of multimodal feedback on the performance of older adults with an ocular disease, Age-Related Macular Degeneration (AMD), when completing a simple computer-based task. Visually healthy older users (n = 6) and older users with AMD (n = 6) performed a series of drag-and-drop tasks that incorporated a variety of different feedback modalities. The user groups were equivalent with respect to traditional visual function metrics and measured subject cofactors, aside from the presence or absence of AMD. Results indicate that users with AMD exhibited decreased performance, with respect to required feedback exposure time. Some non-visual and multimodal feedback forms show potential as solutions to enhance performance, for those with AMD as well as for visually healthy older adults.	Isolating the effects of visual impairment: exploring the effect of AMD on the utility of multimodal feedback	NA:NA:NA:NA:NA:NA:NA	2018
Luis von Ahn:Laura Dabbish	We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.	Labeling images with a computer game	NA:NA	2018
Timothy Beamish:Karon Maclean:Sidney Fels	In this paper we consider the general goal of supporting physical manipulation of digital audio in a specific context: the performance disk jockey (DJ) seeking to migrate from vinyl to digital media. We classify both the DJ's traditional processes and tools and the field's newest technology.D'Groove, our own technological contribution, is a force feedback turntable used to manipulate digital audio in novel ways. We present an observational study of professional DJ's using D'Groove, and discuss this approach's attributes and directions for future augmentation. Finally, we extend our conclusions about the DJ's emerging needs to the broader domain of digital audio manipulation.	Manipulating music: multimodal interaction for DJs	NA:NA:NA	2018
Mick McGee	Master Usability Scaling (MUS) is a measurement method for developing a universal usability continuum based on magnitude estimation and master scaling. The universal usability continuum allows true ratio comparisons, potentially between all items measurable by the construct of usability (attributes, tasks, or products -- software or hardware) that have contributed to the meta-set by following the procedures prescribed. This paper describes the background for MUS, data reduction, and cases studies in software usability assessment.MUS is based on a new measurement method of usability, Usability Magnitude Estimation (UME) [9], where users estimate usability magnitude according to an objective definition of usability. UME allows all items measured within a single usability activity to be compared across one continuum. MUS utilizes UME to assess standard reference tasks across different usability activities to construct one meta-set of data. This meta-set of data can be represented as a universal usability continuum. MUS is simple to administer, easy to comprehend, and with advanced underlying calculations, powerful to use. The MUS continuum has the potential to be a widespread, robust, universal measurement scale of usability.	Master usability scaling: magnitude estimation and master scaling applied to usability measurement	NA	2018
Robert St. Amant:Thomas E. Horton:Frank E. Ritter	Cell phone interfaces are now ubiquitous. In this paper, we describe concepts to support the analysis of cell phone menu hierarchies. We present an empirical study of user performance on five simple tasks of menu traversal on a cell phone. Two models we tested, based on GOMS and ACT-R, give very good predictions of behavior. We use the study results to motivate an effective evaluation process for menu hierarchies. Our work makes several contributions: a novel and timely study of a new, very common HCI task; new models for accurately predicting performance; novel development tools to support such modeling; and a search procedure to generate menu hierarchies that reduce traversal time, in simulation studies, by about a third.	Model-based evaluation of cell phone menu interaction	NA:NA:NA	2018
Andriy Pavlovych:Wolfgang Stuerzlinger	In this paper we present a new model for predicting text entry speed on a 12-button mobile phone keypad. The proposed model can predict the performance of novice users. Like other models for text entry, the proposed model includes a movement component based on Fitts' law and a linguistic component based on letter digraph probabilities. It also adds cognitive delay times before key presses and takes into account the fact that Fitts' law cannot model multiple presses of the same key accurately. Finally, we compare the prediction of our model to previously published experimental results, demonstrate that it fits observed results for novices very well, and list some observations about learning.	Model for non-expert text entry speed on 12-button phone keypads	NA:NA	2018
Barry A. Po:Brian D. Fisher:Kellogg S. Booth	Neuroanatomical evidence indicates the human eye's visual field can be functionally divided into two vertical hemifields, each specialized for specific functions. The upper visual field (UVF) is specialized to support perceptual tasks in the distance, while the lower visual field (LVF) is specialized to support visually-guided motor tasks, such as pointing. We present a user study comparing mouse- and touchscreen-based pointing for items presented in the UVF and LVF on an interactive display. Consistent with the neuroscience literature, we found that mouse and touchscreen pointing were faster and more accurate for items presented in the LVF when compared to pointing at identical targets presented in the UVF. Further analysis found previously unreported performance differences between the visual fields for touchscreen pointing that were not observed for mouse pointing. This indicates that a placement of interactive items favorable to the LVF yields superior user performance, especially for systems dependent on direct touch interactions.	Mouse and touchscreen selection in the upper and lower visual fields	NA:NA:NA	2018
Patrick Baudisch:Carl Gutwin	Alpha blending allows the simultaneous display of overlapping windows-such as palette windows in visual workspaces. Although alpha blending has been used in some applications, such as games, it has not been widely adopted. One reason for the limited acceptance is that in many scenarios, alpha blending compromises the readability of content. We introduce a new blending mechanism called multiblending that uses a vector of blending weights, one for each class of features, rather than a single transparency value. Multiblending can in most cases be automatically optimized to preserve the most relevant features of both the palette and the background window. We present the results of a user study in which multiblended palettes provided higher recognizability of both the background and the palette than the best participating version of alpha blending.	Multiblending: displaying overlapping windows simultaneously without the drawbacks of alpha blending	NA:NA	2018
Michael J. Muller:Werner Geyer:Beth Brownholtz:Eric Wilcox:David R. Millen	This paper describes a new collaboration technology that is carefully poised between informal, ad hoc, easy-to-initiate collaborative tools, vs. more formal, structured, and high-overhead collaborative applications. Our approach focuses on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared objects with dynamic membership. We introduce our design concepts, and we provide a detailed first look at data from the first 100 days of usage by 20 researchers and 13 interns, who both confirmed our hypotheses and surprised us by reinventing the technology in several ways.	One-hundred days in an activity-centric collaboration environment based on shared objects	NA:NA:NA:NA:NA	2018
Ryan Shaun Baker:Albert T. Corbett:Kenneth R. Koedinger:Angela Z. Wagner	We investigate the prevalence and learning impact of different types of off-task behavior in classrooms where students are using intelligent tutoring software. We find that within the classrooms studied, no other type of off-task behavior is associated nearly so strongly with reduced learning as "gaming the system": behavior aimed at obtaining correct answers and advancing within the tutoring curriculum by systematically taking advantage of regularities in the software's feedback and help. A student's frequency of gaming the system correlates as strongly to post-test score as the student's prior domain knowledge and general academic achievement. Controlling for prior domain knowledge, students who frequently game the system score substantially lower on a post-test than students who never game the system. Analysis of students who choose to game the system suggests that learned helplessness or performance orientation might be better accounts for why students choose this behavior than lack of interest in the material. This analysis will inform the future re-design of tutors to respond appropriately when students game the system.	Off-task behavior in the cognitive tutor classroom: when students "game the system"	NA:NA:NA:NA	2018
Andy Crabtree:Steve Benford:Tom Rodden:Chris Greenhalgh:Martin Flintham:Rob Anastasi:Adam Drozd:Matt Adams:Ju Row-Farr:Nick Tandavanitj:Anthony Steed	Successfully staging a mixed reality game in which online players are chased through a virtual city by runners located in the real world requires extensive orchestration work. An ethnographic study shows how this concerted achievement extends beyond the control room to the runners on the street. This, in turn, suggests the need to 'decentralize' orchestration and develop support for collaboration 'on the ground'. The study leads to design proposals for orchestration interfaces for mobile experiences that augment situational awareness and surreptitious monitoring among mobile participants and support troubleshooting in situations where participants are disconnected or are unable to access positioning systems such as GPS.	Orchestrating a mixed reality game 'on the ground'	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Scott R. Klemmer:Jack Li:James Lin:James A. Landay	Tangible user interfaces (TUIs) augment the physical world by integrating digital information with everyday physical objects. Currently, building these UIs requires "getting down and dirty" with input technologies such as computer vision. Consequently, only a small cadre of technology experts can currently build these UIs. Based on a literature review and structured interviews with nine TUI researchers, we created Papier-Mâché, a toolkit for building tangible interfaces using computer vision, electronic tags, and barcodes. Papier-Mache introduces a high-level event model for working with these technologies that facilitates technology portability. For example, an application can be prototyped with computer vision and deployed with RFID. We present an evaluation of our toolkit with six class projects and a user study with seven programmers, finding the input abstractions, technology portability, and monitoring window to be highly effective.	Papier-Mache: toolkit support for tangible input	NA:NA:NA:NA	2018
Karyn Moffatt:Joanna McGrenere:Barbara Purves:Maria Klawe	Aphasia is a cognitive disorder that impairs speech and language. From interviews with aphasic individuals, their caregivers, and speech-language pathologists, the need was identified for a daily planner that allows aphasic users to independently manage their appointments. We used a participatory design approach to develop ESI Planner (the Enhanced with Sound and Images Planner) for use on a PDA and subsequently evaluated it in a lab study. This methodology was used in order to achieve both usable and adoptable technology. In addition to describing our experience in designing ESI Planner, two main contributions are provided: general guidelines for working with special populations in the development of technology, and design guidelines for accessible handheld technology.	The participatory design of a sound and image enhanced daily planner for people with aphasia	NA:NA:NA:NA	2018
Jaime Teevan:Christine Alvarado:Mark S. Ackerman:David R. Karger	This paper presents a modified diary study that investigated how people performed personally motivated searches in their email, in their files, and on the Web. Although earlier studies of directed search focused on keyword search, most of the search behavior we observed did not involve keyword search. Instead of jumping directly to their information target using keywords, our participants navigated to their target with small, local steps using their contextual knowledge as a guide, even when they knew exactly what they were looking for in advance. This stepping behavior was especially common for participants with unstructured information organization. The observed advantages of searching by taking small steps include that it allowed users to specify less of their information need and provided a context in which to understand their results. We discuss the implications of such advantages for the design of personal information management tools.	The perfect search engine is not enough: a study of orienteering behavior in directed search	NA:NA:NA:NA	2018
Poika Isokoski	We report results on the performance of the combination of soft keyboards and marking menus. A model of expert user performance indicated an 11 - 37% (depending on the keyboard layout) improvement in text entry rate over the same keyboard without the menu. To verify the advantage in real usage, we conducted two experiments using the QWERTY keyboard layout with and without the menu. The first experiment imitated nearly perfect cognitive performance and measured motor performance. Using the menu saved time. The second experiment measured performance in a realistic text entry task. Initially using the menu slows down text entry. By the end of the 20-session experiment both conditions were equally fast. With continued practice text entry is likely to be faster with the menu.	Performance of menu-augmented soft keyboards	NA	2018
Darren Gergle:David R. Millen:Robert E. Kraut:Susan R. Fussell	How much history of the dialogue should a chat client include? Some chat clients have minimized the dialogue history to deploy the space for other purposes. A theory of conversational coordination suggests that stripping away history raises the cost of conversational grounding, creating problems for both writers and readers. To test this proposition and inform design, we conducted an experiment in which one person instructed another on how to solve a simple puzzle. Participants had chat clients that showed either a single conversational turn or six of them. Having the dialogue history helped collaborators communicate efficiently and led to faster and better task performance. The dialogue history was most useful when the puzzles were more linguistically complex and when instructors could not see the work area. We present evidence of participants adapting their discourse to partially compensate for deficits in the communication media.	Persistence matters: making the most of chat in tightly-coupled work	NA:NA:NA:NA	2018
Desney S. Tan:Darren Gergle:Peter G. Scupelli:Randy Pausch	Previous results have shown that users perform better on spatial orientation tasks involving static 2D scenes when working on physically large displays as compared to small ones. This was found to be true even when the displays presented the same images at equivalent visual angles. Further investigation has suggested that large displays may provide a greater sense of presence, which biases users into adopting more efficient strategies to perform tasks. In this work, we extend those findings, demonstrating that users are more effective at performing 3D virtual navigation tasks on large displays. We also show that even though interacting with the environment affects performance, effects induced by interactivity are independent of those induced by physical display size. Together, these findings allow us to derive guidelines for the design and presentation of interactive 3D environments on physically large displays.	Physically large displays improve path integration in 3D virtual navigation tasks	NA:NA:NA:NA	2018
Tovi Grossman:Ravin Balakrishnan	We investigate pointing in true 3D environments where the target size varies in three spatial dimensions. We also study the effect of the user's physical movement angle on pointing performance. Results show that target size dimension along the primary axis of movement has a greater impact on performance than the other two dimensions. Movement angle also significantly affects performance, and changes the relative impact of the three target dimensions. Building upon recent results in the modeling of bivariate pointing, we propose and validate a new model that describes pointing at trivariate targets. This model also accounts for movement angle, and outperforms previously published models.	Pointing at trivariate targets in 3D environments	NA:NA	2018
Bonnie E. John:Konstantine Prevas:Dario D. Salvucci:Ken Koedinger	Although engineering models of user behavior have enjoyed a rich history in HCI, they have yet to have a widespread impact due to the complexities of the modeling process. In this paper we describe a development system in which designers generate predictive cognitive models of user behavior simply by demonstrating tasks on HTML mock-ups of new interfaces. Keystroke-Level Models are produced automatically using new rules for placing mental operators, then implemented in the ACT-R cognitive architecture. They interact with the mock-up through integrated perceptual and motor modules, generating behavior that is automatically quantified and easily examined. Using a query-entry user interface as an example [19], we demonstrate that this new system enables more rapid development of predictive models, with more accurate results, than previously published models of these tasks.	Predictive human performance modeling made easy	NA:NA:NA:NA	2018
Jeffrey Heer:Nathaniel S. Good:Ana Ramirez:Marc Davis:Jennifer Mankoff	As human-computer interaction becomes more closely modeled on human-human interaction, new techniques and strategies for human-computer interaction are required. In response to the inevitable shortcomings of recognition technologies, researchers have studied mediation: interaction techniques by which users can resolve system ambiguity and error. In this paper we approach the human-computer dialogue from the other side, examining system-initiated direction and mediation of human action. We conducted contextual interviews with a variety of experts in fields involving human-human direction, including a film director, photographer, golf instructor, and 911 operator. Informed by these interviews and a review of prior work, we present strategies for directing physical human action and an associated design space for systems that perform such direction. We illustrate these concepts with excerpts from our interviews and with our implemented system for automated media capture or "Active Capture," in which an unaided computer system uses techniques identified in our design space to act as a photographer, film director, and cinematographer.	Presiding over accidents: system direction of human action	NA:NA:NA:NA:NA	2018
Carlos Jensen:Colin Potts	Studies have repeatedly shown that users are increasingly concerned about their privacy when they go online. In response to both public interest and regulatory pressures, privacy policies have become almost ubiquitous. An estimated 77% of websites now post a privacy policy. These policies differ greatly from site to site, and often address issues that are different from those that users care about. They are in most cases the users' only source of information.This paper evaluates the usability of online privacy policies, as well as the practice of posting them. We analyze 64 current privacy policies, their accessibility, writing, content and evolution over time. We examine how well these policies meet user needs and how they can be improved. We determine that significant changes need to be made to current practice to meet regulatory and usability requirements.	Privacy policies as decision-making tools: an evaluation of online privacy notices	NA:NA	2018
Dag Svanaes:Gry Seland	This paper sums up lessons learned from a sequence of cooperative design workshops where end users were enabled to design mobile systems through scenario building, role playing, and low-fidelity prototyping. We present a resulting fixed workshop structure with well-chosen constraints that allows for end users to explore and design new technology and work practices. In these workshops, the systems developers get input to design from observing how users stage and act out current and future use scenarios and improvise new technology to fit their needs. A theoretical framework is presented to explain the creative processes involved and the workshop as a user-centered design method. Our findings encourage us to recommend the presented workshop structure for design projects involving mobility and computer-mediated communication, in particular project where the future use of the resulting products and services also needs to be designed.	Putting the users center stage: role playing and low-fi prototyping enable end users to design mobile systems	NA:NA	2018
Gonzalo Ramos:Matthew Boulos:Ravin Balakrishnan	Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.	Pressure widgets	NA:NA:NA	2018
Joëlle Bitton:Stefan Agamanolis:Matthew Karau	This paper traces the development of RAW, a system combining a tool and a process for capturing and conveying audiovisual impressions of everyday life. The project aims to enable a relationship between the user of the tool and an audience in a different place or time with an absolute minimum of editorial mediation by a third party. The tool itself incorporates a digital camera and a binaural audio recording device that captures the minute of sound before and after a picture is taken. To inform the design process, we tested prototypes in a progression of three studies within different cultural contexts in Ireland, France, and Mali. We present the results of these experiences, in which we observed among our participants an emerging set of ways of exploiting the tool for different purposes: social glances, depictions of activities, active documentation, and intentional discourses. We also discuss more generally the advantages and pitfalls of multicultural analyses of prototype technologies like the one we undertook.	RAW: conveying minimally-mediated impressions of everyday life with an audio-photographic tool	NA:NA:NA	2018
Carl Gutwin:Steve Benford:Jeff Dyck:Mike Fraser:Ivan Vaghi:Chris Greenhalgh	Delay is an unavoidable reality in collaborative environments. We propose an approach to dealing with delay in which 'decorators' are introduced into the interface. Decorators show the presence, magnitude and effects of delay so that participants can better understand its consequences and adopt their own natural coping strategies. Two experiments with different decorators show that this approach can significantly reduce errors in specific collaborative activities. We conclude that revealing delays is one way in which groupware can benefit from accepting and working with the reality of distributed systems, rather than trying to maintain the illusion of copresent interaction.	Revealing delay in collaborative environments	NA:NA:NA:NA:NA:NA	2018
Stephen Hughes:Michael Lewis	A video stream from a single camera is often the foundation for situational awareness in teleoperation activities. Poor camera placement, narrow field-of-view and other camera properties can significantly impair the operator's perceptual link to the environment, inviting cognitive mistakes and general disorientation. This paper provides a brief overview of viewpoint control research for 3D virtual environments (VE) to motivate a user study that evaluates the effectiveness of viewpoint controls on a simulated robotic vehicle. Findings suggest that providing a camera that is controlled independently from the orientation of the vehicle may facilitate wayfinding tasks. Moreover, there is evidence to support the use of separate cameras and interfaces for different navigational subtasks.	Robotic camera control for remote exploration	NA:NA	2018
Renaud Blanch:Yves Guiard:Michel Beaudouin-Lafon	We introduce semantic pointing, a novel interaction technique that improves target acquisition in graphical user interfaces (GUIs). Semantic pointing uses two independent sizes for each potential target presented to the user: one size in motor space adapted to its importance for the manipulation, and one size in visual space adapted to the amount of information it conveys. This decoupling between visual and motor size is achieved by changing the control-to-display ratio according to cursor distance to nearby targets. We present a controlled experiment supporting our hypothesis that the performance of semantic pointing is given by Fitts' index of difficulty in motor rather than visual space. We apply semantic pointing to the redesign of traditional GUI widgets by taking advantage of the independent manipulation of motor and visual widget sizes.	Semantic pointing: improving target acquisition with control-display ratio adaptation	NA:NA:NA	2018
Steve Whittaker:Brian Amento	Editing speech data is currently time-consuming and error-prone. Speech editors rely on acoustic waveform representations, which force users to repeatedly sample the underlying speech to identify words and phrases to edit. Instead we developed a semantic editor that reduces the need for extensive sampling by providing access to meaning. The editor shows a time-aligned errorful transcript produced by applying automatic speech recognition (ASR) to the original speech. Users visually scan the words in the transcript to identify important phrases. They then edit the transcript directly using standard word processing 'cut and paste' operations, which extract the corresponding time-aligned speech. ASR errors mean that users must supplement what they read in the transcript by accessing the original speech. Even when there are transcript errors, however, the semantic representation still provides users with enough information to target what they edit and play, reducing the need for extensive sampling. A laboratory evaluation showed that semantic editing is more efficient than acoustic editing even when ASR is highly inaccurate.	Semantic speech editing	NA:NA	2018
John D. McCarthy:M. Angela Sasse:Dimitrios Miras	We introduce a new methodology to evaluate the perceived quality of video with variable physical quality. The methodology is used to evaluate existing guidelines - that high frame rate is more important than quantization when watching high motion video, such as sports coverage. We test this claim in two studies that examine the relationship between these physical quality metrics and perceived quality. In Study 1, 41 soccer fans viewed CIF-sized images on a desktop computer. Study 2 repeated the experiment with 37 soccer fans, viewing the same content, in QCIF size, on a palmtop device. Contrary to existing guidelines, we found that users prefer high-resolution images to high frame rate. We conclude that the rule "high motion = high frame rate" does not apply to small screens. With small screen devices, reducing quantization removes important information about the players and the ball. These findings have important implications for service providers and designers of streamed video applications.	Sharp or smooth?: comparing the effects of quantization vs. frame rate for streamed video	NA:NA:NA	2018
Cliff Lampe:Paul Resnick	Can a system of distributed moderation quickly and consistently separate high and low quality comments in an online conversation? Analysis of the site Slashdot.org suggests that the answer is a qualified yes, but that important challenges remain for designers of such systems. Thousands of users act as moderators. Final scores for comments are reasonably dispersed and the community generally agrees that moderations are fair. On the other hand, much of a conversation can pass before the best and worst comments are identified. Of those moderations that were judged unfair, only about half were subsequently counterbalanced by a moderation in the other direction. And comments with low scores, not at top-level, or posted late in a conversation were more likely to be overlooked by moderators.	Slash(dot) and burn: distributed moderation in a large online conversation space	NA:NA	2018
Danyel Fisher:Paul Dourish	Everyday work frequently involves coordinating and collaborating with others, but the structure of collaboration is largely invisible to conventional desktop applications. We are exploring ways to support everyday collaboration by allowing applications access to the social, organizational, and temporal settings within which work is conducted. In this paper, we present two generations of systems supporting everyday collaboration, focusing on ways to recover and represent the temporal and social structures of online activity.	Social and temporal structures in everyday collaboration	NA:NA	2018
Thomas Erickson:Wei Huang:Catalina Danis:Wendy A. Kellogg	This paper describes an approach to managing tasks and processes that are distributed across a large number of people. The basic idea is to use a social visualization called a task proxy to create a shared awareness amongst the participants in a task or process. The process awareness provided by the task proxy enables its users to monitor the task state, the states of participants, and to communicate with those in particular states. We describe the concept, a first prototype, its evaluation, and discuss future directions.	A social proxy for distributed tasks: design and evaluation of a working prototype	NA:NA:NA:NA	2018
Richard J. Anderson:Crystal Hoyer:Steven A. Wolfman:Ruth Anderson	Digital inking systems are becoming increasingly popular across a variety of domains. In particular, many systems now allow instructors to write on digital surfaces in the classroom. Yet, our understanding of how people actually use writing in these systems is limited. In this paper, we report on classroom use of writing in one such system, in which the instructor annotates projected slides using a Tablet PC. Through a detailed analysis of lecture archives, we identify key use patterns. In particular, we categorize a major use of ink as analogous to physical gestures and present a framework for analyzing this ink; we explore the relationship between the ephemeral meaning of many annotations and their persistent representation; and we observe that instructors make conservative use of the system's features. Finally, we discuss implications of our study to the design of future digital inking systems.	A study of digital ink in lecture presentation	NA:NA:NA:NA	2018
Fernanda B. Viégas:Martin Wattenberg:Kushal Dave	The Internet has fostered an unconventional and powerful style of collaboration: "wiki" web sites, where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia, a prominent, thriving wiki. We make three contributions. First, we introduce a new exploratory data analysis tool, the history flow visualization, which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second, we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third, we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship, the value of community surveillance in ameliorating antisocial behavior, and how authors with competing perspectives negotiate their differences.	Studying cooperation and conflict between authors with history flow visualizations	NA:NA:NA	2018
Richard Boardman:M. Angela Sasse	This paper reports a study of Personal Information Management (PIM), which advances research in two ways: (1) rather than focusing on one tool, we collected cross-tool data relating to file, email and web bookmark usage for each participant, and (2) we collected longitudinal data for a subset of the participants. We found that individuals employ a rich variety of strategies both within and across PIM tools, and we present new strategy classifications that reflect this behaviour. We discuss synergies and differences between tools that may be useful in guiding the design of tool integration. Our longitudinal data provides insight into how PIM behaviour evolves over time, and suggests how the supporting nature of PIM discourages reflection by users on their strategies. We discuss how the promotion of some reflection by tools and organizations may benefit users.	"Stuff goes into the computer and doesn't come out": a cross-tool study of personal information management	NA:NA	2018
Steve Tsang:Ravin Balakrishnan:Karan Singh:Abhishek Ranjan	We present an image guided pen-based suggestive interface for sketching 3D wireframe models. Rather than starting from a blank canvas, existing 2D images of similar objects serve as a guide to the user. Image based filters enable attraction, smoothing, and resampling of input curves, and allows for their selective application using pinning and gluing techniques. New input strokes also invoke suggestions of relevant geometry that can be used, reducing the need to explicitly draw all parts of the new model. All suggestions appear in-place with the model being built, in the user's focal attention space. A curve matching algorithm seamlessly augments basic suggestions with more complex ones from a database populated with previously used geometry. The interface also incorporates gestural command input, and interaction techniques for camera controls that enable smooth transitions between orthographic and perspective views.	A suggestive interface for image guided 3D sketching	NA:NA:NA:NA	2018
Scott Counts:Eric Fellheimer	Lightweight photo sharing, particularly via mobile devices, is fast becoming a common communication medium used for maintaining a presence in the lives of friends and family. How should such systems be designed to maximize this social presence while maintaining simplicity? An experimental photo sharing system was developed and tested that, compared to current systems, offers highly simplified, group-centric sharing, automatic and persistent people-centric organization, and tightly integrated desktop and mobile sharing and viewing. In an experimental field study, the photo sharing behaviors of groups of family or friends were studied using their normal photo sharing methods and with the prototype sharing system. Results showed that users found photo sharing easier and more fun, shared more photos, and had an enhanced sense of social presence when sharing with the experimental system. Results are discussed in the context of design principles for the rapidly increasing number of lightweight photo sharing systems.	Supporting social presence through lightweight photo sharing on and off the desktop	NA:NA	2018
Sachi Mizobuchi:Michiaki Yasumura	Tapping-based selection methods for handheld devices may need to be supplemented with other approaches as increasingly complex tasks are carried out using those devices. Circling selection methods (such as the Lasso) allow users to select objects on a touch screen by circling with a pen. An experimental comparison of the selection time and accuracy between a circling method and a traditional tapping style of selection was carried out. The experiment used a two dimensional grid (varying in terms of the sizes and the distances of the targets). Analysis of variance showed that tapping selection time differed significantly depending on the size and spacing of the targets. In contrast, circling selection times differed significantly for different levels of target cohesiveness and shape complexity. The results are discussed in terms of implications for design of new pen-based selection methods for handheld devices, and also in terms of evaluation methodology for input selection methods.	Tapping vs. circling selections on pen-based devices: evidence for different performance-shaping factors	NA:NA	2018
Karrie Karahalios:Judith Donath	Telemurals is an abstract audio-video installation that seeks to initiate and sustain interaction between and within two remote spaces. Our goal is to improve the social aspects of casual mediated communications by incorporating events into the design of the communication medium that encourage people to engage in interaction when they otherwise would not. We call these events social catalysts, for they encourage people to initiate and sustain interaction. In this paper we discuss the design process and goals of our first Telemurals link between two public spaces, the building of Telemurals, and an ethnographic study describing how the system affected interaction between and within these two spaces based on the theories discussed in this paper.	Telemurals: linking remote spaces with social catalysts	NA:NA	2018
S. M. Goza:R. O. Ambrose:M. A. Diftler:I. M. Spain	Engineers at the Johnson Space Center recently combined the upper body of the National Aeronautics and Space Administration (NASA) / Defense Advanced Research Projects Agency (DARPA) Robonaut system with a Robotic Mobility Platform (RMP) to make an extremely mobile humanoid robot designed to interact with human teammates. Virtual Reality gear that immerses a human operator into Robonaut's working environment provides the primary control pathway for remote operations. Human/robot interface challenges are addressed in the control system for teleoperators, console operators and humans working directly with the Robonaut. Multiple control modes are available for controlling the five fingered dexterous robot hands and operator selectable depending on the type of grasp required. A relative positioning system is used to maximize operator comfort during arm and head motions. Foot pedals control the mobility base. Initial tasks that include working with human rated tools, navigating hallways and cutting wires are presented and show the effectiveness of telepresence control for this class of robot.	Telepresence control of the NASA/DARPA robonaut on a mobility platform	NA:NA:NA:NA	2018
Pamela J. Ludford:Dan Cosley:Dan Frankowski:Loren Terveen	Online communities can help people form productive relationships. Unfortunately, this potential is not always fulfilled: many communities fail, and designers don't have a solid understanding of why. We know community activity begets activity. The trick, however, is to inspire participation in the first place. Social theories suggest methods to spark positive community participation. We carried out a field experiment that tested two such theories. We formed discussion communities around an existing movie recommendation web site, manipulating two factors: (1) similarity-we controlled how similar group members' movie ratings were; and (2) uniqueness-we told members how their movie ratings (with respect to a discussion topic) were unique within the group. Both factors positively influenced participation. The results offer a practical success story in applying social science theory to the design of online communities.	Think different: increasing online community participation using uniqueness and group dissimilarity	NA:NA:NA:NA	2018
Magnus Ingmarsson:David Dinka:Shumin Zhai	With the evolving functionality in television-based (TV-based) information and entertainment appliances, there is an increased need to enable users input text through remote control devices. We present a novel text input method, The Numpad Typer (TNT), for interactive TV, multimedia home terminals or other similar applications. Embodied in a TV remote control and guided by a visual map on the TV screen, TNT was designed for consistent spatial Stimuli-Response (S-R) compatibility and consistency of use. Five users tested TNT in ten sessions of 45-minutes. This initial investigation showed that users on average could type 9.3 and 17.7 correct words per minute with TNT doing the slowest and the fastest session respectively. The study also showed that the users found the TNT method easy to grasp and fun to use. Subjectively the participants felt they mastered the method rather quickly in comparison to their actual speed improvement.	TNT: a numeric keypad based text input method	NA:NA:NA	2018
Hayes Solos Raffle:Amanda J. Parkes:Hiroshi Ishii	We introduce Topobo, a 3D constructive assembly system embedded with kinetic memory, the ability to record and playback physical motion. Unique among modeling systems is Topobo's coincident physical input and output behaviors. By snapping together a combination of Passive (static) and Active (motorized) components, people can quickly assemble dynamic biomorphic forms like animals and skeletons with Topobo,animate those forms by pushing, pulling, and twisting them, and observe the system repeatedly play back those motions. For example, a dog can be constructed and then taught to gesture and walk by twisting its body and legs. The dog will then repeat those movements and walk repeatedly.Our evaluation of Topobo in classrooms with children ages 5-13 suggests that children develop affective relationships with Topobo creations and that their experimentation with Topobo allows them to learn about movement and animal locomotion through comparisons of their creations to their own bodies. Eighth grade science students' abilities to quickly develop various types of walking robots suggests that a tangible interface can support understanding how balance, leverage and gravity affect moving structures because the interface itself responds to the forces of nature that constrain such systems.	Topobo: a constructive assembly system with kinetic memory	NA:NA:NA	2018
Hideyuki Nakanishi:Satoshi Koizumi:Toru Ishida:Hideaki Ito	Many studies have been conducted on supporting communication in home and office spaces, but relatively few studies have explored supporting communication in large-scale public spaces, despite the importance of such environments in our daily lives. We propose a transcendent means of communication as an emerging style in this pervasive computing era: a system that allows administrative staff to effectively help visitors in large-scale public spaces. The visitors' context is used to provide a bird's-eye view of a simulated public space for the staff to grasp the situation and point at a particular location within the view to indicate the visitors they intend to address. The results of an experiment showed synergic effects between the bird's-eye view and the first-person one in determining the spatial movements of people. In indoor and outdoor large-scale public spaces, a central railway station and a park, we installed our prototypes and learned the implications of its use.	Transcendent communication: location-based guidance for large-scale public spaces	NA:NA:NA:NA	2018
Elizabeth Sillence:Pam Briggs:Lesley Fishwick:Peter Harris	Do different design and information content factors influence trust and mistrust of online health sites? Fifteen women faced with a risky health decision were observed while searching the Internet for information and advice over four consecutive weeks. In some sessions their searches were unstructured, whilst in other sessions they were directed to review specific sites, chosen for their trust design elements. Content analysis of concurrent verbalisations and group discussion protocols provided support for a staged model wherein design appeal predicted rejection (mistrust) and credibility of information and personalisation of content predicted selection (trust) of advice sites.	Trust and mistrust of online health sites	NA:NA:NA:NA	2018
Kent Lyons:Thad Starner:Daniel Plaisted:James Fusia:Amanda Lyons:Aaron Drew:E. W. Looney	An experienced user of the Twiddler, a one--handed chording keyboard, averages speeds of 60 words per minute with letter--by--letter typing of standard test phrases. This fast typing rate coupled with the Twiddler's 3x4 button design, similar to that of a standard mobile telephone, makes it a potential alternative to multi--tap for text entry on mobile phones. Despite this similarity, there is very little data on the Twiddler's performance and learnability. We present a longitudinal study of novice users' learning rates on the Twiddler. Ten participants typed for 20 sessions using two different methods. Each session is composed of 20 minutes of typing with multi--tap and 20 minutes of one--handed chording on the Twiddler. We found that users initially have a faster average typing rate with multi--tap; however, after four sessions the difference becomes negligible, and by the eighth session participants type faster with chording on the Twiddler. Furthermore, after 20 sessions typing rates for the Twiddler are still increasing.	Twiddler typing: one-handed chording text entry for mobile phones	NA:NA:NA:NA:NA:NA:NA	2018
Xiaodong Jiang:Jason I. Hong:Leila A. Takayama:James A. Landay	In this paper, we demonstrate how field studies, interviews, and low-fidelity prototypes can be used to inform the design of ubiquitous computing systems for firefighters. We describe the artifacts and processes used by firefighters to assess, plan, and communicate during emergency situations, showing how accountability affects these decisions, how their current Incident Command System supports these tasks, and some drawbacks of existing solutions. These factors informed the design of a large electronic display for supporting the incident commander, the person who coordinates the overall response strategy in an emergency. Although our focus was on firefighters, our results are applicable for other aspects of emergency response as well, due to common procedures and training.	Ubiquitous computing for firefighters: field studies and prototypes of large displays for incident command	NA:NA:NA:NA	2018
Min Lin:Wayne G. Lutters:Tina S. Kim	People frequently write messages to themselves. These informal, hurried personal jottings serve as temporary storage for notable information as well as reminders for future action. Many mobile technologies have been designed specifically to support this ubiquitous behavior; however, adoption has been universally problematic. Despite its clear utility, the process of taking micronotes stubbornly resists computing support. This field study examines the lifecycles of the canonical micronote forms (immediate use, temporary storage, and prospective memory aid), pinpointing the behaviors that are mismatched with current mobile support. Implications for improving the design of these systems are presented, culminating in a vision for integrated paper-digital micronote systems. This shifts the development focus away from trying to support the entire micronote lifecycle, emphasizing instead the different behaviors best supported by the different technologies.	Understanding the micronote lifecycle: improving mobile support for informal note taking	NA:NA:NA	2018
Sarah P. Everett:Michael D. Byrne	Users of modern GUIs routinely engage in visual searches for various control items, such as buttons and icons. Because this is so ubiquitous, it is important that the visual properties of user interfaces support such searches. The current research is aimed at deepening our understanding of how the visual spacing between icons affects visual search times. We constructed an experiment based on previous icon sets [8] where spacing between icons was systematically manipulated, and for which we had a computational cognitive model that predicted performance. In particular, the model predicted that larger spacing would lead to slower search times. While this prediction was borne out, there was an unanticipated finding: users in this new experiment were substantially slower than in previous similar experiments with smaller spacing. In fact, results from this new experiment were better fit with a model that employed a fundamentally different, and less efficient, search strategy. A second experiment was conducted to explicitly test the surprising result that this varied and larger icon spacing would lead to increased search times. Results were consistent with this hypothesis. These results imply that while small differences in visual layout may not intrinsically produce large differences in user performance, they may cause users to adopt suboptimal strategies that do produce such differences.	Unintended effects: varying icon spacing changes users' visual search strategy	NA:NA	2018
Steve Cornett	This study examines the usability challenges faced by new players of massively multiplayer online role-playing games (MMORPGs), one of the fastest-growing segments of the video game industry. Played in completely online worlds, these games allow players to communicate with one another, form groups and communities, and compete in a variety of fantasy environments.Nineteen subjects participated in an exploratory usability study of four games, three MMORPGs and a similar single-player game used for comparison. Results reveal that many people not usually considered as potential players of these games may be interested in them, but a wide variety of usability issues present serious problems for players inexperienced with the genre. Based on an analysis of the usability data and player feedback, specific recommendations are made to improve the experience of these games for new players. These results further demonstrate the applicability and importance of usability testing to video games.	The usability of massively multiplayer online roleplaying games: designing for new users	NA	2018
Michael Terry:Elizabeth D. Mynatt:Kumiyo Nakakoji:Yasuhiro Yamamoto	The complexity of many problems necessitates creating and exploring multiple, alternative solutions. However, current user interfaces do not cleanly support creating alternatives at a time when they are likely to be discovered: as users interactively modify data. This paper presents Parallel Paths, a novel model of interaction that facilitates generating, manipulating, and comparing alternative solutions. In contrast to existing approaches such as automated history capture tools, Parallel Paths emphasizes the active, simultaneous development of multiple, alternative solutions. We demonstrate this model of interaction in Parallel Pies, a user interface mechanism developed for image manipulation tasks that allows users to: easily create solution alternatives as they interact with a command; embed the alternatives in the same workspace; manipulate the alternatives independently or simultaneously as if they were the same object; and perform side-by-side comparisons of each. Results from an initial evaluation are presented, along with implications for future designs.	Variation in element and action: supporting simultaneous development of alternative solutions	NA:NA:NA:NA	2018
James J. W. Lin:Habib Abi-Rached:Michal Lahav	This study developed a new procedure, a Virtual Guiding Avatar (VGA), which combined self-motion prediction cues and an independent visual background (IVB) to alleviate simulator sickness (SS). The VGA, which was embodied as an abstract airplane, was designed to lead the participant along a horizontal motion trajectory through a virtual environment. Both motion prediction cues and IVBs, which provide an earth-fixed reference frame, reduced SS in separate previous studies. Participants were exposed to complex visual motion through a cartoon-like simulated environment in a very wide field of view driving simulator. Participants' responses to avatars with varying motion properties - fixed, rotation only or rotation plus translation - were assessed using a within-subjects experimental design. Results indicated that SS was reduced by a VGA that presented rotational cues alone or rotation plus translation. The VGA also increased participants' sense of presence and enjoyment relative to conditions lacking a VGA. The VGA procedure can be used to enhance user experiences in immersive virtual environments as well as to improve motion simulator design.	Virtual guiding avatar: an effective procedure to reduce simulator sickness in virtual environments	NA:NA:NA	2018
Tim Paek:Susan Dumais:Ron Logan	Internet search results are typically displayed as a list conforming to a static style sheet. The difficulty of perusing this list can be exacerbated when screen real estate is limited. When space is limited, either, few results are seen, or result descriptions are abbreviated, making it difficult to know whether to follow a particular web link. In this paper, we describe "WaveLens," a dynamic layout technique for displaying search results, which addresses these issues by combining a fisheye lens with progressive exposure of page content. Results from a usability study showed that participants performed faster and more accurately on a search task with one of two distinct parameter settings of WaveLens as compared to the typical static list. In a post-hoc questionnaire, participants favored that setting over both the static list and another setting which involved animated zoom. We discuss design implications for the retrieval and display of search results.	WaveLens: a new view onto Internet search results	NA:NA:NA	2018
John M. Carroll:Mary Beth Rosson:Jingying Zhou	As human-computer interaction increasingly focuses on mediated interactions among groups of individuals, there is a need to develop techniques for measurement and analysis of groups that have been scoped at the level of the group. Bandura's construct of perceived self-efficacy has been used to understand individual behavior as a function of domain-specific beliefs about personal capacities. The construct of collective efficacy extends self-efficacy to organizations and groups, referring to beliefs about collective capacities in specific domains. We describe the development and refinement of a collective efficacy scale, the factor analysis of the construct, and its external validation in path models of community-oriented attitudes, beliefs, and behaviors.	Collective efficacy as a measure of community	NA:NA:NA	2018
Gary Olson	NA	Session details: Large communities	NA	2018
Dan Cosley:Dan Frankowski:Sara Kiesler:Loren Terveen:John Riedl	Online communities need regular maintenance activities such as moderation and data input, tasks that typically fall to community owners. Communities that allow all members to participate in maintenance tasks have the potential to be more robust and valuable. A key challenge in creating member-maintained communities is building interfaces, algorithms, and social structures that encourage people to provide high-quality contributions. We use Karau and Williams' collective effort model to predict how peer and expert editorial oversight affect members' contributions to a movie recommendation website and test these predictions in a field experiment with 87 contributors. Oversight increased both the quantity and quality of contributions while reducing antisocial behavior, and peers were as effective at oversight as experts. We draw design guidelines and suggest avenues for future work from our results.	How oversight improves member-maintained communities	NA:NA:NA:NA:NA	2018
Jeremy P. Birnholtz:Thomas A. Finholt:Daniel B. Horn:Sung Joo Bae	This paper reports on the emergent use of lightweight text chat to provide important grounding and facilitation information in a large, distributed, ad-hoc group of researchers participating in a live experiment. The success of chat in this setting suggests a critical re-examination and extension of Clark and Brennan's work on grounding in communication. Specifically, it is argued that there are some settings characterized by reduced information and clarification needs, where the use of extremely lightweight tools (such as basic text chat) can be sufficient for achieving common ground - even when conversational participants are unknown to each other. Theoretical and design implications are then presented.	Grounding needs: achieving common ground via lightweight chat in large, distributed, ad-hoc groups	NA:NA:NA:NA	2018
Ed Chi	NA	Session details: Web interactions	NA	2018
Marilyn Hughes Blackmon:Muneo Kitajima:Peter G. Polson	The Cognitive Walkthrough for the Web (CWW) is a partially automated usability evaluation method for identifying and repairing website navigation problems. Building on five earlier experiments [3,4], we first conducted two new experiments to create a sufficiently large dataset for multiple regression analysis. Then we devised automatable problem-identification rules and used multiple regression analysis on that large dataset to develop a new CWW formula for accurately predicting problem severity. We then conducted a third experiment to test the prediction formula and refined CWW against an independent dataset, resulting in full cross-validation of the formula. We conclude that CWW has high psychological validity, because CWW gives us (a) accurate measures of problem severity, (b) high success rates for repairs of identified problems (c) high hit rates and low false alarms for identifying problems, and (d) high rates of correct rejections and low rates of misses for identifying non-problems.	Tool for accurately predicting website navigation problems, non-problems, problem severity, and effectiveness of repairs	NA:NA:NA	2018
Jennifer Mankoff:Holly Fait:Tu Tran	Web access for users with disabilities is an important goal and challenging problem for web content developers and designers. This paper presents a comparison of different methods for finding accessibility problems affecting users who are blind. Our comparison focuses on techniques that might be of use to Web developers without accessibility experience, a large and important group that represents a major source of inaccessible pages. We compare a laboratory study with blind users to an automated tool, expert review by web designers with and without a screen reader, and remote testing by blind users. Multiple developers, using a screen reader, were most consistently successful at finding most classes of problems, and tended to find about 50% of known problems. Surprisingly, a remote study with blind users was one of the least effective methods. All of the techniques, however, had different, complementary strengths and weaknesses.	Is your web page accessible?: a comparative study of methods for assessing web page accessibility for the blind	NA:NA:NA	2018
Ishwinder Kaur:Anthony J. Hornof	A predictive tool to simulate human visual search behavior would help interface designers inform and validate their design. Such a tool would benefit from a semantic component that would help predict search behavior even in the absence of exact textual matches between goal and target. This paper discusses a comparison of three semantic systems-LSA, WordNet and PMI-IR-to evaluate their performance in predicting the link that people would select given an information goal and a webpage. PMI-IR best predicted human performance as observed in a user study.	A comparison of LSA, wordNet and PMI-IR for predicting user click behavior	NA:NA	2018
Yves Guiard	NA	Session details: Basic level interaction techniques	NA	2018
David Ahlström	Selecting a menu item in a cascading pull-down menu is a frequent but time consuming and complex GUI task. This paper describes an approach aimed to support the user during selection in cascading pull-down menus when using an indirect pointing device. By enhancing such a cascading pull-down menu with "force fields", the cursor is attracted toward a certain direction, e.g. toward the right hand side within a menu item, which opens up a sub-menu, making the cursor steering task easier and faster. The experiment described here shows that the force fields can decrease selection times, on average by 18%, when a mouse, a track point, or touch pad is used as input device. The results also suggest that selection times in cascading pull-down menus can be modeled using a combination of Fitts' law and the steering law. The proposed model proved to hold for all three devices, in both standard and in enhanced cascading pull-down menus, with correlations better than r2=0.90.	Modeling and improving selection in cascading pull-down menus using Fitts' law, the steering law and force fields	NA	2018
Andy Cockburn:Joshua Savage:Andrew Wallace	Speed dependent automatic zooming (SDAZ) is a promising refinement to scrolling in which documents are automatically zoomed-out as the scroll rate increases. By automatically zooming, the visual flow rate is reduced enabling rapid scrolling without motion blur. In order to aid SDAZ calibration we theoretically and empirically scrutinise human factors of the speed/zoom relationship. We then compare user performance with four alternative text-document scrolling systems, two of which employ automatic zooming. One of these systems, which we term 'DDAZ', is based on van Wijk and Nuij's recent and important theory that calculates optimal pan/zoom paths between known locations in 2D space. van Wijk and Nuij suggested that their theory could be applied to scrolling, but did not implement or test their formulaic suggestions. Participants in our evaluation (n=27) completed scrolling tasks most rapidly when using SDAZ, followed by DDAZ, normal scrollbars, and traditional rate-based scrolling. Workload assessments and preferences strongly favoured SDAZ. We finish by examining issues for consideration in commercial deployments.	Tuning and testing scrolling interfaces that automatically zoom	NA:NA:NA	2018
Jason Hong	NA	Session details: Privacy 1	NA	2018
Sunny Consolvo:Ian E. Smith:Tara Matthews:Anthony LaMarca:Jason Tabert:Pauline Powledge	Advances in location-enhanced technology are making it easier for us to be located by others. These new technologies present a difficult privacy tradeoff, as disclosing one's location to another person or service could be risky, yet valuable. To explore whether and what users are willing to disclose about their location to social relations, we conducted a three-phased formative study. Our results show that the most important factors were who was requesting, why the requester wanted the participant's location, and what level of detail would be most useful to the requester. After determining these, participants were typically willing to disclose either the most useful detail or nothing about their location. From our findings, we reflect on the decision process for location disclosure. With these results, we hope to influence the design of future location-enhanced applications and services.	Location disclosure to social relations: why, when, & what people want to share	NA:NA:NA:NA:NA:NA	2018
Giovanni Iachello:Gregory D. Abowd	We argue that an analytic proportionality assessment balancing usefulness and burden on individual or group privacy must be conducted throughout the design process to create acceptable ubiquitous computing (ubicomp) applications and services. We introduce the principle of proportionality, which originates within the legal and data protection communities. Inspired by this principle, we develop a design method for ubicomp applications, based on our own experience, and aimed at HCI practitioners and designers. We discuss the method in relation to real-world examples, user inquiry techniques and requirements engineering models. Finally, we report a sample application of the method, involving a ubiquitous, personal memory aid tool.	Privacy and proportionality: adapting legal evaluation techniques to inform design in ubiquitous computing	NA:NA	2018
Sameer Patil:Jennifer Lai	We report on a study (N=36) of user preferences for balancing awareness with privacy. Participants defined permissions for sharing of location, availability, calendar information and instant messaging (IM) activity within an application called mySpace. MySpace is an interactive visualization of the physical workplace that provides dynamic information about people, places and equipment. We found a significant preference for defining privacy permissions at the group level. While "family" received high levels of awareness sharing, interestingly, "team" was granted comparable levels during business hours at work. Surprisingly, presenting participants with a detailed list of all pieces of personal context to which the system had access, did not result in more conservative privacy settings. Although location was the most sensitive aspect of awareness, participants were comfortable disclosing room-level location information to their team members at work. Our findings suggest utilizing grouping mechanisms to balance privacy control with configuration burden, and argue for increased system transparency to build trust.	Who gets to know what when: configuring privacy permissions in an awareness application	NA:NA	2018
Kumiyo Nakakoji	NA	Session details: Document interaction	NA	2018
Catherine C. Marshall:Sara Bly	As part of a focus on electronic publications, we undertook an exploratory study of how people saved and used the information they encountered while reading. In particular, we wanted to understand the role of clipping and whether it would be a necessary form of interaction with electronic publications. We interviewed 20 diverse individuals at home and at work, bringing together narrative accounts and physical and digital examples to investigate how people currently collect and use clippings from their everyday reading. All study participants had examples of materials they had deliberately saved from periodicals, ranging from ads torn from newspapers and URLs received in email messages to large stacks of magazines. Participants rarely read periodicals specifically to clip but rather recognized items of interest when they were encountered. The work highlights the importance of encountering information as an activity distinct from task-focused browsing and searching and reveals design implications for online reading and clipping technologies.	Saving and using encountered information: implications for electronic periodicals	NA:NA	2018
Olha Bondarenko:Ruud Janssen	In this paper the results of a two-year ethnographic study of the personal document management of 28 information workers is described. Both the paper and digital domain were taken into account during the study. The results reaffirmed that document management is strongly related to task management. Digital tools do not adequately support two important user needs related to task management, namely that documents should be embedded within meaningful (task-related) context information, and that they should be easily accessible for regrouping as the task goes on. In contrast, paper supports these needs very well. Following a discussion of personal document management using paper, email, and digital file folder structures, six implications are outlined for the design of digital document management systems that combine the advantages of both domains.	Documents at Hand: Learning from Paper to Improve Digital Technologies	NA:NA	2018
Mika Käki	Long web search result lists can be hard to browse. We demonstrated experimentally, in a previous study, the usefulness of a categorization algorithm and filtering interface. However, the nature of interaction in real settings is not known from an experiment in laboratory settings. To address this problem, we provided our categorizing web search user interface to 16 users for a two month period. The interactions with the system were logged and the users' opinions were elicited with two questionnaires. The results show that categories are successfully used as part of users' search habits. They are helpful when the result ranking of the search engine fails. In those cases, the users are able to access results that locate far in the rank order list with the categories. Users can also formulate simpler queries and find needed results with the help of the categories. In addition, the categories are beneficial when more than one result is needed like in an exploratory or undirected search task.	Findex: search result categories help users when document ranking fails	NA	2018
Kari-Jouko Räihä	NA	Session details: Eyes on interaction	NA	2018
Sajay Sadasivan:Joel S. Greenstein:Anand K. Gramopadhye:Andrew T. Duchowski	Aircraft inspection is a vital element in assuring safety and reliability of the air transportation system. The human inspector performing visual inspection of an aircraft is the backbone of this process and training is an effective strategy for improving their inspection performance. Previous studies have shown offline feedback training to be effective in improving subsequent visual inspection performance. Because experienced inspectors are known to adopt a better inspection strategy than novices, providing visualization of experts' cognitive processes a priori can accelerate novices' adoption of the experts' strategy. Using eye tracking equipment, we record the point of regard of an expert inspector performing an inspection task in a virtual reality simulator. Analysis of their eye movements leads to a visualization of their scanpaths and allows us to display the inspector's visual search (hence cognitive) strategy. We show how providing this type of scanpath-based feedforward training of novices leads to improved accuracy performance in the simulator coupled with an observed speed-accuracy tradeoff. We contend that the tradeoff results from trained novices adopting a slower paced strategy through increased fixation durations, suggesting trained novices learn a more deliberate target search/discrimination strategy that requires more time to execute.	Use of eye movements as feedforward training for a synthetic aircraft inspection task	NA:NA:NA:NA	2018
David Fono:Roel Vertegaal	In this paper, we present an attentive windowing technique that uses eye tracking, rather than manual pointing, for focus window selection. We evaluated the performance of 4 focus selection techniques: eye tracking with key activation, eye tracking with automatic activation, mouse and hotkeys in a typing task with many open windows. We also evaluated a zooming windowing technique designed specifically for eye-based control, comparing its performance to that of a stan-dard tiled windowing environment. Results indicated that eye tracking with automatic activation was, on average, about twice as fast as mouse and hotkeys. Eye tracking with key activation was about 72% faster than manual conditions, and preferred by most participants. We believe eye input performed well because it allows manual input to be provided in parallel to focus selection tasks. Results also suggested that zooming windows outperform static tiled windows by about 30%. Furthermore, this performance gain scaled with the number of windows used. We conclude that eye-controlled zooming windows with key activation pro-vides an efficient and effective alternative to current focus window selection techniques.	EyeWindows: evaluation of eye-controlled zooming windows for focus selection	NA:NA	2018
Anthony J. Hornof:Anna Cavender	EyeDraw is a software program that, when run on a computer with an eye tracking device, enables children with severe motor disabilities to draw pictures by just moving their eyes. This paper discusses the motivation for building the software, how the program works, the iterative development of two versions of the software, user testing of the two versions by people with and without disabilities, and modifications to the software based on user testing. Feedback from both children and adults with disabilities, and from their caregivers, was especially helpful in the design process. The project identifies challenges that are unique to controlling a computer with the eyes, and unique to writing software for children with severe motor impairments.	EyeDraw: enabling children with severe motor impairments to draw with their eyes	NA:NA	2018
Joseph Konstan	NA	Session details: Personal technologies	NA	2018
Amy Voida:Elizabeth D. Mynatt	In this paper, we explore the use of digital photographs in computer-mediated communication. We present Lascaux, an instant messaging client that serves as a research platform for studying visual communication with digital photographs. Through a combined analysis of the uses of images in Lascaux as well as the uses of images in other communicative contexts, we arrived at six themes of appropriation: the image as amplification, the image as narrative, the image as awareness, the image as local expression, the image as invitation, and the image as object/instrument. For each theme, we explore the ways in which a medium may be designed to support that class of appropriation. Finally, we reflect on the relationship between literacy, mastery, and appropriation.	Six themes of the communicative appropriation of photographic images	NA:NA	2018
Paul M. Aoki:Allison Woodruff	Pervasive personal communication technologies offer the potential for important social benefits for individual users, but also the potential for significant social difficulties and costs. In research on face-to-face social interaction, ambiguity is often identified as an important resource for resolving social difficulties. In this paper, we discuss two design cases of personal communication systems, one based on fieldwork of a commercial system and another based on an unrealized design concept. The cases illustrate how user behavior concerning a particular social difficulty, unexplained unresponsiveness, can be influenced by technological issues that result in interactional ambiguity. The cases also highlight the need to balance the utility of ambiguity against the utility of usability and communicative clarity.	Making space for stories: ambiguity in the design of personal communication systems	NA:NA	2018
Amy Voida:Rebecca E. Grinter:Nicolas Ducheneaut:W. Keith Edwards:Mark W. Newman	This paper presents a descriptive account of the social practices surrounding the iTunes music sharing of 13 participants in one organizational setting. Specifically, we characterize adoption, critical mass, and privacy; impression management and access control; the musical impressions of others that are created as a result of music sharing; the ways in which participants attempted to make sense of the dynamic system; and implications of the overlaid technical, musical, and corporate topologies. We interleave design implications throughout our results and relate those results to broader themes in a music sharing design space.	Listening in: practices surrounding iTunes music sharing	NA:NA:NA:NA:NA	2018
Gene Golovchinsky	NA	Session details: Small devices 1	NA	2018
Amy K. Karlson:Benjamin B. Bederson:John SanGiovanni	We present two interfaces to support one-handed thumb use for PDAs and cell phones. Both use Scalable User Interface (ScUI) techniques to support multiple devices with different resolutions and aspect ratios. The designs use variations of zooming interface techniques to provide multiple views of application data: AppLens uses tabular fisheye to access nine applications, while LaunchTile uses pure zoom to access thirty-six applications. We introduce two sets of thumb gestures, each representing different philosophies for one-handed interaction. We conducted two studies to evaluate our designs. In the first study, we explored whether users could learn and execute the AppLens gesture set with minimal training. Participants performed more accurately and efficiently using gestures for directional navigation than using gestures for object interaction. In the second study, we gathered user reactions to each interface, as well as comparative preferences. With minimal exposure to each design, most users favored AppLens's tabular fisheye interface.	AppLens and launchTile: two designs for one-handed thumb use on small devices	NA:NA:NA	2018
Jun Gong:Peter Tarasewich	The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.	Alphabetically constrained keypad designs for text entry on mobile devices	NA:NA	2018
Robert Jacob	NA	Session details: Eye gaze and multimodal integration patterns	NA	2018
Pernilla Qvarfordt:Shumin Zhai	Motivated by and grounded in observations of eye-gaze patterns in human-human dialogue, this study explores using eye-gaze patterns in managing human-computer dialogue. We developed an interactive system, iTourist, for city trip planning, which encapsulated knowledge of eye-gaze patterns gained from studies of human-human collaboration systems. User study results show that it was possible to sense users' interest based on eye-gaze patterns and manage computer information output accordingly. Study participants could successfully plan their trip with iTourist and positively rated their experience of using it. We demonstrate that eye-gaze could play an important role in managing future multimodal human-computer dialogues.	Conversing with the user based on eye-gaze patterns	NA:NA	2018
Jiazhi Ou:Lui Min Oh:Jie Yang:Susan R. Fussell	Helpers providing guidance for collaborative physical tasks shift their gaze between the workspace, supply area, and instructions. Understanding when and why helpers gaze at each area is important both for a theoretical understanding of collaboration on physical tasks and for the design of automated video systems for remote collaboration. In a laboratory experiment using a collaborative puzzle task, we recorded helpers' gaze while manipulating task complexity and piece differentiability. Helpers gazed toward the pieces bay more frequently when pieces were difficult to differentiate and less frequently over repeated trials. Preliminary analyses of message content show that helpers tend to look at the pieces bay when describing the next piece and at the workspace when describing where it goes. The results are consistent with a grounding model of communication, in which helpers seek visual evidence of understanding unless they are confident that they have been understood. The results also suggest the feasibility of building automated video systems based on remote helpers' shifting visual requirements.	Effects of task properties, partner actions, and message content on eye gaze patterns in a collaborative task	NA:NA:NA:NA	2018
Sharon Oviatt:Rebecca Lunsford:Rachel Coulston	Techniques for information fusion are at the heart of multimodal system design. To develop new user-adaptive approaches for multimodal fusion, the present research investigated the stability and underlying cause of major individual differences that have been documented between users in their multimodal integration pattern. Longitudinal data were collected from 25 adults as they interacted with a map system over six weeks. Analyses of 1,100 multimodal constructions revealed that everyone had a dominant integration pattern, either simultaneous or sequential, which was 95-96% consistent and remained stable over time. In addition, coherent behavioral and linguistic differences were identified between these two groups. Whereas performance speed was comparable, sequential integrators made only half as many errors and excelled during new or complex tasks. Sequential integrators also had more precise articulation (e.g., fewer disfluencies), although their speech rate was no slower. Finally, sequential integrators more often adopted terse and direct command-style language, with a smaller and less varied vocabulary, which appeared focused on achieving error-free communication. These distinct interaction patterns are interpreted as deriving from fundamental differences in reflective-impulsive cognitive style. Implications of these findings are discussed for the design of adaptive multimodal systems with substantially improved performance characteristics.	Individual differences in multimodal integration patterns: what are they and why do they exist?	NA:NA:NA	2018
Sidney Fels	NA	Session details: Touch & such	NA	2018
Yuji Ayatsuka:Jun Rekimoto	A virtually connected medium called tranStick is described that functions both as a "virtual wire" and as a "memory card" containing a shared space. A user can connect two networked devices by simply placing one of a pair of tranSticks with the same identifier into each device. The tranSticks provide feedback indicating that the devices are connected; the connection to be closed or changed in the same way it would be if the devices were connected by a physical cable. A user can also access to a shared space on a network as if the space were in the tranStick. Since tranSticks contain long secret keys, the process of finding another tranStick with the same identifier can be encrypted. The tranStick approach differs from other approaches in that it provides feedback from the connection as well as serving as a medium for establishing a connection, and it enables disconnection and switchover to be done intuitively because the operations are reversible.	tranSticks: physically manipulatable virtual connections	NA:NA	2018
Paul Gnanayutham:Chris Bloor:Gilbert Cockton	We present two studies that have advanced the design of brain-body interfaces for use in the rehabilitation of individuals with severe neurological impairment due to traumatic brain injury. We first developed and evaluated an adaptive cursor acceleration algorithm based on screen areas. This improved the initial design, but was too inflexible to let users make the most of their highly varied abilities. Only some individuals were well served by this adaptive interface. We therefore developed and evaluated an approach based on personalized tile layouts. The rationales for both designs are presented, along with details of their implementation. Evaluation studies for each are reported, which show that we have extended the user population who can use our interfaces relative to previous studies. We have also extended the usable functionality for some of our user group. We thus claim that personalized tiling with discrete acceleration has allowed us to extend the usable functionality of brain-body interfaces to a wider population with traumatic brain injury, thus creating new options for neurorehabiliation.	Discrete acceleration and personalised tiling as brain?body interface paradigms for neurorehabilitation	NA:NA:NA	2018
Robert W. Lindeman:John L. Sibert:Erick Mendez-Mendez:Sachin Patil:Daniel Phifer	This paper presents empirical results to support the use of vibrotactile cues as a means of improving user performance on a spatial task. In a building-clearing exercise, directional vibrotactile cues were employed to alert subjects to areas of the building that they had not yet cleared, but were currently exposed to. Compared with performing the task without vibrotactile cues, subjects were exposed to uncleared areas a smaller percentage of time, and cleared more of the overall space, when given the added vibrotactile stimulus. The average length of each exposure was also significantly less when vibrotactile cues were present.	Effectiveness of directional vibrotactile cuing on a building-clearing task	NA:NA:NA:NA:NA	2018
Steven Feiner	NA	Session details: Smart interaction techniques 1	NA	2018
Tovi Grossman:Ravin Balakrishnan	We present the bubble cursor - a new target acquisition technique based on area cursors. The bubble cursor improves upon area cursors by dynamically resizing its activation area depending on the proximity of surrounding targets, such that only one target is selectable at any time. We also present two controlled experiments that evaluate bubble cursor performance in 1D and 2D target acquisition tasks, in complex situations with multiple targets of varying layout densities. Results show that the bubble cursor significantly outperforms the point cursor and the object pointing technique [7], and that bubble cursor performance can be accurately modeled and predicted using Fitts' law.	The bubble cursor: enhancing target acquisition by dynamic resizing of the cursor's activation area	NA:NA	2018
Barry A. Po:Brian D. Fisher:Kellogg S. Booth	Most graphical user interfaces provide visual cursors to facilitate interaction with input devices such as mice, pointers, and pens. These cursors often include directional cues that could influence the stimulus-response compatibility of user input. We conducted a controlled evaluation of four cursor orientations and an orientation-neutral cursor in a circular menu selection task. Mouse interaction on a desktop, pointer (i.e. wand) interaction on a large screen, and pen interaction on a Tablet PC were evaluated. Our results suggest that choosing appropriate cursors is especially important for pointer interaction, but may be less important for mice or pens. Cursors oriented toward the lower-right corner of a display yielded the poorest performance overall while orientation-neutral cursors were generally the best. Advantages were found for orientations aligned with the direction of movement. We discuss these results and suggest guidelines for the appropriate use of cursors in various input and display configurations.	Comparing cursor orientations for mouse, pointer, and pen interaction	NA:NA:NA	2018
Patrick Baudisch:Edward Cutrell:Ken Hinckley:Adam Eversole	Snapping is a widely used technique that helps users position graphical objects precisely, e.g., to align them with a grid or other graphical objects. Unfortunately, whenever users want to position a dragged object close to such an aligned location, they first need to deactivate snapping. We propose snap-and-go, a snapping technique that overcomes this limitation. By merely stopping dragged objects at aligned positions, rather than "warping" them there, snap-and-go helps users align objects, yet still allows placing dragged objects anywhere else. While this approach of inserting additional motor space renders snap-and-go slightly slower than traditional snapping, snap-and-go simplifies the user interface by eliminating the need for a deactivation option and thereby allows introducing snapping to application scenarios where traditional snapping is inapplicable. In our user studies, participants were able to align objects up to 138% (1D) and 231% (2D) faster with snap-and-go than without and snap-and-go proved robust against the presence of distracting snap targets.	Snap-and-go: helping users align objects without the modality of traditional snapping	NA:NA:NA:NA	2018
John C. Thomas	NA	Session details: Take a number, stand in line (interruptions & attention 1)	NA	2018
Shamsi T. Iqbal:Piotr D. Adamczyk:Xianjun Sam Zheng:Brian P. Bailey	To contribute to systems that reason about human attention, our work empirically demonstrates how a user's mental workload changes during task execution. We conducted a study where users performed interactive, hierarchical tasks while mental workload was measured through the use of pupil size. Results show that (i) different types of subtasks impose different mental workload, (ii) workload decreases at subtask boundaries, (iii) workload decreases more at boundaries higher in a task model and less at boundaries lower in the model, (iv) workload changes among subtask boundaries within the same level of a task model, and (v) effective understanding of why changes in workload occur requires that the measure be tightly coupled to a validated task model. From the results, we show how to map mental workload onto a computational Index of Opportunity that systems can use to better reason about human attention.	Towards an index of opportunity: understanding changes in mental workload during task execution	NA:NA:NA:NA	2018
Gloria Mark:Victor M. Gonzalez:Justin Harris	We present data from detailed observation of 24 information workers that shows that they experience work fragmentation as common practice. We consider that work fragmentation has two components: length of time spent in an activity, and frequency of interruptions. We examined work fragmentation along three dimensions: effect of collocation, type of interruption, and resumption of work. We found work to be highly fragmented: people average little time in working spheres before switching and 57% of their working spheres are interrupted. Collocated people work longer before switching but have more interruptions. Most internal interruptions are due to personal work whereas most external interruptions are due to central work. Though most interrupted work is resumed on the same day, more than two intervening activities occur before it is. We discuss implications for technology design: how our results can be used to support people to maintain continuity within a larger framework of their working spheres.	No task left behind?: examining the nature of fragmented work	NA:NA:NA	2018
James Fogarty:Andrew J. Ko:Htet Htet Aung:Elspeth Golden:Karen P. Tang:Scott E. Hudson	The computer and communication systems that office workers currently use tend to interrupt at inappropriate times or unduly demand attention because they have no way to determine when an interruption is appropriate. Sensor?based statistical models of human interruptibility offer a potential solution to this problem. Prior work to examine such models has primarily reported results related to social engagement, but it seems that task engagement is also important. Using an approach developed in our prior work on sensor?based statistical models of human interruptibility, we examine task engagement by studying programmers working on a realistic programming task. After examining many potential sensors, we implement a system to log low?level input events in a development environment. We then automatically extract features from these low?level event logs and build a statistical model of interruptibility. By correctly identifying situations in which programmers are non?interruptible and minimizing cases where the model incorrectly estimates that a programmer is non?interruptible, we can support a reduction in costly interruptions while still allowing systems to convey notifications in a timely manner.	Examining task engagement in sensor-based statistical models of human interruptibility	NA:NA:NA:NA:NA:NA	2018
Polle Zellweger	NA	Session details: Design thoughts & methods	NA	2018
Eric Paulos:Tom Jenkins	Urban Atmospheres captures a unique, synergistic moment - expanding urban populations, rapid adoption of Bluetooth mobile devices, tiny ad hoc sensor networks, and the widespread influence of wireless technologies across our growing urban landscapes. The United Nations recently reported that 48 percent of the world's population current live in urban areas and that this number is expected to exceed the 50 percent mark world wide by 2007 [1]. In developed nations the number of urban dwellers is even more dramatic - expected to exceed 75%. Current studies project Bluetooth-enabled devices to reach 5.4 billion units by 2005 - five times the number of mobile phones or Internet connections [2]. Mobile phone penetration already exceeds 80% of the population in places like the European Union (EU) and parts of Asia [3]. WiFi hardware is being deployed at the astonishing rate of one every 4 seconds globally [4]. We argue that now is the time to initiate inspirational research into the very essence of these newly emerging technological urban spaces. We desire to move towards an improved understanding of the emotional experience of urban life. This paper describes Urban Probes - a lightweight, provocative, intervention methodology designed to rapidly deconstruct urban situations, reveal new opportunities for technology in urban spaces, and guide future long term research in urban computing. We also describe a completed Urban Probe exploring urban trash.	Urban probes: encountering our emerging urban atmospheres	NA:NA	2018
Younghee Jung:Per Persson:Jan Blom	This paper presents the design, implementation and validation of an enhanced mobile phone messaging system (DeDe), allowing the sender to define the context in which the message will be delivered to the recipient. A field trial among a socially tight group of teenagers showed that the DeDe feature was incorporated as part of the participants' existing messaging culture. 11,4% of their total messaging output made use of the DeDe feature. The most frequently used context parameters were location (based on network cell-ID) and time. Novel message practices emerged, as compared to 'normal' messaging, both in terms of timing of message sending, as well as creating content that specifically exploited the DeDe feature. Some use barriers were recognized, the most important being the sender's uncertainty of delivery success. Implications for design are discussed.	DeDe: design and evaluation of a context-enhanced mobile messaging system	NA:NA:NA	2018
Mary Czerwinski	NA	Session details: Smart interaction techniques 2	NA	2018
Anastasia Bezerianos:Ravin Balakrishnan	We present the design and evaluation of the vacuum, a new interaction technique that enables quick access to items on areas of a large display that are difficult for a user to reach without significant physical movement. The vacuum is a circular widget with a user controllable arc of influence that is centered at the widget's point of invocation and spans out to the edges of the display. Far away objects residing inside this influence arc are brought closer to the widget's centre in the form of proxies that can be manipulated in lieu of the original. We conducted two experiments which compare the vacuum to direct picking and an existing technique called drag-and-pick [2]. Results show that the vacuum outperforms existing techniques when selecting multiple targets in a sequence, performs similarly to existing techniques when selecting single targets located moderately far away, and slightly worse with single targets located very far away in the presence of distracter targets along the path.	The vacuum: facilitating the manipulation of distant objects	NA:NA	2018
Miguel A. Nacenta:Dzmitry Aliakseyeu:Sriram Subramanian:Carl Gutwin	Recent advances in multi-user collaboration have seen a proliferation of interaction techniques for moving digital objects from one device to another. However, little is known about how these techniques work in realistic situations, or how they compare to one another. We conducted a study to compare the efficiency of six techniques for moving objects from a tablet to a tabletop display. We compared the techniques in four different distance ranges and with three movement directions. We found that techniques like the Radar View and Pick-and-Drop, that have a control-to-display ratio of 1, are significantly faster for object movement than techniques that have smaller control-to-display ratios. We also found that using spatial manipulation of objects was faster than pressure-based manipulation.	A comparison of techniques for multi-display reaching	NA:NA:NA:NA	2018
Scott E. Hudson:Jennifer Mankoff:Ian Smith	The subArctic user interface toolkit has extensibility as one of its central goals. It seeks not only to supply a powerful library of reusable interactive objects, but also make it easy to create new, unusual, and highly customized interactions tailored to the needs of particular interfaces or task domains. A central part of this extensibility is the input model used by the toolkit. The subArctic input model provides standard reusable components that implement many typical input handling patterns for the programmer, allows inputs to be handled in very flexible ways, and allows the details of how inputs are handled to be modified to meet custom needs. This paper will consider the structure and operation of the subArctic input handling mechanism. It will demonstrate the flexibility of the system through a series of examples, illustrating techniques that it enables - many of which would be very difficult to implement in most toolkits.	Extensible input handling in the subArctic toolkit	NA:NA:NA	2018
William Newman	NA	Session details: Methods & usability	NA	2018
Kasper Hornbæk:Erik Frøkjær	Usability problems predicted by evaluation techniques are useful input to systems development; it is uncertain whether redesign proposals aimed at alleviating those problems are likewise useful. We present a study of how developers of a large web application assess usability problems and redesign proposals as input to their systems development. Problems and redesign proposals were generated by 43 evaluators using an inspection technique and think aloud testing. Developers assessed redesign proposals to have higher utility in their work than usability problems. In interviews they explained how redesign proposals gave them new ideas for tackling well known problems. Redesign proposals were also seen as constructive and concrete input. Few usability problems were new to developers, but the problems supported prioritizing ongoing development of the application and taking design decisions. No developers, however, wanted to receive only problems or redesigns. We suggest developing and using redesign proposals as an integral part of usability evaluation.	Comparing usability problems and redesign proposals as input to practical systems development	NA:NA	2018
Jeff Sauro:Erika Kindlund	Current methods to represent system or task usability in a single metric do not include all the ANSI and ISO defined usability aspects: effectiveness, efficiency & satisfaction. We propose a method to simplify all the ANSI and ISO aspects of usability into a single, standardized and summated usability metric (SUM). In four data sets, totaling 1860 task observations, we show that these aspects of usability are correlated and equally weighted and present a quantitative model for usability. Using standardization techniques from Six Sigma, we propose a scalable process for standardizing disparate usability metrics and show how Principal Components Analysis can be used to establish appropriate weighting for a summated model. SUM provides one continuous variable for summative usability evaluations that can be used in regression analysis, hypothesis testing and usability reporting.	A method to standardize usability metrics into a single score	NA:NA	2018
Irene Tollinger:Richard L. Lewis:Michael McCurdy:Preston Tollinger:Alonso Vera:Andrew Howes:Laura Pelton	This paper presents X-PRT, a new cognitive modeling tool supporting activities ranging from interface design to basic cognitive research. X-PRT provides a graphical model development environment for the CORE constraint-based cognitive modeling engine [7,13,21]. X-PRT comprises a novel feature set: (a) it supports the automatic generation of predictive models at multiple skill levels from a single task-specification, (b) it supports a comprehensive set of modeling activities, and (c) it supports compositional reuse of existing cognitive/perceptual/motor skills by transforming high-level, hierarchical task descriptions into detailed performance predictions. Task hierarchies play a central role in X-PRT, serving as the organizing construct for task knowledge, the locus for compositionality, and the cognitive structures over which the learning theory is predicated. Empirical evidence supports the role of task hierarchies in routine skill acquisition.	Supporting efficient development of cognitive models at multiple skill levels: exploring recent advances in constraint-based modeling	NA:NA:NA:NA:NA:NA:NA	2018
Eser Kandogan	NA	Session details: Interactive information visualization	NA	2018
Jeffrey Heer:Stuart K. Card:James A. Landay	Although information visualization (infovis) technologies have proven indispensable tools for making sense of complex data, wide-spread deployment has yet to take hold, as successful infovis applications are often difficult to author and require domain-specific customization. To address these issues, we have created prefuse, a software framework for creating dynamic visualizations of both structured and unstructured data. prefuse provides theoretically-motivated abstractions for the design of a wide range of visualization applications, enabling programmers to string together desired components quickly to create and customize working visualizations. To evaluate prefuse we have built both existing and novel visualizations testing the toolkit's flexibility and performance, and have run usability studies and usage surveys finding that programmers find the toolkit usable and effective.	prefuse: a toolkit for interactive information visualization	NA:NA:NA	2018
George G. Robertson:Mary P. Czerwinski:John E. Churchill	In this paper we describe a novel approach to the visualization of the mapping between two schemas. Current approaches to visually defining such a mapping fail when the schemas or maps become large. The new approach uses various information visualization techniques to simplify the view, making it possible for users to effectively deal with much larger schemas and maps. A user study verifies that the new approach is useful, usable, and effective. The primary contribution is a demonstration of novel ways to effectively present highly complex information.	Visualization of mappings between schemas	NA:NA:NA	2018
Cecilia R. Aragon:Marti A. Hearst	Many aircraft accidents each year are caused by encounters with invisible airflow hazards. Recent advances in aviation sensor technology offer the potential for aircraft-based sensors that can gather large amounts of airflow velocity data in real-time. With this influx of data comes the need to study how best to present it to the pilot - a cognitively overloaded user focused on a primary task other than that of information visualization.We focus on one particular aviation application, but the results may be relevant to user interfaces in other operationally stressful environments.	Improving aviation safety with information visualization: a flight simulation study	NA:NA	2018
Sharon Oviatt	NA	Session details: Pen-based interfaces	NA	2018
Ken Hinckley:Patrick Baudisch:Gonzalo Ramos:Francois Guimbretiere	We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.	Design and analysis of delimiters for selection-action pen gesture phrases in scriboli	NA:NA:NA:NA	2018
Yang Li:Ken Hinckley:Zhiwei Guan:James A. Landay	Inking and gesturing are two central tasks in pen-based user interfaces. Switching between modes for entry of uninterpreted ink and entry of gestures is required by many pen-based user interfaces. Without an appropriate mode switching technique, pen-based interactions in such situations may be inefficient and cumbersome. In this paper, we investigate five techniques for switching between ink and gesture modes in pen interfaces, including a pen-pressure based mode switching technique that allows implicit mode transition. A quantitative experimental study was conducted to evaluate the performance of these techniques. The results suggest that pressing a button with the non-preferred hand offers the fastest performance, while the technique of holding the pen still is significantly slower and more prone to error than the other techniques. Pressure, while promising, did not perform as well as the non-preferred hand button with our current implementation.	Experimental analysis of mode switching techniques in pen-based user interfaces	NA:NA:NA:NA	2018
Gloria Mark	NA	Session details: Affect and intimacy	NA	2018
Frank Vetere:Martin R. Gibbs:Jesper Kjeldskov:Steve Howard:Florian 'Floyd' Mueller:Sonja Pedell:Karen Mecoles:Marcus Bunyan	Intimacy is a crucial element of domestic life, and many interactive technologies designed for other purposes have been appropriated for use within intimate relationships. However, there is a deficit in current understandings of how technologies are used within intimate relationships, and how to design technologies to support intimate acts. In this paper we report on work that has addressed these deficits. We used cultural probes and contextual interviews and other ethnographically informed techniques to investigate how interactive technologies are used within intimate relationships. From this empirical work we generated a thematic understanding of intimacy and the use of interactional technologies to support intimate acts. We used this understanding to inform the design of intimate technologies. A selection of our design concepts is also presented.	Mediating intimacy: designing technologies to support strong-tie relationships	NA:NA:NA:NA:NA:NA:NA:NA	2018
Enrico Costanza:Samuel A. Inverso:Rebecca Allen	Using a mobile device in a social context should not cause embarrassment and disruption to the immediate environment. Interaction with mobile and wearable devices needs to be subtle, discreet and unobtrusive. Therefore, we promote the idea of "intimate interfaces": discrete interfaces that allow control of mobile devices through subtle gestures in order to gain social acceptance. To achieve this goal, we present an electromyogram (EMG) based wearable input device which recognizes isometric muscular activity: activity related to very subtle or no movement at all. In the online experiment reported, the EMG device, worn on an armband around the bicep, was able to reliably recognize a motionless gesture without calibration or training across users with different muscle volumes. Hence, EMG-based input devices can provide an effective solution for designing mobile interfaces that are subtle and intimate, and therefore socially acceptable.	Toward subtle intimate interfaces for mobile devices using an EMG controller	NA:NA:NA	2018
Jenni Anttonen:Veikko Surakka	New methods for unobtrusive monitoring of computer users' emotion psychophysiology are very much needed in human-computer interaction research. The present aim was to study heart rate changes during emotionally provocative stimulation. Six-second long auditory, visual, and audiovisual emotionally negative, neutral, and positive stimuli were presented to 24 participants. Heart rate responses were measured with a regular office chair embedded with electromechanical film (the EMFi chair) and with traditional earlobe photoplethysmography (PPG). Ratings of the stimuli were also collected. The results showed that the two heart rate measurements were significantly correlated, r = 0.99. In line with other studies the results showed that, in general, heart rate decelerated in response to emotional stimulation and it decelerated the most in response to negative stimuli as compared with responses to positive and neutral stimuli. Especially, emotional stimulation caused significant changes in heart rate at the 6th second from the stimulus onset. We suggest that the EMFi chair could be used in human-computer interaction for unobtrusive measurement of the user's emotional reactions.	Emotions and heart rate while sitting on a chair	NA:NA	2018
Terry Winograd	NA	Session details: Assistive applications	NA	2018
Kimberly Tee:Karyn Moffatt:Leah Findlater:Eve MacGregor:Joanna McGrenere:Barbara Purves:Sidney S. Fels	Cooking is a daily activity for many people. However, traditional text recipes are often prohibitively difficult to follow for people with language disorders, such as aphasia. We have developed a multi-modal application that leverages the retained ability of aphasic individuals to recognize image-based representations of objects, providing a presentation format that can be more easily followed than a traditional text recipe. Through a systematic approach to developing a visual language for cooking, and the subsequent case study evaluation of a prototype developed according to this language, we show that a combination of visual instructions and navigational structure can help individuals with relatively large language deficits to cook more independently.	A visual recipe book for persons with language impairments	NA:NA:NA:NA:NA:NA:NA	2018
Mike Wu:Ron Baecker:Brian Richards	We present the participatory design and evaluation of an orientation aid for individuals who have anterograde amnesia. Our design team included six amnesics who have extreme difficulty storing new memories. We describe the methods we used to enable the participation of individuals with such severe cognitive impairments. Through this process, we have conceived, designed, and developed the OrientingTool, a software application for Personal Digital Assistants that can be used by amnesics to orient themselves when feeling lost or disoriented. Two complementary studies were conducted to evaluate the effectiveness of this tool in ecologically valid contexts. Our findings suggest that the OrientingTool can improve an amnesic's independence and confidence in managing situations when disoriented, and that participatory design may be productively used with participants who have significant cognitive disabilities.	Participatory design of an orientation aid for amnesics	NA:NA:NA	2018
Jim Rowan:Elizabeth D. Mynatt	A growing social problem in the U.S., and elsewhere, is enabling older adults to continue living independently, as opposed to moving to an institutional care setting. One key part of this complex problem is providing awareness of senior adults day-to-day activities, promoting "peace of mind" for extended family members. The Digital Family Portrait (DFP) is one approach to providing peace of mind that has shown promise. To date, research on the DFP has been limited to wizard-of-oz based experiments over short periods of time. This paper describes a DFP field trial in which a private home was instrumented with sensors rather than relying on input from wizard-of-oz technology. This field trial was conducted over a period of one year between an aging parent living alone in her own home and her adult child living 50 miles distant. From this field trial we find that even though there was no critical reason for the adult child to be concerned about his mother, all involved parties found utility in the presence of the DFP, even those family members who were not directly involved in the field trial itself.	Digital Family Portrait Field Trial: Support for Aging in Place	NA:NA	2018
Wendy Mackay	NA	Session details: Educational & help systems	NA	2018
Matthew Kam:Jingtao Wang:Alastair Iles:Eric Tse:Jane Chiu:Daniel Glaser:Orna Tarshish:John Canny	We describe Livenotes, a shared whiteboard system and educational practice that uses wireless communication and tablet computing to support real-time conversations within small groups of students during lectures, independent of class size. We present an interface design that enables group members to interact with one another by taking lecture notes cooperatively, as well as to augment student note-taking by providing instructor slides in the background to annotate over. Livenotes was designed to facilitate more efficient, stimulating modes of learning that other collaborative approaches do not. We report how the system impacts cooperative learning in an undergraduate class and how students interacted with background slides in the workspace. We conclude with directions for improving the system and learning practice.	Livenotes: a system for cooperative and augmented note-taking in lectures	NA:NA:NA:NA:NA:NA:NA:NA	2018
Caitlin Kelleher:Randy Pausch	Users of traditional tutorials and help systems often have difficulty finding the components described or pictured in the procedural instructions. Users also unintentionally miss steps, and perform actions that the documentation's authors did not intend, moving the application into an unknown state. We introduce Stencils, an interaction technique for presenting tutorials that uses translucent colored stencils containing holes that direct the user's attention to the correct interface component and prevent the user from interacting with other components. Sticky notes on the stencil's surface provide necessary tutorial material in the context of the application. In a user study comparing a Stencils-based and paper-based version of the same tutorial in Alice, a complex software application designed to teach introductory computer programming, we found that users of a Stencils-based tutorial were able complete the tutorial 26% faster, with fewer errors, and less reliance on human assistance. Users of the Stencils-based and paper-based tutorials attained statistically similar levels of learning.	Stencils-based tutorials: design and evaluation	NA:NA	2018
Susan Yee:Kat S. Park	StudioBRIDGE is an awareness system, based on instant messaging (IM), developed for students working in open studio spaces in the Architecture Department at the Massachusetts Institute of Technology (MIT). The goal of StudioBRIDGE is to help students initiate online and offline interactions by giving them an awareness of nearby people, groups, locations, and events of the community. Even when students are working in close proximity to each other, they are often not aware of the activities and expertise of their colleagues nearby. We believe that this integrated awareness could lead to increased peer learning and expertise sharing by encouraging informal social communication, particularly in groups whose members have existing social and physical ties. In this paper, we describe the user community and the motivation, design, and initial pilot deployment of StudioBRIDGE.	StudioBRIDGE: using group, location, and event information to bridge online and offline encounters for co-located learning groups	NA:NA	2018
Clifford Nass	NA	Session details: In-vehicle interfaces	NA	2018
Mike Schneider:Sara Kiesler	Cell phone conversations distract drivers. This research explores the possibility of reducing distracting by providing callers with remote information about the driver's traffic. We asked whether providing such contextual information would change the caller's conversation such that drivers would be less distracted. In Experiment 1 we examined this question in a low-fidelity driving simulator; in Experiment 2 we examined this question in a higher fidelity simulator. In both experiments, remote callers and passengers were distracting. Providing traffic information to the remote caller significantly reduced crashes in the low fidelity tests and significantly reduced passing in the high fidelity tests, compared with the control conditions. We consider the implications for development of remote displays or signals to promote driving safety.	Calling while driving: effects of providing remote traffic context	NA:NA	2018
Joonhwan Lee:Jodi Forlizzi:Scott E. Hudson	In-vehicle navigation has changed substantially in recent years, due to the advent of computer generated maps and directions. However, these maps are still problematic, due to a mismatch between the complexity of the maps and the attentional demands of driving. In response to this problem, we are developing the MOVE (Maps Optimized for Vehicular Environments) system. This system will provide situationally appropriate map information by presenting information that uses appropriate amounts of the driver's attention. In this paper, we describe our findings of studies to help shape the design of the MOVE system, including studies on map reading and in-vehicle navigation, and studies on the effectiveness of a variety of contextually optimized route map visualizations in a simulated driving context.Results show that contextually optimized displays designed for the MOVE system should significantly reduce perceptual load in the context of driving. In our laboratory experiment there was a six-fold decrease in the total map display fixation time and nearly threefold decrease in the number of glances needed to interpret the contextually optimized display compared to a static display.	Studying the effectiveness of MOVE: a contextually optimized in-vehicle navigation system	NA:NA:NA	2018
Dario D. Salvucci:Mark Zuber:Ekaterina Beregovaia:Daniel Markley	As driver distraction from in-vehicle devices increasingly becomes a concern on our roadways, researchers have searched for better scientific understanding of distraction along with better engineering tools to build less distracting devices. This paper presents a new system, Distract-R, that allows designers to rapidly prototype and evaluate new in-vehicle interfaces. The core engine of the system relies on a rigorous cognitive model of driver performance, which the system integrates with models of behavior on the prototyped interfaces to generate predictions of distraction. Distract-R allows a designer to prototype basic interfaces, demonstrate possible tasks on these interfaces, specify relevant driver characteristics and driving scenarios, and finally simulate, visualize, and analyze the resulting behavior as generated by the cognitive model. The paper includes two sample studies that demonstrate the system's ability to account for effects of input modality and driver age on performance.	Distract-R: rapid prototyping and evaluation of in-vehicle interfaces	NA:NA:NA:NA	2018
Michel Beaudouin-Lafon	NA	Session details: Physical interaction	NA	2018
David Holman:Roel Vertegaal:Mark Altosaar:Nikolaus Troje:Derek Johns	In this paper, we present Paper Windows, a prototype windowing environment that simulates the use of digital paper displays. By projecting windows on physical paper, Paper Windows allows the capturing of physical affordances of paper in a digital world. The system uses paper as an input device by tracking its motion and shape with a Vicon Motion Capturing System. We discuss the design of a number of interaction techniques for manipulating information on paper displays.	Paper windows: interaction techniques for digital paper	NA:NA:NA:NA:NA	2018
Russell Kruger:Sheelagh Carpendale:Stacey D. Scott:Anthony Tang	Previous research has shown that rotation and orientation of items plays three major roles during collaboration: comprehension, coordination and communication. Based on these roles of orientation and advice from kinesiology research, we have designed the Rotate'N Translate (RNT) interaction mechanism, which provides integrated control of rotation and translation using only a single touch-point for input. We present an empirical evaluation comparing RNT to a common rotation mechanism that separates control of rotation and translation. Results of this study indicate RNT is more efficient than the separate mechanism and better supports the comprehension, coordination and communication roles of orientation.	Fluid integration of rotation and translation	NA:NA:NA:NA	2018
Stephen Voida:Mark Podlaseck:Rick Kjeldsen:Claudio Pinhanez	Are the object manipulation techniques traditionally used in head-mounted displays (HMDs) applicable to augmented reality based projection systems? This paper examines the differences between HMD- and projector/camera-based AR interfaces in the light of a manipulation task involving documents and applications projected on common office surfaces such as tables, walls, cabinets, and floor. We report a Wizard of Oz study where subjects were first asked to create gesture/voice commands to move 2D objects on those surfaces and then exposed to gestures created by the authors. Among the options, subjects could select the object to be manipulated using voice command; touching, pointing, and grabbing gesture; or a virtual mouse. The results show a strong preference for a manipulation interface based on pointing gestures using small hand movements and involving minimal body movement. Direct touching of the object was also common when the object being manipulated was within the subjects' arm reach. Based on these results, we expect that the preferred interface resembles, in many ways, the egocentric model traditionally used in AR.	A study on the manipulation of 2D objects in a projector/camera-based augmented reality environment	NA:NA:NA:NA	2018
Kristina Höök	NA	Session details: Technology in the home	NA	2018
Irina A. Shklovski:Scott D. Mainwaring	One of the outcomes of massive adoption of technology is that much of daily technology use and consumption is embedded into "unremarkable" daily life routines. Occasionally, these routines undergo major shifts, often in conjunction with major life events such as marriage, birth of a child, or a residential move. We propose a model of settling into a new location as a function of balance between the pull of the things left behind and the demands of the new and unknown. It is through this experience of being unsettled that we explore the processes of behavior adjustment and re-evaluation of old patterns of technology use as it relates to the old location and the demands of the new location.	Exploring technology adoption and use through the lens of residential mobility	NA:NA	2018
Ernesto Arroyo:Leonardo Bonanni:Ted Selker	This paper presents an exploration of user interfaces, persuasive interfaces and feedback techniques in the domain of the sink. Waterbot is a system to inform and motivate behavior at the sink for the purpose of increasing safety and functionality and ultimately motivating behavior change. Waterbot can be adapted to many current sink scenarios and demonstrates the breadth of interaction possible at the point of use of water. It functions as a platform for experimenting with safety, hygiene and water conservation in a sink. This paper presents the feedback and persuasion techniques of augmented physical interfaces with value-added design, automation, just-in-time prompts, positive and negative reinforcement, social validation and adaptive interfaces. Four design iterations are presented to affect behavior at the increasing cognitive levels of safety, functionality and behavior change.	Waterbot: exploring feedback and persuasive techniques at the sink	NA:NA:NA	2018
Alex S. Taylor:Laurel Swan	In this paper we introduce the idea of organizing systems. Through a number of examples from an ongoing ethnographic study of family life, we suggest that organizing systems come about through the artful design and use of informational artifacts in the home, such as calendars, paper notes, to-do lists, etc. These systems are not only seen to organize household routines and schedules, but also, crucially, to shape the social relations between family members. Drawing attention to the material properties of informational artifacts and how assemblies of these artifacts come to make up organizing systems, we discuss some general implications for designing information technology for the home. Most importantly, we suggest that technologies must be designed to accommodate the rich and diverse ways in which people organize their homes, providing them with the resources to artfully construct their own systems rather than enforcing ones that are removed from their own experiences.	Artful systems in the home	NA:NA	2018
Gerrit van der Veer	NA	Session details: Safety in a complex world	NA	2018
C. W. Johnson	The collapse of buildings, such as terminal 2E at Paris' Charles de Gaule Airport, and of fires, such as the Rhode Island, Station Night Club tragedy, has focused public attention on the safety of large public buildings. Initiatives in the United States and in Europe have led to the development of interactive simulators that model evacuation from these buildings. The tools avoid some of the ethical and legal problems from simulating evacuations; many people were injured during the 1993 evacuation of the World Trade Center (WTC) complex. They also use many concepts that originate within the CHI communities. For instance, some simulators use simple task models to represent the occupants' goal structures as they search for an available exit. However, the recent release of the report from the National Commission on Terrorist Attacks upon the United States (the '9/11 commission') has posed serious questions about the design and use of this particular class of interactive systems. This paper argues that simulation research needs to draw on insights from the CHI communities in order to meet some the challenges identified by the 9/11 commission.	Applying the lessons of the attack on the world trade center, 11th September 2001, to the design and use of interactive evacuation simulations	NA	2018
Ben Bederson	NA	Session details: Small devices 2	NA	2018
Boreum Choi:Inseong Lee:Jinwoo Kim:Yunsuk Jeon	As the use of mobile data services has spread across the globe, the effect of cultural differences on user requirements has become important issue. To date, however, little research has been conducted on the role cultural factors play in the design of mobile data services. This paper proposes a set of critical design attributes for mobile data services that takes cross-cultural differences into account. To determine these attributes, we devised a qualitative method and conducted in-depth long interviews in Korea, Japan, and Finland. We found 52 attributes considered important by mobile data service users, and 11 critical attributes that showed a clear correlation with characteristics of the user's culture. The paper concludes with a discussion of limitations and of implications for developers of mobile data services.	A qualitative cross-national study of cultural influences on mobile data service design	NA:NA:NA:NA	2018
Xing Xie:Hao Liu:Simon Goumaz:Wei-Ying Ma	Mobile devices which can capture and view pictures are becoming increasingly common in our life. The limitation of these small-form-factor devices makes the user experience of image browsing quite different from that on desktop PCs. In this paper, we first present a user study on how users interact with a mobile image browser with basic functions. We found that on small displays, users tend to use more zooming and scrolling actions in order to view interesting regions in detail. From this fact, we designed a new method to detect user interest maps and extract user attention objects from the image browsing log. This approach is more efficient than image-analysis based methods and can better represent users' actual interest. A smart image viewer was then developed based on user interest analysis. A second experiment was carried out to study how users behave with such a viewer. Experimental results demonstrate that the new smart features can improve the browsing efficiency and are a good compliment to traditional image browsers.	Learning user interest for image browsing on small-form-factor devices	NA:NA:NA:NA	2018
Heidi Lam:Patrick Baudisch	In order to display web pages designed for desktop-sized monitors, some small-screen web browsers provide single-column or thumbnail views. Both have limitations. Single-column views affect page layouts and require users to scroll significantly more. Thumbnail views tend to reduce contained text beyond readability, so differentiating visually similar areas requires users to zoom. In this paper, we present Summary Thumbnails-thumbnail views enhanced with readable text fragments. Summary Thumbnails help users identify viewed material and distinguish between visually similar areas. In our user study, participants located content in web pages about 41% faster and with 71% lower error rates when using the Summary Thumbnail interface than when using the Single-Column interface, and zoomed 59% less than when using the Thumbnail interface. Nine of the eleven participants preferred Summary Thumbnails over both the Thumbnail and Single-Column interfaces.	Summary thumbnails: readable overviews for small screen web browsers	NA:NA	2018
Victoria Bellotti	NA	Session details: Email and security	NA	2018
Laura A. Dabbish:Robert E. Kraut:Susan Fussell:Sara Kiesler	Email consumes significant time and attention in the workplace. We conducted an organizational survey to understand how and why people attend to incoming email messages. We examined people's ratings of message importance and the actions they took on specific email messages, based on message characteristics and characteristics of receivers and senders. Respondents kept half of their new messages in the inbox and replied to about a third of them. They rated messages as important if they were about work and required action. Importance, in turn, had a modest impact on whether people replied to their incoming messages and whether they saved them. The results indicate that factors other than message importance (e.g., their social nature) also determine how people handle email. Overall, email usage reflects attentional differences due both to personal propensities and to work demands and relationships.	Understanding email use: predicting action on a message	NA:NA:NA:NA	2018
Simson L. Garfinkel:David Margrave:Jeffrey I. Schiller:Erik Nordlander:Robert C. Miller	Cryptographically protected email has a justly deserved reputation of being difficult to use. Based on an analysis of the PEM, PGP and S/MIME standards and a survey of 470 merchants who sell products on Amazon.com, we argue that the vast majority of Internet users can start enjoying digitally signed email today. We present suggestions for the use of digitally signed mail in e-commerce and simple modifications to webmail systems that would significantly increase integrity, privacy and authorship guarantees that those systems make. We then show how to use the S/MIME standard to extend such protections Internet-wide. Finally, we argue that software vendors must make minor changes to the way that mail clients store email before unsophisticated users can safely handle mail that is sealed with encryption.	How to make secure email easier to use	NA:NA:NA:NA:NA	2018
Kumar Chellapilla:Kevin Larson:Patrice Simard:Mary Czerwinski	HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.	Designing human friendly human interaction proofs (HIPs)	NA:NA:NA:NA	2018
Tom Erickson	NA	Session details: Public life	NA	2018
Steve Benford:Duncan Rowland:Martin Flintham:Adam Drozd:Richard Hull:Josephine Reid:Jo Morrison:Keri Facer	We study a collaborative location-based game in which groups of 'lions' hunt together on a virtual savannah that is overlaid on an open playing field. The game implements a straight-forward approach to location-based triggering in which players must be in the same spatial locale in order to share information and act together. Comparison of video recordings of physical play with system recordings of game events reveals subtle and complex interactions between highly dynamic player behavior and the underlying technology. While players exhibit a fluid approach to group formation, the system embodies a more rigid view, leading to difficulties with sharing context and coordinating actions, most notably when groups of players span virtual locale boundaries or initiate actions while on the move. We propose techniques for extending locales to support more flexible grouping and also discuss the broader implications of our findings for location-based applications in general.	Life on the edge: supporting collaboration in location-based experiences	NA:NA:NA:NA:NA:NA:NA:NA	2018
Eric Lee:Marius Wolf:Jan Borchers	Designing interactive conducting exhibits for public spaces poses unique challenges, primarily because the conceptual model of conducting music varies amongst users. In a user study, we compared how conductors and non-conductors place their beats when conducting to a fixed orchestral recording of Radetzky March, and found significant differences between these two groups. Conductors lead the actual music beat with their gestures by an average of 150 ms, compared to 50 ms for non-conductors; non-conductors also vary their placement of the beat 50% more than conductors. Furthermore, we found differences in how users conceptually mapped their gestures to the music, such as conducting to the musical rhythm rather than to the beat. We are incorporating these results into an upcoming conducting system for public spaces to increase its usability; we believe they also apply to a more general class of musical gestures such as dance.	Improving orchestral conducting systems in public spaces: examining the temporal characteristics and conceptual models of conducting gestures	NA:NA:NA	2018
Stuart Reeves:Steve Benford:Claire O'Malley:Mike Fraser	Interaction is increasingly a public affair, taking place in our theatres, galleries, museums, exhibitions and on the city streets. This raises a new design challenge for HCI - how should spectators experience a performer's interaction with a computer? We classify public interfaces (including examples from art, performance and exhibition design) according to the extent to which a performer's manipulations of an interface and their resulting effects are hidden, partially revealed, fully revealed or even amplified for spectators. Our taxonomy uncovers four broad design strategies: 'secretive,' where manipulations and effects are largely hidden; 'expressive,' where they tend to be revealed enabling the spectator to fully appreciate the performer's interaction; 'magical,' where effects are revealed but the manipulations that caused them are hidden; and finally 'suspenseful,' where manipulations are apparent but effects are only revealed as the spectator takes their turn.	Designing the spectator experience	NA:NA:NA:NA	2018
Shelly Farnham	NA	Session details: Social behaviors	NA	2018
Mary Flanagan:Daniel C. Howe:Helen Nissenbaum	Significant work in the CHI community has focused on designing systems that support human values. Designers and engineers have also become increasingly aware of ways in which the artifacts they create can embody political, social, and ethical values. Despite such an awareness, there has been little work towards producing practical methodologies that systematically incorporate values into the design process. Many designers struggle to find a balance between their own values, those of users and other stakeholders, and those of the surrounding culture. In this paper, we present the RAPUNSEL project as a case study of game design in a values-rich context and describe our efforts toward navigating the complexities this entails. Additionally, we present initial steps toward the development of a systematic methodology for discovery, analysis, and integration of values in technology design in the hope that others may both benefit from and build upon this work.	Values at play: design tradeoffs in socially-oriented game design	NA:NA:NA	2018
Dan Olsen	NA	Session details: Display	NA	2018
Ruth Rosenholtz:Yuanzhen Li:Jonathan Mansfield:Zhenlan Jin	Management of clutter is an important factor in the design of user interfaces and information visualizations, allowing improved usability and aesthetics. However, clutter is not a well defined concept. In this paper, we present the Feature Congestion measure of display clutter. This measure is based upon extensive modeling of the saliency of elements of a display, and upon a new operational definition of clutter. The current implementation is based upon two features: color and luminance contrast. We have tested this measure on maps that observers ranked by perceived clutter. Results show good agreement between the observers' rankings and our measure of clutter. Furthermore, our measure can be used to make design suggestions in an automated UI critiquing tool.	Feature congestion: a measure of display clutter	NA:NA:NA:NA	2018
Amy Skopik:Carl Gutwin	The distortion caused by an interactive fisheye lens can make it difficult for people to remember items and locations in the data space. In this paper we introduce the idea of visit wear - a visual representation of the places that the user has previously visited - as a way to improve navigation in spaces affected by distortion. We outline the design dimensions of visit wear, and report on two studies. The first shows that increasing the distortion of a fisheye view does significantly reduce people's ability to remember object locations. The second study looks at the effects of visit wear on performance in revisitation tasks, and shows that both completion time and error rates are significantly improved when visit wear is present. Visit wear works by changing the revisitation problem from one of memory to one of visual search. Although there are limitations to the technique, visit wear has the potential to substantially improve the usability both of fisheye views and of graphical information spaces more generally.	Improving revisitation in fisheye views with visit wear	NA:NA	2018
Daniel Russell	NA	Session details: Enhancing virtual spaces and large displays	NA	2018
Perttu Hämäläinen:Tommi Ilmonen:Johanna Höysniemi:Mikko Lindholm:Ari Nykänen	This paper presents Kick Ass Kung-Fu, a martial arts game installation where the player fights virtual enemies with kicks and punches as well as acrobatic moves such as cartwheels. Using real-time image processing and computer vision, the video image of the user is embedded inside 3D graphics. Compared to previous work, our system uses a profile view and two displays, which allows an improved view of many martial arts techniques. We also explore exaggerated motion and dynamic slow-motion effects to transform the aesthetic of kung-fu movies into an interactive, embodied experience. The system is described and analyzed based on results from testing the game in a theater, in a television show, and in a user study with 46 martial arts practitioners.	Martial arts in artificial reality	NA:NA:NA:NA:NA	2018
Azam Khan:Justin Matejka:George Fitzmaurice:Gordon Kurtenbach	We describe a new interaction technique, called a spotlight, for directing the visual attention of an audience when viewing data or presentations on large wall-sized displays. A spotlight is simply a region of the display where the contents are displayed normally while the remainder of the display is somewhat darkened. In this paper we define the behavior of spotlights, show unique affordances of the technique, and discuss design characteristics. We also report on experiments that show the benefit of using the spotlight a large display and standard desktop configuration. Our results suggest that the spotlight is preferred over the standard cursor and outperforms it by a factor of 3.4 on a wall-sized display.	Spotlight: directing users' attention on large displays	NA:NA:NA:NA	2018
Maria Stone	NA	Session details: Look	NA	2018
David Nguyen:John Canny	MultiView is a new video conferencing system that supports collaboration between remote groups of people. MultiView accomplishes this by being spatially faithful. As a result, MultiView preserves a myriad of nonverbal cues, includ-ing gaze and gesture, in a way that should improve com-munication. Previous systems fail to support many of these cues because a single camera perspective warps spatial char-acteristics in group-to-group meetings. In this paper, we present a formal definition of spatial faithfulness. We then apply a metaphor-based design methodology to help us spec-ify and evaluate MultiView's support of spatial faithfulness. We then present results from a low-level user study to mea-sure MultiView's effectiveness at conveying gaze and ges-ture perception. MultiView is the first practical solution to spatially faithful group-to-group conferencing, one of the most common applications of video conferencing.	MultiView: spatially faithful group video conferencing	NA:NA	2018
Ken Hinckley	NA	Session details: Papers on presenting papers	NA	2018
QianYing Wang:Clifford Nass	When devices become less visible and recede to the background, what kinds of influences would they have on users'? This paper presents two experiments (N=48 and N=96) that examine the effects of four different types of microphones (and voice vs. text output) on user's behaviors and attitudes. The microphones differ with respect to their visibility and users' mobility. Participants performed two different tasks: a standard creativity task and a standard disclosure task. Mobility facilitated creativity and disclosure of personal information. Recording reminder discouraged creativity and disclosure. Output modality had no significant effect. Implications for ubiquitous computing and voice user interfaces are discussed.	Less visible and wireless: two experiments on the effects of microphone type on users' performance and perception	NA:NA	2018
Kori Inkpen	NA	Session details: Designing for and with kids	NA	2018
Morris Williams:Owain Jones:Constance Fleuriot:Lucy Wood	In this paper, we describe design work with 36 children aged 9 and 10 in Bristol, United Kingdom. The design work was conducted using emerging mobile and wireless technology which has the potential to impact on the problematic issue of children's access to, use of, and safety within the wider urban environment. A series of workshops are described in which children were encouraged to think about their use of an outdoor space before their introduction to the technology. The children designed and created "soundscapes" in the outdoor environment. The future potential impact of the technology on children's spatial practice is discussed and the concept of children "tagging" environmental hazards is raised.	Children and emerging wireless technologies: investigating the potential for spatial practice	NA:NA:NA:NA	2018
Sonia Chiasson:Carl Gutwin	Designers of children's technology are often more interested in user motivation than those who design systems for adults. Since children's technology often has aims such as education or practice, keeping the user engaged and interested is an important objective. The Media Equation - the idea that people respond socially to computers - shows potential for improving engagement and motivation. Studies have shown that people are more positive about both themselves and the computer when software exhibits certain social characteristics. To explore the possible value of the Media Equation as a design concept for children's software, we replicated two of the original Media Equation studies, concerning the effects of praise and team formation. Our results, however, were contrary to our expectations: we did not find evidence that children were significantly affected by social characteristics in software, and adults were influenced in only a few cases. These results raise questions about using the Media Equation as a design principle for children's software.	Testing the media equation with children	NA:NA	2018
K. K. Lamberty:Janet L. Kolodner	In this paper, we describe how encouraging children to talk to the camera can structure their behavior and provide them opportunity for reflection. Encouraging "camera talk," interactions directed at the camera, can effectively elicit verbal comments from children participants. We describe a study in which children participants were told that they could tell the camera anything they wanted to about the designs they were making using a piece of educational software, but not to behave in a disruptive manner for the camera. By allowing children to interact with the camera in a particular way, rather than encouraging them to ignore its presence, we were able to elicit information about some children's design activities, thoughts, and struggles. The camera became an integral part of the socio-technical system for some children. This method may be useful to researchers interested in what children are thinking about in-the-moment as they work with software.	Camera talk: making the camera a partial participant	NA:NA	2018
John Canny	NA	Session details: Educational issues	NA	2018
Loucas Louca	This is a descriptive case study investigating the use of two computer-based programming environments (CPEs), MicroWorlds™ Logo (MW) and Stagecast Creator™ (SC) for collaborative scientific modeling. The purpose of the study was to investigate and comparatively describe student approaches to scientific modeling through the use of textual or graphical program languages (PL). I analyzed student activities and conversations in two after-school clubs, one working with MW and the other with SC, using contextual inquiry, analysis of student conversation and artifact analysis. The findings suggest that student work with CPEs differed between different PL. Students used SC to create games (focusing on the overall story) whereas MW students used MW through a frame of formal programming. Programming in SC was much easier than MW, whereas reading code in MW was more tangible. Findings suggest that differences in student approaches to scientific modeling through programming need to be considered by educators seeking to engage students in such activities and software developers seeking to develop CPEs for young learners.	The syntax or the story behind it?: a usability study of student work with computer-based programming environments in elementary science	NA	2018
Oren Zuckerman:Saeed Arida:Mitchel Resnick	This paper introduces a new framework for thinking about tangible interfaces in education, with specific focus on abstract problem domains.Manipulatives are physical objects specifically designed to foster learning. We offer a new classification of Manipulatives: "Froebel-inspired Manipulatives" (FiMs) and "Montessori-inspired Manipulatives" (MiMs). We argue that FiMs are design materials, fostering modeling of real-world structures, while MiMs foster modeling of more abstract structures. We show that our classification extends to computationally enhanced versions of manipulatives.We present Digital MiMs - computationally enhanced building blocks. We describe two prototypical members of the Digital MiMs class: FlowBlocks and SystemBlocks, physical, modular interactive systems that serve as general-purpose modeling and simulation tools for dynamic behavior. We present findings from qualitative studies, and conclude that digital MiMs are accessible to young children, engaging, and encourage learning of abstract structures of dynamic behavior through an iterative process of hands-on modeling, simulating, and analogizing.	Extending tangible interfaces for education: digital montessori-inspired manipulatives	NA:NA:NA	2018
Laura Beckwith:Margaret Burnett:Susan Wiedenbeck:Curtis Cook:Shraddha Sorte:Michelle Hastings	Although gender differences in a technological world are receiving significant research attention, much of the research and practice has aimed at how society and education can impact the successes and retention of female computer science professionals-but the possibility of gender issues within software has received almost no attention. If gender issues exist with some types of software features, it is possible that accommodating them by changing these features can increase effectiveness, but only if we know what these issues are. In this paper, we empirically investigate gender differences for end users in the context of debugging spreadsheets. Our results uncover significant gender differences in self-efficacy and feature acceptance, with females exhibiting lower self-efficacy and lower feature acceptance. The results also show that these differences can significantly reduce females' effectiveness.	Effectiveness of end-user debugging software features: are there gender issues?	NA:NA:NA:NA:NA:NA	2018
Robin Jeffries	NA	Session details: Understanding users and usage patterns	NA	2018
David R. Millen:Michael J. Muller:Werner Geyer:Eric Wilcox:Beth Brownholtz	This paper describes a new collaboration technology that is based on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared items with dynamic membership. We introduce our design concepts, and we provide a detailed analysis of user behavior during a five month field study. We present the patterns of media use that we observed, using a variety of analytical methods including thread clustering and analysis. Major findings include four patterns of media use: communicating, exchanging mixed objects, coordinating, (e.g., of status reports), and semi-archival filing. We observed differential use of various media including highly variable use of chats and surprisingly informal uses of files. We discuss the implications for the design of mixed media collaborative tools to support the work activities of small to medium sized work teams.	Patterns of media use in an activity-centric collaborative environment	NA:NA:NA:NA:NA	2018
A.J. Bernheim Brush:Xiaoqing Wang:Tammara Combs Turner:Marc A. Smith	We describe a usage study of NetscanTech, a system that generates and publishes daily a range of social metrics across three dimensions: newsgroup, author, and thread, for a set of approximately 15,000 technical newsgroups in Usenet. We bring together three interlinked datasets: survey data, usage log data and social accounting data from Usenet participation, to triangulate the relationship between various user roles and differential usage of social metrics in NetscanTech. We found our most frequent users focused on information related to individual authors far more than any other information provided. In contrast, users that visited less frequently focused more on information related to newsgroups and viewing newsgroup metrics. Our results suggest features that designers and developers of online communities may wish to include in their interfaces to support the cultivation of different community roles.	Assessing differential usage of usenet social accounting meta-data	NA:NA:NA:NA	2018
Scott Carter:Jennifer Mankoff	In this paper, we investigate how the choice of media for capture and access affects the diary study method. The diary study is a method of understanding participant behavior and intent in situ that minimizes the effects of observers on participants. We first situate diary studies within a framework of field studies and review related literature. We then report on three diary studies we conducted that involve photographs, audio recordings, location information and tangible artifacts. We then analyze our findings, specifically addressing the following questions: How do context information and episodic memory prompts captured by participants vary with media? In what way do different media "jog" memory? How do different media affect the diary study process? These questions are particularly important for diary studies because they can be especially useful as compared to other methods when a participant intends to do an action but does not or when actions are particularly difficult to sense. We also built and tested a tool based on participant and researcher frustrations with the method. Our contribution includes suggested modifications to traditional diary techniques that enable annotation and review of captured media; a new variation on the diary study appropriate for researchers using digital capture media; and a lightweight tool to support it, motivated by past work and findings from our studies.	When participants do the capturing: the role of media in diary studies	NA:NA	2018
John Tang	NA	Session details: Interruptions and attention 2: attending to interruptions	NA	2018
Joyce Ho:Stephen S. Intille	The potential for sensor-enabled mobile devices to proactively present information when and where users need it ranks among the greatest promises of ubiquitous computing. Unfortunately, mobile phones, PDAs, and other computing devices that compete for the user's attention can contribute to interruption irritability and feelings of information overload. Designers of mobile computing interfaces, therefore, require strategies for minimizing the perceived interruption burden of proactively delivered messages. In this work, a context-aware mobile computing device was developed that automatically detects postural and ambulatory activity transitions in real time using wireless accelerometers. This device was used to experimentally measure the receptivity to interruptions delivered at activity transitions relative to those delivered at random times. Messages delivered at activity transitions were found to be better received, thereby suggesting a viable strategy for context-aware message delivery in sensor-enabled mobile computing devices.	Using context-aware computing to reduce the perceived burden of interruptions from mobile devices	NA:NA	2018
Andy Cockburn:Carl Gutwin:Jason Alexander	Scrolling is the standard way to navigate through many types of digital documents. However, moving more than a few pages can be slow because all scrolling techniques constrain visual search to only a small document region. To improve document navigation, we developed Space-Filling Thumbnails (SFT), an overview display that eliminates most scrolling. SFT provides two views: a standard page view for reading, and a thumbnail view that shows all pages. We tested SFT in three experiments that involved finding pages in documents. The first study (n=13) compared seven current scrolling techniques, and showed that SFT is significantly faster than the other methods. The second and third studies (n=32 and n=14) were detailed comparisons of SFT with thumbnail-enhanced scrollbars (TES), which performed well in the first experiment. SFT was faster than TES across all document types and lengths, particularly when tasks involved revisitation. In addition, SFT was strongly preferred by participants.	Faster document navigation with space-filling thumbnails	NA:NA:NA	2018
Dmitry Nekrasovski:Adam Bodnar:Joanna McGrenere:François Guimbretière:Tamara Munzner	We present a study that evaluates conventional Pan and Zoom Navigation and Rubber Sheet Navigation, a rectilinear Focus+Context technique. Each of the two navigation techniques was evaluated both with and without an overview. All interfaces guaranteed that regions of interest would remain visible, at least as a compressed landmark, independent of navigation actions. Interfaces implementing these techniques were used by 40 subjects to perform a task that involved navigating a large hierarchical tree dataset and making topological comparisons between nodes in the tree. Our results show that Pan and Zoom Navigation was significantly faster and required less mental effort than Rubber Sheet Navigation, independent of the presence or absence of an overview. Also, overviews did not appear to improve performance, but were still perceived as beneficial by users. We discuss the implications of our task and guaranteed visibility on the results and the limitations of our study, and we propose preliminary design guidelines and recommendations for future work.	An evaluation of pan & zoom and rubber sheet navigation with and without an overview	NA:NA:NA:NA:NA	2018
Caroline Appert:Jean-Daniel Fekete	This article introduces the OrthoZoom Scroller, a novel interaction technique that improves target acquisition in very large one-dimensional spaces. The OrthoZoom Scroller requires only a mouse to perform panning and zooming in a 1D space. Panning is performed along the slider dimension while zooming is performed along the orthogonal one. We present a controlled experiment showing that the OrthoZoom Scroller is about twice as fast as Speed Dependant Automatic Zooming to perform pointing tasks whose index of difficulty is in the 10-30 bits range. We also present an application to browse large textual documents with the OrthoZoom Scroller that uses semantic zooming and snapping on the structure.	OrthoZoom scroller: 1D multi-scale navigation	NA:NA	2018
Martin Halvey:Mark T. Keane:Barry Smyth	In this paper we investigate environmental factors that can result in users having different preferences and behaviors at different times of the day. An analysis is carried out of a large sample of user data for Wireless Application Protocol (WAP) browsing to determine whether user surfing patterns vary depending on time. We examine traffic on an hourly and daily basis, and show that accesses to particular categories of pages vary relative to time. We also build Markov models, which are temporal; to predict user navigation, and illustrate those predictive models are more accurate and beneficial to mobile Internet users than traditional methods. This analysis provides insight into improving the effectiveness and efficiency of navigation prediction.	Time based patterns in mobile-internet surfing	NA:NA:NA	2018
Virpi Roto:Andrei Popescu:Antti Koivisto:Elina Vartiainen	The Web has become available even on mobile phones, but the current methods to view large pages on small screens have not been highly usable. Current mobile phone browsers reformat Web pages to a single column that fits the screen width. Because not all content is comprehensible in this format, browsers provide a second mode for viewing pages in the same layout as on a PC. We have developed a modeless Web page visualization method called Minimap that shows pages in a modified Original layout. We conducted a long-term usability study with 20 participants to compare the state-of-the-art mobile phone browser with this new method. 18 participants preferred the new method, and it also scored better in more detailed usability ratings.	Minimap: a web page visualization method for mobile phones	NA:NA:NA:NA	2018
Gerard McAtamney:Caroline Parker	Wearable computers have the potential to support our memory, facilitate our creativity, our communication and augment our physical senses [15] but, like email and cell-phones, they also have the potential to interrupt, displace or downgrade our social interactions. This paper presents the results of a simple laboratory-based study which examines the impact of a xybernaut head-mounted Shimadzu display on conversation between two people. We hypothesized that the wearable, by reducing eye-contact and attention in the wearer would have a detrimental effect. Pairs of friends discussed pre-defined topics under three conditions, no wearable, wearable present but inactive, wearable present and active. Likert scale statements were used to record the wearer's level of attention, concentration, listening, eye contact, naturalness and relaxation, and the impact of the wearable. The presence of the wearable without an active display did not have an effect on the conversation. The quality of the interaction was however impaired in the active wearable condition and eye-contact was effected. This effect may be the result of the nature of the information type, the interface used, the characteristics of its presentation or the novelty of the display to the user. Additional research to identify design implications is discussed.	An examination of the effects of a wearable display on informal face-to-face communication	NA:NA	2018
Luis von Ahn:Ruoran Liu:Manuel Blum	We introduce Peekaboom, an entertaining web-based game that can help computers locate objects in images. People play the game because of its entertainment value, and as a side effect of them playing, we collect valuable image metadata, such as which pixels belong to which object in the image. The collected data could be applied towards constructing more accurate computer vision algorithms, which require massive amounts of training and testing data not currently available. Peekaboom has been played by thousands of people, some of whom have spent over 12 hours a day playing, and thus far has generated millions of data points. In addition to its purely utilitarian aspect, Peekaboom is an example of a new, emerging class of games, which not only bring people together for leisure purposes, but also exist to improve artificial intelligence. Such games appeal to a general audience, while providing answers to problems that computers cannot yet solve.	Peekaboom: a game for locating objects in images	NA:NA:NA	2018
Keith Wiley:Lance R. Williams	The state-of-the-art in computer drawing programs is based on a number of concepts that are over two decades old. One such concept is the use of layers for ordering the surfaces in a drawing from top to bottom. Unfortunately, the use of layers unnecessarily imposes a partial ordering on the depths of the surfaces and prevents the user from creating a large class of potential drawings, e.g., of Celtic knots and interwoven surfaces. In this paper we describe a novel approach which only requires local depth ordering of segments of the boundaries of surfaces in a drawing rather than a global depth relation between entire surfaces. Our program provides an intuitive user interface which allows a novice to create complex drawings of interwoven surfaces that would be difficult and time-consuming to create with standard drawing programs.	Representation of interwoven surfaces in 2 1/2 D drawing	NA:NA	2018
Luis von Ahn:Mihir Kedia:Manuel Blum	We address the problem of collecting a database of ""common-sense facts"" using a computer game. Informally, a common-sense fact is a true statement about the world that is known to most humans: ""milk is white,"" ""touching hot metal hurts,"" etc. Several efforts have been devoted to collecting common-sense knowledge for the purpose of making computer programs more intelligent. Such efforts, however, have not succeeded in amassing enough data because the manual process of entering these facts is tedious. We therefore introduce Verbosity, a novel interactive system in the form of an enjoyable game. People play Verbosity because it is fun, and as a side effect of them playing, we collect accurate common-sense knowledge. Verbosity is an example of a game that not only brings people together for leisure, but also collects useful data for computer science.	Verbosity: a game for collecting common-sense facts	NA:NA:NA	2018
Luis von Ahn:Shiry Ginosar:Mihir Kedia:Ruoran Liu:Manuel Blum	Images on the Web present a major accessibility issue for the visually impaired, mainly because the majority of them do not have proper captions. This paper addresses the problem of attaching proper explanatory text descriptions to arbitrary images on the Web. To this end, we introduce Phetch, an enjoyable computer game that collects explanatory descriptions of images. People play the game because it is fun, and as a side effect of game play we collect valuable information. Given any image from the World Wide Web, Phetch can output a correct annotation for it. The collected data can be applied towards significantly improving Web accessibility. In addition to improving accessibility, Phetch is an example of a new class of games that provide entertainment in exchange for human processing power. In essence, we solve a typical computer vision problem with HCI tools alone.	Improving accessibility of the web with a computer game	NA:NA:NA:NA:NA	2018
Clare-Marie Karat:John Karat:Carolyn Brodie:Jinjuan Feng	Privacy policy rules are often written in organizations by a team of people in different roles. Currently, people in these roles have no technological tools to guide the creation of clear and implementable high-quality privacy policy rules. High-quality privacy rules can be the basis for verifiable automated privacy access decisions. An empirical study was conducted with 36 users who were novices in privacy policy authoring to evaluate the quality of rules created and user satisfaction with two experimental privacy authoring tools and a control condition. Results show that users presented with scenarios were able to author significantly higher quality rules using either the natural language with a privacy rule guide tool or a structured list tool as compared to an unguided natural language control condition. The significant differences in quality were found in both user self-ratings of rule quality and objective quality scores. Users ranked the two experimental tools significantly higher than the control condition. Implications of the research and future research directions are discussed.	Evaluating interfaces for privacy policy rule authoring	NA:NA:NA:NA	2018
Karen P. Tang:Pedram Keyani:James Fogarty:Jason I. Hong	The emergence of location-based computing promises new and compelling applications, but raises very real privacy risks. Existing approaches to privacy generally treat people as the entity of interest, often using a fidelity tradeoff to manage the costs and benefits of revealing a person's location. However, these approaches cannot be applied in some applications, as a reduction in precision can render location information useless. This is true of a category of applications that use location data collected from multiple people to infer such information as whether there is a traffic jam on a bridge, whether there are seats available in a nearby coffee shop, when the next bus will arrive, or if a particular conference room is currently empty. We present hitchhiking, a new approach that treats locations as the primary entity of interest. Hitchhiking removes the fidelity tradeoff by preserving the anonymity of reports without reducing the precision of location disclosures. We can therefore support the full functionality of an interesting class of location-based applications without introducing the privacy concerns that would otherwise arise.	Putting people in their place: an anonymous and privacy-sensitive approach to collecting sensed data in location-based applications	NA:NA:NA:NA	2018
Kirsten Boehner:Jeffrey T. Hancock	Ambiguity is an important concept for HCI because of its pervasiveness in everyday life, yet its emergent nature challenges the role of design. We examine these difficulties with regards to Aoki and Woodruff's [1] proposal to use ambiguity as a resource for designing space for stories in personal communication systems. We challenge certain assumptions about ambiguity and propose a set of design and evaluation guidelines that flow from this re-conceptualization of ambiguity and design.	Advancing ambiguity	NA:NA	2018
Wendy March:Constance Fleuriot	This paper describes a study undertaken to explore the ways in which older teenage girls use technology to construct and maintain a sense of private space while living at home with parents. The study used blogging as an experimental and integral part of the research, in order to facilitate ongoing communication between researcher and participant.	Girls, technology and privacy: "is my mother listening?"	NA:NA	2018
David R. Millen:Jonathan Feinberg:Bernard Kerr	We describe a social bookmarking service de-signed for a large enterprise. We discuss design principles addressing online identity, privacy, information discovery (including search and pivot browsing), and service extensi-bility based on a web-friendly architectural style. In addi-tion we describe the key design features of our implementa-tion. We provide the results of an eight week field trial of this enterprise social bookmarking service, including a de-scription of user activities, based on log file analysis. We share the results of a user survey focused on the benefits of the service. The feedback from the user trial, comprising survey results, log file analysis and informal communica-tions, is quite positive and suggests several promising en-hancements to the service. Finally, we discuss potential extension and integration of social bookmarking services with other corporate collaborative applications.	Dogear: Social bookmarking in the enterprise	NA:NA:NA	2018
Pearl Pu:Paolo Viappiani:Boi Faltings	The internet presents people with an increasingly bewildering variety of choices. Online consumers have to rely on computerized search tools to find the most preferred option in a reasonable amount of time. Recommender systems address this problem by searching for options based on a model of the user's preferences. We consider example critiquing as a methodology for mixed-initiative recommender systems. In this technique, users volunteer their preferences as critiques on examples. It is thus important to stimulate their preference expression by selecting the proper examples, called suggestions. We describe the look-ahead principle for suggestions and describe several suggestion strategies based on it. We compare them in simulations and, for the first time, report a set of user studies which prove their effectiveness in increasing users' decision accuracy by up to 75%.	Increasing user decision accuracy using suggestions	NA:NA:NA	2018
Qixing Zheng:Kellogg Booth:Joanna McGrenere	Most co-authoring tools support basic annotations, such as edits and comments that are anchored at specific locations in the document. However, they do not support meta-commentary about a document (such as an author's summary of modifications) which gets separated from the document, often in the body of email messages. This causes unnecessary overhead in the write-review-edit workflow inherent in co-authoring. We present document-embedded structured annotations called "bundles" that incorporate the meta-commentary into a unified annotation model that meets a set of annotation requirements we identified through a small field investigation. A usability study with 20 subjects evaluated the annotation reviewing stage of co-authoring and showed that annotation bundles in our high-fidelity prototype reduced reviewing time and increased accuracy, compared to a system that only supports edits and comments.	Co-authoring with structured annotations	NA:NA:NA	2018
Carman Neustaedter:A. J. Bernheim Brush	Families must continually organize, plan, and stay aware of the activities of their households in order to coordinate everyday life. Despite having organization schemes, many people still feel overwhelmed when it comes to family coordination. To help overcome this, we present our research efforts on LINC: an inkable family calendar designed for the kitchen. LINC was developed using a participatory design process involving interviews, paper prototyping, and a formative evaluation. Our work outlines key implications for digital family calendars and family coordination systems in general. We found that coordination is not typically done through the family calendar; rather, the family calendar is a tool that provides family members with an awareness of activities and changes that in turn enables coordination. Thus, digital family calendars should provide tools that enable families to use their own coordination routines which leverage the social affordances prominent in existing paper calendars.	"LINC-ing" the family: the participatory design of an inkable family calendar	NA:NA	2018
Jordan L. Boyd-Graber:Sonya S. Nikolova:Karyn A. Moffatt:Kenrick C. Kin:Joshua Y. Lee:Lester W. Mackey:Marilyn M. Tremaine:Maria M. Klawe	In this paper, we describe the design and preliminary evaluation of a hybrid desktop-handheld system developed to support individuals with aphasia, a disorder which impairs the ability to speak, read, write, or understand language. The system allows its users to develop speech communication through images and sound on a desktop computer and download this speech to a mobile device that can then support communication outside the home. Using a desktop computer for input addresses some of this population's difficulties interacting with handheld devices, while the mobile device addresses stigma and portability issues. A modified participatory design approach was used in which proxies, that is, speech-language pathologists who work with aphasic individuals, assumed the role normally filled by users. This was done because of the difficulties in communicating with the target population and the high variability in aphasic disorders. In addition, the paper presents a case study of the proxy-use participatory design process that illustrates how different interview techniques resulted in different user feedback.	Participatory design with proxies: developing a desktop-PDA system to support people with aphasia	NA:NA:NA:NA:NA:NA:NA:NA	2018
Margit Kristensen:Morten Kyng:Leysia Palen	We describe our research-its approach, results and products-on Danish emergency medical service (EMS) field or "pre-hospital" work in minor and major incidents. We discuss how commitments to participatory design and attention to the qualitative differences between minor and major incidents address challenges identified by disaster sociolo-gists when designing for major incidents. Through qualitative research and participatory design, we have examined the features of EMS work and technology use in different emergency situations from the perspective of multiple actors. We conceptualize victims in incidents-and particularly in major incidents, where on-site medical as-sessments is highly incomplete-as boundary objects over which the complex and imperfect work of coordination is done. As an outcome of our participatory design approach, we describe a set of designs in support of future EMS work.	Participatory design in emergency medical service: designing for future practice	NA:NA:NA	2018
Joseph Luk:Jerome Pasquero:Shannon Little:Karon MacLean:Vincent Levesque:Vincent Hayward	Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering.	A role for haptics in mobile interaction: initial design using a handheld tactile display prototype	NA:NA:NA:NA:NA:NA	2018
Ken Hinckley:Francois Guimbretiere:Patrick Baudisch:Raman Sarin:Maneesh Agrawala:Ed Cutrell	Modes allow a few inputs to invoke many operations, yet if a user misclassifies or forgets the state of a system, modes can result in errors. Spring-loaded modes (quasimodes) maintain a mode while the user holds a control such as a button or key. The Springboard is an interaction technique for tablet computers that extends quasimodes to encompass multiple tool modes in a single spring-loaded control. The Springboard allows the user to continue holding down a nonpreferred-hand command button after selecting a tool from a menu as a way to repeatedly apply the same tool. We find the Springboard improves performance for both a local marking menu and for a non-local marking menu ("lagoon") at the lower left corner of the screen. Despite the round-trip costs incurred to move the pen to a tool lagoon, a keystroke-level analysis of the true cost of each technique reveals the local marking menu is not significantly faster.	The springboard: multiple modes in one spring-loaded control	NA:NA:NA:NA:NA:NA	2018
Bernd Froehlich:Jan Hochstrate:Verena Skuk:Anke Huckauf	We introduce two new six degree of freedom desktop input devices based on the key concept of combining forceless isotonic rotational input with force-requiring elastic translational input. The GlobeFish consists of a custom three degrees of freedom trackball which is elastically connected to a frame. The trackball is accessible from the top and bottom and can be moved slightly in all spatial directions by using force. The GlobeMouse device works in a similar way. Here the trackball is placed on top of a movable base, which requires to change the grip on the device to switch between rotating the trackball and moving the base.Our devices are manipulated with the fingertips allowing precise interaction with virtual objects. The elastic translation allows uniform input for all three axes and the isotonic trackball provides a natural mapping for rotations. Our user study revealed that the new devices perform significantly better in a docking task in comparison to the SpaceMouse, an integrated six degrees of freedom controller. Subjective data confirmed these results.	The GlobeFish and the GlobeMouse: two new six degree of freedom input devices for graphics applications	NA:NA:NA:NA	2018
Jonas Landgren	This paper presents descriptive accounts from an ethnographic study of time-critical work in the domain of emergency response and the operative work of fire crews. The verbal communication as part of such work creates difficulties in providing accountability of the fire crew's actions. The concept of work rhythms and temporal structures is used as an analytical framework. Design implications are presented suggesting that verbal communication should be made persistent, visible and accessible in order to support accountability. These design implications are discussed in relation to the fire crew's work practice.	Making action visible in time-critical work	NA	2018
Jakob Bardram:Jonathan Bunde-Pedersen:Mads Soegaard	Research has shown that computers are notoriously bad at supporting the management of parallel activities and interruptions, and that mobility increases the severity of these problems. This paper presents activity-based computing (ABC) which supplements the prevalent data- and application-oriented computing paradigm with technologies for handling multiple, parallel and mobile work activities. We present the design and implementation of ABC support embedded in the Windows XP operating system. This includes replacing the Windows Taskbar with an Activity Bar, support for handling Windows applications, a zoomable user interface, and support for moving activities across different computers. We report an evaluation of this Windows XP ABC system which is based on a multi-method approach, where perceived ease-of-use and usefulness was evaluated together with rich interview material. This evaluation showed that users found the ABC XP extension easy to use and likely to be useful in their own work.	Support for activity-based computing in a personal computing operating system	NA:NA:NA	2018
Stephen Voida:W. Keith Edwards:Mark W. Newman:Rebecca E. Grinter:Nicolas Ducheneaut	With the rapid growth of personal computer networks and the Internet, sharing files has become a central activity in computer use. The ways in which users control the what, how, and with whom of sharing are dictated by the tools they use for sharing; there are a wide range of sharing practices, and hence a wide range of tools to support these practices. In practice, users' requirements for certain sharing features may dictate their choice of tool, even though the other affordances available through that tool may not be an ideal match to the desired manner of sharing.In this paper, we explore users' current practices in file sharing and examine the tools used to share files. Based on our findings, we unpack the features and affordances of these tools into a set of dimensions along which sharing tools can be characterized. Then, we present the set of user interface features we have prototyped in an interface called a sharing palette, which provides a platform for exploration and experimentation with new modalities of sharing. We briefly present the tool as a whole and then focus on the individual features of the sharing palette that support reported styles of sharing.	Share and share alike: exploring the user interface affordances of file sharing	NA:NA:NA:NA:NA	2018
Laura Beckwith:Cory Kissinger:Margaret Burnett:Susan Wiedenbeck:Joseph Lawrance:Alan Blackwell:Curtis Cook	Earlier research on gender effects with software features intended to help problem-solvers in end-user debugging environments has shown that females are less likely to use unfamiliar software features. This poses a serious problem because these features may be key to helping them with debugging problems. Contrasting this with research documenting males' inclination for tinkering in unfamiliar environments, the question arises as to whether encouraging tinkering with new features would help females overcome the factors, such as low self-efficacy, that led to the earlier results. In this paper, we present an experiment with males and females in an end-user debugging setting, and investigate how tinkering behavior impacts several measures of their debugging success. Our results show that the factors of tinkering, reflection, and self-efficacy, can combine in multiple ways to impact debugging effectiveness differently for males than for females.	Tinkering and gender in end-user programmers' debugging	NA:NA:NA:NA:NA:NA:NA	2018
Madhu Prabaker:Lawrence Bergman:Vittorio Castelli	Much existing documentation is informal and serves to communicate "how-to" knowledge among restricted working groups. Using current practices, such documentation is both difficult to maintain and difficult to use properly.In this paper, we propose a documentation system, called DocWizards, that uses programming by demonstration to support low-cost authoring and guided walkthrough techniques to improve document usability.We report a comparative study between the use of DocWizards and traditional techniques for authoring and following documentation. The study participants showed significant gains in efficiency and reduction in error rates when using DocWizards. In addition, they expressed a clear preference for using the DocWizards tool, both for authoring and for following documentation.	An evaluation of using programming by demonstration and guided walkthrough techniques for authoring and utilizing documentation	NA:NA:NA	2018
Gahgene Gweon:Carolyn Rose:Regan Carey:Zachary Zaiss	This paper describes results from a series of experimental studies to explore issues related to structuring productive group dynamics for collaborative learning using an adaptive support mechanism. The first study provides evidence in favor of the feasibility of the endeavor by demonstrating with a tightly controlled study that even without adaptive support, problem solving in pairs is significantly more effective for learning than problem solving alone. The results from a second study offer guidelines for strategic matching of students with learning partners. Furthermore, the results reveal specific areas for needed support. Based on the results from the second study, we present the design of an adaptive support mechanism, which we evaluate in a third study. The results from the third study provide evidence that certain aspects of our design for adaptive support in the form of strategic prompts are effective for manipulating student behavior in productive ways and for supporting learning. These results also motivate specific modifications to the original design.	Providing support for adaptive scripting in an on-line collaborative learning environment	NA:NA:NA:NA	2018
Edward Cutrell:Daniel Robbins:Susan Dumais:Raman Sarin	Systems for fast search of personal information are rapidly becoming ubiquitous. Such systems promise to dramatically improve personal information management, yet most are modeled on Web search in which users know very little about the content that they are searching. We describe the design and deployment of a system called Phlat that optimizes search for personal information with an intuitive interface that merges search and browsing through a variety of associative and contextual cues. In addition, Phlat supports a unified tagging (labeling) scheme for organizing personal content across storage systems (files, email, etc.). The system has been deployed to hundreds of employees within our organization. We report on both quantitative and qualitative aspects of system use. Phlat is available as a free download at http://research.microsoft.com/adapt/phlat.	Fast, flexible filtering with phlat	NA:NA:NA:NA	2018
Ofer Bergman:Ruth Beyth-Marom:Rafi Nachmias	The project fragmentation problem in personal information management occurs when someone who is working on a single project stores and retrieves information items relating to that project from separate format-related collections (documents, emails and favorite Web sites). This study was aimed to test empirically users' working habits in order to shed light on the project fragmentation problem. Twenty personal computer users participated in the study. Data collection tools included an interview, screen captures and a questionnaire. Results indicate that users tend to store and retrieve project-related information items based on different formats in one project folder when the interface design encourages it. However, they store and retrieve project- related information items in different folders (documents, emails and favorite Web sites) when the design encourages such fragmentation. Two types of attempts to solve the project fragmentation problem are reviewed and a new possible solution is suggested.	The project fragmentation problem in personal information management	NA:NA:NA	2018
Joseph 'Jofish' Kaye:Janet Vertesi:Shari Avery:Allan Dafoe:Shay David:Lisa Onaga:Ivan Rosero:Trevor Pinch	The personal archive is not only about efficient storage and retrieval of information. This paper describes a study of forty-eight academics and the techniques and tools they use to manage their digital and material archiving of papers, emails, documents, internet bookmarks, correspondence, and other artifacts. We present two sets of results: we first discuss rationales behind subjects' archiving, which go beyond information retrieval to include creating a legacy, sharing resources, confronting fears and anxieties, and identity construction. We then show how these rationales were mapped into our subjects' physical, social and electronic spaces, and discuss implications for development of digital tools that allow for personal archiving.	To have and to hold: exploring the personal archive	NA:NA:NA:NA:NA:NA:NA:NA	2018
Gary Hsieh:Kenneth Wood:Abigail Sellen	We present a system for the peripheral display of digital handwritten notes, motivated by the joint observation that people seldom refer back to their notes and that these notes often contain useful information. We describe the user-led design of the system, incorporating interviews, paper prototypes, and interactive prototypes. A preliminary field trial of the system indicates that users derive value from the system both for low-distraction reminding and for serendipitous idea generation. These promising initial results suggest significant scope for future work.	Peripheral display of digital handwritten notes	NA:NA:NA	2018
Miguel A. Nacenta:Samer Sallam:Bernard Champoux:Sriram Subramanian:Carl Gutwin	Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.	Perspective cursor: perspective-based interaction for multi-display environments	NA:NA:NA:NA:NA	2018
Pourang Irani:Carl Gutwin:Xing Dong Yang	Many systems provide the user with a limited viewport of a larger graphical workspace. In these systems, the user often needs to find and select targets that are in the workspace, but not visible in the current view. Standard methods for navigating to the off-screen targets include scrolling, panning, and zooming; however, these are laborious when users cannot see a target's direction or distance. Techniques such as halos can provide awareness of targets, but actually getting to the target is still slow with standard navigation. To improve off-screen target selection, we developed a new technique called hop, which combines halos with a teleportation mechanism that shows proxies of distant objects. Hop provides both awareness of off-screen targets and fast navigation to the target context. A study showed that users are significantly faster at selecting off-screen targets with hopping than with two-level zooming or grab-and-drag panning, and it is clear that hop will be faster than either halos or proxy-based techniques (like drag-and-pop or vacuum filtering) by themselves. Hop both improves on halo-based navigation and extends the value of proxies to small-screen environments.	Improving selection of off-screen targets with hopping	NA:NA:NA	2018
Daniel Wigdor:Chia Shen:Clifton Forlines:Ravin Balakrishnan	In many environments, it is often the case that input is made to displays that are positioned non-traditionally relative to one or more users. This typically requires users to perform interaction tasks under transformed input-display spatial mappings, and the literature is unclear as to how such transformations affect performance. We present two experiments that explore the impact of display space position and input control space orientation on user's subjective preference and objective performance in a docking task. Our results provide guidelines as to optimal display placement and control orientation in collaborative computing environments with one or more shared displays.	Effects of display position and control space orientation on user preference and performance	NA:NA:NA:NA	2018
Min Yin:Shumin Zhai	Automatic interactive voice response (IVR) based telephone routing has long been recognized as a frustrating interaction experience. This paper presents a series of experiments examining the benefits of augmenting telephone voice menus with coordinated visual displays and keyword search. The first experiment qualitatively studied callers' experience of having a visual menu on a screen in synchronization with the telephone voice menu tree navigation. The second experiment quantitatively measured callers' performance in time and accuracy with and without visual display augmentation. The third experiment tested keyword search in comparison to visual browsing of telephone menu trees. Study participants uniformly and enthusiastically liked the visual augmentation of voice menus. On average with visual augmentation callers could navigate phone trees 36% faster with 75% fewer errors, and made choices ahead of the voice menu over 60% of the time. Search vs. browsing had similar navigation performance but offered different and complementary user experiences. Overall our studies conclude that telephone voice menu navigation can be significantly improved with a visual channel augmentation, resulting in both business cost reduction and user experience satisfaction.	The benefits of augmenting telephone voice menu navigation with visual browsing and search	NA:NA	2018
Simon Tucker:Steve Whittaker	Although speech is a potentially rich information source, a major barrier to exploiting speech archives is the lack of useful tools for efficiently accessing lengthy speech recordings. This paper develops and evaluates techniques for temporal compression - reducing the time people take to listen to a recording while still extracting critical information. We first describe an exploratory study that identifies novel excision techniques that remove unimportant words or utterances from the recording. We then develop a new method for evaluating how well temporal compression supports users in forming a general understanding of a recording. Applying this method, we demonstrate that excision techniques are generally more effective than standard compression techniques that simply speed up the entire recording.	Time is of the essence: an evaluation of temporal compression algorithms	NA:NA	2018
Moira Burke:Brian Amento:Philip Isenhour	Despite its widespread use, voicemail presents numerous usability challenges: People must listen to messages in their entirety, they cannot search by keywords, and audio files do not naturally support visual skimming. SCANMail overcomes these flaws by automatically generating text transcripts of voicemail messages and presenting them in an email-like interface. Transcripts facilitate quick browsing and permanent archive. However, errors from the automatic speech recognition (ASR) hinder the usefulness of the transcripts. The work presented here specifically addresses these problems by evaluating user-initiated error correction of transcripts. User studies of two editor interfaces-a grammar-assisted menu and simple replacement by typing-reveal reduced audio playback times and an emphasis on editing important words with the menu, suggesting its value in mobile environments where limited input capabilities are the norm and user privacy is essential. The study also adds to the scarce body of work on ASR confidence shading, suggesting that shading may be more helpful than previously reported.	Error correction of voicemail transcripts in SCANMail	NA:NA:NA	2018
Celine Latulipe:Stephen Mann:Craig S. Kaplan:Charlie L. A. Clarke	We introduce symSpline: a symmetric, dual-mouse technique for the manipulation of spline curves. In symSpline, two cursors control the positions of the ends of the tangent to an edit point. By moving the tangent with both mice, the tangent and the edit point can be translated while the curvature of the spline is adjusted simultaneously, according to the length and angle of the tangent. We compare the symSpline technique to two asymmetric dual-mouse spline manipulation techniques and to a standard single-mouse technique. In a spline matching experiment, symSpline outperformed the two asymmetric dual-mouse techniques and all three dual-mouse techniques proved to be faster than the single-mouse technique. Additionally, symSpline was the technique most preferred by test participants.	symSpline: symmetric two-handed spline manipulation	NA:NA:NA:NA	2018
Georgios N. Marentakis:Stephen A. Brewster	We present the results of an empirical study investigating the effect of feedback, mobility and index of difficulty on a deictic spatial audio target acquisition task in the horizontal plane in front of a user. With audio feedback, spatial audio display elements are found to enable usable deictic interac-tion that can be described using Fitts law. Feedback does not affect perceived workload or preferred walking speed compared to interaction without feedback. Mobility is found to degrade interaction speed and accuracy by 20%. Participants were able to perform deictic spatial audio target acquisition when mobile while walking at 73% of their pre-ferred walking speed. The proposed feedback design is ex-amined in detail and the effects of variable target widths are quantified. Deictic interaction with a spatial audio display is found to be a feasible solution for future interface designs.	Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane	NA:NA	2018
Gabor Blasko:Chandra Narayanaswami:Steven Feiner	Accessing information on mobile and wearable devices often requires the user's visual attention, and the precise operation of virtual or physical widgets. However, these interactions may sometimes be too time-consuming and socially inappropriate. To address this, we introduce a novel input/output device that is based on the manipulation of a retractable string in a polar coordinate frame. Depending on how the user pulls the string from its enclosure--to a particular length, at a particular angle--various system features may be directly accessed. Furthermore, we present our concept for a 1D pixel array, embedded in the string that may be used as a secondary 1D display. Since it is possible to unwind the display itself and trigger functionality with a single pull, information may be accessed and presented quickly, and perceived at a glance. We present scenarios for how the string input/output device may be used in conjunc-tion with the mobile device's primary 2D display and describe our augmented reality proof-of-concept prototype.	Prototyping retractable string-based interaction techniques for dual-display mobile devices	NA:NA:NA	2018
Alexandre Plouznikoff:Nicolas Plouznikoff:Jean-Marc Robert:Michel Desmarais	This paper studies a novel approach advocating the virtual alteration of real-world interfaces through a form of augmented reality. Following an introduction reminding the need for easy to use and more consistent interfaces across our many day to day devices, this paper makes the case for using wearable computers to enhance the interactions between humans and conventional appliances. We present the rationale behind our research and summarize our current prototype's functionalities, architecture and implementation. Preliminary results suggest that virtually altering the interface of real world devices improves execution times for simple tasks using these devices.	Enhancing human-machine interactions: virtual interface alteration through wearable computers	NA:NA:NA:NA	2018
Mikkel R. Jakobsen:Kasper Hornbæk	Navigating and understanding the source code of a program are highly challenging activities. This paper introduces a fisheye view of source code to a Java programming environment. The fisheye view aims to support a programmer's navigation and understanding by displaying those parts of the source code that have the highest degree of interest given the current focus. An experiment was conducted which compared the usability of the fisheye view with a common, linear presentation of source code. Sixteen participants performed tasks significantly faster with the fisheye view, although results varied dependent on the task type. The participants generally preferred the interface with the fisheye view. We analyse participants' interaction with the fisheye view and suggest how to improve its performance. In the calculation of the degree of interest, we suggest to emphasize those parts of the source code that are semantically related to the programmer's current focus.	Evaluating a fisheye view of source code	NA:NA	2018
Andrew J. Ko:Brad A. Myers	Recent advances in programming environments have focused on improving programmer productivity by utilizing the inherent structure in computer programs. However, because these environments represent code as plain text, it is difficult and sometimes impossible to embed interactive tools, annotations, and alternative views in the code itself. Barista is an implementation framework that enables the creation of such user interfaces by simplifying the implementation of editors that represent code internally as an abstract syntax tree and maintain a corresponding, fully structured visual representation on-screen. Barista also provides designers of editors with a standard text-editing interaction technique that closely mimics that of conventional text editors, overcoming a central usability issue of previous structured code editors.	Barista: An implementation framework for enabling new tools, interaction techniques and views in code editors	NA:NA	2018
Brad A. Myers:David A. Weitzman:Andrew J. Ko:Duen H. Chau	Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The ""Crystal"" application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.	Answering why and why not questions in user interfaces	NA:NA:NA:NA	2018
Nicolas Ducheneaut:Nicholas Yee:Eric Nickell:Robert J. Moore	Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players' social experiences. In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft. Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity. We discuss the implications of our findings for the design of future games and other online social spaces.	"Alone together?": exploring the social dynamics of massively multiplayer online games	NA:NA:NA:NA	2018
Marek Bell:Matthew Chalmers:Louise Barkhuus:Malcolm Hall:Scott Sherwood:Paul Tennent:Barry Brown:Duncan Rowland:Steve Benford:Mauricio Capra:Alastair Hampshire	We introduce a location--based game called Feeding Yoshi that provides an example of seamful design, in which key characteristics of its underlying technologies-the coverage and security characteristics of WiFi-are exposed as a core element of gameplay. Feeding Yoshi is also a long--term, wide--area game, being played over a week between three different cities during an initial user study. The study, drawing on participant diaries and interviews, supported by observation and analysis of system logs, reveals players' reactions to the game. We see the different ways in which they embedded play into the patterns of their daily lives, augmenting existing practices and creating new ones, and observe the impact of varying location on both the ease and feel of play. We identify potential design extensions to Feeding Yoshi and conclude that seamful design provides a route to creating engaging experiences that are well adapted to their underlying technologies.	Interweaving mobile games with everyday life	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Steve Benford:Andy Crabtree:Stuart Reeves:Jennifer Sheridan:Alan Dix:Martin Flintham:Adam Drozd	Mobile experiences that take place in public settings such as on city streets create new opportunities for interweaving the fictional world of a performance or game with the everyday physical world. A study of a touring performance reveals how designers generated excitement and dramatic tension by implicating bystanders and encouraging the (apparent) crossing of normal boundaries of behaviour. The study also shows how designers dealt with associated risks through a process of careful orchestration. Consequently, we extend an existing framework for designing spectator interfaces with the concept of performance frames, enabling us to distinguish audience from bystanders. We conclude that using ambiguity to blur the frame can be a powerful design tactic, empowering players to willingly suspend disbelief, so long as a safety-net of orchestration ensures that they do not stray into genuine difficulty.	The Frame of the Game: Blurring the Boundary between Fiction and Reality in Mobile Experiences	NA:NA:NA:NA:NA:NA:NA	2018
Eva Hornecker:Jacob Buur	Our current understanding of human interaction with hybrid or augmented environments is very limited. Here we focus on 'tangible interaction', denoting systems that rely on embodied interaction, tangible manipulation, physical representation of data, and embeddedness in real space. This synthesis of prior 'tangible' definitions enables us to address a larger design space and to integrate approaches from different disciplines. We introduce a framework that focuses on the interweaving of the material/physical and the social, contributes to understanding the (social) user experience of tangible interaction, and provides concepts and perspectives for considering the social aspects of tangible interaction. This understanding lays the ground for evolving knowledge on collaboration-sensitive tangible interaction design. Lastly, we analyze three case studies, using the framework, thereby illustrating the concepts and demonstrating their utility as analytical tools.	Getting a grip on tangible interaction: a framework on physical space and social interaction	NA:NA	2018
Ylva Fernaeus:Jakob Tholander	We reflect upon the process of developing a tangible space for children's collaborative construction of screen-based systems. As in all design work, the design process involved continual refinements of initial ideas and their practical realisation. We discuss how some widely held assumptions often put forward with tangible interfaces were given up in favour of reaching overall goals of interaction. In particular our design involved a shift from a focus on persistent representation and readability of tangible code structures, to instead focus on achieving reusability of programming resources. On a general level, our results illustrate a view on tangibles as resources for action instead of only as alternative forms of data representation. Importantly, this view includes action directed towards the computer as well as off-line socially oriented action conducted with the tangible artefacts.	Finding design qualities in a tangible programming space	NA:NA	2018
Sunny Consolvo:Katherine Everitt:Ian Smith:James A. Landay	Overweight and obesity are a global epidemic, with over one billion overweight adults worldwide (300+ million of whom are obese). Obesity is linked to several serious health problems and medical conditions. Medical experts agree that physical activity is critical to maintaining fitness, reducing weight, and improving health, yet many people have difficulty increasing and maintaining physical activity in everyday life. Clinical studies have shown that health benefits can occur from simply increasing the number of steps one takes each day and that social support can motivate people to stay active. In this paper, we describe Houston, a prototype mobile phone application for encouraging activity by sharing step count with friends. We also present four design requirements for technologies that encourage physical activity that we derived from a three-week long in situ pilot study that was conducted with women who wanted to increase their physical activity.	Design requirements for technologies that encourage physical activity	NA:NA:NA:NA	2018
Morten Proschowsky:Nette Schultz:Niels Ebbe Jacobsen	In this paper we describe a new method for doing text input with touch sensitive wheels. The method is called Transparent User guided Prediction (TUP). With TUP all characters are assigned to fixed positions on the wheel. A language prediction algorithm is used to make it easy to select the most likely characters. The use of the prediction algorithm is transparent for the users, which makes the use of TUP very intuitive. A prototype of TUP is evaluated against the date stamp method for doing wheel text input. Text entry speed for TUP is about 6-7 words per minute for novice users. This is approximately 30% faster than the date stamp method.	An intuitive text input method for touch wheels	NA:NA:NA	2018
Jun Gong:Peter Tarasewich	On devices such as mobile phones, text is often entered using keypads and predictive text entry techniques. Current metrics used for measuring text entry error rates have limitations in terms of the types of errors they account for, and cannot easily distinguish between different types of errors. This research proposes a new text entry error metric that addresses some of the outstanding issues that exist with current metrics. Specifically, the metric accounts in detail for the way the user handles corrections during text entry, moving beyond current keystroke level error measurement. The feasibility and usefulness of this new metric is shown through the analysis of an experiment that tests an alphabetically constrained keypad design that includes upper and lower case letters, numbers, and punctuation marks.	A new error metric for text entry method evaluation	NA:NA	2018
Andrew D. Wilson:Maneesh Agrawala	We present a new bimanual text entry technique designed for today's dual-joystick game controllers. The left and right joysticks are used to independently select characters from the corresponding (left/right) half of an on-screen se-lection keyboard. Our dual-stick approach is analogous to typing on a standard keyboard, where each hand (left/right) presses keys on the corresponding side of the keyboard. We conducted a user study showing that our technique supports keyboarding skills transfer and is thereby readily learnable. Our technique increases entry speed significantly compared to the status quo single stick selection keyboard technique.	Text entry using a dual joystick game controller	NA:NA	2018
Jacob Wobbrock:Brad Myers	We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by ""pulsing"" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with <4% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0% uncorrected errors, compared to 5.95 wpm with 0% uncorrected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead.	Trackball text entry for people with motor impairments	NA:NA	2018
Jacob Wobbrock:Brad Myers:Brandon Rothrock	We present a new 4-key text entry method that, unlike most few-key methods, is gestural instead of selection-based. Importantly, its gestures mimic the writing of Roman letters for high learnability. We compare this new 4-key method to predominant 3-key and 5-key methods theoretically using KSPC and empirically using a longitudinal study of 5 subjects over 10 sessions. The study includes an evaluation of the 4-key method without any on-screen visualization-an impossible condition for the selection-based methods. Our results show that the new 4-key method is quickly learned, becoming faster than the 3-key and 5-key methods after just ~10 minutes of writing, although it produces more errors. Interestingly, removing a visualization of the gestures being made causes no detriment to the 4-key method, which is an advantage for eyes-free text entry.	Few-key text entry revisited: mnemonic gestures on four keys	NA:NA:NA	2018
Cosmin Munteanu:Ronald Baecker:Gerald Penn:Elaine Toms:David James	The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives.	The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives	NA:NA:NA:NA:NA	2018
Andrew Dillon:Lisa Kleinman:Gil Ok Choi:Randolph Bias	Two experiments comparing user performance on ClearType and Regular displays are reported. In the first, 26 participants scanned a series of spreadsheets for target information. Speed of performance was significantly faster with ClearType. In the second experiment, 25 users read two articles for meaning. Reading speed was significantly faster for ClearType. In both experiments no differences in accuracy of performance or visual fatigue scores were observed. The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers.	Visual search and reading tasks using ClearType and regular displays: two experiments	NA:NA:NA:NA	2018
Yevgeniy "Eugene" Medynskiy:Nicolas Ducheneaut:Ayman Farahat	Social network-based systems usually suffer from two major limitations: they tend to rely on a single data source (e.g. email traffic), and the form of network patterns is often privileged over their content. To go beyond these limitations we describe a system we developed to visualize and navigate hybrid networks constructed from multiple data sources - with a direct link between formal representations and the raw content. We illustrate the benefits of our approach by analyzing patterns of collaboration in a large Open Source project, using hybrid networks to uncover important roles that would otherwise have been missed.	Using hybrid networks for the analysis of online software development communities	NA:NA:NA	2018
Weixin Wang:Hui Wang:Guozhong Dai:Hongan Wang	In this paper a novel approach is described for tree visualization using nested circles. The brother nodes at the same level are represented by externally tangent circles; the tree nodes at different levels are displayed by using 2D nested circles or 3D nested cylinders. A new layout algorithm for tree structure is described. It provides a good overview for large data sets. It is easy to see all the branches and leaves of the tree. The new method has been applied to the visualization of file systems.	Visualization of large hierarchical data by circle packing	NA:NA:NA:NA	2018
Tracee Vetting Wolf:Jennifer A. Rode:Jeremy Sussman:Wendy A. Kellogg	We discuss the legacy and processes of creative design, and differentiate it from the type of user-centered design commonly found in CHI. We provide an example of this process, and discuss how design practice constitutes an essential mode of inquiry. We argue the complementary nature of creative design and user-centered design practices. Syncretic disciplines shift and drift from their original practice. A key issue is how CHI is to respond to changes in acceptable design practice. A key contribution of this work is an illustrative example showing how designers can communicate their intellectual rigor to the CHI community.	Dispelling "design" as the black art of CHI	NA:NA:NA:NA	2018
Tim Coughlan:Peter Johnson	The design of tools for creative activities affects the creative processes and output of users. In this paper we consider how an understanding of creative interaction can inform the design of support tools in a creative domain, and where creative needs cross domain boundaries. Using observations of musical composers we analyse the theoretical approaches to understanding creativity and their use to HCI. Cycles of ideation and evaluation are suggested as atomic elements of creative interactions, with the representation of ideas a central activity for individual and collaborating composers. A model of collaborative composition was developed, along with an analysis of the representational types used in the domain. This led to the design and evaluation of a prototype Sonic Sketchpad for musical idea representation.	Interaction in creative tasks	NA:NA	2018
Paul Dourish	Although ethnography has become a common approach in HCI research and design, considerable confusion still attends both ethnographic practice and the criteria by which it should be evaluated in HCI. Often, ethnography is seen as an approach to field investigation that can generate requirements for systems development; by that token, the major evaluative criterion for an ethnographic study is the implications it can provide for design. Exploring the nature of ethnographic inquiry, this paper suggests that "implications for design" may not be the best metric for evaluation and may, indeed, fail to capture the value of ethnographic investigations.	Implications for design	NA	2018
Tapan S. Parikh:Paul Javid:Sasikumar K.:Kaushik Ghosh:Kentaro Toyama	CAM is a user interface toolkit that allows a camera-equipped mobile phone to interact with paper documents. It is designed to automate inefficient, paper-intensive information processes in the developing world. In this paper we present a usability evaluation of an application built using CAM for collecting data from microfinance groups in rural India. This application serves an important and immediate need in the microfinance industry. Our quantitative results show that the user interface is efficient, accurate and can quickly be learned by rural users. The results were competitive with an equivalent PC-based UI. Qualitatively, the interface was found easy to use by almost all users. This shows that, with a properly designed user interface, mobile phones can be a preferred platform for many rural computing applications. Voice feedback and numeric data entry were particularly well-received by users. We are conducting a pilot of this application with 400 microfinance groups in India.	Mobile phones and paper documents: evaluating a new approach for capturing microfinance data in rural India	NA:NA:NA:NA:NA	2018
Paul Luff:Christian Heath:Hideaki Kuzuoka:Keiichi Yamazaki:Jun Yamashita	Recently a number of researchers have uncovered various ways in which paper documents support everyday work practice and have suggested how these may be reflected in the design of new technologies. In this paper we consider how activities on and around paper documents may be supported when participants are remote from each other. When we consider the uses of an experimental system that provides a number of resources for supporting work over documents, it becomes apparent how critical it is to support apparently simple pointing and referencing, and how complex such conduct can be. This suggests some considerations both for developers of enhanced media spaces and analysts of everyday conduct.Clarified descriptions of technology and fragments including changes to figures. Added points concerning the scope of the technology the conception of sequence and calrified the requirement regarding redundancy. Revised descriptions of fragments in an atempt to make thsee less dense Corrected several typographic errors including those mentioned by the reviewers' gesture.	Handling documents and discriminating objects in hybrid spaces	NA:NA:NA:NA:NA	2018
Ron Yeh:Chunyuan Liao:Scott Klemmer:François Guimbretière:Brian Lee:Boyko Kakaradov:Jeannie Stamberger:Andreas Paepcke	Through a study of field biology practices, we observed that biology fieldwork generates a wealth of heterogeneous information, requiring substantial labor to coordinate and distill. To manage this data, biologists leverage a diverse set of tools, organizing their effort in paper notebooks. These observations motivated ButterflyNet, a mobile capture and access system that integrates paper notes with digital photographs captured during field research. Through ButterflyNet, the activity of leafing through a notebook expands to browsing all associated digital photos. ButterflyNet also facilitates the transfer of captured content to spreadsheets, enabling biologists to share their work. A first-use study with 14 biologists found this system to offer rich data capture and transformation, in a manner felicitous with current practice.	ButterflyNet: a mobile capture and access system for field biology research	NA:NA:NA:NA:NA:NA:NA:NA	2018
Rachna Dhamija:J. D. Tygar:Marti Hearst	To build systems shielding users from fraudulent (or phishing) websites, designers need to know which attack strategies work and why. This paper provides the first empirical evidence about which malicious strategies are successful at deceiving general users. We first analyzed a large set of captured phishing attacks and developed a set of hypotheses about why these strategies might work. We then assessed these hypotheses with a usability study in which 22 participants were shown 20 web sites and asked to determine which ones were fraudulent. We found that 23% of the participants did not look at browser-based cues such as the address bar, status bar and the security indicators, leading to incorrect choices 40% of the time. We also found that some visual deception attacks can fool even the most sophisticated users. These results illustrate that standard security indicators are not effective for a substantial fraction of users, and suggest that alternative approaches are needed.	Why phishing works	NA:NA:NA	2018
Shirley Gaw:Edward W. Felten:Patricia Fernandez-Kelly	We consider the social context behind users' decisions about whether and when to encrypt email, interviewing a sample of users from an organization whose mission requires secrecy. Interview participants varied in their level of technical sophistication and in their involvement with secrets. We found that users saw universal, routine use of encryption as paranoid. Encryption flagged a message not only as confidential but also as urgent, so users found the encryption of mundane messages annoying. In general, decisions about encryption were driven not just by technical issues such as usability, but also by social factors. We argue that understanding these social factors is necessary to guide the design of encryption technologies that can be more widely adopted.	Secrecy, flagging, and paranoia: adoption criteria in encrypted email	NA:NA:NA	2018
Min Wu:Robert C. Miller:Simson L. Garfinkel	Security toolbars in a web browser show security-related information about a website to help users detect phishing attacks. Because the toolbars are designed for humans to use, they should be evaluated for usability -- that is, whether these toolbars really prevent users from being tricked into providing personal information. We conducted two user studies of three security toolbars and other browser security indicators and found them all ineffective at preventing phishing attacks. Even though subjects were asked to pay attention to the toolbar, many failed to look at it; others disregarded or explained away the toolbars' warnings if the content of web pages looked legitimate. We found that many subjects do not understand phishing attacks or realize how sophisticated such attacks can be.	Do security toolbars actually prevent phishing attacks?	NA:NA:NA	2018
Jeffrey Nichols:Brad A. Myers:Brandon Rothrock	A problem with many of today's appliance interfaces is that they are inconsistent. For example, the procedure for setting the time on alarm clocks and VCRs differs, even among different models made by the same manufacturer. Finding particular functions can also be a challenge, because appliances often organize their features differently. This paper presents a system, called Uniform, which approaches this problem by automatically generating remote control interfaces that take into account previous interfaces that the user has seen during the generation process. Uniform is able to automatically identify similarities between different devices and users may specify additional similarities. The similarity information allows the interface generator to use the same type of controls for similar functions, place similar functions so that they can be found with the same navigation steps, and create interfaces that have a similar visual appearance.	UNIFORM: automatically generating consistent remote control user interfaces	NA:NA:NA	2018
Katherine Eng:Richard L. Lewis:Irene Tollinger:Alina Chu:Andrew Howes:Alonso Vera	It has been well established in Cognitive Psychology that humans are able to strategically adapt performance, even highly skilled performance, to meet explicit task goals such as being accurate (rather than fast). This paper describes a new capability for generating multiple human performance predictions from a single task specification as a function of different performance objective functions. As a demonstration of this capability, the Cognitive Constraint Modeling approach was used to develop models for several tasks across two interfaces from the aviation domain. Performance objectives are explicitly declared as part of the model, and the CORE (Constraint-based Optimal Reasoning Engine) architecture itself formally derives the detailed strategies that are maximally adapted to these objectives. The models are analyzed for emergent strategic variation, comparing those optimized for task time with those optimized for working memory load. The approach has potential application in user interface and procedure design.	Generating automated predictions of behavior strategically adapted to specific performance objectives	NA:NA:NA:NA:NA:NA	2018
Ryan West:Katherine Lehman	This paper evaluates a method for summative usability testing using an automated data collection system. We found automated summative testing to be a simple and effective alternative to lab-based summative testing and could be successfully conducted remotely. In our study, a web-based control window led participants through the summative study, provided tasks to perform, and asked follow up questions about the user experience. Using a within-group comparison, we found no major differences between data collected by a usability engineer and that collected through an automated testing system for performance metrics. Using a between-group comparison, we found automated summative studies could be conducted remotely with minor but acceptable differences in time on task and likelihood to give up on a task compared to lab-based testing. Task success and task satisfaction ratings were not different between remote and lab-based summative testing. Written comments provided by participants through the testing system were sufficient to identify the major usability problems that led to task failure but did not reveal as comprehensive a set of issues as did a usability engineer observing the sessions.	Automated summative usability studies: an empirical evaluation	NA:NA	2018
Stephen Brewster:David McGookin:Christopher Miller	We present a study into the use of smell for searching digi-tal photo collections. Many people now have large photo libraries on their computers and effective search tools are needed. Smell has a strong link to memory and emotion so may be a good way to cue recall when searching. Our study compared text and smell based tagging. For the first stage we generated a set of smell and tag names from user de-scriptions of photos, participants then used these to tag pho-tos, returning two weeks later to answer questions on their photos. Results showed that participants could tag effec-tively with text labels, as this is a common and familiar task. Performance with smells was lower but participants performed significantly above chance, with some partici-pants using smells well. This suggests that smell has poten-tial. Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices. We also discuss some practical issues of using smell for interaction.	Olfoto: designing a smell-based interaction	NA:NA:NA	2018
Barry Brown:Louise Barkhuus	This paper investigates television-watching practices amongst early adopters of personal hard-disk video recorders (PVRs such as TiVotm) and Internet downloading of shows. Through in-depth interviews with early adopters, we describe how the rhythms of television watching change when decoupled from broadcast TV. For both the PVR users and downloaders TV watching has become less of a passive process, with viewers instead actively gathered shows from the schedules or online, and watching shows from their stored collection. From these results we discuss the 'video media lifecycle', and three new design concepts for supporting TV watching.	The television will be revolutionized: effects of PVRs and filesharing on television watching	NA:NA	2018
Frank Bentley:Crysta Metcalf:Gunnar Harboe	We describe the results of two ethnographic-style studies that investigated consumer use of photos and music respectively. Although the studies were designed, executed, and analyzed separately, in our findings we discovered striking similarities between the ways in which our participants used personally captured photos and commercially purchased music. These findings have implications for the design of future systems with respect to handling and sharing content in photo or music form. We discuss making allowances for satisficing behavior, sharing media as a way to reminisce or to communicate an experience (tell a story), getting sidetracked while browsing, and similarities in organizing behaviors.	Personal vs. commercial content: the similarities between consumer use of photos and music	NA:NA:NA	2018
Duck Gun Park:Jin Kyung Kim:Jin Bong Sung:Jung Hwan Hwang:Chang Hee Hyung:Sung Weon Kang	An intuitive context aware service between two devices is possible using touch with the intrabody communication. Using this technology, users with multimedia devices may simply touch them to establish network connection, transfer data, and provide the required service; hence the name Touch-And-Play (TAP). Using TAP, users can disclose their context by touching the specific device. For instance, a user carrying a digital camera touches the TV to begin a slide show or a printer to print a photo. TAP is expected to enable the provision of intuitive, context-aware service. This paper discusses the feasibility of TAP and its application in user interface.	TAP: touch-and-play	NA:NA:NA:NA:NA:NA	2018
Hayes Raffle:Amanda Parkes:Hiroshi Ishii:Joshua Lifton	Digital Manipulatives embed computation in familiar children's toys and provide means for children to design behavior. Some systems use "record and play" as a form of programming by demonstration that is intuitive and easy to learn. With others, children write symbolic programs with a GUI and download them into a toy, an approach that is conceptually extensible, but is inconsistent with the physicality of educational manipulatives. The challenge we address is to create a tangible interface that can retain the immediacy and emotional engagement of "record and play" and incorporate a mechanism for real time and direct modulation of behavior during program execution.We introduce the Backpacks, modular physical components that children can incorporate into robotic creations to modulate frequency, amplitude, phase and orientation of motion recordings. Using Backpacks, children can investigate basic kinematic principles that underly why their specific creations exhibit the specific behaviors they observe. We demonstrate that Backpacks make tangible some of the benefits of symbolic abstraction, and introduce sensors, feedback and behavior modulation to the record and play paradigm. Through our review of user studies with children ages 6-15, we argue that Backpacks extend the conceptual limits of record and play with an interface that is consistent with both the physicality of educational manipulatives and the local-global systems dynamics that are characteristic of complex robots.	Beyond record and play: backpacks: tangible modulators for kinetic behavior	NA:NA:NA:NA	2018
Tom Moher	'Embedded phenomena' is a learning technology framework in which simulated scientific phenomena are mapped onto the physical space of classrooms. Students monitor and control the local state of the simulation through distributed media positioned around the room, gathering and aggregating evidence to solve problems or answer questions related to those phenomena. Embedded phenomena are persistent, running continuously over weeks and months, creating information channels that are temporally and physically interleaved with, but asynchronous with respect to, the regular flow of instruction. In this paper, we describe the motivations for the framework, describe classroom experiences with three embedded phenomena in the domains of seismology, insect ecology, and astronomy, and situate embedded phenomena within the context of human-computer interaction research in co-located group interfaces and learning technologies.	Embedded phenomena: supporting science learning with classroom-sized distributed simulations	NA	2018
Maryam Kamvar:Shumeet Baluja	We present a large scale study of search patterns on Google's mobile search interface. Our goal is to understand the current state of wireless search by analyzing over 1 Million hits to Google's mobile search sites. Our study also includes the examination of search queries and the general categories under which they fall. We follow users throughout multiple interactions to determine search behavior; we estimate how long they spend inputting a query, viewing the search results, and how often they click on a search result. We also compare and contrast search patterns between 12-key keypad phones (cellphones), phones with QWERTY keyboards (PDAs) and conventional computers.	A large scale study of wireless search behavior: Google mobile search	NA:NA	2018
Amy K. Karlson:George G. Robertson:Daniel C. Robbins:Mary P. Czerwinski:Greg R. Smith	In this paper we describe a novel approach for searching large data sets from a mobile phone. Existing interfaces for mobile search require keyword text entry and are not suited for browsing. Our alternative uses a hybrid model to de-emphasize tedious keyword entry in favor of iterative data filtering. We propose navigation and selection of hierarchical metadata (facet navigation), with incremental text entry to further narrow the results. We conducted a formative evaluation to understand the relative advantages of keyword entry versus facet navigation for both browse and search tasks on the phone. We found keyword entry to be more powerful when the name of the search target is known, while facet navigation is otherwise more effective and strongly preferred.	FaThumb: a facet-based interface for mobile search	NA:NA:NA:NA:NA	2018
Abhishek Ranjan:Ravin Balakrishnan:Mark Chignell	Searching audio data can potentially be facilitated by the use of automatic speech recognition (ASR) technology to generate text transcripts which can then be easily queried. However, since current ASR technology cannot reliably generate 100% accurate transcripts, additional techniques for fluid browsing and searching of the audio itself are required. We explore the impact of transcripts of various qualities, dichotic presentation, and time-compression on an audio search task. Results show that dichotic presentation and reasonably accurate transcripts can assist in the search process, but suggest that time-compression and low accuracy transcripts should be used carefully.	Searching in audio: the utility of transcripts, dichotic presentation, and time-compression	NA:NA:NA	2018
Daniel Avrahami:Scott E. Hudson	For the majority of us, inter-personal communication is an essential part of our daily lives. Instant Messaging, or IM, has been growing in popularity for personal and work-related communication. The low cost of sending a message, combined with the limited awareness provided by current IM systems result in messages often arriving at inconvenient or disruptive times. In a step towards solving this problem, we created statistical models that successfully predict responsiveness to incoming instant messages -- simply put: whether the receiver is likely to respond to a message within a certain time period. These models were constructed using a large corpus of real IM interaction collected from 16 participants, including over 90,000 messages. The models we present can predict, with accuracy as high as 90.1%, whether a message sent to begin a new session of communication would get a response within 30 seconds, 1, 2, 5, and 10 minutes. This type of prediction can be used, for example, to drive online-status indicators, or in services aimed at finding potential communicators.	Responsiveness in instant messaging: predictive models supporting inter-personal communication	NA:NA	2018
Shamsi T. Iqbal:Brian P. Bailey	A challenge in building interruption reasoning systems is to compute an accurate cost of interruption (COI). Prior work has used interface events and other cues to predict COI, but ignore characteristics related to the structure of a task. This work investigates how well characteristics of task structure can predict COI, as objectively measured by resumption lag. In an experiment, users were interrupted during task execution at various boundaries to collect a large sample of resumption lag values. Statistical methods were employed to create a parsimonious model that uses characteristics of task structure to predict COI. A subsequent experiment with different tasks showed that the model can predict COI with reasonably high accuracy. Our model can be expediently applied to many goal-directed tasks, allowing systems to make more effective decisions about when to interrupt.	Leveraging characteristics of task structure to predict the cost of interruption	NA:NA	2018
Alexander Faaborg:Henry Lieberman	Many users are familiar with the interesting but limited functionality of Data Detector interfaces like Microsoft's Smart Tags and Google's AutoLink. In this paper we significantly expand the breadth and functionality of this type of user interface through the use of large-scale knowledge bases of semantic information. The result is a Web browser that is able to generate personalized semantic hypertext, providing a goal-oriented browsing experience.We present (1) Creo, a Programming by Example system for the Web that allows users to create a general-purpose procedure with a single example, and (2) Miro, a Data Detector that matches the content of a page to high-level user goals.An evaluation with 34 subjects found that they were more efficient using our system, and that the subjects would use features like these if they were integrated into their Web browser.	A goal-oriented web browser	NA:NA	2018
David Kirk:Abigail Sellen:Carsten Rother:Ken Wood	In this paper we introduce the notion of "photowork" as the activities people perform with their digital photos after cap-ture but prior to end use such as sharing. Surprisingly, these processes of reviewing, downloading, organizing, editing, sorting and filing have received little attention in the litera-ture yet they form the context for a large amount of the 'search' and 'browse' activities so commonly referred to in studies of digital photo software. Through a deeper under-standing of photowork using field observation and inter-views, we seek to highlight its significance as an interaction practice. At the same time, we discover how "search" as it is usually defined may have much less relevance than new ways of browsing for the design of new digital photo tools, in particular, browsing in support of the photowork activi-ties we describe.	Understanding photowork	NA:NA:NA:NA	2018
Anthony Santella:Maneesh Agrawala:Doug DeCarlo:David Salesin:Michael Cohen	We present an interactive method for cropping photographs given minimal information about important content location, provided by eye tracking. Cropping is formulated in a general optimization framework that facilitates adding new composition rules, and adapting the system to particular applications. Our system uses fixation data</ to identify important image content and compute the best crop for any given aspect ratio or size, enabling applications such as automatic snapshot recomposition, adaptive documents, and thumbnailing. We validate our approach with studies in which users compare our crops to ones produced by hand and by a completely automatic approach. Experiments show that viewers prefer our gaze-based crops to uncropped images and fully automatic crops.	Gaze-based interaction for semi-automatic photo cropping	NA:NA:NA:NA:NA	2018
Trent Apted:Judy Kay:Aaron Quigley	We have recently begun to see hardware support for the tabletop user interface, offering a number of new ways for humans to interact with computers. Tabletops offer great potential for face-to-face social interaction; advances in touch technology and computer graphics provide natural ways to directly manipulate virtual objects, which we can display on the tabletop surface. Such an interface has the potential to benefit a wide range of the population and it is important that we design for usability and learnability with diverse groups of people.This paper describes the design of SharePic -- a multiuser, multi-touch, gestural, collaborative digital photograph sharing application for a tabletop -- and our evaluation with both young adult and elderly user groups. We describe the guidelines we have developed for the design of tabletop interfaces for a range of adult users, including elders, and the user interface we have built based on them. Novel aspects of the interface include a design strongly influenced by the metaphor of physical photographs placed on the table with interaction techniques designed to be easy to learn and easy to remember. In our evaluation, we gave users the final task of creating a digital postcard from a collage of photographs and performed a realistic think-aloud with pairs of novice participants learning together, from a tutorial script.	Tabletop sharing of digital photographs for the elderly	NA:NA:NA	2018
Eytan Adar	As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis.	GUESS: a language and interface for graph exploration	NA	2018
William Wright:David Schroh:Pascale Proulx:Alex Skaburskis:Brian Cort	The Sandbox is a flexible and expressive thinking environment that supports both ad-hoc and more formal analytical tasks. It is the evidence marshalling and sense-making component for the analytical software environment called nSpace. This paper presents innovative Sandbox human information interaction capabilities and the rationale underlying them including direct observations of analysis work as well as structured interviews. Key capabilities for the Sandbox include "put-this-there" cognition, automatic process model templates, gestures for the fluid expression of thought, assertions with evidence and scalability mechanisms to support larger analysis tasks. The Sandbox integrates advanced computational linguistic functions using a Web Services interface and protocol. An independent third party evaluation experiment with the Sandbox has been completed. The experiment showed that analyst subjects using the Sandbox did higher quality analysis in less time than with standard tools. Usability test results indicated the analysts became proficient in using the Sandbox with three hours of training.	The Sandbox for analysis: concepts and methods	NA:NA:NA:NA:NA	2018
Martin Wattenberg	This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are "multivariate," i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets.	Visual exploration of multivariate graphs	NA	2018
Kirstie Hawkey:Kori M. Inkpen	We conducted a survey of 155 participants to examine privacy concerns relating to the viewing of incidental information (i.e. traces of previous activity unrelated to the task at hand) in web browsers. We have identified several dimensions of privacy for this domain. Results revealed the scope of this problem and how location and device affect web browsing activity and contribute to the types of incidental information that may be visible. We found that there are different privacy comfort levels inherent to the participant and dependent on the context of subsequent viewing of incidental information, including the sensitivity of the content, their relationship to the viewer and the level of control retained over input devices.	Keeping up appearances: understanding the dimensions of incidental information privacy	NA:NA	2018
Erica Robles:Abhay Sukumaran:Kathryn Rickertsen:Cliff Nass	This paper explores the relationship between display of feedback (public vs. private) and the basis for evaluation (present vs. absent) of that feedback. Using a controlled, laboratory setting, we employ a fundamentally social, interpersonal context (speed-dating). Two participants (one male and one female) receive real-time performance feedback about either only themselves (private) or about both participants (public). We measure participant perceptions of monitoring, conformity, and self-consciousness about themselves and their dating partner. We also assess perceptions of system invasiveness, system competence, and system support. Results reveal a consistent pattern of significant interaction between feedback display and basis for evaluation conditions. In each of these interactions, public feedback with an added, trivial, basis for evaluation creates significantly lower perception of monitoring, conformity, self-consciousness, and system invasiveness, than the other three conditions. Additionally there is a main effect for basis for evaluation with respect to system competence and supportiveness. In each case, the presence of a basis produces more positive assessments than its absence. The experiment shows that reactions to being monitored and evaluated do not differ strictly along the dimension of public vs. private; basis for evaluation of feedback functions as a mediator and thus co-determines participant attitudinal responses. We discuss the implications of this at several levels, and present a broader cultural explanation in terms of the theory of rationalization. We also discuss the issues around and functionality of linking laboratory settings to larger cultural contexts in this and related fields of inquiry.	Being watched or being special: how I learned to stop worrying and love being monitored, surveilled, and assessed	NA:NA:NA:NA	2018
Muhd Dzulkhiflee Hamzah:Shun'ichi Tano:Mitsuru Iwata:Tomonori Hashiyama	Unlike documents, annotation for multimedia information needs to be input as text, not in the form of symbols such as underlines and circles. This is problematic with keyboard input for non-alphabetical languages, especially the East Asian languages such as Chinese and Japanese, because it is labor intensive and imposes a high cognitive load. This study provides a quantitative analysis of the effectiveness of making annotations by hand during a note-taking task in Japanese. Although the lessons learned from this study come from Japanese text input, they are also generally applicable to other East Asian Languages which use ideographic characters such as Chinese. In our study, we focused on both the ergonomic and cognitive aspects and found that during annotation and note-taking task input by hand is more effective than input by keyboard. Finally, we anatomized the keyboard input problem and discuss it in this paper.	Effectiveness of annotating by hand for non-alphabetical languages	NA:NA:NA:NA	2018
Kazutaka Kurihara:Masataka Goto:Jun Ogata:Takeo Igarashi	It is tedious to handwrite long passages of text by hand. To make this process more efficient, we propose predictive handwriting that provides input predictions when the user writes by hand. A predictive handwriting system presents possible next words as a list and allows the user to select one to skip manual writing. Since it is not clear if people are willing to use prediction, we first run a user study to compare handwriting and selecting from the list. The result shows that, in Japanese, people prefer to select, especially when the expected performance gain from using selection is large. Based on these observations, we designed a multimodal input system, called speech-pen, that assists digital writing during lectures or presentations with background speech and handwriting recognition. The system recognizes speech and handwriting in the background and provides the instructor with predictions for further writing. The speech-pen system also allows the sharing of context information for predictions among the instructor and the audience; the result of the instructor's speech recognition is sent to the audience to support their own note-taking. Our preliminary study shows the effectiveness of this system and the implications for further improvements.	Speech pen: predictive handwriting based on ambient multimodal recognition	NA:NA:NA:NA	2018
Tovi Grossman:Ken Hinckley:Patrick Baudisch:Maneesh Agrawala:Ravin Balakrishnan	We present Hover Widgets, a new technique for increasing the capabilities of pen-based interfaces. Hover Widgets are implemented by using the pen movements above the display surface, in the tracking state. Short gestures while hovering, followed by a pen down, access the Hover Widgets, which can be used to activate localized interface widgets. By using the tracking state movements, Hover Widgets create a new command layer which is clearly distinct from the input layer of a pen interface. In a formal experiment Hover Widgets were found to be faster than a more traditional command activation technique, and also reduced errors due to divided attention.	Hover widgets: using the tracking state to extend the capabilities of pen-operated devices	NA:NA:NA:NA:NA	2018
Kenton O'Hara:Alison Black:Matthew Lipson	The mobile phone allowed people to communicate when and where they wanted, dramatically changing how audio telephony was integrated into daily life. With video telephony services now available on everyday mobile phones, comparable arguments are being made that this will change how people relate to and use video telephony. The mobile and personal natures of mobile phones remove factors that previously hindered use of video telephony. Mobility also brings new challenges and concerns that may hinder use of video telephony in particular contexts. With this in mind, the paper revisits the notion of video telephony but within the context of mobile phones. A study is presented of people's everyday use of mobile video telephony using diary techniques and ethnographic interviews. The study uses real episodes to highlight key motivations and circumstances under which mobile video telephony was and wasn't used. Implications for adoption of design of mobile video phones are discussed.	Everyday practices with mobile video telephony	NA:NA:NA	2018
Eric Paulos:Chris Beckmann	No longer confined to our offices, schools, and homes, technology is expanding at an astonishing rate across our everyday public urban landscapes. From the visible (mobile phones, laptops, and blackberries) to the invisible (GPS, WiFi, GSM, and EVDO), we find the full spectrum of digital technologies transforming nearly every facet of our urban experience. Many current urban computing systems focus on improving our efficiency and productivity in the city by providing "location services" and/or interactive navigation and mapping tools. While agreeing with the need for such systems, we are reminded that urban life spans a much wider range of emotions and experiences. Our claim is that our successful future urban technological tools will be those that incorporate the full range of urban experiences -- from improving productivity and efficiency to promoting wonderment and daydreaming. We discuss intervention as a research strategy for understanding wonderment; demonstrate an example of such a study using a matchbook experiment to expose relationships between locations and emotions within a city; and use the results to develop Sashay -- a mobile phone application that promotes wonderment by visualizing an individual's personal patterns across the invisible, manufactured geography of mobile phone cellular towers.	Sashay: designing for wonderment	NA:NA	2018
Christine M. Liu:Judith S. Donath	Humans use fashion signals to indicate access to information. While fashion is typically associated with clothing, fashion also transpires within the domain of electronic media: weblogs, discussion lists, and online communities teem continuously with fresh, digestible content. A fashionable status - well-informed and well-connected - is demonstrated through a consistent, timely, and meaningful display of newly acquired information. While production constraints of material-based fashions limit the signal refresh rate, ephemeral electronic fashions can cycle as quickly as the flow of information. The challenge we present is to develop physical objects that can go beyond the limitations of their materiality, and to signal with the rapidity of electronic fashions. We introduce the design of urbanhermes as a communicative accessory that integrates the fresh, dynamic, fluid nature of electronic-based fashion signals within the tactile, face-to-face environment of a physical space. This paper presents the design discussion within the framework of fashion as a social signal.	Urbanhermes: social signaling with electronic fashion	NA:NA	2018
Pamela J. Ludford:Dan Frankowski:Ken Reily:Kurt Wilms:Loren Terveen	Although they have potential, to date location-based information systems have not radically improved the way we interact with our surroundings. To study related issues, we developed a location-based reminder system, PlaceMail, and demonstrate its utility in supporting everyday tasks through a month-long field study. We identify current tools and practices people use to manage distributed tasks and note problems with current methods, including the common "to-do list". Our field study shows that PlaceMail supports useful location-based reminders and functional place-based lists. The study also sheds rich and surprising light on a new issue: when and where to deliver location-based information. The traditional 'geofence' radius around a place proves insufficient. Instead, effective delivery depends on people's movement patterns through an area and the geographic layout of the space. Our results both provide a compelling demonstration of the utility of location-based information and raise significant new challenges for location-based information distribution.	Because I carry my cell phone anyway: functional location-based reminder applications	NA:NA:NA:NA:NA	2018
Anind K. Dey:Ed de Guzman	Computer displays can be helpful for making users aware of the remote presence of friends and family. In many of the research projects that have explored the use of novel displays, the real goal is to improve a user's sense of connectedness to those remote loved ones. However, very few have leveraged a user-centered design process or empirically studied the effects of using a display on users' sense of awareness and connectedness. In this paper, we present our multi-phase, user-centered design process for building displays that support awareness and connectedness: Presence Displays, which are physical, peripheral awareness displays of online presence of close friends or family. We present evidence, from a 5-week long field study, that these displays provide significantly better awareness of and connectedness to a loved one, than a traditional graphical display of online presence.	From awareness to connectedness: the design and deployment of presence displays	NA:NA	2018
Steve Howard:Jesper Kjeldskov:Mikael B. Skov:Kasper Garnæs:Olga Grünberger	On the basis of a longitudinal field study of domestic communication, we report some essential constituents of the user experience of awareness of others who are distant in space or time, i.e. presence-in-absence. We discuss presence-in-absence in terms of its social (Contact) and informational (Content) facets, and the circumstances of the experience (Context). The field evaluation of a prototype, 'The Cube', designed to support presence-in-absence, threw up issues in the interrelationships between contact, content and context; issues that the designers of similar social artifacts will need to address.	Negotiating presence-in-absence: contact, content and context	NA:NA:NA:NA:NA	2018
Adam D. I. Kramer:Lui Min Oh:Susan R. Fussell	We propose a method of measuring people's sense of presence in computer-mediated communication (CMC) systems) based on linguistic features of their dialogues. We create variations in presence by asking participants to collaborate on physical tasks in four CMC conditions. We then correlate self-reported feelings of presence with the use of specific linguistic features. Regression analyses show that 30% of the variance in self-reported presence can be accounted for by a small number of task-independent linguistic features. Even better prediction can be obtained when self-reported coordination is added to the regression equation. We conclude that linguistic measures of presence have value for studies of CMC.	Using linguistic features to measure presence in computer-mediated communication	NA:NA:NA	2018
Christof C. van Nimwegen:Daniel D. Burgos:Herre H. van Oostendorp:Hermina H. J. M. Schijf	This paper investigates the influence of interface styles on problem solving performance. It is often assumed that performance on problem solving tasks improves when users are assisted by externalizing task-related information on the interface. Although externalization requires less recall and relieves working memory, it does not instigate planning, understanding and knowledge acquisition. Without this assistance, task-information must be internalized, stored in the user's memory, leading to more planning and thinking and perhaps to better performance and knowledge. Another variable that can influence behavior is "Need for Cognition" (NFC), the tendency to engage in effortful cognitive tasks. We investigated the effects of interface style and cognitive style on performance using a conference planning application. Interface style influenced behavior and performance, but NFC did not. The internalization interface led to more planful behavior and smarter solutions. When planning and learning are the aim, designers should thus beware of giving a user (too) much assistance. Understanding how people react to interface information can be crucial in designing effective software, especially important in the areas of education and learning.	The paradox of the assisted user: guidance can be counterproductive	NA:NA:NA:NA	2018
Lena Mamykina:Elizabeth D. Mynatt:David R. Kaufman	Chronic diseases, endemic in the rapidly aging population, are stretching the capacity of healthcare resources. Increasingly, individuals need to adopt proactive health attitudes and contribute to the management of their own health. We investigate existing diabetes self-management practices and ways in which reflection on prior actions impacts future lifestyle choices. The findings suggest that individuals generate and evaluate hypotheses regarding health implications of their actions. Thus, health-monitoring applications can assist individuals in making educated choices by facilitating discovery of correlations between their past actions and health states. Deployment of an early prototype of a health-monitoring application demonstrated the need for careful presentation techniques to promote more robust understanding and to avoid reinforcement of biases.	Investigating health management practices of individuals with diabetes	NA:NA:NA	2018
Gillian R. Hayes:Gregory D. Abowd	Evidence-based care is an increasingly popular process for long term diagnosis and monitoring of education and healthcare disabilities. Because this evidence must also be collected in everyday life, it is a technique that can greatly benefit from automated capture technologies. These solutions, however, can raise significant concerns about privacy, control, and surveillance. In this paper, we present an analysis of these concerns with regard to evidence-based care. This analysis underscores the need to consider community-based risk and reward analyses in addition to the traditionally used analyses for individual users when designing socially appropriate technologies.	Tensions in designing capture technologies for an evidence-based care community	NA:NA	2018
Katie A. Siek:Kay H. Connelly:Yvonne Rogers	In this paper, we describe a formative study to learn how one chronically ill population thinks about food, mentally organizes food, and interprets consumption-level icons. We found that many participants let their pride influence their choices, resulting in preferred interfaces that they could not accurately interpret. The results indicate that participants organized food in similar ways, had difficulty reading from their preferred consumption-level icons, and wanted to combine multiple interface designs when searching for food.	Pride and prejudice: learning how chronically ill people think about food	NA:NA:NA	2018
Sara Drenner:Max Harper:Dan Frankowski:John Riedl:Loren Terveen	Item-oriented Web sites maintain repositories of information about things such as books, games, or products. Many of these Web sites offer discussion forums. However, these forums are often disconnected from the rich data available in the item repositories. We describe a system, movie linking, that bridges a movie recommendation Web site and a movie-oriented discussion forum. Through automatic detection and an interactive component, the system recognizes references to movies in the forum and adds recommendation data to the forums and conversation threads to movie pages. An eight week observational study shows that the system was able to identify movie references with precision of .93 and recall of .78. Though users reported that the feature was useful, their behavior indicates that the feature was more successful at enriching the interface than at integrating the system.	Insert movie reference here: a system to bridge conversation and item-oriented web sites	NA:NA:NA:NA:NA	2018
Al M. Rashid:Kimberly Ling:Regina D. Tassone:Paul Resnick:Robert Kraut:John Riedl	One of the important challenges faced by designers of online communities is eliciting sufficent contributions from community members. Users in online communities may have difficulty either in finding opportunities to add value, or in understanding the value of their contributions to the community. Various social science theories suggest that showing users different perspectives on the value they add to the community will lead to differing amounts of contribution. The present study investigates a design augmentation for an existing community Web site that could benefit from additional contribution. The augmented interface includes individualized opportunities for contribution and an estimate of the value of each contribution to the community. The value is computed in one of four different ways: (1) value to self; (2) value to a small group the user has affinity with; (3) value to a small group the user does not have affinity with; and (4) value to the entire user community. The study compares the effectiveness of the different notions of value to 160 community members.	Motivating participation by displaying the value of contribution	NA:NA:NA:NA:NA:NA	2018
Jaime Arguello:Brian S. Butler:Elisabeth Joyce:Robert Kraut:Kimberly S. Ling:Carolyn Rosé:Xiaoqing Wang	People come to online communities seeking information, encouragement, and conversation. When a community responds, participants benefit and become more committed. Yet interactions often fail. In a longitudinal sample of 6,172 messages from 8 Usenet newsgroups, 27% of posts received no response. The information context, posters' prior engagement in the community, and the content of their posts all influenced the likelihood that they received a reply, and, as a result, their willingness to continue active participation. Posters were less likely to get a reply if they were newcomers. Posting ontopic, introducing oneself via autobiographical testimonials, asking questions, using less complex language and other features of the messages, increased replies. Results suggest ways that developers might increase the ability of online communities to support successful individual-group interactions.	Talk to me: foundations for successful individual-group interactions in online communities	NA:NA:NA:NA:NA:NA:NA	2018
Irina Shklovski:Robert Kraut:Jonathon Cummings	In this paper we examine how routine uses of the Internet for communication with family and friends and for entertainment may serve as indicators of overall levels of psychological well-being. Changes in psychological well-being in response to a major life event, such as a residential move, can drive changes in routine uses of the Internet, suggesting Internet-based coping strategies. Specifically, women who report high levels of depressive affect, decrease internet use for communication. Men with similar levels of depressive affect increase internet use for entertainment. We discuss implications of these findings for our understanding of the role of the Internet in everyday behavior and instances of coping with stressful situations.	Routine patterns of internet use & psychological well-being: coping with a residential move	NA:NA:NA	2018
Fernanda B. Viégas:Scott Golder:Judith Donath	We present Themail, a visualization that portrays relationships using the interaction histories preserved in email archives. Using the content of exchanged messages, it shows the words that characterize one's correspondence with an individual and how they change over the period of the relationship.This paper describes the interface and content-parsing algorithms in Themail. It also presents the results from a user study where two main interaction modes with the visualization emerged: exploration of "big picture" trends and themes in email (haystack mode) and more detail-oriented exploration (needle mode). Finally, the paper discusses the limitations of the content parsing approach in Themail and the implications for further research on email content visualization.	Visualizing email content: portraying relationships from conversational histories	NA:NA:NA	2018
Tara Matthews:Mary Czerwinski:George Robertson:Desney Tan	Information workers often have to balance many tasks and interruptions. In this work, we explore peripheral display techniques that improve multitasking efficiency by helping users maintain task flow, know when to resume tasks, and more easily reacquire tasks. Specifically, we compare two types of abstraction that provide different task information: semantic content extraction, which displays only the most relevant content in a window, and change detection, which signals when a change has occurred in a window (all de-signed as modifications to Scalable Fabric [17]). Results from our user study suggest that semantic content extraction improves multitasking performance more so than either change detection or our base case of scaling. Results also show that semantic content extraction provides significant benefits to task flow, resumption timing, and reacquisition. We discuss the implication of these findings on the design of peripheral interfaces that support multitasking.	Clipping lists and change borders: improving multitasking efficiency with peripheral information design	NA:NA:NA:NA	2018
George W. Furnas	Information worlds continue to grow, posing daunting challenges for interfaces. This paper tries to increase our understanding of approaches to the problem, building on the Generalized Fisheye View framework. Three issues are discussed. First a number of existing techniques are unified by the commonality of what they show, certain fisheye-related subsets, with the techniques differing only in how they show those subsets. Then the elevated importance of these subsets, and their generality, is used to discuss the possibility of non-visual fisheye-views, to attack problems not so amenable to visualization. Finally, several models are given for why these subsets might be important in user interactions, with the goal of better informing design rationales.	A fisheye follow-up: further reflections on focus + context	NA	2018
Giovanni Iachello:Khai N. Truong:Gregory D. Abowd:Gillian R. Hayes:Molly Stevens	We developed an inquiry technique, which we called "paratype," based on experience prototyping and event-contingent experience sampling, to survey people in real-life situations about ubiquitous computing (ubicomp) technology. We used this tool to probe the opinions of the conversation partners of users of the Personal Audio Loop, a memory aid that can have a strong impact on their privacy. We present the findings of this study and their implications, specifically the need to broaden public awareness of ubicomp applications and the unfitness of traditional data protection guidelines for tackling the privacy issues of many ubicomp applications. We also point out benefits and methodological issues of paratypes and discuss why they are particularly fit for studying certain classes of mobile and ubicomp applications.	Prototyping and sampling experience to evaluate ubiquitous computing privacy in the real world	NA:NA:NA:NA:NA	2018
Yang Li:Evan Welbourne:James A. Landay	Wizard of Oz (WOz) testing has shown promise as an effective way to test location-enhanced applications. However, it is challenging to conduct a location-based WOz test because of the dynamic nature of target settings in the field. In particular, continuous location tracking, a major task in such a test, requires a wizard to frequently update a user's location to simulate a location system. This imposes a heavy task load on a wizard. To ease wizards' tasks for location tracking, we designed two techniques, Directional Crossing and Steering, and conducted a field experiment to investigate the performance of the two techniques. A quantitative analysis shows that Directional Crossing and Steering significantly lowered a wizard's task load for location tracking without sacrificing accuracy.	Design and experimental analysis of continuous location tracking techniques for Wizard of Oz testing	NA:NA:NA	2018
Richard L. Hazlett	This paper describes the use of facial electromyography (EMG) as a measure of positive and negative emotional valence during interactive experience. Thirteen boys played a car racing video game on an Xbox platform while facial EMG data were collected. Through video review positive and negative events during play were identified. The zygomaticus muscle EMG, which controls smiling, was found to be significantly greater during positive events as compared to negative. The corrugator muscle EMG, which controls frowning, was found to be significantly greater during negative events. The results of this study demonstrate that positive valence can be measured during interactive experiences with physiologic measures. This study also found that the corrugator EMG can still measure negative valence during high intensity interactive play in spite of the confounding factor of mental effort. These methods appear useful for associating the player's emotion with game events, and could be applied to HCI in general.	Measuring emotional valence during interactive experiences: boys at video game play	NA	2018
Regan L. Mandryk:M. Stella Atkins:Kori M. Inkpen	Researchers are using emerging technologies to develop novel play environments, while established computer and console game markets continue to grow rapidly. Even so, evaluating the success of interactive play environments is still an open research challenge. Both subjective and objective techniques fall short due to limited evaluative bandwidth; there remains no corollary in play environments to task performance with productivity systems. This paper presents a method of modeling user emotional state, based on a user's physiology, for users interacting with play technologies. Modeled emotions are powerful because they capture usability and playability through metrics relevant to ludic experience; account for user emotion; are quantitative and objective; and are represented continuously over a session. Furthermore, our modeled emotions show the same trends as reported emotions for fun, boredom, and excitement; however, the modeled emotions revealed differences between three play conditions, while the differences between the subjective reports failed to reach significance.	A continuous and objective evaluation of emotional experience with interactive play environments	NA:NA:NA	2018
Dan Cosley:Dan Frankowski:Loren Terveen:John Riedl	Many online communities are emerging that, like Wikipedia, bring people together to build community-maintained artifacts of lasting value (CALVs). Motivating people to contribute is a key problem because the quantity and quality of contributions ultimately determine a CALV's value. We pose two related research questions: 1) How does intelligent task routing---matching people with work---affect the quantity of contributions? 2) How does reviewing contributions before accepting them affect the quality of contributions? A field experiment with 197 contributors shows that simple, intelligent task routing algorithms have large effects. We also model the effect of reviewing contributions on the value of CALVs. The model predicts, and experimental data shows, that value grows more slowly with review before acceptance. It also predicts, surprisingly, that a CALV will reach the same final value whether contributions are reviewed before or after they are made available to the community.	Using intelligent task routing and contribution review to help communities build artifacts of lasting value	NA:NA:NA:NA	2018
Mike Brzozowski:Kendra Carattini:Scott R. Klemmer:Patrick Mihelich:Jiang Hu:Andrew Y. Ng	As our business, academic, and personal lives continue to move at an ever-faster pace, finding times for busy people to meet has become an art. One of the most perplexing challenges facing groupware is effective asynchronous group scheduling (GS). This paper presents a lightweight interaction model for GS that can extend its reach beyond users of current group calendaring solutions. By expressing availability in terms of preferences, we create a flexible framework for GS that preserves plausible deniability while exerting social pressure to encourage honesty among users. We also propose an ontology that enables us to model user preferences with machine learning, predicting user responses to further lower cognitive load. The combination of visualization/direct manipulation with machine learning allows users to easily and efficiently optimize meeting times. We also suggest resulting design implications for this class of intelligent user interfaces.	groupTime: preference based group scheduling	NA:NA:NA:NA:NA:NA	2018
Philip Bonhard:Clare Harries:John McCarthy:M. Angela Sasse	Recommender systems have been developed to address the abundance of choice we face in taste domains (films, music, restaurants) when shopping or going out. However, consumers currently struggle to evaluate the appropriateness of recommendations offered. With collaborative filtering, recommendations are based on people's ratings of items. In this paper, we propose that the usefulness of recommender systems can be improved by including more information about recommenders. We conducted a laboratory online experiment with 100 participants simulating a movie recommender system to determine how familiarity of the recommender, profile similarity between decision-maker and recommender, and rating overlap with a particular recommender influence the choices of decision-makers in such a context. While familiarity in this experiment did not affect the participants' choices, profile similarity and rating overlap had a significant influence. These results help us understand the decision-making processes in an online context and form the basis for user-centered social recommender system design.	Accounting for taste: using profile similarity to improve recommender systems	NA:NA:NA:NA	2018
David Ahlstroem:Rainer Alexandrowicz:Martin Hitz	In this paper we show how a model centered analysis of the usage of the mouse click interaction action in graphical user interfaces can be used to create a new menu system. The analysis identifies a possible new usage of the click action in cascading pull-down menus which can make it easier for the user during menu navigation and selection. A new menu system which is easy to implement, the ""Jumping Menu"", is introduced. The new menu system warps the screen cursor to the right into open sub-menu levels when a mouse click is detected inside a parent item. The Jumping Menu was compared with standard pull-down menus and force enhanced menus in a user experiment. The results show that the Jumping Menu and a force enhanced menu can facilitate menu interaction and that they are promising alternatives to conventional menu systems. Based on the results, a prediction model for selection times in Jumping Menus is developed.	Improving menu interaction: a comparison of standard, force enhanced and jumping menus	NA:NA:NA	2018
Shengdong Zhao:Maneesh Agrawala:Ken Hinckley	We present Zone and Polygon menus, two new variants of multi-stroke marking menus that consider both the relative position and orientation of strokes. Our menus are designed to increase menu breadth over the 8 item limit of status quo orientation-based marking menus. An experiment shows that Zone and Polygon menus can successfully increase breadth by a factor of 2 or more over orientation-based marking menus, while maintaining high selection speed and accuracy. We also discuss hybrid techniques that may further increase menu breadth and performance. Our techniques offer UI designers new options for balancing menu breadth and depth against selection speed and accuracy.	Zone and polygon menus: using relative position to increase the breadth of multi-stroke marking menus	NA:NA:NA	2018
Robert Pastel	The steering law is intended to predict the performance of cursor manipulations in user interfaces, but the law has been verified for only a few path shapes and should be verified for more if it is to be generalized. This study extends the steering law to paths with corners. Two experiments compare the movement times of negotiating paths with corners to straight paths with the same width and movement amplitude. The experimental results show a significant effect on the movement times due to the corners, extending far into the legs of the path's corner. Modeling the results using resource theory, a cognitive theory for divided attention, suggests that steering through corners is two simultaneous tasks: steering along the legs of the corner and aiming at the corner.	Measuring the difficulty of steering through corners	NA	2018
Shuo Wang:Xiaocao Xiong:Yan Xu:Chao Wang:Weiwei Zhang:Xiaofeng Dai:Dongmei Zhang	Motion-detection only games have inherent limitations on game experience in that the systems cannot identify the player's existence and identity. A way of improvement is by introducing information such as a player's face or head into the system. We designed and implemented two game prototypes that apply real-time face position information as intrinsic elements of gameplay to enhance game experience. The first prototype augmented a typical motion-detection-based game. Face information was designed to enhance the sense of presence and role-playing. In the second prototype, face tracking is applied as a new axis of control in a First Person Shooter (FPS) game.Although Face detection and tracking technology has started utilizing in game scenarios, there was little systematic research on how user experience is leveraged by applying face information to video games. The results of our user tests on comparing camera-based video games with and without face tracking demonstrated that using face position information can effectively enhance presence and role-playing. In addition, an intuitive control that augmented by face-tracking in the FPS game also got positive feedbacks from the test.	Face-tracking as an augmented input in video games: enhancing presence, role-playing and control	NA:NA:NA:NA:NA:NA:NA	2018
Hao Jiang:Eyal Ofek:Neema Moraveji:Yuanchun Shi	This paper describes the design and evaluation of a technique, Direct Pointer, that enables users to interact intuitively with large displays using cameras equipped on handheld devices, such as mobile phones and personal digital assistant (PDA). In contrast to many existing interaction methods that attempt to address the same problem, ours offers direct manipulation of the pointer position with continuous visual feedback. The primary advantage of this technique is that it only requires equipment that is readily available: an electronic display, a handheld digital camera, and a connection between the two. No special visual markers in the display content are needed, nor are fixed cameras pointing at the display. We evaluated the performance of Direct Pointer as an interaction product, showing that it performs as well as comparable techniques that require more sophisticated equipment.	Direct pointer: direct manipulation for large-display interaction using handheld cameras	NA:NA:NA:NA	2018
Jacob Eisenstein:Wendy E. Mackay	Communication appliances, intended for home settings, require intuitive forms of interaction. Computer vision offers a potential solution, but is not yet sufficiently accurate.As interaction designers, we need to know more than the absolute accuracy of such techniques: we must also be able to compare how they will work in our design settings, especially if we allow users to collaborate in the interpretation of their actions. We conducted a 2x4 within-subjects experiment to compare two interaction techniques based on computer vision: motion sensing, with EyeToy®-like feedback, and object tracking. Both techniques were 100% accurate with 2 or 5 choices. With 21 choices, object-tracking had significantly fewer errors and took less time for an accurate selection. Participants' subjective preferences were divided equally between the two techniques. This study compares these techniques as they would be used in real-world applications, with integrated user feedback, allowing interface designers to choose the one that best suits the specific user requirements for their particular application.	Interacting with communication appliances: an evaluation of two computer vision-based selection techniques	NA:NA	2018
Frank Biocca:Arthur Tang:Charles Owen:Fan Xiao	The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space. The technique utilizes dynamic perceptual affordances to draw user attention "down" the funnel to the target location. Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls.An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65%, increased search speed by 22%, and decreased mental workload by 18%. The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces.	Attention funnel: omnidirectional 3D cursor for mobile augmented reality platforms	NA:NA:NA:NA	2018
Steven Wall:Stephen Brewster	Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques.	Feeling what you hear: tactile feedback for navigation of audio graphs	NA:NA	2018
Helen Petrie:Fraser Hamilton:Neil King:Pete Pavan	Finding participants for evaluations with specific demographics can be a problem for usability and user experience specialists. In particular, finding participants with disabilities is especially problematic, yet testing with disabled people is becoming increasingly important. Two case studies are presented that explore using asynchronous remote evaluation techniques with disabled participants. These show that while quantitative data are comparable, the amount and richness of qualitative data are not likely to be comparable. The implications for formative and summative evaluations are discussed and a set of principles for local and remote evaluations with disabled users is presented.	Remote usability evaluations With disabled people	NA:NA:NA:NA	2018
Melissa Dawe	A surprisingly high percentage of assistive technology devices (35% or more) are purchased, but not successfully adopted. Through semi-structured interviews with a dozen families, we have come to understand the role technology plays in the lives of families who have a young adult with cognitive disabilities, and how families find, acquire, and use these technologies. This study addresses gaps in existing research and informs future efforts in assistive technology design. Design implications include the importance of simplicity not only in technology function but in configuration, documentation, maintenance, and upgrade or replacement; as well as the need for designers to use methods that consider the multiple individuals and stages involved in the technology adoption process.	Desperately seeking simplicity: how young adults with cognitive disabilities and their families adopt assistive technologies	NA	2018
Catherine Zanbaka:Paula Goolkasian:Larry Hodges	This study examines the roles of gender and visual realism in the persuasiveness of speakers. Participants were presented with a persuasive passage delivered by a male or female person, virtual human, or virtual character. They were then assessed on attitude change and their ratings of the argument, message, and speaker. The results indicated that the virtual speakers were as effective at changing attitudes as real people. Male participants were more persuaded when the speaker was female than when the speaker was male, whereas female participants were more persuaded when the speaker was male than when the speaker was female. Cross gender interactions occurred across all conditions, suggesting that some of the gender stereotypes that occur with people may carry over to interaction with virtual characters. Ratings of the perceptions of the speaker were more favorable for virtual speakers than for human speakers. We discuss the application of these findings in the design of persuasive human computer interfaces.	Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness	NA:NA:NA	2018
Katherine Isbister:Kristina Höök:Michael Sharp:Jarmo Laaksolahti	In this paper we describe the development and initial testing of a tool for self-assessment of affect while interacting with computer systems: the Sensual Evaluation Instrument. We discuss our research approach within the context of existing affective and HCI theory, and describe stages of evolution of the tool, and initial testing of its effectiveness.	The sensual evaluation instrument: developing an affective evaluation tool	NA:NA:NA:NA	2018
Saurabh Bhatia:Scott McCrickard	Our research investigates notification qualities of different types of voices, moving toward interfaces that support optimal allocation of attention to maximize system utility. We conducted an experiment to determine the interruption, reaction, and comprehension values of three different voice categories: the user's voice, a familiar voice, and an unfamiliar voice. Initial testing showed significant and impactful results: unfamiliar voices are the least interruptive, and a user reacts most quickly to one's own voice. Motivated by these findings, we report on the development and deployment of a notification system that exploits the differences in familiarity of a voice.	Listening to your inner voices: investigating means for voice notifications	NA:NA	2018
Jamie Pearson:Jiang Hu:Holly P. Branigan:Martin J. Pickering:Clifford I. Nass	People display adaptive language behaviors in face-to-face conversations, but will computer users do the same during HCI? We report an experiment (N=20) demonstrating that users' use of language (in terms of lexical choice) is influenced by their beliefs and expectations about a system: When users believe that the system is unsophisticated and restricted in capability, they adapt their language to match the system's language more than when they believe the system is relatively sophisticated and capable. Moreover, this tendency is based entirely on users' expectations about the system; it is unaffected by the actual behavior that the system exhibits. Our results demonstrate that interface design engenders particular beliefs in users about a system's capabilities, and that these beliefs can determine the extent to which users adapt to the system. We argue that such effects can be leveraged to improve the quality and effectiveness of human-computer interactions.	Adaptive language behavior in HCI: how expectations and beliefs about a system affect users' word choice	NA:NA:NA:NA:NA	2018
Anthony Tang:Melanie Tory:Barry Po:Petra Neumann:Sheelagh Carpendale	Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design.	Collaborative coupling over tabletop displays	NA:NA:NA:NA:NA	2018
David Kirk:Danae Stanton Fraser	The design of remote gesturing technologies is an area of growing interest. Current technologies have taken differing approaches to the representation of remote gesture. It is not clear which approach has the most benefit to task performance. This study therefore compared performance in a collaborative physical (assembly) task using remote gesture systems constructed with combinations of three different gesture formats (unmediated hands only, hands and sketch and digital sketch only) and two different gesture output locations (direct projection into a worker's task space or on an external monitor). Results indicated that gesturing with an unmediated representation of the hands leads to faster performance with no loss of accuracy. Comparison of gesture output locations did not find a significant difference between projecting gestures and presenting them on external monitors. These results are discussed in relation to theories of conversational grounding and the design of technologies from a 'mixed ecologies' perspective.	Comparing remote gesture technologies for supporting collaborative physical tasks	NA:NA	2018
Meredith Ringel Morris:Anqi Huang:Andreas Paepcke:Terry Winograd	Multi-user, touch-sensing input devices create opportunities for the use of cooperative gestures -- multi-user gestural interactions for single display groupware. Cooperative gestures are interactions where the system interprets the gestures of more than one user as contributing to a single, combined command. Cooperative gestures can be used to enhance users' sense of teamwork, increase awareness of important system events, facilitate reachability and access control on large, shared displays, or add a unique touch to an entertainment-oriented activity. This paper discusses motivating scenarios for the use of cooperative gesturing and describes some initial experiences with CollabDraw, a system for collaborative art and photo manipulation. We identify design issues relevant to cooperative gesturing interfaces, and present a preliminary design framework. We conclude by identifying directions for future research on cooperative gesturing interaction techniques.	Cooperative gestures: multi-user gestural interactions for co-located groupware	NA:NA:NA:NA	2018
Antti Salovaara:Giulio Jacucci:Antti Oulasvirta:Timo Saari:Pekka Kanerva:Esko Kurvinen:Sauli Tiitta	Traditionally, mobile media sharing and messaging has been studied from the perspective of an individual author making media available to other users. With the aim of supporting spectator groups at large-scale events, we developed a messaging application for camera phones with the idea of collectively created albums called Media Stories. The field trial at a rally competition pointed out the collective and participative practices involved in the creation and sense-making of media, challenging the view of individual authorship. Members contributed actively to producing chains of messages in Media Stories, with more than half of the members as authors on average in each story. Observations indicate the centrality of collocated viewing and creation in the use of media. Design implications include providing a ""common space"" and possibilities of creating collective objects, adding features that enrich collocated collective use, and supporting the active construction of awareness and social presence through the created media.	Collective creation and sense-making of mobile media	NA:NA:NA:NA:NA:NA:NA	2018
Mattias Esbjörnsson:Barry Brown:Oskar Juhlin:Daniel Normark:Mattias Östergren:Eric Laurier	Spectating at sport events is a common and popular leisure activity worldwide. Recently spectating has also become a topic of interest to CHI, particularly the design of technology for both performers and audiences. In this paper we describe an in-depth study of spectating, drawn from fieldwork of outdoor car rallies in the UK and Sweden. We describe three findings with relevance to design: the viewing paradox of spectating, active spectating and the role of sociability. We describe the MySplitTime prototype which address these issues while retaining the active sociable nature of the spectating experience.	Watching the cars go round and round: designing for active spectating	NA:NA:NA:NA:NA:NA	2018
Peta Wyeth	This paper describes an ethnographic study completed within a kindergarten environment with the view of gaining insights into the development of new technology for young children. Ethnography within HCI has primarily focused on studies of work practices. This project explored the effectiveness of ethnography in supporting the design of playful technology for a constantly changing, creative, and (sometimes) messy environment. The study was effective in drawing out patterns in observations and as such provides useful suggestions for the development of technology for kindergarten settings.	Ethnography in the kindergarten: examining children's play experiences	NA	2018
Gil Weinberg:Scott Driscoll	The paper presents our approach for human-machine interaction with an anthropomorphic mechanical percussionist that can listen to live players, analyze perceptual musical aspects in real-time, and use the product of this analysis to play along in a collaborative manner. Our robot, named Haile, is designed to combine the benefits of computational power, perceptual modeling, and algorithmic music with the richness, visual interactivity, and expression of acoustic playing. We believe that when interacting with live players, Haile can facilitate a musical experience that is not possible by any other means, inspiring users to collaborate with it in novel and expressive manners. Haile can, therefore, serve a test-bed for novel forms of musical human-machine interaction, bringing perceptual aspects of computer music into the physical world both visually and acoustically.	Robot-human interaction with an anthropomorphic percussionist	NA:NA	2018
Michael McCurdy:Christopher Connors:Guy Pyrzak:Bob Kanefsky:Alonso Vera	This paper presents a summary of the space of commonly-used HCI prototyping methods (low-fidelity to high-fidelity) and asserts that with a better understanding of this space, HCI practitioners will be better equipped to direct scarce prototyping resources toward an effort likely to yield specific results. It presents a set of five dimensions along which prototypes can be planned and characterized. The paper then describes an analysis of this space performed by members of the NASA Ames Human-Computer Interaction Group when considering prototyping approaches for a new set of tools for Mars mission planning and scheduling tools. A description is presented of a prototype that demonstrates design solutions that would have been particularly difficult to test given conventional low- or mid- fidelity prototyping methods. The prototype created was "mixed-fidelity," that is, high-fidelity on some dimensions and low-fidelity on others. The prototype is compared to a preexisting tool being redesigned and to a tool that has been developed using the prototype. Experimental data are presented that show the prototype to be a good predictor of eventual user performance with the final application. Given the relative cost of developing prototypes, it is critical to better characterize the space of fidelity in order to more precisely allocate design and development resources.	Breaking the fidelity barrier: an examination of our current characterization of prototypes and an example of a mixed-fidelity success	NA:NA:NA:NA:NA	2018
Maryam Tohidi:William Buxton:Ronald Baecker:Abigail Sellen	We present a study comparing usability testing of a single interface versus three functionally equivalent but stylistically distinct designs. We found that when presented with a single design, users give significantly higher ratings and were more reluctant to criticize than when presented with the same design in a group of three. Our results imply that by presenting users with alternative design solutions, subjective ratings are less prone to inflation and give rise to more and stronger criticisms when appropriate. Contrary to our expectations, our results also suggest that usability testing by itself, even when multiple designs are presented, is not an effective vehicle for soliciting constructive suggestions about how to improve the design from end users. It is a means to identify problems, not provide solutions.	Getting the right design and the design right	NA:NA:NA:NA	2018
Zhiwei Guan:Shirley Lee:Elisabeth Cuddihy:Judith Ramey	Retrospective Think aloud (RTA) is a usability method that collects the verbalization of a user's performance after the performance is over. There has been little work done to investigate the validity and reliability of RTA. This paper reports on an experiment investigating these issues with a form of the method called stimulated RTA. By comparing subjects' verbalizations with their eye movements, we support the validity and reliability of stimulated RTA: the method provides a valid account of what people attended to in completing tasks, it has a low risk of introducing fabrications, and its validity isn't affected by task complexity. More detailed analysis of RTA shows that it also provides additional information about user's inferences and strategies in completing tasks. The findings of this study provide valuable support for usability practitioners to use RTA and to trust the users' performance information collected by this method in a usability study.	The validity of the stimulated retrospective think-aloud method as measured by eye tracking	NA:NA:NA:NA	2018
Hrvoje Benko:Andrew D. Wilson:Patrick Baudisch	The size of human fingers and the lack of sensing precision can make precise touch screen interactions difficult. We present a set of five techniques, called Dual Finger Selections, which leverage the recent development of multi-touch sensitive displays to help users select very small targets. These techniques facilitate pixel-accurate targeting by adjusting the control-display ratio with a secondary finger while the primary finger controls the movement of the cursor. We also contribute a "clicking" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity. We implemented our techniques on a multi-touch tabletop prototype that offers computer vision-based tracking. In our formal user study, we tested the performance of our three most promising techniques (Stretch, X-Menu, and Slider) against our baseline (Offset), on four target sizes and three input noise levels. All three chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by our participants, with Stretch being the overall performance and preference winner.	Precise selection techniques for multi-touch screens	NA:NA:NA	2018
Meredith Ringel Morris:Andreas Paepcke:Terry Winograd:Jeannie Stamberger	We explore how the placement of control widgets (such as menus) affects collaboration and usability for co-located tabletop groupware applications. We evaluated two design alternatives: a centralized set of controls shared by all users, and separate per-user controls replicated around the borders of the shared tabletop. We conducted this evaluation in the context of TeamTag, a system for collective annotation of digital photos. Our comparison of the two design alternatives found that users preferred replicated over shared controls. We discuss the cause of this preference, and also present data on the impact of these interface design variants on collaboration, as well as the role that orientation, co-touching, and the use of different regions of the table played in shaping users' behavior and preferences.	TeamTag: exploring centralized versus replicated controls for co-located tabletop groupware	NA:NA:NA:NA	2018
Anand Agarawala:Ravin Balakrishnan	We explore making virtual desktops behave in a more physically realistic manner by adding physics simulation and using piling instead of filing as the fundamental organizational structure. Objects can be casually dragged and tossed around, influenced by physical characteristics such as friction and mass, much like we would manipulate lightweight objects in the real world. We present a prototype, called BumpTop, that coherently integrates a variety of interaction and visualization techniques optimized for pen input we have developed to support this new style of desktop organization.	Keepin' it real: pushing the desktop metaphor with physics, piles and the pen	NA:NA	2018
Justin D. Weisz:Thomas Erickson:Wendy A. Kellogg	IBM Community Tools (ICT) is a synchronous broadcast messaging system in use by a very large, globally distributed organization. ICT is interesting for a number of reasons, including its scale of use (thousands of users per day), its usage model of employing large scale broadcast to strangers to initiate small group interactions, and the fact that it is a synchronous system used across multiple time zones. In this paper we characterize the use of ICT in its context, examine the activities for which it is used, the motivations of its users, and the values they derive from it. We also explore problems with the system, and look at the social and technical ways in which users deal with them.	Synchronous broadcast messaging: the use of ICT	NA:NA:NA	2018
Darren Gergle:Robert E. Kraut:Susan R. Fussell	When pairs work together on a physical task, seeing a common workspace benefits their performance and transforms their use of language. Previous results have demonstrated that visual information helps collaborative pairs to understand the current state of their task, ground their conversations, and communicate efficiently. However, collaborative technologies often impinge on the visual information needed to support successful collaboration. One example of this is the introduction of delayed visual feedback in a collaborative environment. We present results from two studies that detail the form of the function that describes the relationship between visual delay and collaborative task performance. The first study precisely demonstrates how a range of visual delays differentially impact performance and the collaborative strategies employed. The second study describes how parameters of the task, such as the dynamics of the visual environment, reduce the amount of delay that can be tolerated.	The impact of delayed visual feedback on collaborative performance	NA:NA:NA	2018
Nick Yee:Jeremy N Bailenson:Kathryn Rickertsen	The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces.	A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces	NA:NA:NA	2018
Anne Anderson	NA	Session details: Faces & bodies in interaction	NA	2018
Tadeusz Stach:Carl Gutwin:David Pinelle:Pourang Irani	Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways.	Improving recognition and characterization in groupware with rich embodiments	NA:NA:NA:NA	2018
Robert J. Moore:E. Cabell Hankinson Gathman:Nicolas Ducheneaut:Eric Nickell	Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game's standard awareness cues and the other with enhanced cues. We use conversation analysis to demonstrate interactional slippages caused by the absence of awareness cues, user practices that circumvent such limitations and ways in which enhanced cues can enable tighter coordination.	Coordinating joint activity in avatar-mediated interaction	NA:NA:NA:NA	2018
David Gilmore:Jeremy Ashley:Tucker Viemeister:Tim Wood	NA	Industrial Design: Challenges and Successes Towards an integrated Product Development Process	NA:NA:NA:NA	2018
John Kolko:Jeff Veen:Jonathan Grubb	NA	Web 2.0 and the Enterprise: The Business Impact of Modern Technological Approaches to Web Application Design	NA:NA:NA	2018
Marti Hearst	NA	Faceted Metadata for Information Architecture and Search	NA	2018
Jim Herbsleb:Gary Olson	NA	Introduction to CSCW - 2	NA:NA	2018
Mary Beth Rosson	NA	Welcome to CHI	NA	2018
Stu Feldman	NA	ACM welcome	NA	2018
Bill Moggridge	NA	Opening Plenary Talk	NA	2018
Jim Herbsleb:Gary Olson	NA	Introduction to CSCW - 1	NA:NA	2018
Louise Barkhuus:Jennifer A. Rode	NA	From Mice to Men - 24 Years of Evaluation in CHI	NA:NA	2018
Mary Beth Rosson	NA	Thanks to our sponsors	NA	2018
Ana Klasnja	NA	Public Usability Laboratory	NA	2018
Mary Czerwinski:Desney Tan:Arnie Lund:Ben Shneiderman	NA	CHI 2008 Preview	NA:NA:NA:NA	2018
Gonzalo Ramos	NA	Tuesday CHI Madness	NA	2018
Keith Butler:Rob Jacobs:David Kieras	NA	Introduction to HCI - 1	NA:NA:NA	2018
Partick Baudish	NA	Monday CHI Madness	NA	2018
Bonnie E. John:Len Bass:Elspeth Golden	NA	Avoiding We Can't Change THAT!: An Introduction to Usability & Software Architecture	NA:NA:NA	2018
Jim Foley	NA	Past, Present, and Future of HCC Education: What We Teach, How We Teach	NA	2018
Patrick Baudisch	NA	Wednesday CHI Madness	NA	2018
Steven Wall:Ilona Posner	NA	Introduction	NA:NA	2018
Patrick Baudisch:Gonzalo Ramos	NA	CHI Madness: Summary of other entries	NA:NA	2018
NA	NA	Program addenda	NA	2018
Joseph 'Jofish' Kaye:Phoebe Sengers	NA	The Evolution of Evaluation	NA:NA	2018
Dennis Wixon:Mary Beth Rosson:David Gilmore	NA	CHI 2007 Welcome	NA:NA:NA	2018
Bonnie E. John:Elspeth Golden	NA	Avoiding We Can't Change That Either!: Usability Supporting Architectural Patterns	NA:NA	2018
Gregory D. Abowd	NA	Using Computing Technologies to Face the Challenges of Autism	NA	2018
Niti Bhan	NA	The mobile as a post Industrial platform for socio-economic development	NA	2018
Gilbert Cockton	NA	Make Evaluation Poverty History	NA	2018
Keith Butler:Rob Jacobs:David Kieras	NA	Introduction to HCI - 2	NA:NA:NA	2018
Gonzalo Ramos	NA	Thursday CHI Madness	NA	2018
Gary Marsden	NA	Doing HCI Differently -- Stories from the Developing World	NA	2018
Bill Lucas:Hiroshi Ishii:Jake Kolojejchick:Peter Lucas:David Rose	NA	Along the Path of Pervasive Computing: Selected Works in GUI and TUI Design	NA:NA:NA:NA:NA	2018
Brian Bailey	NA	Session details: Attention & interruption	NA	2018
Joe Tullio:Anind K. Dey:Jason Chalecki:James Fogarty	In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems.	How it works: a field study of non-technical users interacting with an intelligent system	NA:NA:NA:NA	2018
Jennifer Gluck:Andrea Bunt:Joanna McGrenere	This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed.	Matching attentional draw with utility in interruption	NA:NA:NA	2018
Daniel Avrahami:James Fogarty:Scott E. Hudson	People have developed a variety of conventions for negotiating face to face interruptions. The physical distribution of teams, however, together with the use of computer mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator. This paper presents a detailed comparison between self-reports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings. Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility. We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility. We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems.	Biases in human estimation of interruptibility: effects and implications for practice	NA:NA:NA	2018
Sara Kiesler	NA	Session details: Capturing life experiences	NA	2018
David Kirk:Abigail Sellen:Richard Harper:Ken Wood	In this paper we elucidate the patterns of behavior of home movie makers through a study of 12 families and a separate focus group of 7 teenagers. Analogous to a similar study of photowork [13], the goal is to provide a deeper understanding of what people currently do with video technologies, balancing the preponderence of techno-centric work in the area with appropriate user-centric insight. From our analysis, we derive a videowork lifecycle to frame the practices users engage in when working with video technologies in the home, and uncover two broad types of video usage therein. This has implications for how we conceive of and devise tools to support these practices, as we discuss.	Understanding videowork	NA:NA:NA:NA	2018
Vaiva Kalnikaité:Steve Whittaker	Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy.	Software or wetware?: discovering when and why people use digital prosthetic memory	NA:NA	2018
Abigail J. Sellen:Andrew Fogg:Mike Aitken:Steve Hodges:Carsten Rother:Ken Wood	We report on the results of a study using SenseCam, a "life-logging" technology in the form of a wearable camera, which aims to capture data about everyday life in order to support people's memory for past, personal events. We find evidence that SenseCam images do facilitate people's ability to connect to their past, but that images do this in different ways. We make a distinction between "remembering" the past, and "knowing" about it, and provide evidence that SenseCam images work differently over time in these capacities. We also compare the efficacy of user-captured images with automatically captured images and discuss the implications of these findings and others for how we conceive of and make claims about life-logging technologies.	Do life-logging technologies support memory for the past?: an experimental study using sensecam	NA:NA:NA:NA:NA:NA	2018
Mary Czerwinski	NA	Session details: Large displays	NA	2018
Jeremy P. Birnholtz:Tovi Grossman:Clarissa Mak:Ravin Balakrishnan	This paper reports on an exploratory study of the effects of input configuration on group behavior and performance in a collaborative task performed by a collocated group using a large display. Twelve groups completed a mixed-motive negotiation task under two conditions: a single, shared mouse and one mouse per person. Results suggest that the multiple mouse condition allowed for more parallel work, but the quality of discussion was higher in the single mouse condition. Moreover, participants were more likely to act in their own best interest in the multiple mouse condition.	An exploratory study of input configuration and group process in a negotiation task using a large display	NA:NA:NA:NA	2018
Beth Yost:Yonca Haciahmetoglu:Chris North	The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed.	Beyond visual acuity: the perceptual scalability of information visualizations for large displays	NA:NA:NA	2018
Derek F. Reilly:Kori M. Inkpen	The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute.	White rooms and morphing don't mix: setting and the evaluation of visualization techniques	NA:NA	2018
Lars Erik Holmquist	NA	Session details: Shake, rattle and roll: new forms of input and output	NA	2018
John Williamson:Roderick Murray-Smith:Stephen Hughes	Shoogle is a novel, intuitive interface for sensing data withina mobile device, such as presence and properties of textmessages or remaining resources. It is based around activeexploration: devices are shaken, revealing the contents rattlingaround "inside". Vibrotactile display and realistic impactsonification create a compelling system. Inertial sensingis used for completely eyes-free, single-handed interactionthat is entirely natural. Prototypes are described runningboth on a PDA and on a mobile phone with a wireless sensorpack. Scenarios of use are explored where active sensing ismore appropriate than the dominant alert paradigm.	Shoogle: excitatory multimodal interaction on mobile devices	NA:NA:NA	2018
Beverly Harrison	NA	Session details: Ubicomp tools	NA	2018
Scott Carter:Jennifer Mankoff:Jeffrey Heer	We present the iterative design of Momento, a tool that providesintegrated support for situated evaluation of ubiquitouscomputing applications. We derived requirements for Momento from a user-centered design process that includedinterviews, observations and field studies of early versionsof the tool. Motivated by our findings, Momento supportsremote testing of ubicomp applications, helps with participantadoption and retention by minimizing the need for newhardware, and supports mid-to-long term studies to addressinfrequently occurring data. Also, Momento can gather logdata, experience sampling, diary, and other qualitative data.	Momento: support for situated ubicomp experimentation	NA:NA:NA	2018
James Fogarty:Scott E. Hudson	Sensor based statistical models promise to support a variety of advances in human computer interaction, but building applications that use them is currently difficult and potential advances go unexplored. We present Subtle, a toolkit that removes some of the obstacles to developing and deploying applications using sensor based statistical models of human situations. Subtle provides an appropriate and extensible sensing library, continuous learning of personalized models, fully automated high level feature generation, and support for using learned models in deployed applications. By removing obstacles to developing and deploying sensor based statistical models, Subtle makes it easier to explore the design space surrounding sensor based statistical models of human situations. Subtle thus helps to move the focus of human computer interaction research onto applications and datasets, instead of the difficulties of developing and deploying sensor based statistical models.	Toolkit support for developing and deploying sensor-based statistical models of human situations	NA:NA	2018
Björn Hartmann:Leith Abdulla:Manas Mittal:Scott R. Klemmer	Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework.	Authoring sensor-based interactions by demonstration with direct manipulation and pattern recognition	NA:NA:NA:NA	2018
Kori Inkpen	NA	Session details: Mobile interaction	NA	2018
Matt Jones:George Buchanan:Richard Harper:Pierre-Louis Xech	Mobile search is becoming an increasingly important user activity. In this paper, instead of investigating the most efficient and effective ways of providing search results, the answers, we consider the value of giving access to previous queries, the questions, relating to a user's location. By exposing what other people have searched for, the aim is to provide useful insights into a location's character. To consider the value of the approach we deployed two mobile probes in a large-scale field study involving 391 participants. Our experiences suggest that presenting users with other people's in situ queries influences their information seeking interactions positively.	Questions not answers: a novel mobile search technique	NA:NA:NA:NA	2018
Stephen Brewster:Faraz Chohan:Lorna Brown	We present a study investigating the use of vibrotactile feedback for touch-screen keyboards on PDAs. Such key-boards are hard to use when mobile as keys are very small. We conducted a laboratory study comparing standard but-tons to ones with tactile feedback added. Results showed that with tactile feedback users entered significantly more text, made fewer errors and corrected more of the errors they did make. We ran the study again with users seated on an underground train to see if the positive effects trans-ferred to realistic use. There were fewer beneficial effects, with only the number of errors corrected significantly im-proved by the tactile feedback. However, we found strong subjective feedback in favour of the tactile display. The results suggest that tactile feedback has a key role to play in improving interactions with touch screens.	Tactile feedback for mobile interactions	NA:NA:NA	2018
Edward Clarkson:Kent Lyons:James Clawson:Thad Starner	MacKenzie and Soukoreff have previously introduced a Fitts' Law-based performance model of expert two-thumb text entry on mini-QWERTY keyboards [4]. In this work we validate the original model using results from a longitudinal study of mini-QWERTY keyboards, and update the model to account for observed inter-key time data.	Revisiting and validating a model of two-thumb text entry	NA:NA:NA:NA	2018
Martin Hachet:Joachim Pouderoux:Florence Tyndiuk:Pascal Guitton	Standard input devices for mobile phones are directional keys and discrete thumb-joysticks. These devices are dedicated to the discrete GUIs of the phones (eg. scroll lists and small icons arrays). Today, new mobile applications are arising and require adapted interfaces. In particular, the widespread of 3D applications will be favored if users can efficiently point on any part of thescreen. In this paper, we propose a new interaction technique called Jump and Refine for selection tasks on mobile phones. This technique is based on two levels of cursor displacement in order to reduce the number of keystrokes. The first level allows fast movements into an underlying grid. The second one can be used for accurate positioning into the selected area. We present a user study which shows that using a first coarse jump level decreases the selection completion times. The study also shows that the technique is widely accepted by the users. Finally, we discuss the optimal grid sizes.	"Jump and refine" for rapid pointing on mobile phones	NA:NA:NA:NA	2018
Jodi Forlizzi	NA	Session details: Politics & activism	NA	2018
Michael D. Byrne:Kristen K. Greene:Sarah P. Everett	In the United States, computer-based voting machines are rapidly replacing other older technologies. While there is potential for this to be a usability improvement, particularly in terms of accessibility, the only way it is possible to know if usability has improved is to have baseline data on the usability of traditional technologies. We report an experiment assessing the usability of punch cards, lever machines, and two forms of paper ballot. There were no differences in ballot completion time between the four methods, but there were substantial effects on error rate, with the paper ballots superior to the other methods as well as an interaction with age of voters. Subjective usability was assessed with the System Usability Scale and showed a slight advantage for bubble-style paper ballots. Overall, paper ballots were found to be particularly usable, which raises important technological and policy issues.	Usability of voting systems: baseline data for paper, punch cards, and lever machines	NA:NA:NA	2018
Mary Flanagan:Helen Nissenbaum	Can a set of articulated and tested methodologies be created whose endpoint is the reliable capacity for taking activist social themes into account? In this paper we explore a variety of educational and activist game approaches, and look specifically at the themes emerging from recent projects involving game design for young women. We articulate here design practices in a methodology, Values at Play (VAP), that could be used in the creation of games as well as the teaching of game design.	A game design methodology to incorporate social activist themes	NA:NA	2018
Patrick Baudisch	NA	Session details: Navigation & interaction	NA	2018
Robert Ball:Chris North:Doug A. Bowman	In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface.	Move to improve: promoting physical navigation to increase user performance with large displays	NA:NA:NA	2018
Olivier Chapuis:Nicolas Roussel	Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.	Copy-and-paste between overlapping windows	NA:NA	2018
Dugald Ralph Hutchings:John Stasko	We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.	Consistency, multiple monitors, and multiple windows	NA:NA	2018
Edward Tse:Chia Shen:Saul Greenberg:Clifton Forlines	Co-located collaborators often work over physical tabletops using combinations of expressive hand gestures and verbal utterances. This paper provides the first observations of how pairs of people communicated and interacted in a multimodal digital table environment built atop existing single user applications. We contribute to the understanding of these environments in two ways. First, we saw that speech and gesture commands served double duty as both commands to the computer, and as implicit communication to others. Second, in spite of limitations imposed by the underlying single-user application, people were able to work together simultaneously, and they performed interleaving acts: the graceful mixing of inter-person speech and gesture actions as commands to the system. This work contributes to the intricate understanding of multi-user multimodal digital table interaction.	How pairs interact over a multimodal digital table	NA:NA:NA:NA	2018
David McDonald	NA	Session details: Medical	NA	2018
Charlotte Tang:Sheelagh Carpendale	We present an observational study that was conducted to guide the design and development of technologies to support information flow during nurses' shift change in a hospital ward. Our goal is to find out how the complex information sharing processes during nurses' brief shift change unfold in a hospital setting. Our study shows the multitude of information media that nurses access during the parallel processes of information assembly and disassembly: digital, paper-based, displayed and verbal media. An initial analysis reveals how the common information spaces, where information media are positioned and accessible by all participants, are actively used and how they interact with the personal information spaces ephemerally constructed by the participants. Several types of information are consistently transposed from the common information spaces to the personal information space including: demographics, historical data, reminders and to-dos, alerts, prompts, scheduling and reporting information. Information types are often enhanced with a variety of visual cues to help nurses carry out their tasks.	An observational study on information flow during nurses' shift change	NA:NA	2018
Dorrit Billman:Eric A. Bier	Knowledge workers making sense of a topic divide their time among activities including searching for information, reading, and taking notes. We have built a software system that supports and integrates these activities. To test its effectiveness, we conducted a study where subjects used it to perform medical question-answering tasks. Initial results indicate that subjects could use the system, but that the nature of this use depended on the subject's overall question-answering strategy. Two dominant strategies emerged that we call the Reader and Searcher strategies.	Medical sensemaking with entity workspace	NA:NA	2018
Anthony Hornof	NA	Session details: Task & attention	NA	2018
Duncan P. Brumby:Andrew Howes:Dario D. Salvucci	The paper describes an approach to modeling the strategic variations in performing secondary tasks while driving. In contrast to previous efforts that are based on simulation of a cognitive architecture interacting with a task environment, we take an approach that develops a cognitive constraint model of the interaction between the driver and the task environment in order to make inferences about dual-task performance. Analyses of driving performance data reveal that a set of simple equations can be used to accurately model changes in the lateral position of the vehicle within the lane. The model quantifies how the vehicle's deviation from lane center increases during periods of inattention, and how the vehicle returns to lane center during periods of active steering. We demonstrate the benefits of the approach by modeling the dialing of a cellular phone while driving, where drivers balance the speed in performing the dial task with accuracy (or safety) in keeping the vehicle centered in the roadway. In particular, we show how understanding, rather than simulating, the constraints imposed by the task environment can help to explain the costs and benefits of a range of strategies for interleaving dialing and steering. We show how particular strategies are sensitive to a combination of internal constraints (including switch costs) and the trade-off between the amount of time allocated to secondary task and the risk of extreme lane deviation.	A cognitive constraint model of dual-task trade-offs in a highly dynamic driving task	NA:NA:NA	2018
Dario D. Salvucci:Daniel Markley:Mark Zuber:Duncan P. Brumby	Portable music players such as Apple's iPod have become ubiquitous in many environments, but one environment in particular has elicited new safety concerns and challenges -- in-vehicle use while driving. We present the first study of portable music-player interaction while driving, examining the effects of iPod interaction by drivers navigating a typical roadway in a driving simulator. Results showed that selecting media on the iPod had a significant effect on driver performance as measured by lateral deviation from lane center; the effect was comparable to previously reported effects of dialing a cellular phone. In addition, selecting media and watching videos had a significant effect on car-following speed, resulting in speed reductions that presumably compensated for impaired lateral performance. Given that iPod interaction has become increasingly common while driving, these results serve as a first step toward understanding the potential effects of portable music-player interaction on driver behavior and performance.	iPod distraction: effects of portable music-player use on driver performance	NA:NA:NA:NA	2018
Ken Hinckley:Shengdong Zhao:Raman Sarin:Patrick Baudisch:Edward Cutrell:Michael Shilman:Desney Tan	Using a notebook to sketch designs, reflect on a topic, or capture and extend creative ideas are examples of active note taking tasks. Optimal experience for such tasks demands concentration without interruption. Yet active note taking may also require reference documents or emails from team members. InkSeine is a Tablet PC application that supports active note taking by coupling a pen-and-ink interface with an in situ search facility that flows directly from a user's ink notes (Fig. 1). InkSeine integrates four key concepts: it leverages preexisting ink to initiate a search; it provides tight coupling of search queries with application content; it persists search queries as first class objects that can be commingled with ink notes; and it enables a quick and flexible workflow where the user may freely interleave inking, searching, and gathering content. InkSeine offers these capabilities in an interface that is tailored to the unique demands of pen input, and that maintains the primacy of inking above all other tasks.	InkSeine: In Situ search for active note taking	NA:NA:NA:NA:NA:NA:NA	2018
Paul Aoki	NA	Session details: Expert/novice	NA	2018
Jeffrey Wong:Lui Min Oh:Jiazhi Ou:Carolyn P. Rosé:Jie Yang:Susan R. Fussell	Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system.	Sharing a single expert among multiple partners	NA:NA:NA:NA:NA:NA	2018
Amy Hurst:Scott E. Hudson:Jennifer Mankoff	If applications were able to detect a user's expertise, then software could automatically adapt to better match exper-tise. Detecting expertise is difficult because a user's skill changes as the user interacts with an application and differs across applications. This means that expertise must be sensed dynamically, continuously, and unobtrusively so as not to burden the user. We present an approach to this prob-lem that can operate without a task model based on low-level mouse and menu data which can typically be sensed across applications at the operating systems level. We have implemented and trained a classifier that can detect "nov-ice" or "skilled" use of an image editing program, the GNU Image Manipulation Program (GIMP), at 91% accuracy, and tested it against real use. In particular, we developed and tested a prototype application that gives the user dy-namic application information that differs depending on her performance.	Dynamic detection of novice vs. skilled use without a task model	NA:NA:NA	2018
Anna Dickinson:Michael J. Smith:John L. Arnott:Alan F. Newell:Robin L. Hill	A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful "proof of concept" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group.	Approaches to web search and navigation for older computer novices	NA:NA:NA:NA:NA	2018
Scott McCrickard	NA	Session details: Mobile applications	NA	2018
Sean Michael White:Dominic Marino:Steven Feiner	Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general.	Designing a mobile user interface for automated species identification	NA:NA:NA	2018
Alan L. Liu:Yang Li	It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications.	BrickRoad: a light-weight tool for spontaneous design of location-enhanced applications	NA:NA	2018
Lucy E. Dunne:Barry Smyth	Wearable technology presents a wealth of new HCI issues. In particular, this paper addresses the impact of the physical interaction between the user's body and the device's physical form on the user's mental representation of self and cognitive abilities, a blend of HCI and ergonomics that is unique to wearable computing. We explore the human sensory mechanisms that facilitate perception of worn objects and the elements of sensation that influence the comfort of worn objects, and discuss the psychological elements that may cause worn objects to be forgotten or detected, wearable or not. We discuss the implications of un-wearability on attention and cognitive capability.	Psychophysical elements of wearability	NA:NA	2018
Feng Tian:Xiang Ao:Hongan Wang:Vidya Setlur:Guozhong Dai	In order to improve stimulus-response compatibility of touchpad in pen-based user interface, we present the tilt cursor, i.e. a cursor dynamically reshapes itself to providing the 3D orientation cue of pen. We also present two experiments that evaluate the tilt cursor's performance in circular menu selection and specific marking menu selection tasks. Results show that in a specific marking menu selection task, the tilt cursor significantly outperforms the shape-fixed arrow cursor and the live cursor [4]. In addition, results show that by using the tilt cursor, the response latencies for adjusting drawing directions are smaller than that by using the other two kinds of cursors.	The tilt cursor: enhancing stimulus-response compatibility by providing 3d orientation cue of pen	NA:NA:NA:NA:NA	2018
Martina Ziefle:Ulrik Schroeder:Judith Strenk:Thomas Michel	In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks.	How younger and older adults master the usage of hyperlinks in small screen devices	NA:NA:NA:NA	2018
Robert Jacob	NA	Session details: Navigation	NA	2018
Raghavendra S. Kattinakere:Tovi Grossman:Sriram Subramanian	Interaction techniques that utilize the space above the display surface to extend the functionalities of digitized surfaces continue to emerge. In such techniques, movements are constrained by the bounds of a layer. In addition, constraints imposed on the direction of movement within the layer may be present. Despite the presence of such techniques, there is limited understanding of human capabilities for performing the required steering task. In this paper we study and model user performance when steering through constrained and unconstrained paths in above-the-surface layers. Through a series of experiments we validate the derivation and applicability of our proposed models.	Modeling steering within above-the-surface interaction layers	NA:NA:NA	2018
Yves Guiard:Yangzhou Du:Olivier Chapuis	This article pursues a two-fold goal. First we introduce degree of goal directedness (DGD), a novel quantitative dimension for the taxonomy of navigation tasks in general. As an attempt to operationalize the DGD concept in the context of electronic documents navigation, we introduce the serial target-acquisition (STA) experimental paradigm. We suggest that DGD and the STA paradigm may usefully enrich the conceptual toolkit of HCI research for the evaluation of navigation techniques. Our second goal is to illustrate the utility of the DGD concept by showing with a concrete example, Perspective Drag, the refinement it allows in evaluating navigation techniques. We report data obtained from two experiments with the STA paradigm that cast light on what Perspective Drag is specifically good for: it is particularly suitable in realistic task contexts where navigation is less than 100% directed by its terminal goal, that is, where the user wants not only to reach a particular item but also to pick up information from the document during document traversal.	Quantifying degree of goal directedness in document navigation: application to the evaluation of the perspective-drag technique	NA:NA:NA	2018
Aurélien Tabard:Wendy Mackay:Nicolas Roussel:Catherine Letondal	PageLinker is a browser extension that allows to contextualise navigation by linking web pages together and to navigate through a network of related web pages without prior planning. The design is based on extensive interviews with biologists, which highlighted their difficulties finding previously visited web pages. They found current browser tools inadequate, resulting in poorly organised bookmarks and rarely used history lists. In a four-week controlled field experiment, PageLinker significantly reduced time, page loads and mouse clicks. By presenting links in context, PageLinker facilitates web page revisitation, is less prone to bookmark overload and is highly robust to change.	PageLinker: integrating contextual bookmarks within a browser	NA:NA:NA:NA	2018
Jakob Bardram	NA	Session details: Photo sharing	NA	2018
Andrew D. Miller:W. Keith Edwards	In this paper, we present initial findings from the study of a digital photo-sharing website: Flickr.com. In particular, we argue that Flickr.com appears to support-for some people-a different set of photography practices, socialization styles, and perspectives on privacy that are unlike those described in previous research on consumer and amateur photographers. Further, through our examination of digital photographers' photowork activities-organizing, finding, sharing and receiving-we suggest that privacy concerns and lack of integration with existing communication channels have the potential to prevent the 'Kodak Culture' from fully adopting current photo-sharing solutions.	Give and take: a study of consumer photo-sharing culture and practice	NA:NA	2018
Shane Ahern:Dean Eckles:Nathaniel S. Good:Simon King:Mor Naaman:Rahul Nair	As sharing personal media online becomes easier and widely spread, new privacy concerns emerge - especially when the persistent nature of the media and associated context reveals details about the physical and social context in which the media items were created. In a first-of-its-kind study, we use context-aware camerephone devices to examine privacy decisions in mobile and online photo sharing. Through data analysis on a corpus of privacy decisions and associated context data from a real-world system, we identify relationships between location of photo capture and photo privacy settings. Our data analysis leads to further questions which we investigate through a set of interviews with 15 users. The interviews reveal common themes in privacy considerations: security, social disclosure, identity and convenience. Finally, we highlight several implications and opportunities for design of media sharing applications, including using past privacy patterns to prevent oversights and errors.	Over-exposed?: privacy patterns and considerations in online and mobile photo sharing	NA:NA:NA:NA:NA:NA	2018
Jingyu Cui:Fang Wen:Rong Xiao:Yuandong Tian:Xiaoou Tang	Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: "cluster annotation" puts similar faces or photos with similar scene together, and enables user label them in one operation; "contextual re-ranking" boosts the labeling productivity by guessing the user intention; "ad hoc annotation" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album.	EasyAlbum: an interactive photo annotation system based on face clustering and re-ranking	NA:NA:NA:NA:NA	2018
Joanna McGrenere	NA	Session details: Empirical studies of web interaction	NA	2018
Melanie Kellar:Carolyn Watters:Kori M. Inkpen	Monitoring occurs when users return to previously viewed web pages to view new or updated information. While tools exist to support web-based monitoring, we know little about the monitoring activities users engage in and the nature of the support needed. We have conducted 40 semi-structured interviews in order to better understand the types of information users monitor and the characteristics of different monitoring activities. Using the data collected during the interviews, we characterized monitoring as an activity within six web information tasks: Browsing, Communications, Fact Finding, Information Gathering, Maintenance, and Transactions. The results of our study have been used to provide general, as well as task specific, recommendations for the design of monitoring tools.	An exploration of web-based monitoring: implications for design	NA:NA:NA	2018
Jan Hartmann:Alistair Sutcliffe:Antonella De Angeli	A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed.	Investigating attractiveness in web user interfaces	NA:NA:NA	2018
Helen Petrie:Omar Kheir	Accessibility and usability are well established concepts for user interfaces and websites. Usability is precisely defined, but there are different approaches to accessibility. In addition, different possible relationships could exist between problems encountered by disabled and non-disabled users, yet little empirical data have been gathered on this question. Guidelines for accessibility and usability of websites provide ratings of the importance of problems for users, yet little empirical data have been gathered to validate these ratings. A study investigated the accessibility of two websites with 6 disabled (blind) and 6 non-disabled (sighted) people. Problems encountered by the two groups comprised two intersecting sets, with approximately 15% overlap. For one of the two websites, blind people rated problems significantly more severely than sighted people. There was high agreement between participants as to the severity of problems, and agreement between participants and researchers. However, there was no significant agreement between either participants or researchers and the importance/priority ratings provided by accessibility and usability guidelines. Practical and theoretical implications of these results are discussed.	The relationship between accessibility and usability of websites	NA:NA	2018
Chris North	NA	Session details: Gaze & eye tracking	NA	2018
Edward Cutrell:Zhiwei Guan	Web search services are among the most heavily used applications on the World Wide Web. Perhaps because search is used in such a huge variety of tasks and contexts, the user interface must strike a careful balance to meet all user needs. We describe a study that used eye tracking methodologies to explore the effects of changes in the presentation of search results. We found that adding information to the contextual snippet significantly improved performance for informational tasks but degraded performance for navigational tasks. We discuss possible reasons for this difference and the design implications for better presentation of search results.	What are you looking for?: an eye-tracking study of information usage in web search	NA:NA	2018
Zhiwei Guan:Edward Cutrell	Web search engines present search results in a rank ordered list. This works when what a user wants is near the top, but sometimes the information that the user really wants is located at the bottom of the page. This study examined how users' search behaviors vary when target results were displayed at various positions for informational and navigational tasks. We found that when targets were placed relatively low in the first page of search results, people spent more time searching and were less successful in finding the target, especially for informational tasks. Further analysis of eye movements showed that the decrease in search performance was partially due to the fact that users rarely looked at lower ranking results. The large decrease in performance for informational search is probably because users have high confidence in the search engine's ranking; in contrast to navigational tasks, where the target is more obvious from information presented in the results, in informational tasks, users try out the top ranked results even if these results are perceived as less relevant for the task.	An eye tracking study of the effect of target rank on web search	NA:NA	2018
Manu Kumar:Andreas Paepcke:Terry Winograd	We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.	EyePoint: practical pointing and selection using gaze and keyboard	NA:NA:NA	2018
Tim Halverson:Anthony J. Hornof	Visual search is an important part of human-computer interaction. It is critical that we build theory about how people visually search displays in order to better support the users' visual capabilities and limitations in everyday tasks. One way of building such theory is through computational cognitive modeling. The ultimate promise for cognitive modeling in HCI it to provide the science base needed for predictive interface analysis tools. This paper discusses computational cognitive modeling of the perceptual, strategic, and oculomotor processes people used in a visual search task. This work refines and rounds out previously reported cognitive modeling and eye tracking analysis. A revised "minimal model" of visual search is presented that explains a variety of eye movement data better than the original model. The revised model uses a parsimonious strategy that is not tied to a particular visual structure or feature beyond the location of objects. Three characteristics of the minimal strategy are discussed in detail.	A minimal model for predicting visual search in human-computer interaction	NA:NA	2018
A. J. Brush	NA	Session details: Online representation of self	NA	2018
Cliff A.C. Lampe:Nicole Ellison:Charles Steinfield	Using data from a popular online social network site, this paper explores the relationship between profile structure (namely, which fields are completed) and number of friends, giving designers insight into the importance of the profile and how it works to encourage connections and articulated relationships between users. We describe a theoretical framework that draws on aspects of signaling theory, common ground theory, and transaction costs theory to generate an understanding of why certain profile fields may be more predictive of friendship articulation on the site. Using a dataset consisting of 30,773 Facebook profiles, we determine which profile elements are most likely to predict friendship links and discuss the theoretical and design implications of our findings.	A familiar face(book): profile elements as signals in an online social network	NA:NA:NA	2018
Asimina Vasalou:Adam N. Joinson:Jeremy Pitt	Three studies investigated whether users' strategies for customising online avatars increase their self-focused attention, also known as private self-awareness. Study 1 showed that a high number of users adapt their avatars toreflect their own appearance. Study 2 demonstrated that users who perceive their avatars to be similar to their own appearance experience as a result heightened private self-awareness. In Study 3, private self-awareness pervadedsocial interaction taking place over time when users with representative avatars, compared to a control group, reported increased private self-awareness. Drawing from research in interpersonal communication, we suggest that avatars which increase their owners' self-focus may have an influence on online behavior in the context of social computing.	Constructing my online self: avatars that increase self-focused attention	NA:NA:NA	2018
Jeffrey T. Hancock:Catalina Toma:Nicole Ellison	Online dating is a popular new tool for initiating romantic relationships, although recent research and media reports suggest that it may also be fertile ground for deception. Unlike previous studies that rely solely on self-report data, the present study establishes ground truth for 80 online daters' height, weight and age, and compares ground truth data to the information provided in online dating profiles. The results suggest that deception is indeed frequently observed, but that the magnitude of the deceptions is usually small. As expected, deceptions differ by gender. Results are discussed in light of the Hyperpersonal model and the self-presentational tensions experienced by online dating participants.	The truth about lying in online dating profiles	NA:NA:NA	2018
Aniket Kittur:Bongwon Suh:Bryan A. Pendleton:Ed H. Chi	Wikipedia, a wiki-based encyclopedia, has become one of the most successful experiments in collaborative knowledge building on the Internet. As Wikipedia continues to grow, the potential for conflict and the need for coordination increase as well. This article examines the growth of such non-direct work and describes the development of tools to characterize conflict and coordination costs in Wikipedia. The results may inform the design of new collaborative knowledge systems.	He says, she says: conflict and coordination in Wikipedia	NA:NA:NA:NA	2018
Ian Smith	NA	Session details: Innovative interactions	NA	2018
Tovi Grossman:Nicholas Kong:Ravin Balakrishnan	We investigate pointing at graphical targets of arbitrary shapes. We first describe a previously proposed probabilistic Fitts' law model [7] which, unlike previous models that only account for rectangular targets, has the potential to handle arbitrary shapes. Three methods of defining the centers of arbitrarily shaped targets for use within the model are developed. We compare these methods of defining target centers, and validate the model using a pointing experiment in which the targets take on various shapes. Results show that the model can accurately account for the varying target shapes. We discuss the implications of our results to interface design.	Modeling pointing at targets of arbitrary shapes	NA:NA:NA	2018
Daniel Wigdor:Chia Shen:Clifton Forlines:Ravin Balakrishnan	Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments.	Perception of elementary graphical elements in tabletop and multi-surface environments	NA:NA:NA:NA	2018
Tovi Grossman:Daniel Wigdor:Ravin Balakrishnan	Volumetric displays, which provide a 360° view of imagery illuminated in true 3D space, are a promising platform for interactive 3D applications. However, presenting text in volumetric displays can be a challenge, as the text may not be oriented towards the user. This is especially problematic with multiple viewers, as the text could, for example, appear forwards to one user, and backwards to another. In a first experiment we determined the effects of 3D rotations on text readability. Based on the results, we developed and evaluated a new technique which optimizes text orientation for multiple viewers. This technique provided 33% faster group reading times in a collaborative experimental task.	Exploring and reducing the effects of orientation on text readability in volumetric displays	NA:NA:NA	2018
Jon Kolko	NA	Session details: Design theory	NA	2018
John Zimmerman:Jodi Forlizzi:Shelley Evenson	For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.	Research through design as a method for interaction design research in HCI	NA:NA:NA	2018
Eli Blevis	This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being. This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates--with particular examples of design critique for interactive products and appeals to secondary research--how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described.	Sustainable interaction design: invention & disposal, renewal & reuse	NA	2018
Anna Vallgårda:Johan Redström	Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.	Computational composites	NA:NA	2018
Elizabeth Goodman	NA	Session details: Play & exercise	NA	2018
Shannon O'Brien:Florian "Floyd" Mueller	People enjoy jogging with others for social and motivational reasons. However, as reported by forum participants, finding a compatible, local jogging partner who shares the ability to jog at the same pace for the same duration is not always easy. One possible way to overcome this challenge is to expand the range of potential jogging partners by allowing for interaction with remote joggers. We investigated whether a jogging experience supporting conversation between remote partners could be desirable and motivating. We conducted an experiment with 18 volunteers using conventional mobile phones with headsets to support conversations as participants jogged in disjoint, outdoor areas. Results show that a simple audio connection supports participants' need to socialize and allows partners to encourage each other.	Jogging the distance	NA:NA	2018
Michael Muller	NA	Session details: Home spirituality	NA	2018
Allison Woodruff:Sally Augustin:Brooke Foucault	We present a qualitative study of 20 American Orthodox Jewish families' use of home automation for religious purposes. These lead users offer insight into real-life, long-term experience with home automation technologies. We discuss how automation was seen by participants to contribute to spiritual experience and how participants oriented to the use of automation as a religious custom. We also discuss the relationship of home automation to family life. We draw design implications for the broader population, including surrender of control as a design resource, home technologies that support long-term goals and lifestyle choices, and respite from technology.	Sabbath day home automation: "it's like mixing technology and religion"	NA:NA:NA	2018
William Gaver:Phoebe Sengers:Tobie Kerridge:Joseph Kaye:John Bowers	Domestic ubiquitous computing systems often rely on inferences about activities in the home, but the open-ended, dynamic and heterogeneous nature of the home poses serious problems for such systems. In this paper, we propose that by shifting the responsibility for interpretation from the system to the user, we can build systems that interact with people at humanly meaningful levels, preserve privacy, and encourage engagement with suggested topics. We describe a system that embodies this hypothesis, using sensors and inferencing software to assess 'domestic wellbeing' and presenting the results to inhabitants through an output chosen for its ambiguity. In a three-month field study of the system, customised for a particular volunteer household, users engaged extensively with the system, discussing and challenging its outputs and responding to the particular topics it raised.	Enhancing ubiquitous computing with user interpretation: field testing the home health horoscope	NA:NA:NA:NA:NA	2018
Erika Shehan:W. Keith Edwards	For much of the industrialized world, network connectivity in the home is commonplace. Despite the large number of networked homes, even the most technically savvy people can have difficulties with home network installation and maintenance. We contend that these problems will not disappear over time as the networking industry matures, but rather are due to structural usability flaws inherent in the design of existing network infrastructure, devices, and protocols. The HCI community can offer a unique perspective to overcoming the challenges associated with home networking. This paper discusses why home networking is difficult, based on analysis of historical, social, and technical factors. It explores how the designs of existing home networking technologies have implications for usability, and examines a range of models for addressing these usability challenges. The paper concludes with a discussion of how these models may impact future research efforts in both HCI and networking.	Home networking and HCI: what hath god wrought?	NA:NA	2018
Margaret Burnett	NA	Session details: Programming by professionals	NA	2018
Mauro Cherubini:Gina Venolia:Rob DeLine:Andrew J. Ko	Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research.	Let's go to the whiteboard: how and why software developers use drawings	NA:NA:NA:NA	2018
Marat Boshernitsan:Susan L. Graham:Marti A. Hearst	Software developers must modify their programs to keepup with changing requirements and designs. Often, aconceptually simple change can require numerous editsthat are similar but not identical, leading to errors andomissions. Researchers have designed programming environmentsto address this problem, but most of thesesystems are counter-intuitive and difficult to use.By applying a task-centered design process, we developeda visual tool that allows programmers to makecomplex code transformations in an intuitive manner.This approach uses a representation that aligns wellwith programmers' mental models of programming structures.The visual language combines textual and graphicalelements and is expressive enough to support a broadrange of code-changing tasks. To simplify learning thesystem, its user interface scaffolds construction and executionof transformations. An evaluation with Java programmerssuggests that the interface is intuitive, easyto learn, and effective on a representative editing task.	Aligning development tools with the way programmers think about code changes	NA:NA:NA	2018
Jason B. Ellis:Shahtab Wahid:Catalina Danis:Wendy A. Kellogg	As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles.	Task and social visualization in software development: evaluation of a prototype	NA:NA:NA:NA	2018
Ed Chi	NA	Session details: Web usability	NA	2018
Shuo Wang:Feng Jing:Jibo He:Qixing Du:Lei Zhang	Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable. IGroup, a proposed image search engine addresses these problems by presenting the result in semantic clusters. The original result set was clustered in semantic groups with a cluster name relevant to user typed queries. Instead of looking through the result pages or modifying queries, IGroup users can refine findings to the interested sub-result sets with a navigational panel, where each cluster (sub-result set) was listed with a cluster name and representative thumbnails of the cluster. We compared IGroup with a general web image search engine: MSN, in term of efficiency, coverage, and satisfaction with a substantial user study. Our tool shows significant improvement in such criteria.	IGroup: presenting web image search results in semantic clusters	NA:NA:NA:NA:NA	2018
Hartmut Obendorf:Harald Weinreich:Eelco Herder:Matthias Mayer	This paper presents results of an extensive long-term click-stream study of Web browser usage. Focusing on character and challenges of page revisitation, previous findings from seven to thirteen years ago are updated. The term page re-visit had to be differentiated, since the recurrence rate--the key measure for the share of page revisits--turns out to strongly depend on interpretation. We identify different types of revisitation that allow assessing the quality of current user support and developing concepts for new tools. Individual navigation strategies differ dramatically and are strongly influenced by personal habits and type of site visited. Based on user action logs and interviews, we distinguished short-term revisits (backtrack or undo) from medium-term (re-utilize or observe) and long-term revisits (rediscover). We analyze current problems and provide suggestions for improving support for different revisitation types.	Web page revisitation revisited: implications of a long-term click-stream study of browser usage	NA:NA:NA:NA	2018
Nathaniel S. Good:Jens Grossklags:Deirdre K. Mulligan:Joseph A. Konstan	Spyware is an increasing problem. Interestingly, many programs carrying spyware honestly disclose the activities of the software, but users install the software anyway. We report on a study of software installation to assess the effectiveness of different notices for helping people make better decisions on which software to install. Our study of 222 users showed that providing a short summary notice, in addition to the End User License Agreement (EULA), before the installation reduced the number of software installations significantly. We also found that providing the short summary notice after installation led to a significant number of uninstalls. However, even with the short notices, many users installed the program and later expressed regret for doing so. These results, along with a detailed analysis of installation, regret, and survey data about user behaviors informs our recommendations to policymakers and designers for assessing the "adequacy" of consent in the context of software that exhibits behaviors associated with spyware.	Noticing notice: a large-scale experiment on the timing of software license agreements	NA:NA:NA:NA	2018
Ann Blandford	NA	Session details: Empirical models	NA	2018
Kasper Hornbæk:Effie Lai-Chong Law	Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 ± .059 (Pearson's product-moment correlation with 95% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 ± .064, and effectiveness and satisfaction one of .164 ± .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized.	Meta-analysis of correlations among usability measures	NA:NA	2018
Andy Cockburn:Carl Gutwin:Saul Greenberg	Menus are a primary control in current interfaces, but there has been relatively little theoretical work to model their performance. We propose a model of menu performance that goes beyond previous work by incorporating components for Fitts' Law pointing time, visual search time when novice, Hick-Hyman Law decision time when expert, and for the transition from novice to expert behaviour. The model is able to predict performance for many different menu designs, including adaptive split menus, items with different frequencies and sizes, and multi-level menus. We tested the model by comparing predictions for four menu designs (traditional menus, recency and frequency based split menus, and an adaptive 'morphing' design) with empirical measures. The empirical data matched the predictions extremely well, suggesting that the model can be used to explore a wide range of menu possibilities before implementation.	A predictive model of menu performance	NA:NA:NA	2018
Edward Lank:Yi-Chun Nikko Cheng:Jaime Ruiz	Recently proposed novel interaction techniques such as cursor jumping [1] and target expansion for tiled arrangements [13] are predicated on an ability to effectively estimate the endpoint of an input gesture prior to its completion. However, current endpoint estimation techniques lack the precision to make these interaction techniques possible. To address a recognized lack of effective endpoint prediction mechanisms, we propose a new technique for endpoint prediction that applies established laws of motion kinematics in a novel way to the identification of motion endpoint. The technique derives a model of speed over distance that permits extrapolation. We verify our model experimentally using stylus targeting tasks, and demonstrate that our endpoint prediction is almost twice as accurate as the previously tested technique [13] at points more than twice as distant from motion endpoint.	Endpoint prediction using motion kinematics	NA:NA:NA	2018
Stephen Brewster	NA	Session details: Mobile interaction techniques I	NA	2018
Clifton Forlines:Daniel Wigdor:Chia Shen:Ravin Balakrishnan	We investigate the differences -- in terms of bothquantitative performance and subjective preference -- between direct-touch and mouse input for unimanual andbimanual tasks on tabletop displays. The results of twoexperiments show that for bimanual tasks performed ontabletops, users benefit from direct-touch input. However,our results also indicate that mouse input may be moreappropriate for a single user working on tabletop tasksrequiring only single-point interaction.	Direct-touch vs. mouse input for tabletop displays	NA:NA:NA:NA	2018
Daniel Vogel:Patrick Baudisch	Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary--over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets.	Shift: a technique for operating pen-based interfaces using touch	NA:NA	2018
Jacob O. Wobbrock:Duen Horng Chau:Brad A. Myers	A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like "pressure strokes." In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70% of the speed of the front, and the front joystick could be used eyes-free at about 80% of the speed of normal use.	An alternative to push, press, and tap-tap-tap: gesturing on an isometric joystick for mobile phone text entry	NA:NA:NA	2018
Scott Klemmer	NA	Session details: Tasks	NA	2018
Shamsi T. Iqbal:Eric Horvitz	We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.	Disruption and recovery of computing tasks: field study, analysis, and directions	NA:NA	2018
Tye Rattenbury:John Canny	Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more "ready-at-hand" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system.	CAAD: an automatic task support system	NA:NA	2018
Shamsi T. Iqbal:Brian P. Bailey	The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks.	Understanding and developing models for detecting and differentiating breakpoints during interactive tasks	NA:NA	2018
John Carroll	NA	Session details: Emergency action	NA	2018
Zachary O. Toups:Andruid Kerne	Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.	Implicit coordination in firefighting practice: design implications for teaching fire emergency responders	NA:NA	2018
Paul M. Aoki	While tactical command. control and communication environments might appear to be entirely instrumental in nature, they nevertheless provide a setting for social interaction. This paper describes how such interaction occurs in a particular naval tactical command and control system, focusing on the shared perspectives created by the organizational, administrative and professional aspects of the environment and on issues of self-presentation. It is argued that the complexity and multiplicity of interactional regions in this environment lead to problematic situations for key actors, and that these problems may have relevance to future computing environments.	Back stage on the front lines: perspectives and performance in the combat information center	NA	2018
Leysia Palen:Sophia B. Liu	Recent world-wide crisis events have drawn new attention to the role information communication technology (ICT) can play in warning and response activities. Drawing on disaster social science, we consider a critical aspect of post-impact disaster response that does not yet receive much information science research attention. Public participation is an emerging, large-scale arena for computer-mediated interaction that has implications for both informal and formal response. With a focus on persistent citizen communications as one form of interaction in this arena, we describe their spatial and temporal arrangements, and how the emerging information pathways that result serve different post-impact functions. However, command-and-control models do not easily adapt to the expanding data-generating and -seeking activities by the public. ICT in disaster contexts will give further rise to improvised activities and temporary organizations with which formal response organizations need to align.	Citizen communications in crisis: anticipating a future of ICT-supported public participation	NA:NA	2018
Steve Harrison	NA	Session details: Design methods	NA	2018
Sara Ljungblad:Lars Erik Holmquist	Transfer scenarios is a method developed to support the design of innovative interactive technology. Such a method should help the designer to come up with inventive ideas, and at the same time provide grounding in real human needs. In transfer scenarios, we use marginal practices to encourage a changed mindset throughout the design process. A marginal practice consists of individuals who share an activity that they find meaningful. We regard these individuals not as end-users, but as valuable input in the design process. We applied this method when designing novel applications for autonomous embodied agents, e.g. robots. Owners of unusual pets, such as snakes and spiders, were interviewed - not with the intention to design robot pets, but to determine underlying needs and interests of their practice. The results were then used to design a set of applications for more general users, including a dynamic living-room wall and a set of communicating hobby robots.	Transfer scenarios: grounding innovation with marginal practices	NA:NA	2018
Keith A. Butler:Jiajie Zhang:Chris Esposito:Ali Bahrami:Ron Hebron:David Kieras	We present the case study of a complex, mixed-initiative scheduling system to illustrate Work-Centered Design (WCD), a new approach for the design of information systems. WCD is based on theory of distributed cognition and extends established user-centered methods with abstract task modeling, using innovative techniques for work ontology and top-level algorithms to capture the logic of a human-computer interaction paradigm. WCD addresses a long-standing need for more effective methods of function allocation. The illustrating case study succeeded on a large, difficult problem for aircraft scheduling where prior expensive attempts failed. The new system, called Solver, reduces scheduling labor from 9 person-days a week to about 1 person-hour. These results were obtained from the first user test, demonstrating notable effectiveness of WCD. Further, the value of Solver's higher quality schedules is far-reaching. WCD extends HCI methods to fill an important need for technical problem-solving systems.	Work-centered design: a case study of a mixed-initiative scheduler	NA:NA:NA:NA:NA:NA	2018
Shumin Zhai	NA	Session details: Mobile interaction techniques II	NA	2018
Gonzalo Ramos:Andy Cockburn:Ravin Balakrishnan:Michel Beaudouin-Lafon	Using a stylus on a tablet computer to acquire small targets can be challenging. In this paper we present pointing lenses -- interaction techniques that help users acquire and select targets by presenting them with an enlarged visual and interaction area. We present and study three pointing lenses for pen-based systems and find that our proposed Pressure-Activated Lens is the top overall performer in terms of speed, accuracy and user preference. In addition, our experimental results not only show that participants find all pointing lenses beneficial for targets smaller than 5 pixels, but they also suggest that this benefit may extend to larger targets as well.	Pointing lenses: facilitating stylus input through visual-and motor-space magnification	NA:NA:NA:NA	2018
Will Seager:Danae Stanton Fraser	It is well-established finding that people find maps easier to use when they are aligned so that "up" on the map corresponds to the user's forward direction. With map-based applications on handheld mobile devices, this forward/up correspondence can be maintained in several ways: the device can be physically rotated within the user's hands or the user can manually operate buttons to digitally rotate the map; alternatively, the map can be rotated automatically using data from an electronic compass. This paper examines all three options. In a field experiment, each method is compared against a baseline north-up condition. The study provides strong evidence that physical rotation is the most effective with applications that present the user with a wider map. The paper concludes with some suggestions for design improvements.	Comparing physical, automatic and manual map rotation for pedestrian navigation	NA:NA	2018
Chia Shen	NA	Session details: Tangibility	NA	2018
Vincent LeClerc:Amanda Parkes:Hiroshi Ishii	We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes. Using Senspectra, a user incrementally assembles and refines a physical 3D model of discrete elements with a real-time visualization of structural strain. While the Senspectra infrastructure provides a flexible modular sensor network platform, its primary application derives from the need to couple physical modeling techniques utilized in architecture and design disciplines with systems for structural engineering analysis. This offers direct manipulation augmented with visual feedback for an intuitive approach to physical real-time finite element analysis, particularly for organic forms.	Senspectra: a computationally augmented physical modeling toolkit for sensing and visualization of structural strain	NA:NA:NA	2018
Morten Fjeld:Jonas Fredriksson:Martin Ejdestig:Florin Duca:Kristina Bötschi:Benedikt Voegtli:Patrick Juchli	Augmented Chemistry (AC) is an application that utilizes a tangible user interface (TUI) for organic chemistry education. The empirical evaluation described in this paper compares learning effectiveness and user acceptance of AC versus the more traditional ball-and-stick model (BSM). Learning effectiveness results were almost the same for both learning environments. User preference and rankings, using NASA-TLX and SUMI, showed more differences and it was therefore decided to focus mainly on improving these aspects in a re-design of the AC system. For enhanced interaction, keyboard-free system configuration, and internal/external database (DB) access, a graphical user interface (GUI) has been incorporated into the TUI. Three-dimensional (3D) rendering has also been improved using shadows and related effects, thereby enhancing depth perception. The re-designed AC system was then compared to the old system by means of a small qualitative user study. This user study showed an improvement in subjective opinions a out the system's ease of use and ease of learning.	Tangible user interface for chemistry education: comparative evaluation and re-design	NA:NA:NA:NA:NA:NA:NA	2018
James Patten:Hiroshi Ishii	This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation.	Mechanical constraints as computational constraints in tabletop tangible interfaces	NA:NA	2018
Enrico Costanza:Samuel A. Inverso:Rebecca Allen:Pattie Maes	Mobile communication devices, such as mobile phones and networked personal digital assistants (PDAs), allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces. This private -- public contrast can be problematic. As a remedy, we promote intimate interfaces: interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment. In particular, motionless gestures sensed through the electromyographic (EMG) signal have been proposed as a solution to allow subtle input in a mobile context. In this paper we present an expansion of the work on EMG-based motionless gestures including (1) a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and (2) a formal assessment of how noticeable they are to informed observers. Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.	Intimate interfaces in action: assessing the usability and subtlety of emg-based motionless gestures	NA:NA:NA:NA	2018
Carl Gutwin	NA	Session details: Games	NA	2018
A. Fleming Seay:Robert E. Kraut	A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency.	Project massive: self-regulation and problematic use of online gaming	NA:NA	2018
Nicolas Ducheneaut:Nicholas Yee:Eric Nickell:Robert J. Moore	Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or "guilds" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.	The life and death of online gaming communities: a look at guilds in world of warcraft	NA:NA:NA:NA	2018
Archer L. Batcheller:Brian Hilligoss:Kevin Nam:Emilee Rader:Marta Rey-Babarro:Xiaomu Zhou	Video connections can establish a media space in which games may be played, just as people play games while collocated. Experiments with participants playing the game 'Mafia' indicate that people in a video condition have similar levels of satisfaction, fun, and frustration, to those that play while collocated. This finding holds for both those with prior experience using video systems and those without, suggesting it is not merely a "novelty effect." Results differ about whether there exist differences in focus of attention, suspicion/trust, and pointing for people playing the game while using a video system. Implications for both fun and work uses of video are suggested.	Testing the technology: playing games with video conferencing	NA:NA:NA:NA:NA:NA	2018
Ville Nenonen:Aleksi Lindblad:Ville Häkkinen:Toni Laitinen:Mikko Jouhtio:Perttu Hämäläinen	This paper presents a novel way of using real-time heart rate information to control a physically interactive biathlon (skiing and shooting) computer game. Instead of interfacing the game to an exercise bike or other equipment with speed output, the skiing speed is directly proportional to heart rate. You can freely choose the form of physical exercise, which makes it easier for people with different skill levels and backgrounds to play together. The system can be used with any exercise machine or form. To make playing meaningful instead of simply exercising as hard as you can, a high heart rate impedes the shooting part of the game by making the sight less steady. This balancing mechanism lets the player try out different tactics, varying from very slow skiing and sharp shooting to fast skiing and random shooting. The game has been evaluated in a user study with eight participants. The results show that heart rate interaction is fun and usable interaction method.	Using heart rate to control an interactive game	NA:NA:NA:NA:NA:NA	2018
Wendy Mackay	NA	Session details: Video	NA	2018
Kenton O'Hara:April Slayden Mitchell:Alex Vorbau	Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed.	Consuming video on mobile devices	NA:NA:NA	2018
Yaxiao Song:Gary Marchionini	Video surrogates are meant to help people quickly make sense of the content of a video before downloading or seeking more detailed information. In this paper we present the results of a study comparing the effectiveness of three different surrogates for objects in digital video libraries. Thirty-six people participated in a within subjects user study in which they did five tasks for each of three surrogate alternatives: visual alone (a storyboard), audio alone (spoken description), and combined visual and audio (a storyboard augmented with spoken description). The results show that combined surrogates are more effective, strongly preferred, and do not penalize efficiency. The results also demonstrate that spoken descriptions alone lead to better understanding of the video segments than do visual storyboards alone, although people like to have visual surrogates and use them to confirm interpretations and add context. Participants were able to easily use the combined surrogates even though they were not synchronized, suggesting that synchronization of different media channels may not be necessary in surrogates as it is in full video. The results suggest that multimodal surrogates should be incorporated into video retrieval user interfaces and audio surrogates should be used in small display interfaces. The study also raises questions about the need to synchronize different information channels in multimedia surrogates.	Effects of audio and visual surrogates for making sense of digital video	NA:NA	2018
Justin D. Weisz:Sara Kiesler:Hui Zhang:Yuqing Ren:Robert E. Kraut:Joseph A. Konstan	Watching video online is becoming increasingly popular, and new video streaming technologies have the potential to transform video watching from a passive, isolating experience into an active, socially engaging experience. However, the viability of an active social experience is unclear: both chatting and watching video require attention, and may interfere with one another and detract from the experience. In this paper, we empirically examine the activity of chatting while watching video online. We examine how groups of friends and strangers interact, and find that chat has a positive influence on social relationships, and people chat despite being distracted. We discuss the benefits and opportunities provided by mixing chat and video, uncover some of the attentional and social challenges inherent in this combination of media, and provide guidance for structuring the viewing experience.	Watching together: integrating text chat with video	NA:NA:NA:NA:NA:NA	2018
Carlos Jensen	NA	Session details: Security	NA	2018
Wendy Moncur:Grégory Leplâtre	Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security.	Pictures at the ATM: exploring the usability of multiple graphical passwords	NA:NA	2018
Supriya Singh:Anuja Cabraal:Catherine Demosthenous:Gunela Astbrink:Michele Furlong	Current systems for banking authentication require that customers not reveal their access codes, even to members of the family. A study of banking and security in Australia shows that the practice of sharing passwords does not conform to this requirement. For married and de facto couples, password sharing is seen as a practical way of managing money and a demonstration of trust. Sharing Personal Identification Numbers (PINs) is a common practice among remote indigenous communities in Australia. In areas with poor banking access, this is the only way to access cash. People with certain disabilities have to share passwords with carers, and PIN numbers with retail clerks. In this paper we present the findings of a qualitative user study of banking and money management. We suggest design criteria for banking security systems, based on observed social and cultural practices of password and PIN number sharing.	Password sharing: implications for security design based on social practice	NA:NA:NA:NA:NA	2018
Ponnurangam Kumaraguru:Yong Rhee:Alessandro Acquisti:Lorrie Faith Cranor:Jason Hong:Elizabeth Nunge	Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems.	Protecting people from phishing: the design and evaluation of an embedded training email system	NA:NA:NA:NA:NA:NA	2018
Diane Schiano	NA	Session details: Emotion & empathy	NA	2018
Sascha Mahlke:Manfred Thüring	This paper describes a research approach to the experimental study of emotional experiences and their connections to other components of user experience in human-technology interaction. We present a model of user experience that integrates interaction characteristics, instrumental and non-instrumental quality perceptions, emotional user reactions and overall judgments of system quality. An experiment is reported to illustrate the application of our approach. System properties of an interactive prototype were varied to produce versions of different usability and aesthetics which in turn led to different perceptions of instrumental and non-instrumental qualities. The results indicate that both quality aspects significantly influence emotional reactions with respect to subjective feelings, facial expressions and physiological responses. These findings are consistent with the users' overall judgments of the systems and show that the perception of both, instrumental and non-instrumental qualities influences the appraisal of interactive systems.	Studying antecedents of emotional experiences in interactive contexts	NA:NA	2018
Ulrike Pfeil:Panayiotis Zaphiris	This article presents an investigation of empathy within an online community for older people (SeniorNet). Qualitative content analysis of 400 messages from a discussion board about depression was used to determine how empathy is expressed and facilitated in online communication. Special emphasis was placed on determining the components of online empathy. A code scheme that we developed to analyse online empathy is also presented. The findings were compared to offline studies about empathy in order to investigate the influence that the mediating technology has on the phenomenon.	Patterns of empathy in online communication	NA:NA	2018
Jeffrey T. Hancock:Christopher Landrigan:Courtney Silver	Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication.	Expressing emotion in text-based communication	NA:NA:NA	2018
Colin Swindells:Karon E. MacLean:Kellogg S. Booth:Michael J. Meitner	Physical controls such as knobs, sliders, and buttons are experiencing a revival as many computing systems progress from personal computing architectures towards ubiquitous computing architectures. We demonstrate a process for measuring and comparing visceral emotional responses of a physical control to performance results of a target acquisition task. In our user study, participants experienced mechanical and rendered friction, inertia, and detent dynamics as they turned a haptic knob towards graphical targets of two different widths and amplitudes. Together, this process and user study provide novel affect- and performance-based design guidance to developers of physical controls for emerging ubiquitous computing environments. Our work bridges extensive human factors work in mechanical systems that peaked in the 1960's, to contemporary trends, with a goal of integrating mechatronic controls into emerging ubiquitous computing systems.	Exploring affective design for physical controls	NA:NA:NA:NA	2018
Wendy Kellogg	NA	Session details: Collaboration at work	NA	2018
Greg Little:Tessa A. Lau:Allen Cypher:James Lin:Eben M. Haber:Eser Kandogan	We present Koala, a system that enables users to capture, share, automate, and personalize business processes on the web. Koala is a collaborative programming-by-demonstration system that records, edits, and plays back user interactions as pseudo-natural language scripts that are both human- and machine-interpretable. Unlike previous programming by demonstration systems, Koala leverages sloppy programming that interprets pseudo-natural language instructions (as opposed to formal syntactic statements) in the context of a given web page's elements and actions. Koala scripts are automatically stored in the Koalescence wiki, where a community of users can share, run, and collaboratively develop their "how-to" knowledge. Koala also takes advantage of corporate and personal data stores to automatically generalize and instantiate user-specific data, so that scripts created by one user are automatically personalized for others. Our initial experiences suggest that Koala is surprisingly effective at interpreting instructions originally written for people.	Koala: capture, share, automate, personalize business processes on the web	NA:NA:NA:NA:NA:NA	2018
A.J. Bernheim Brush:Brian R. Meyers:Desney S. Tan:Mary Czerwinski	Software can now track which computer applications and documents you use. This provides us with the potential to help end-users recall past activities for tasks such as status reporting. We describe findings from field observations of eight participants writing their status reports. We observed interesting trends, including the reliance on memory triggers, which were either retrieved from explicit self-reminders, from implicit breadcrumbs left while performing their tasks or directly from memory. Participants perceived spending relatively short amounts of time composing their status reports, suggesting that any technology solution must offer dramatic improvements over current practice.	Understanding memory triggers for task tracking	NA:NA:NA:NA	2018
John C. Tang:Clemens Drews:Mark Smith:Fei Wu:Alison Sue:Tessa Lau	We studied files stored by members of a work organization for patterns of social commonality. Discovering identical or similar documents, applications, developer libraries, or other files may suggest shared interests or experience among users. Examining actual file data revealed a number of individual and aggregate practices around file storage. For example, pairs of users typically have many (over 13,000) files in common. A prototype called LiveWire exploits this commonality to make file backup and restore more efficient for a work organization. We removed commonly shared files and focused on specific filetypes that represent user activity to find more meaningful files in common. The Consolidarity project explores how patterns of file commonality could encourage social networking in an organizational context. Mechanisms for addressing the privacy concerns raised by this approach are discussed.	Exploring patterns of social commonality among file directories at work	NA:NA:NA:NA:NA:NA	2018
Saverio Perugini:Taylor J. Anderson:William F. Moroney	We present the first user study of out-of-turn interaction inmenu-based, interactive voice-response systems. Out-of-turn interaction is atechnique which empowers the user (unable to respond to the current prompt) totake the conversational initiative by supplying information that is currentlyunsolicited, but expected later in the dialog. The technique permits the userto circumvent any flows of navigation hardwired into the design and navigatethe menus in a manner which reflects their model of the task. We conducted alaboratory experiment to measure the effect of the use of out-of-turninteraction on user performance and preference in a menu-based, voice interfaceto voicemail. Specifically, we compared two interfaces with the exact samehierarchical menu design: one with the capability of accepting out-of-turnutterances and one without this feature. The results indicate that out-of-turninteraction significantly reduces task completion time, improves usability, andis preferred to the baseline. This research studies an unexplored dimension ofthe design space for automated telephone services, namely the nature ofuser-addressable input (utterance) supplied (in-turn vs. out-of-turn), incontrast to more traditional dimensions such as input modality (touch-tone vs.text vs. voice) and style of interaction (menu-based vs. natural language).	A study of out-of-turn interaction in menu-based, IVR, voicemail systems	NA:NA:NA	2018
Gina Venolia	NA	Session details: Tags, tagging & notetaking	NA	2018
Morgan Ames:Mor Naaman	Why do people tag? Users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. We investigate the incentives for annotation in Flickr, a popular web-based photo-sharing system, and ZoneTag, a cameraphone photo capture and annotation tool that uploads images to Flickr. In Flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. ZoneTag, in turn, makes it easier to tag cameraphone photos that are uploaded to Flickr by allowing annotation and suggesting relevant tags immediately after capture. A qualitative study of ZoneTag/Flickr users exposed various tagging patterns and emerging motivations for photo annotation. We offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. Our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation.	Why we tag: motivations for annotation in mobile and online media	NA:NA	2018
Aaron Bauer:Kenneth R. Koedinger	The increasing integration of education and technology has led to the development of a range of note-taking applications. Our project's goal is to provide empirical data to guide the design of such note-taking applications by evaluating the behavioral and learning outcomes of different note-taking functionality. The study reported here compares note-taking using a text editor and four interaction techniques. The two standard techniques are typing and copy-paste. The two novel techniques are restricted copy-paste and menu-selection, intended to increase attention and processing respectively. Hypothesized learning gains from the novel techniques were not observed. As implemented these techniques were less efficient and appeared to be more frustrating to use. However, data regarding differences in both note-taking efficiency and learning suggest several important implications for selection-based note-taking applications, such as pasting and highlighting. Our results also indicate that students have strong opinions regarding their note-taking practices, which may complicate potentially beneficial interventions.	Selection-based note-taking applications	NA:NA	2018
Kaj Mäkelä:Sara Belt:Dan Greenblatt:Jonna Häkkilä	In this paper, we present a study of user perceptions on mobile interaction with visual and RFID tags. Although mobile interaction with tags has been proposed in several earlier studies, user perceptions and usability comparisons of different tag technologies have not been intensively investigated. In contrast to earlier studies, which report on user studies with evaluating new concepts or interaction techniques, we take another approach and examine the current understanding of the techniques and user perceptions on them. Our field study of 50 users charts currently existing user perceptions and reveals potential usability risks that are due to the limited or erroneous understanding of the interaction technique.	Mobile interaction with visual and RFID tags: a field study on user perceptions	NA:NA:NA:NA	2018
A. W. Rivadeneira:Daniel M. Gruen:Michael J. Muller:David R. Millen	Tagclouds are visual presentations of a set of words, typically a set of "tags" selected by some rationale, in which attributes of the text such as size, weight, or color are used to represent features, such as frequency, of the associated terms. This note describes two studies to evaluate the effectiveness of differently constructed tagclouds for the various tasks they can be used to support, including searching, browsing, impression formation and recognition. Based on these studies, we propose a paradigm for evaluating tagclouds and ultimately guidelines for tagcloud construction.	Getting our head in the clouds: toward evaluation studies of tagclouds	NA:NA:NA:NA	2018
Ed Cuttrell	NA	Session details: Multimodal interactions	NA	2018
Garth Shoemaker:Carl Gutwin	Multi-point interaction tasks involve the manipulation of several mutually-dependent control points in a visual workspace -- for example, adjusting a selection rectangle in a drawing application. Multi-point interactions place conflicting requirements on the interface: the system must display objects at sufficient scale for detailed manipulation, but it must also provide an efficient means of navigating from one control point to another. Current interfaces lack any explicit support for tasks that combine these two requirements, forcing users to carry out sequences of zoom and pan actions. In this paper, we describe three novel mechanisms for view control that explicitly support multi-point interactions with a single mouse, and preserve both visibility and scale for multiple regions of interest. We carried out a study to compare two of the designs against standard zoom and pan techniques, and found that task completion time was significantly reduced with the new approaches. The study shows the potential of interfaces that combine support for both scale and navigation.	Supporting multi-point interaction in visual workspaces	NA:NA	2018
Edward C. Kaiser:Paulo Barthelmess:Candice Erdmann:Phil Cohen	Lecturers, presenters and meeting participants often say what they publicly handwrite. In this paper, we report on three empirical explorations of such multimodal redundancy -- during whiteboard presentations, during a spontaneous brainstorming meeting, and during the informal annotation and discussion of photographs. We show that redundantly presented words, compared to other words used during a presentation or meeting, tend to be topic specific and thus are likely to be out-of-vocabulary. We also show that they have significantly higher tf-idf (term frequency-inverse document frequency) weights than other words, which we argue supports the hypothesis that they are dialogue-critical words. We frame the import of these empirical findings by describing SHACER, our recently introduced Speech and HAndwriting reCognizER, which can combine information from instances of redundant handwriting and speech to dynamically learn new vocabulary.	Multimodal redundancy across handwriting and speech during computer mediated human-human interactions	NA:NA:NA:NA	2018
Susan Fussell	NA	Session details: Distributed interaction	NA	2018
Xianghua Ding:Thomas Erickson:Wendy A. Kellogg:Stephen Levy:James E. Christensen:Jeremy Sussman:Tracee Vetting Wolf:William E. Bennett	IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics.	An empirical study of the use of visually enhanced voip audio conferencing: the case of IEAC	NA:NA:NA:NA:NA:NA:NA:NA	2018
Jeffrey Heer:Fernanda B. Viégas:Martin Wattenberg	This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.	Voyagers and voyeurs: supporting asynchronous collaborative information visualization	NA:NA:NA	2018
David Kirk:Tom Rodden:Danaë Stanton Fraser	Remote gesture systems have been shown to provide a significant enhancement to performance in collaborative physical tasks, an effect ascribed to the ability of remote gestures to help ground deictic references. The argument that this effect works by replacing complex referential descriptions with simple pointing behaviours has been drawn into question by recent research. In this paper we significantly unpack the effects of remote gesturing on collaborative language, arguing for a more complex role for remote gestures in interaction. We demonstrate how remote gestures influence the structure of collaborative discourse, and how their use can also influence the temporal nature of the grounding process. Through generating a deeper understanding of these effects of remote gesturing on collaborative language we derive implications for the development and deployment of these technologies.	Turn it this way: grounding collaborative action with remote gestures	NA:NA:NA	2018
Deborah Tatar	NA	Session details: Learning & education	NA	2018
Kyle Johnsen:Andrew Raij:Amy Stevens:D. Scott Lind:Benjamin Lok	Any new tool introduced for education needs to be validated. We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.	The validity of a virtual human experience for interpersonal skills education	NA:NA:NA:NA:NA	2018
Ryan S.J.d. Baker	We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.	Modeling and understanding students' off-task behavior in intelligent tutoring systems	NA	2018
Elizabeth Gerber	Existing research addresses how designers create tools to support improvisation, yet little research explores how improvisation offers tools to support design work. This paper explores the potential relationship between improvisation and design, examining how design can benefit from improvisation. The paper argues that improvisation can build perspectives and skills that are critical for designers, such as creative collaboration, fostering innovation, supporting spontaneity, learning through error, and presenting ideas. The paper reviews the use of improvisation activities by designers in a multi-case study. The applications are analyzed to demonstrate individual and group level outcomes in design work.	Improvisation principles and techniques for design	NA	2018
Piotr D. Adamczyk:Michael B. Twidale	Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design.	Supporting multidisciplinary collaboration: requirements from novel HCI education	NA:NA	2018
John Thomas	NA	Session details: Designing for specific cultures	NA	2018
Kirsten Boehner:Janet Vertesi:Phoebe Sengers:Paul Dourish	We trace how cultural probes have been adopted and adapted by the HCI community. The flexibility of probes has been central to their uptake, resulting in a proliferation of divergent uses and derivatives. The varying patterns of adaptation of the probes reveal important underlying issues in HCI, suggesting underacknowledged disagreements about valid interpretation and the relationship between methods and their underlying methodology. With this analysis, we aim to clarify discussions around probes, and, more importantly, around how we define and evaluate methods in HCI, especially those grounded in unfamiliar conceptions of how research should be done.	How HCI interprets the probes	NA:NA:NA:NA	2018
Divya Ramachandran:Matthew Kam:Jane Chiu:John Canny:James F. Frankel	Technology arguably has the potential to play a key role in improving the lives of people in developing regions. However, these communities are not well understood and designers must thoroughly investigate possibilities for technological innovations in these contexts. We describe findings from two field studies in India and one in Uganda where we explore technological solutions in the domains of communication, microfinance and education. Two common underlying themes emerge from these studies: (1) local stakeholders can contribute cultural information relevant to design such as needs and practices through interaction with technology artifacts and (2) unique social network structures embedded within communities are crucial to the acceptance and potential adoption of technology. We end with a synthesis of the three experiences that draws some practical lessons for ICT designers to elicit meaningful feedback and participation from local stakeholders in developing regions communities.	Social dynamics of early stage co-design in developing regions	NA:NA:NA:NA:NA	2018
Matthew Kam:Divya Ramachandran:Varun Devanathan:Anuj Tewari:John Canny	Poor literacy remains a decisive barrier to the economic empowerment of many people in the developing world. Of particular importance is literacy in a widely spoken "world language" such as English, which is typically a second language for these speakers. For complex reasons, schools are often not effective as vehicles for second language learning. In this paper we explore game-like language learning on cell phones. We argue that phones are an excellent technology platform in the typical ecologies of developing countries. We present the PACE framework that is intended to support the rapid, scalable development of language learning software localized for a particular community of learners. These learners are usually skeptical of formal education and of cultural biases they encounter in learning "remote" languages in particular. Localization of content is crucial to make the language relevant to them and to encourage them to adopt it.	Localized iterative design for language learning in underdeveloped regions: the PACE framework	NA:NA:NA:NA:NA	2018
Yvonne Rogers	NA	Session details: Mobile kits & stuff	NA	2018
Rafael Ballagas:Faraz Memon:Rene Reiners:Jan Borchers	iStuff Mobile is the first rapid prototyping framework that helps explore new sensor-based interfaces with existing mobile phones. It focuses on sensor-enhanced physical interfaces for ubiquitous computing scenarios. The framework includes sensor network platforms, mobile phone software, and a proven rapid prototyping framework. Interaction designers can use iStuff Mobile to quickly create and test functional prototypes of novel interfaces without making internal hardware or software modifications to the handset. A visual programming paradigm provides a low threshold for prototyping activities: the system is not difficult to learn. At the same time, the range of examples built using the toolkit demonstrates a high ceiling for prototyping activities: the toolkit places few limits on prototype complexity. A user study shows that the visual programming metaphor enables prototypes to be built faster and encourages more iterations than a previous approach.	iStuff mobile: rapidly prototyping new mobile phone interfaces for ubiquitous computing	NA:NA:NA:NA	2018
Antti Salovaara	Technologies can be used - or appropriated - in different ways by different users, but how do the use patterns evolve, and how can design facilitate such evolution? This paper approaches these questions in light of a case study in which a group of 8 high school students used Comeks, a mobile comic strip creator that enables users to exchange rich, expressive multimedia messages. A qualitative analysis of the use processes shows how users turned the functionalities embodied in Comeks into particular resources for communication during the 9-week trial period. The paper discusses the relationship of functionalities of the artifact and the development of resources by presenting how functionalities can be designed to support three ways to appropriate communication technologies: increasing technical mastery, re-channeling existing communication into the new medium and inventing new communicative acts between users.	Appropriation of a MMS-based comic creator: from system functionalities to resources for action	NA	2018
Antti Oulasvirta:Lauri Sumari	A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ, appropriating their physical and operational properties. The design implications are discussed.	Mobile kits and laptop trays: managing multiple devices in mobile information work	NA:NA	2018
Anind Dey	NA	Session details: Novel navigation	NA	2018
Per Ola Kristensson:Shumin Zhai	This paper presents a new command selection method that provides an alternative to pull-down menus in pen-based mobile interfaces. Its primary advantage is the ability forusers to directly select commands from a very large set without the need to traverse menu hierarchies. The proposed method maps the character strings representing the commands onto continuous pen-traces on a stylus keyboard. The user enters a command by stroking part of its character string. We call this method "command strokes." We present the results of three experiments assessing the usefulness of the technique. The first experiment shows that command strokes are 1.6 times faster than the de-facto standard pull-down menus and that users find command strokes more fun to use. The second and third experiments investigate the effect of displaying a visual preview of the currently recognized command while the user is still articulating the command stroke. These experiments show that visual preview does not slow users down and leads to significantly lower error rates and shorter gestures when users enter new unpracticed commands.	Command strokes with and without preview: using pen gestures on keyboard for command selection	NA:NA	2018
Mark Hancock:Sheelagh Carpendale:Andy Cockburn	On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -- 3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.	Shallow-depth 3d interaction: design and evaluation of one-, two- and three-touch techniques	NA:NA:NA	2018
Lucia Terrenghi:David Kirk:Abigail Sellen:Shahram Izadi	This work presents the results of a comparative study in which we investigate the ways manipulation of physical versus digital media are fundamentally different from one another. Participants carried out both a puzzle task and a photo sorting task in two different modes: in a physical 3-dimensional space and on a multi-touch, interactive tabletop in which the digital items resembled their physical counterparts in terms of appearance and behavior. By observing the interaction behaviors of 12 participants, we explore the main differences and discuss what this means for designing interactive surfaces which use aspects of the physical world as a design resource.	Affordances for manipulation of physical versus digital media on interactive surfaces	NA:NA:NA:NA	2018
Catalina Danis	NA	Session details: People, looking at people	NA	2018
Andreas Girgensohn:Frank Shipman:Thea Turner:Lynn Wilcox	A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available.	Effects of presenting geographic context on tracking activity between cameras	NA:NA:NA:NA	2018
Abhishek Ranjan:Jeremy P. Birnholtz:Ravin Balakrishnan	We present an experimental study of automatic camera control in the performance of collaborative remote repair tasks using video-mediated communication. Twelve pairs of participants, one "helper" and one "worker," completed a series of Lego puzzle tasks using both a static camera and an automatic camera system that was guided in part by tracking the worker's hand position. Results show substantial performance benefits for the automatic system, particularly for complex tasks. The implications of these results are discussed, along with some lessons for the use of motion tracking as a driver for camera control.	Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task	NA:NA:NA	2018
Johann Schrammel:Arjan Geven:Reinhard Sefelin:Manfred Tscheligi	This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent's line of sight, whether the agent's gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent's gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent's gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent's gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.	"Look!": using the gaze direction of embodied agents	NA:NA:NA:NA	2018
Yoshinori Kuno:Kazuhisa Sadazuka:Michie Kawashima:Keiichi Yamazaki:Akiko Yamazaki:Hideaki Kuzuoka	We are currently working on a museum guide robot with an emphasis on "friendly" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.	Museum guide robot based on sociological interaction analysis	NA:NA:NA:NA:NA:NA	2018
Gonzalo Ramos	NA	Session details: Input techniques	NA	2018
Theophanis Tsandilas:m. c. schraefel	This paper introduces bubbling menus, a new design for cascading drop-down menus. Bubbling menus combine the bubble cursor [10] with directional mouse-gesture techniques to facilitate the access of certain items in a menu, such as frequently selected items. Through an extensive iterative design process, we explore bubbling menus in the context of adaptive and customizable user interfaces. Unlike other adaptation and customization techniques such as split menus, bubbling menus do not disrupt the original structure of menus and enable the activation of menus far from a menu bar. Results from two evaluation studies presented in the paper show that bubbling menus provide an effective alternative to accelerate menu selections tasks.	Bubbling menus: a selective mechanism for accessing hierarchical drop-down menus	NA:NA	2018
Ramona Su Thompson:Esa M. Rantanen:William Yurcik:Brian P. Bailey	Intrusion detection (ID) is one of network security engineers' most important tasks. Textual (command-line) and visual interfaces are two common modalities used to support engineers in ID. We conducted a controlled experiment comparing a representative textual and visual interface for ID to develop a deeper understanding about the relative strengths and weaknesses of each. We found that the textual interface allows users to better control the analysis of details of the data through the use of rich, powerful, and flexible commands while the visual interface allows better discovery of new attacks by offering an overview of the current state of the network. With this understanding, we recommend designing a hybrid interface that combines the strengths of textual and visual interfaces for the next generation of tools used for intrusion detection.	Command line or pretty lines?: comparing textual and visual interfaces for intrusion detection	NA:NA:NA:NA	2018
Emmanuel Pietriga:Caroline Appert:Michel Beaudouin-Lafon	A number of experimental studies based on domain-specific tasks have evaluated the efficiency of navigation techniques for searching multi-scale worlds. The discrepancies among their results call for a more generic framework similar in spirit to Fitts' reciprocal pointing task, but adapted to a task that significantly differs from pure pointing. We introduce such a framework based on an abstract task and evaluate how four multi-scale navigation techniques perform in one particular multi-scale world configuration. Experimental findings indicate that, in this context, pan & zoom combined with an overview is the most efficient technique of all four, and that focus + context techniques perform better than classical pan & zoom. We relate these findings to more realistic situations, discuss their applicability, and how the framework can be used to cover a broad range of situations.	Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching	NA:NA:NA	2018
Dianne Murray	NA	Session details: Location aware systems	NA	2018
Kenton O'Hara:Tim Kindberg:Maxine Glancy:Luciana Baptista:Byju Sukumaran:Gil Kahana:Julie Rowbotham	The use of location-based technology to augment visitor experiences has received considerable attention over the years. In this paper, we take an alternative perspective on these kinds of location-based experiences by focussing on the collecting and keeping of location-based content as opposed to simply the in situ consumption of content. We describe a trial of a location-based experience at London zoo in which mobile camera phones were used to access digital content at particular animal enclosures around the zoo. Through the fieldwork we demonstrate ways in which collecting and keeping have important social values over and above simply consuming the content in situ. More specifically, the role of the collection of location-based content in identity work; in developing a sense of challenge and achievement; in defining a sense of group camaraderie; and in creating a playful sense of competition among group members. Further, we see how narratives told around the collected location-based content over time imbue it with additional value. These narratives become part of the resources through which relationships with family and friends get actively constructed. We discuss how these aspects have different design implications from the in-situ consumption model of location-based experiences and tensions this introduces.	Social practices in location-based collecting	NA:NA:NA:NA:NA:NA:NA	2018
Pamela J. Ludford:Reid Priedhorsky:Ken Reily:Loren Terveen	With new technology, people can share information about everyday places they go; the resulting data helps others find and evaluate places. Recent applications like Dodgeball and Sharescape repurpose everyday place information: users create local place data for personal use, and the systems display it for public use. We explore both the opportunities -- new local knowledge, and concerns -- privacy risks, raised by this implicit information sharing. We conduct two empirical studies: subjects create place data when using PlaceMail, a location-based reminder system, and elect whether to share it on Sharescape, a community map-building system. We contribute by: (1) showing location-based reminders yield new local knowledge about a variety of places, (2) identifying heuristics people use when deciding what place-related information to share (and their prevalence), (3) detailing how these decision heuristics can inform local knowledge sharing system design, and (4) identifying new uses of shared place information, notably opportunistic errand planning.	Capturing, sharing, and using local place information	NA:NA:NA:NA	2018
Steven Strachan:John Williamson:Roderick Murray-Smith	We demonstrate the use of uncertain prediction in asystem for pedestrian navigation via audio with a combination ofGlobal Positioning System data, a music player, inertial sensing,magnetic bearing data and Monte Carlo sampling for a densityfollowing task, where a listener's music is modulated according tothe changing predictions of user position with respect to a targetdensity, in this case a trajectory or path. We show that this system enables eyes-free navigation around set trajectories or paths unfamiliar to the user and demonstrate that the system may be used effectively for varying trajectory width and context.	Show me the way to Monte Carlo: density-based trajectory navigation	NA:NA:NA	2018
Carl DiSalvo:Jeff Maki:Nathan Martin	In this paper we present the MapMover project as a case study into the use and design of an interactive system for collective expression. Informed by analysis and reflection we advance the concept of constructed publics: publics that are established, shaped, and maintained through the actions and influence of others. We conclude by discussing the relevance of constructed publics as a theorectical frame for the analysis and evaluation of projects in the domains of urban computing and exploratory design in HCI.	Mapmover: a case study of design-oriented research into collective expression and constructed publics	NA:NA:NA	2018
Danyel Fisher	NA	Session details: Social network sharing	NA	2018
Cliff A.C. Lampe:Erik Johnston:Paul Resnick	Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.	Follow the reader: filtering comments on slashdot	NA:NA:NA	2018
John C. Tang:James Lin:Jeffrey Pierce:Steve Whittaker:Clemens Drews	We present an empirical study of teams that revealed the amount of extraneous individual work needed to enable collaboration: finding references to other people, finding files to attach to email, managing incoming email attachments, managing the variety of files used in shared activities, and tracking what work is owed to others. Much of this work involves finding recently accessed objects that are needed again in the user's current task focus. These observations led to the design of Recent Shortcuts, a tool to help support coordination by making recently used objects easily accessible. Recent Shortcuts enables quick access to people (including groups of people), received attachments, files, and file folders that the user interacted with recently for re-use in the user's current context. Recent Shortcuts makes it easy to use these objects across applications with no additional user input and minimal changes to the user's applications or work practice. Early user experiences with a working prototype led to an extension that integrates recently accessed objects across multiple devices.	Recent shortcuts: using recent interactions to support shared activities	NA:NA:NA:NA:NA	2018
Giulio Jacucci:Antti Oulasvirta:Tommi Ilmonen:John Evans:Antti Salovaara	Previous attempts to support spectators at large-scale events have concentrated separately on real-time event information, awareness cues, or media-sharing applications. CoMedia combines a group media space with event information and integrates reusable awareness elements throughout. In two field trials, one at a rally and the other at a music festival, we found that CoMedia facilitated onsite reporting to offsite members, coordination of group action, keeping up to date with others, spectating remotely, and joking. In these activities, media, awareness cues, and event information were often used in concert, albeit assuming differing roles. We show that the integrated approach better supports continuous interweaving of use with the changing interests and occurrences in large-scale events.	Comedia: mobile group media for active spectatorship	NA:NA:NA:NA:NA	2018
Alan Blackwell	NA	Session details: Augmentation, automation & agents	NA	2018
Jeffrey Nichols:Duen Horng Chau:Brad A. Myers	We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable and especially desirable where users will benefit from individualized interfaces or where human designers are constrained by cost and other factors.	Demonstrating the viability of automatically generated user interfaces	NA:NA:NA	2018
Jun Xiao:John Stasko:Richard Catrambone	We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray.	The role of choice and customization on users' interaction with embodied conversational agents: effects on perception and performance	NA:NA:NA	2018
John Tang	NA	Session details: Distributed coordination	NA	2018
Mike Fraser:Michael R. McCarthy:Muneeb Shaukat:Phillip Smith	Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause.	Seconds matter: improving distributed coordination bytracking and visualizing display trajectories	NA:NA:NA:NA	2018
Jacob T. Biehl:Mary Czerwinski:Greg Smith:George G. Robertson	Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash.	FASTDash: a visual dashboard for fostering awareness in software teams	NA:NA:NA:NA	2018
Jonas Landgren:Urban Nulden	This paper presents descriptive accounts of time-critical organizing in the domain of emergency response. Patterns of mobile phone interaction in such work is analyzed showing how the dyadic exchange of mobile phone numbers between the actors plays an important role in the social interactions in the organizing and sensemaking of the emergency. Enacted sensemaking is used as an analytical framework. Implications for design of emergency response information technology are outlined and discussed.	A study of emergency response work: patterns of mobile phone interaction	NA:NA	2018
Dennis Wixon	NA	Session details: Usability	NA	2018
François Guimbretiére:Morgan Dixon:Ken Hinckley	We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques.	ExperiScope: an analysis tool for interaction data	NA:NA:NA	2018
Jiang Hu:Andi Winterboer:Clifford I. Nass:Johanna D. Moore:Rebecca Illowsky	A 2x2 enhanced Wizard-of-Oz experiment (N = 32) was conducted to compare two different approaches to presenting information to drivers in easy and difficult driving conditions. Data of driving safety, evaluation of the spoken dialogue system, and perception of self were analyzed. Results show that the user-modeled summarize-and-refine (UMSR) approach led to more efficient information retrieval than did the summarize-and-refine (SR) approach. However, depending on driving condition, higher efficiency did not always translate into pleasant subjective experience. Implications for usability testing and interface design were presented, followed by discussions of future research directions.	Context & usability testing: user-modeled information presentation in easy and difficult driving conditions	NA:NA:NA:NA:NA	2018
Richard Atterer:Albrecht Schmidt	In this paper, we introduce an implementation for detailed monitoring of user actions on web pages. It addresses the problem that the log data recorded by standard web servers is not sufficient for the tracking of users on AJAX websites, e.g. to conduct a usability test. Using standard web technologies, our HTTP proxy can record very detailed usage information, such as mouse movements, clicks, key presses and scrolling, together with the exact HTML DOM tree objects involved. As we show in several case studies, the tracking also works across multiple websites, none of which needs to be under our control. This approach is much less invasive than previous efforts: The test person does not need to install software on her computer, and in certain operation modes, no configuration changes at all are required on her computer. Our research indicates that if the technology described in this paper is employed, arbitrary visitors of a website are more likely to take part in a usability test offered by that site -- this facilitates recruiting test participants over the Internet.	Tracking the interaction of users with AJAX applications for usability testing	NA:NA	2018
John Zimmerman	NA	Session details: Kids & family	NA	2018
Julie A. Kientz:Rosa I. Arriaga:Marshini Chetty:Gillian R. Hayes:Jahmeilah Richardson:Shwetak N. Patel:Gregory D. Abowd	From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain.	Grow and know: understanding record-keeping needs for tracking the development of young children	NA:NA:NA:NA:NA:NA:NA	2018
Frank R. Bentley:Crysta J. Metcalf	We present the Motion Presence application, an augmented phone book style application that allows close friends and family to view each other's current motion status ("moving" or "not moving") on their mobile phones. We performed a two week long field trial with 10 participants to observe usage and investigate any privacy concerns that might arise. We found that our participants used the motion information to infer location and activity as well as to plan communication, to help in coordinating in-person get-togethers, and to stay connected to patterns in each others' lives. Participants saw the motion data as mostly confirming their existing thoughts about the locations and activities of others and expressed few privacy concerns. In fact, they frequently asked for more information to be shared to make the application more compelling.	Sharing motion information with close family and friends	NA:NA	2018
Neema Moraveji:Jason Li:Jiarong Ding:Patrick O'Kelley:Suze Woolf	Comicboarding is a participatory design method that uses specially created comic books to generate engaging, productive brainstorming sessions with children. By leveraging known plot formats, interaction styles, and characters in comics, researchers can elicit ideas even from children who are not accustomed to brainstorming, such as those from schools were rote learning is the norm. We conducted an experiment using two variants of the comicboarding methodology with 17 children in China, where traditional participatory design may fail in the face of local cultural practices. The results suggest that comicboarding holds promise for co-design with children.	Comicboarding: using comics as proxies for participatory design with children	NA:NA:NA:NA:NA	2018
Michel Beaudouin-Lafon	NA	Session details: Alternative interaction	NA	2018
Gonzalo A. Ramos:Ravin Balakrishnan	Selections and actions in GUI's are often separated -- i.e. an action or command typically follows a selection. This sequence imposes a lower bound on the interaction time that is equal to or greater than the sum of its parts. In this paper, we introduce pressure marks -- pen strokes where the variations in pressure make it possible to indicate both a selection and an action simultaneously. We propose a series of design guidelines from which we develop a set of four basictypes of pressure marks. We first assess the viability of this set through an exploratory study that looks at the way users draw straight and lasso pressure marks of different sizes and orientations. We then present the results of a quantitative experiment that shows that users perform faster selection-action interactions with pressure marks than with a combination of lassos and pigtails. Based on these results, we present and discuss a number of interaction designs that incorporate pressure marks.	Pressure marks	NA:NA	2018
Jared Cechanowicz:Pourang Irani:Sriram Subramanian	In this paper we investigate the use of a uni-pressure and dual-pressure augmented mouse. With a pressure augmented mouse users can simultaneously control cursor positions as well as multiple levels of discrete selection modes for common desktop application tasks. Two or more independent pressure sensors can be mounted onto several locations on the body of the mouse. To highlight the design potential of a pressure augmented mouse we conducted a multi-part study. In the first part we identified the number of maximum discrete levels controllable with a uni-pressure augmented mouse, the most appropriate locations for installing pressure sensors on the mouse, and the design of new interaction techniques to support selection with pressure-based input. In a follow-up design we introduced an additional sensor and two different types of selection techniques to control a larger number of discrete levels with two pressure sensors. Our results show that users can comfortably control up to 64 modes with a dual-pressure augmented mouse. We discuss the findings of our results in the context of several desktop interaction techniques and identify several design recommendations.	Augmenting the mouse with pressure sensitive input	NA:NA:NA	2018
Shengdong Zhao:Pierre Dragicevic:Mark Chignell:Ravin Balakrishnan:Patrick Baudisch	We present the design and evaluation of earPod: an eyes-free menu technique using touch input and reactive auditory feedback. Studies comparing earPod with an iPod-like visual menu technique on reasonably-sized static menus indicate that they are comparable in accuracy. In terms of efficiency (speed), earPod is initially slower, but outperforms the visual technique within 30 minutes of practice. Our results indicate that earPod is potentially a reasonable eyes-free menu technique for general use, and is a particularly exciting technique for use in mobile device interfaces.	Earpod: eyes-free menu selection using touch input and reactive audio feedback	NA:NA:NA:NA:NA	2018
Robin Jeffries	NA	Session details: Usability evaluation	NA	2018
Morten Sieker Andreasen:Henrik Villemann Nielsen:Simon Ormholt Schrøder:Jan Stage	The idea of conducting usability tests remotely emerged ten years ago. Since then, it has been studied empirically, and some software organizations employ remote methods. Yet there are still few comparisons involving more than one remote method. This paper presents results from a systematic empirical comparison of three methods for remote usability testing and a conventional laboratory-based think-aloud method. The three remote methods are a remote synchronous condition, where testing is conducted in real time but the test monitor is separated spatially from the test subjects, and two remote asynchronous conditions, where the test monitor and the test subjects are separated both spatially and temporally. The results show that the remote synchronous method is virtually equivalent to the conventional method. Thereby, it has the potential to conveniently involve broader user groups in usability testing and support new development approaches. The asynchronous methods are considerably more time-consuming for the test subjects and identify fewer usability problems, yet they may still be worthwhile.	What happened to remote usability testing?: an empirical study of three methods	NA:NA:NA:NA	2018
Gitte Lindgaard:Jarinee Chattratichart	For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.	Usability testing: what have we overlooked?	NA:NA	2018
Wendy E. Mackay:Caroline Appert:Michel Beaudouin-Lafon:Olivier Chapuis:Yangzhou Du:Jean-Daniel Fekete:Yves Guiard	Touchstone is an open-source experiment design platform designed to help establish a solid research foundation for HCI in the area of novel interaction techniques. Touchstone includes a design platform for exploring alternative designs of controlled laboratory experiments, a run platform for running subjects and a limited analysis platform for advice and access to on-line statistics packages. Designed for HCI researchers and their students, Touchstone facilitates the process of creating new experiments, as well as replicating and extending experiments in the research literature. We tested Touchstone by designing two controlled experiments. One illustrates how to create a new experiment from scratch. The other replicates and extends a previous study of multiscale pointing interaction techniques: OrthoZoom was fastest, followed by bi-manual Pan & Zoom; SDAZ and traditional Pan & Zoom were consistently slower.	Touchstone: exploratory design of experiments	NA:NA:NA:NA:NA:NA:NA	2018
Les Nelson	NA	Session details: Programming by & with end-users	NA	2018
Jeffrey Wong:Jason I. Hong	There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system.	Making mashups with marmite: towards end-user programming for the web	NA:NA	2018
John Zimmerman:Anthony Tomasic:Isaac Simmons:Ian Hargraves:Ken Mohnkern:Jason Cornwell:Robert Martin McGuire	Today many workers spend too much of their time translating their co-workers' requests into structures that information systems can understand. This paper presents the novel interaction design and evaluation of VIO, an agent that helps workers trans late request. VIO monitors requests and makes suggestions to speed up the translation. VIO allows users to quickly correct agent errors. These corrections are used to improve agent performance as it learns to automate work. Our evaluations demonstrate that this type of agent can significantly reduce task completion time, freeing workers from mundane tasks.	Vio: a mixed-initiative approach to learning and automating procedural update tasks	NA:NA:NA:NA:NA:NA:NA	2018
Caitlin Kelleher:Randy Pausch:Sara Kiesler	We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.	Storytelling alice motivates middle school girls to learn computer programming	NA:NA:NA	2018
Terry Winograd	NA	Session details: Trust & engagement	NA	2018
David T. Nguyen:John Canny	Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system.	Multiview: improving trust in group video conferencing through spatial faithfulness	NA:NA	2018
Steven Dow:Manish Mehta:Ellie Harmon:Blair MacIntyre:Michael Mateas	In this paper we present the results of a qualitative, empirical study exploring the impact of immersive technologies on presence and engagement, using the interactive drama Façade as the object of study. In this drama, players are situated in a married couple's apartment, and interact primarily through conversation with the characters and manipulation of objects in the space. We present participants' experiences across three different versions of Façade -- augmented reality (AR) and two desktop computing based implementations, one where players communicate using speech and the other using typed keyboard input. Through interviews and observations of players, we find that immersive AR can create an increased sense of presence, confirming generally held expectations. However, we demonstrate that increased presence does not necessarily lead to more engagement. Rather, mediation may be necessary for some players to fully engage with certain interactive media experiences.	Presence and engagement in an interactive drama	NA:NA:NA:NA:NA	2018
Dirk vom Lehn:Jon Hindmarsh:Paul Luff:Christian Heath	Museums increasingly deploy new technologies to enhance visitors' experience of their exhibitions. They primarily rely on touch-screen computer systems, PDAs and digital audio-guides. Tate Britain recently employed two innovative systems in one of their major exhibitions of John Constable's work; a gestural interface and a touch-screen panel, both connected to large projection screens. This paper reports on the analysis of video-recordings and field observations of visitors' action and interaction. It explores how people interact with and around the systems, how they configure the space around the installation and how they examine and discover their properties. It suggests that designers of interfaces and installations developed for museum exhibitions face particular challenges, such as the transparency of the relationship between people's actions and the system' response, the provision of opportunities for individual and collaborative experiences and the interweaving of technological and aesthetic experiences.	Engaging constable: revealing art with new technology	NA:NA:NA:NA	2018
Robert St. Amant	NA	Session details: Models of mobile interaction	NA	2018
Xiang Cao:Shumin Zhai	This paper presents a quantitative human performance model of making single-stroke pen gestures within certain error constraints in terms of production time. Computed from the properties of Curves, Line segments, and Corners (CLC) in a gesture stroke, the model may serve as a foundation for the design and evaluation of existing and future gesture-based user interfaces at the basic motor control efficiency level, similar to the role of previous "laws of action" played to pointing, crossing or steering-based user interfaces. We report and discuss our experimental results on establishing and validating the CLC model, together with other basic empirical findings in stroke gesture production.	Modeling human performance of pen stroke gestures	NA:NA	2018
Paul Holleis:Friederike Otto:Heinrich Hussmann:Albrecht Schmidt	The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.	Keystroke-level model for advanced mobile phone interaction	NA:NA:NA:NA	2018
Michael Pettitt:Gary Burnett:Alan Stevens	To assess the potential distraction of In-Vehicle Information Systems (IVIS), simple, low cost evaluation methods are required for use in early design stages. The occlusion technique evaluates IVIS tasks in interrupted vision conditions, aiming to predict likely visual demand. However, the technique necessitates performance-focused user trials utilising robust prototypes, and consequently has limitations as an economic evaluation method. HCI practitioners view the Keystroke Level Model (KLM) as a reliable and valid means of modelling human performance, not requiring empirical trials or working prototypes. This paper proposes an extended KLM, which aims to predict measures based on the occlusion protocol. To validate the new method, we compared results of an occlusion study with predictions based on the assumptions of the extended KLM. Analysis revealed significant correlations between observed and predicted results (R=0.93-0.98) and low error rates (7-13%). In conclusion, the extended KLM shows considerable merit as a first-pass design tool.	An extended keystroke level model (KLM) for predicting the visual demand of in-vehicle information systems	NA:NA:NA	2018
Steve Feiner	NA	Session details: Color/blind	NA	2018
Ravi Kuber:Wai Yu:Graham McAllister	Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions.	Towards developing assistive haptic feedback for visually impaired internet users	NA:NA:NA	2018
Luke Jefferson:Richard Harvey	A new method for adapting digital images so that they are suitable for color blind viewers is presented. In contrast to earlier automatic methods which formulate the problem of adapting images for color blind observers as one of optimization, we demonstrate how it is possible to allow a user to compute a very wide range of adaptations in reasonable time under the control of a single variable. We demonstrate how the algorithm can be delivered as an adaptive technology via a simple interface, and evaluate the efficacy of our method using psychovisual experiments with simulated color blind users and a standard color vision test.	An interface to support color blind computer users	NA:NA	2018
Chui Chui Tan:Wai Yu:Graham McAllister	To date, efforts have been made to enable visually impaired people to gain access to graphics on the Internet. However, these studies only offer a solution for a specific type of graphic by using a fixed set of hardware. To address this, a design approach of an adaptive and adaptable architecture is introduced which adapts to different graphical content, input/output devices (including assistive technologies) and user's profile and preferences. This system brings the opportunity to visually impaired people to gain access to graphics via different modalities by providing an adequate accessibility interface and interaction based on their profiles and needs.	An adaptive & adaptable approach to enhance web graphics accessibility for visually impaired people	NA:NA:NA	2018
Elizabeth Churchill	NA	Session details: Social influence	NA	2018
Darren Gergle:Carolyn P. Rose:Robert E. Kraut	A number of recent studies have demonstrated that groups benefit considerably from access to shared visual information. This is due, in part, to the communicative efficiencies provided by the shared visual context. However, a large gap exists between our current theoretical understanding and our existing models. We address this gap by developing a computational model that integrates linguistic cues with visual cues in a way that effectively models reference during tightly-coupled, task-oriented interactions. The results demonstrate that an integrated model significantly outperforms existing language-only and visual-only models. The findings can be used to inform and augment the development of conversational agents, applications that dynamically track discourse and collaborative interactions, and dialogue managers for natural language interfaces.	Modeling the impact of shared visual information on collaborative reference	NA:NA:NA	2018
Nils Dahlbäck:QianYing Wang:Clifford Nass:Jenny Alwin	In a balanced between-participants experiment (N = 96) American and Swedish participants listened to tourist information on a website about an American or Swedish city presented in English with either an American or Swedish accent and evaluated the speakers' knowledge of the topic, the voice characteristics, and the information characteristics. Users preferred accents similar to their own. Similarity-attraction effects were so powerful that same-accents speakers were viewed as being more knowledgeable than different-accent speakers even when the information would be much better-known by the opposite-accent speaker. Implications for similarity-attraction overwhelming expertise are discussed.	Similarity is more important than expertise: accent effects in speech interfaces	NA:NA:NA:NA	2018
Brooke Foucault:Helena M. Mentis:Phoebe Sengers:Devon Welles	In this study, we explore the potential usefulness of disturbing, uncomfortable systems, demonstrating that provocative technology can have a positive effect on social relationships. We designed and evaluated an agent-based system that collects user information by asking seemingly benign questions, and then uses it to spread false, strange gossip throughout an office space. We show that provocative interaction on-line can improve off-line sociability.	Provoking sociability	NA:NA:NA:NA	2018
Catherine Amine Zanbaka:Amy Catherine Ulinski:Paula Goolkasian:Larry F. Hodges	Do human-human social interactions carry over to human-virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head-mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.	Social responses to virtual humans: implications for future interface design	NA:NA:NA:NA	2018
Michael Twidale	NA	Session details: Learning	NA	2018
Andy Cockburn:Per Ola Kristensson:Jason Alexander:Shumin Zhai	Interface designers normally strive for a design that minimises the user's effort. However, when the design's objective is to train users to interact with interfaces that are highly dependent on spatial properties (e.g. keypad layout or gesture shapes) we contend that designers should consider explicitly increasing the mental effort of interaction. To test the hypothesis that effort aids spatial memory, we designed a "frost-brushing" interface that forces the user to mentally retrieve spatial information, or to physically brush away the frost to obtain visual guidance. We report results from two experiments using virtual keypad interfaces -- the first concerns spatial location learning of buttons on the keypad, and the second concerns both location and trajectory learning of gesture shape. The results support our hypothesis, showing that the frost-brushing design improved spatial learning. The participants' subjective responses emphasised the connections between effort, engagement, boredom, frustration, and enjoyment, suggesting that effort requires careful parameterisation to maximise its effectiveness.	Hard lessons: effort-inducing interfaces benefit spatial learning	NA:NA:NA:NA	2018
Udai Singh Pawar:Joyojeet Pal:Rahul Gupta:Kentaro Toyama	This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.	Multiple mice for retention tasks in disadvantaged schools	NA:NA:NA:NA	2018
David Gilmore	NA	CHI madness - Part 1	NA	2018
john Kolko:Ilona Posner	NA	Student Design Competition	NA:NA	2018
Bill Buxton	NA	Being Human in a digital world	NA	2018
Gerrit van der Veer	NA	CHI2008 Latest numbers	NA	2018
Gilbert Cockton:Jakita O. Thomas:Paul Moore	NA	Front Row (Design Theater)	NA:NA:NA	2018
Allen Newell:Thomas P. Moran:Stuart K. Card:David Kieras:Michael Byrne:Wendy Kellog:Bonnie John	NA	Celebrating The Psychology of Human-Computer Interaction	NA:NA:NA:NA:NA:NA:NA	2018
NA	NA	CHI madness - Part 3	NA	2018
Bill Buxton	NA	Conclusions	NA	2018
Fabio Sergio:Sheelagh Carpendale:Eric Schaffer	NA	Student Research Competition	NA:NA:NA	2018
Mary Czerwinski:Arnie Lund:Desney Tan	NA	Welcome to CHI 2008	NA:NA:NA	2018
Desney Tan	NA	CHI 2008 Technical Program	NA	2018
Irene McAra-McWilliam	NA	Opening Plenary Talk	NA	2018
Stella Boess	NA	Do that again?	NA	2018
David Gilmore	NA	CHI madness - Part 2	NA	2018
Antonella De Angeli	NA	Session details: Socio-Cultural Impact	NA	2018
Gunnar Harboe:Crysta J. Metcalf:Frank Bentley:Joe Tullio:Noel Massey:Guy Romano	We examine how ambient displays can augment social television. Social TV 2 is an interactive television solution that incorporates two ambient displays to convey to participants an aggregate view of their friends' current TV-watching status. Social TV 2 also allows users to see which television shows friends and family are watching and send lightweight messages from within the TV-viewing experience. Through a two-week field study we found the ambient displays to be an integral part of the experience. We present the results of our field study with a discussion of the implications for future social systems in the home.	Ambient social tv: drawing people into a shared experience	NA:NA:NA:NA:NA:NA	2018
Susan P. Wyche:Paul M. Aoki:Rebecca E. Grinter	In this paper, we report on design-oriented fieldwork and design research conducted over a six-month period in urban centers in the United States and Kenya. The contributions of this work for the CHI/CSCW community are empirical and methodological. First, we describe how recent design discourse around "designing technology for religion" creates an artificial distinction between instrumental and religious ICT use, particularly in developing regions. As illustrative examples, we relate three themes developed in the course of our fieldwork, which we term mindfulness, watchfulness, and embeddedness, to both "secular" and "religious" aspects of life in the communities studied. Second, we make a methodological contribution by describing how we used design sketches of speculative design concepts to extend and complement our fieldwork. By producing these sketches and soliciting feedback, we elicited additional data about how participants viewed the relationship between religion and ICT and prompted self-reflection on our own ideas.	Re-placing faith: reconsidering the secular-religious use divide in the United States and Kenya	NA:NA:NA	2018
Scott Mainwaring:Wendy March:Bill Maurer	Based on ethnographically-inspired research in Japan, we report on people's experiences using digital money payment systems that use Sony's FeliCa near-field communication smartcard technology. As an example of ubiquitous computing in the here and now, the adoption of digital money is found to be messy and contingent, shot through with cultural and social factors that do not hinder this adoption but rather constitute its specific character. Adoption is strongly tied to Japanese conceptions of the aesthetic and moral virtue of smooth flow and avoidance of commotion, as well as the excitement at winning something for nothing. Implications for design of mobile payment systems stress the need to produce open-ended platforms that can serve as the vehicle for multiple meanings and experiences without foreclosing such possibilities in the name of efficiency.	From meiwaku to tokushita!: lessons for digital money design from japan	NA:NA:NA	2018
Yang Wang:Scott D. Mainwaring	What happens when the domains of HCI design and money intersect? This paper presents analyses from an ethnographic study of virtual currency use in China to discuss implications for game design, and HCI design more broadly. We found that how virtual currency is perceived, obtained, and spent can critically shape gamers' behavior and experience. Virtual and real currencies can interact in complex ways that promote, extend, and/or interfere with the value and character of game worlds. Bringing money into HCI design heightens existing issues of realness, trust, and fairness, and thus presents new challenges and opportunities for user experience innovation.	Human-Currency Interaction: learning from virtual currency use in China	NA:NA	2018
Gregory Abowd	NA	Session details: Interactive Image Search	NA	2018
James Fogarty:Desney Tan:Ashish Kapoor:Simon Winder	Web image search is difficult in part because a handful of keywords are generally insufficient for characterizing the visual properties of an image. Popular engines have begun to provide tags based on simple characteristics of images (such as tags for black and white images or images that contain a face), but such approaches are limited by the fact that it is unclear what tags end users want to be able to use in examining Web image search results. This paper presents CueFlik, a Web image search application that allows end users to quickly create their own rules for re ranking images based on their visual characteristics. End users can then re rank any future Web image search results according to their rule. In an experiment we present in this paper, end users quickly create effective rules for such concepts as "product photos", "portraits of people", and "clipart". When asked to conceive of and create their own rules, participants create such rules as "sports action shot" with images from queries for "basketball" and "football". CueFlik represents both a promising new approach to Web image search and an important study in end user interactive machine learning.	CueFlik: interactive concept learning in image search	NA:NA:NA:NA	2018
Geoffrey B. Duggan:Stephen J. Payne	The importance of background knowledge for effective searching on the Web is not well understood. Participants were given trivia questions on two topics and asked to answer them first using background knowledge and second by searching on the Web. Knowledge of a topic predicted search performance on that topic for all questions and, more importantly, for questions for which participants did not already know the answer. In terms of process, greater topic knowledge led to less time being spent on each Webpage, faster decisions to give up a line of inquiry and shorter queries being entered into the search engine. A more complete theory-led understanding of these effects would assist workers in a whole range of Web-related professions.	Knowledge in the head and on the web: using topic expertise to aid search	NA:NA	2018
Yiwen Luo:Wei Liu:Jianzhuang Liu:Xiaoou Tang	Image search is becoming prevalent in web search as the number of digital photos grows exponentially on the internet. For a successful image search system, removing outliers in the top ranked results is a challenging task. Typical content based image search engines take an input image from one class as a query and compute relevance between the query and images in a database. The results often contain a large number of outliers, since these outliers may be similar to the query image in some way. In this paper we present a novel search scheme using query images from multiple classes. Instead of conducting query search for one image class at a time, we conduct multi-class query search jointly. By using several query classes that are similar to each other for multi-class query, we can utilize information across similar classes to fine tune the similarity measure to remove outliers. This strategy can be used for any information search application. In this work, we use content based image search to illustrate the concept.	MQSearch: image search by multi-class query	NA:NA:NA:NA	2018
Kristina Hook	NA	Session details: Stories and Memories	NA	2018
Daniela Petrelli:Steve Whittaker:Jens Brockmeier	Current technology makes it possible to capture huge amounts of information related to everyday experiences. Despite this, we know little about the processes by which people identify and manage mementos - objects which are directly meaningful to their memories. Among the millions of objects people encounter in a lifetime, few become such reminders of people, places or events. We report fieldwork where participants gave us a tour of their homes describing how and why particular objects become mementos. Our findings extend the existing digital memory literature; first our participants didn't view their activities as experiential 'capture', nor were mementos limited to pictorial representations of people and events; instead they included everyday objects. Furthermore, mementos were not only displayed and shared, but also integrated into everyday activities. Finally there were complex relations between house location and memento type. We discuss the theoretical and technical implications of our work.	AutoTopography: what can physical mementos tell us about digital memories?	NA:NA:NA	2018
Tero Jokela:Jaakko T. Lehikoinen:Hannu Korhonen	A mobile device provides an attractive tool for creating and sharing audio-visual stories. Earlier research has shown that the users enjoy creating digital stories with their mobile devices. However, designing editor interfaces that support creation of rich audio-visual presentations has been a major challenge due to the constrained input and output capabilities of mobile devices. In this paper, we present the design and evaluation of the Mobile Multimedia Presentation Editor, an application that makes it possible to author sophisticated multimedia presentations that integrate several different media types on mobile devices. Based on a user study, we present design principles for multimedia presentation editors on mobile devices. We describe an application design that supports these principles and so demonstrate that editing of sophisticated multimedia presentations is feasible on mobile devices. We report evaluations which indicate that the editor application was easy to use and supported the creativity of the mobile users well.	Mobile multimedia presentation editor: enabling creation of audio-visual stories on mobile devices	NA:NA:NA	2018
Steve Benford:Gabriella Giannachi	Temporal trajectories can represent the complex mappings between story time and clock time that are to be found in shared interactive narratives such as computer games and interactive performances. There are three kinds. Canonical trajectories express an author's intended mapping of story time onto clock time as part of the plot and schedule of an experience. Participant trajectories reflect a participant's actual journey through story time and clock time as they interact with the experience. Historic trajectories represent the subsequent selection and reuse of segments of recorded participant trajectories to create histories of past events. We show how temporal trajectories help us analyse the nature of time in existing experiences and can also generate new approaches to dealing with temporal issues such as: disengagement and reengagement, adapting to different paces of interaction, synchronising different participants, and enabling encounters and travel across time.	Temporal trajectories in shared interactive narratives	NA:NA	2018
Brian Bailey	NA	Session details: Don't Interrupt Me	NA	2018
Norman Makoto Su:Gloria Mark	There is a growing literature on managing multitasking and interruptions in the workplace. In an ethnographic study, we investigated the phenomenon of communication chains, the occurrence of interactions in quick succession. Focusing on chains enable us to better understand the role of communication in multitasking. Our results reveal that chains are prevalent in information workers, and that attributes such as the number of links, and the rate of media and organizational switching can be predicted from the first catalyzing link of the chain. When chains are triggered by external interruptions, they have more links, a trend for more media switches and more organizational switches. We also found that more switching of organizational contexts in communication is associated with higher levels of stress. We describe the role of communication chains as performing alignment in multitasking and discuss the implications of our results.	Communication chains and multitasking	NA:NA	2018
Shamsi T. Iqbal:Brian P. Bailey	We present a novel system for notification management and report results from two studies testing its performance and impact. The system uses statistical models to realize defer-to-breakpoint policies for managing notifications. The first study tested how well the models detect three types of breakpoints within novel task sequences. Results show that the models detect breakpoints reasonably well, but struggle to differentiate their type. Our second study explored effects of managing notifications with our system on users and their tasks. Results showed that scheduling notifications at breakpoints reduces frustration and reaction time relative to delivering them immediately. We also found that the relevance of notification content determines the type of breakpoint at which it should be delivered. The core concept of scheduling notifications at breakpoints fits well with how users prefer notifications to be managed. This indicates that users would likely adopt the use of notification management systems in practice.	Effects of intelligent notification management on users and their tasks	NA:NA	2018
Jeremy Birnholtz:Clarissa Mak:Saul Greenberg:Ron Baecker	Instructor/student interaction in e-learning environments can positively impact both student learning and instructor satisfaction. In online webcast lectures, however, interaction can be difficult because instructors lack basic awareness information about their remote students. Our goal is to better understand the kinds of awareness information that instructors should have if they are to interact frequently and effectively with their students in e-learning environments. We conducted an exploratory study -- via interviews and observations -- of instructor attention in face-to-face classrooms at a large university. Our results imply that a webcast system should provide instructors with overview and detailed data about their students, but that this detailed information should not be displayed publicly.	Attention by proxy? issues in audience awareness for webcasts to distributed groups	NA:NA:NA:NA	2018
Gloria Mark:Daniela Gudith:Ulrich Klocke	We performed an empirical study to investigate whether the context of interruptions makes a difference. We found that context does not make a difference but surprisingly, people completed interrupted tasks in less time with no difference in quality. Our data suggests that people compensate for interruptions by working faster, but this comes at a price: experiencing more stress, higher frustration, time pressure and effort. Individual differences exist in the management of interruptions: personality measures of openness to experience and need for personal structure predict disruption costs of interruptions. We discuss implications for how system design can support interrupted work.	The cost of interrupted work: more speed and stress	NA:NA:NA	2018
Elizabeth Mynatt	NA	Session details: Invited Session: Usability Evaluation Considered H	NA	2018
Saul Greenberg:Bill Buxton	Current practice in Human Computer Interaction as encouraged by educational institutes, academic review processes, and institutions with usability groups advocate usability evaluation as a critical part of every design process. This is for good reason: usability evaluation has a significant role to play when conditions warrant it. Yet evaluation can be ineffective and even harmful if naively done 'by rule' rather than 'by thought'. If done during early stage design, it can mute creative ideas that do not conform to current interface norms. If done to test radical innovations, the many interface issues that would likely arise from an immature technology can quash what could have been an inspired vision. If done to validate an academic prototype, it may incorrectly suggest a design's scientific worthiness rather than offer a meaningful critique of how it would be adopted and used in everyday practice. If done without regard to how cultures adopt technology over time, then today's reluctant reactions by users will forestall tomorrow's eager acceptance. The choice of evaluation methodology - if any - must arise from and be appropriate for the actual problem or research question under consideration.	Usability evaluation considered harmful (some of the time)	NA:NA	2018
Jettie Hoonhout	NA	Session details: Human-Robot Interaction	NA	2018
Cheng Guo:Ehud Sharlin	In this paper we suggest the use of tangible user interfaces (TUIs) for human-robot interaction (HRI) applications. We discuss the potential benefits of this approach while focusing on low-level of autonomy tasks. We present an experimental robotic interaction test bed to support our investigation. We use the test bed to explore two HRI-related task-sets: robotic navigation control and robotic posture control. We discuss the implementation of these two task-sets using an AIBO" robot dog. Both tasks were mapped to two different robotic control interfaces: keypad interface which resembles the interaction approach currently common in HRI, and a gesture input mechanism based on Nintendo Wii" game controllers. We discuss the interfaces implementation and conclude with a detailed user study for evaluating these different HRI techniques in the two robotic tasks-sets.	Exploring the use of tangible user interfaces for human-robot interaction: a comparative study	NA:NA	2018
Akiko Yamazaki:Keiichi Yamazaki:Yoshinori Kuno:Matthew Burdelski:Michie Kawashima:Hideaki Kuzuoka	As research over the last several decades has shown that non-verbal actions such as face and head movement play a crucial role in human interaction, such resources are also likely to play an important role in human-robot interaction. In developing a robotic system that employs embodied resources such as face and head movement, we cannot simply program the robot to move at random but rather we need to consider the ways these actions may be timed to specific points in the talk. This paper discusses our work in developing a museum guide robot that moves its head at interactionally significant points during its explanation of an exhibit. In order to proceed, we first examined the coordination of verbal and non-verbal actions in human guide-visitor interaction. Based on this analysis, we developed a robot that moves its head at interactionally significant points in its talk. We then conducted several experiments to examine human participant non-verbal responses to the robot's head and gaze turns. Our results show that participants are likely to display non-verbal actions, and do so with precision timing, when the robot turns its head and gaze at interactionally significant points than when the robot turns its head at not interactionally significant points. Based on these findings, we propose several suggestions for the design of a guide robot.	Precision timing in human-robot interaction: coordination of head movement and utterance	NA:NA:NA:NA:NA:NA	2018
Mattias Jacobsson:Johan Bodin:Lars Erik Holmquist	We present the see-Puck, a round display module that extends an open robot platform, the e-Puck. It holds 148 LEDs (light emitting diodes) to enable the presentation of eye-catching visual animated patterns, while keeping hardware costs and energy consumption at a minimum. The see-Puck was a result of a study of future robot applications, where relationship and interaction qualities found in owners of unusual pets (e.g. spiders, snakes, and lizards) were transferred to the robotic domain. In our first proof-of-concept application, humans and robots can engage in a playful open ended interaction. We argue that open interactive robot platforms such as the see-Puck point to opportunities not only in robotics but also future user interfaces and ubiquitous computing.	The see-Puck: a platform for exploring human-robot relationships	NA:NA:NA	2018
Laura Beckwith	NA	Session details: Learning Support	NA	2018
Maria F. Costabile:Antonella De Angeli:Rosa Lanzilotti:Carmelo Ardito:Paolo Buono:Thomas Pederson	This paper reports the experimental studies we have performed to evaluate Explore!, an m-learning system that supports middle school students during a visit to an archaeological park. It exploits a learning technique called excursion-game, whose aim is to help students to acquire historical notions while playing and to make archaeological visits more effective and exciting. In order to understand the potentials and limitations of Explore!, our studies compare the experience of playing the excursion-game with and without technological support. The design and evaluation of Explore! have provided knowledge on the advantages and pitfalls of m-learning that may be instrumental in informing the current debate on e-learning.	Explore! possibilities and challenges of mobile learning	NA:NA:NA:NA:NA:NA	2018
Amy Ogan:Vincent Aleven:Christopher Jones	Previous research shows that video viewing (a frequent activity in language courses) is more effective when students receive guidance. We investigate how to support students in an on-line environment in acquiring cultural knowledge and intercultural competence by viewing clips from feature films from the target culture. To test the effectiveness of a set of attention-focusing techniques (pause-predict-ponder), some of which have been shown to be effective in other contexts, we created ICCAT, a simple tutor that enhances an existing classroom model for the development of intercultural competence. We ran a study in two French Online classrooms with 35 participants, comparing ICCAT versions with and without attention-focusing techniques. We found that the addition of the pause-predict-ponder seemed to guide students in acquiring cultural knowledge and significantly increased students' ability to reason from an intercultural perspective. We discuss possible implications for intelligent tutoring systems in such difficult and ill-defined domains.	Pause, predict, and ponder: use of narrative videos to improve cultural discussion and learning	NA:NA:NA	2018
Tom Moher:Brian Uphoff:Darshan Bhatt:Brenda López Silva:Peter Malcolm	The broadening array of technologies available to support the design of classroom activity has the potential to reshape science learning in schools. This paper presents a ubiquitous computing application, WallCology, which situates a virtual ecosystem within the unseen space of classroom walls, presenting affordances for science learners to engage in investigations of ecological phenomena. Motivated by a desire to foster authenticity in classroom science inquiry, WallCology extends the "embedded phenomena" framework in three ways: by enabling collaborative investigations among distributed work teams, by increasing the physicality of investigation activities, and by expanding the loci of activity sites. Pilot studies in two urban classrooms provide qualified support for the effectiveness of WallCology in promoting more authentic inquiry practices, content learning, and attitudes regarding scientific investigations.	WallCology: designing interaction affordances for learner engagement in authentic science inquiry	NA:NA:NA:NA:NA	2018
Clare-Marie Karat	NA	Session details: Trust and Security	NA	2018
Tim Kindberg:Eamonn O'Neill:Chris Bevan:Vassilis Kostakos:Danaë Stanton Fraser:Tim Jay	Pervasive systems provide services that are situated within specific contexts. An everyday example of this is Wi-Fi hotspots. Factors such as branding and presentation are known to affect whether users are prepared to invest trust in services, but little is known about trust in situated services. This paper describes an experiment to measure de facto trust in Wi-Fi hotspots in public places, as opposed to examining trust behaviour in a simulated lab setting. We investigated two hypotheses about the effect of location-specific images in the hotspot's pages on trust behaviours, compared to images of non-specific locations. We found a significant result which confirms that decisions to access an unfamiliar Wi-Fi hotspot can be affected by location-relevant images.	Measuring trust in wi-fi hotspots	NA:NA:NA:NA:NA:NA	2018
Hirokazu Sasamoto:Nicolas Christin:Eiji Hayashi	A number of recent scams and security attacks (phishing, spyware, fake terminals, ...) hinge on a crook's ability to observe user behavior. In this paper, we describe the design, implementation, and evaluation of a novel class of user authentication systems that are resilient to observation attacks. Our proposal is the first to rely on the human ability to simultaneously process multiple sensory inputs to authenticate, and is resilient to most observation attacks. We build a prototype based on user feedback gained through low fidelity tests. We conduct a within-subjects usability study of the prototype with 38 participants, which we complement with a security analysis. Our results show that users can authenticate within times comparable to that of graphical password schemes, with relatively low error rates, while being considerably better protected against observation attacks. Our design and evaluation process allows us to outline design principles for observation-resilient authentication systems.	Undercover: authentication usable in front of prying eyes	NA:NA:NA	2018
Michael Toomim:Xianhang Zhang:James Fogarty:James A. Landay	Controlling the privacy of online content is difficult and often confusing. We present a social access control where users devise simple questions testing shared knowledge instead of constructing authenticated accounts and explicit access control rules. We implemented a prototype and conducted studies to explore the context of photo sharing security, gauge the difficulty of creating shared knowledge questions, measure their resilience to adversarial attack, and evaluate user ability to understand and predict this resilience.	Access control by testing for shared knowledge	NA:NA:NA:NA	2018
Markus Jakobsson:Erik Stolterman:Susanne Wetzel:Liu Yang	Passwords are ubiquitous, and users and service providers alike rely on them for their security. However, good passwords may sometimes be hard to remember. For years, security practitioners have battled with the dilemma of how to authenticate people who have forgotten their passwords. Existing approaches suffer from high false positive and false negative rates, where the former is often due to low entropy or public availability of information, whereas the latter often is due to unclear or changing answers, or ambiguous or fault prone entry of the same. Good security questions should be based on long-lived personal preferences and knowledge, and avoid publicly available information. We show that many of the questions used by online matchmaking services are suitable as security questions. We first describe a new user interface approach suitable to such security questions that is offering a reduced risks of incorrect entry. We then detail the findings of experiments aimed at quantifying the security of our proposed method.	Love and authentication	NA:NA:NA:NA	2018
Joelle Coutaz	NA	Session details: Post-WIMP	NA	2018
Robert J.K. Jacob:Audrey Girouard:Leanne M. Hirshfield:Michael S. Horn:Orit Shaer:Erin Treacy Solovey:Jamie Zigelbaum	We are in the midst of an explosion of emerging human-computer interaction techniques that redefine our understanding of both computers and interaction. We propose the notion of Reality-Based Interaction (RBI) as a unifying concept that ties together a large subset of these emerging interaction styles. Based on this concept of RBI, we provide a framework that can be used to understand, compare, and relate current paths of recent HCI research as well as to analyze specific interaction designs. We believe that viewing interaction through the lens of RBI provides insights for design and uncovers gaps or opportunities for future research.	Reality-based interaction: a framework for post-WIMP interfaces	NA:NA:NA:NA:NA:NA:NA	2018
Seoktae Kim:Hyunjung Kim:Boram Lee:Tek-Jin Nam:Woohun Lee	Inflatable Mouse is a volume-adjustable user interface. It can be inflated up to the volume of a familiar mouse, but be deflated and stored flat in a PC card slot of a laptop computer when not in use. Inflatable Mouse functions just like a typical mouse; moreover, it provides new interaction techniques by sensing the air pressure in the balloon of the mouse. It also addresses some issues associated with pressure-sensing interactions such as the lack of bi-directional input and the lack of effective feedback. Moreover, it can be used as both a control tool and a display tool. In this paper, the design of an Inflatable Mouse prototype is described and potential application scenarios such as zooming in/out and fast scrolling using pressure control are explained. We also discuss the potential use of Inflatable Mouse as an emotional communication tool.	Inflatable mouse: volume-adjustable mouse with air-pressure-sensitive input and haptic feedback	NA:NA:NA:NA:NA	2018
Ramon Hofer:Patrick Kaplan:Andreas Kunz	In this paper, we present a new technology to perform multi Tangible User Interface (TUI) tracking on standard LC-displays. A lot of existing technologies for tangible user interface tracking use back- or front-projection setups, but they suffer from poor image quality, shadow casting, non-ergonomic interaction, and/or large installations. Thus, we introduce a principle that allows using the InfrActables' technology on a large LC-display. It combines simultaneous multiuser input on a display with the advantages of a large flat screen. We use infrared photodiodes (IR-LEDs) mounted behind the display's LC-matrix to track infrared diodes in front of the screen. After initial tests concerning the infrared transparency and sensor characteristics, we developed a proof of concept consisting of 384 sensors, which are addressed through a modular master-slave circuit. Using several interaction devices, multiuser interaction is possible.	MightyTrace: multiuser tracking technology on lc-displays	NA:NA:NA	2018
Daniel L. Ashbrook:James R. Clawson:Kent Lyons:Thad E. Starner:Nirmal Patel	We investigate the effect of placement and user mobility on the time required to access an on-body interface. In our study, a wrist-mounted system was significantly faster to access than a device stored in the pocket or mounted on the hip. In the latter two conditions, 78% of the time it took to access the device was spent retrieving the device from its holder. As mobile devices are beginning to include peripherals (for example, Bluetooth headsets and watches connected to a mobile phone stored in the pocket), these results may help guide interface designers with respect to distributing functions across the body between peripherals.	Quickdraw: the impact of mobility and on-body placement on device access time	NA:NA:NA:NA:NA	2018
Gary Hsieh:Jennifer Lai:Scott E. Hudson:Robert Kraut	In this work, we introduce the use of tags to support the near synchronous use of instant messaging. As a proof-of-concept, we developed a plug-in in Lotus Sametime, an enterprise IM client. Our plug-in supports tasks that do not need immediate attention and tasks that have deadlines. A trial deployment and survey shows that users can see the potential usefulness of such a tagging system in their IM communication. Furthermore, users rated our design intuitive and easy to use. Longer study is needed to explore communication norms that results from its use.	Using tags to assist near-synchronous communication	NA:NA:NA:NA	2018
Dan Morris	NA	Session details: Improved Video Navigation and Capture	NA	2018
Abhishek Ranjan:Jeremy Birnholtz:Ravin Balakrishnan	Video recordings of meetings are often monotonous and tedious to watch. In this paper, we report on the design, implementation and evaluation of an automated meeting capture system that applies television production principles to capture and present videos of small group meetings in a compelling manner. The system uses inputs from a motion capture system and microphones to drive multiple pan-tilt-zoom cameras and uses heuristics to frame shots and cut between them. An evaluation of the system indicates that its performance approaches that of a professional crew while requiring significantly fewer human resources.	Improving meeting capture by applying television production principles with audio and motion detection	NA:NA:NA	2018
Pierre Dragicevic:Gonzalo Ramos:Jacobo Bibliowitcz:Derek Nowrouzezahrai:Ravin Balakrishnan:Karan Singh	We present a method for browsing videos by directly dragging their content. This method brings the benefits of direct manipulation to an activity typically mediated by widgets. We support this new type of interactivity by: 1) automatically extracting motion data from videos; and 2) a new technique called relative flow dragging that lets users control video playback by moving objects of interest along their visual trajectory. We show that this method can outperform the traditional seeker bar in video browsing tasks that focus on visual content rather than time.	Video browsing by direct manipulation	NA:NA:NA:NA:NA:NA	2018
Thorsten Karrer:Malte Weiss:Eric Lee:Jan Borchers	We present DRAGON, a direct manipulation interaction technique for frame-accurate navigation in video scenes. This technique benefits tasks such as professional and amateur video editing, review of sports footage, and forensic analysis of video scenes. By directly dragging objects in the scene along their movement trajectory, DRAGON enables users to quickly and precisely navigate to a specific point in the video timeline where an object of interest is in a desired location. Examples include the specific frame where a sprinter crosses the finish line, or where a car passes a traffic light. Through a user study, we show that DRAGON significantly reduces task completion time for in-scene navigation tasks by an average of 19-42% compared to a standard timeline slider. Qualitative feedback from users is also positive, with multiple users indicating that the DRAGON interaction felt more natural than the traditional timeline slider for in-scene navigation.	DRAGON: a direct manipulation interface for frame-accurate in-scene video navigation	NA:NA:NA:NA	2018
Leonardo Bonanni:Jason Alonso:Neil Chao:Greg Vargas:Hiroshi Ishii	Tangible User Interfaces are well-suited to handling three-dimensional data sets by direct manipulation of real objects in space, but current interfaces can make it difficult to look inside dense volumes of information. This paper presents the Handsaw, a system that detects a virtual cut-plane projected by an outstretched hand or laser-line directly on an object or space and reveals sectional data on an adjacent display. By leaving the hands free and using a remote display, these techniques can be shared between multiple users and integrated into everyday practice. The Handsaw has been prototyped for scientific visualizations in medicine, engineering and urban design. User evaluations suggest that using a hand is more intuitive while projected light is more precise than keyboard and mouse control, and the Handsaw system has the potential to be used effectively by novices and in groups.	Handsaw: tangible exploration of volumetric data by direct cut-plane projection	NA:NA:NA:NA:NA	2018
Jean-Daniel Fekete	NA	Session details: Visual Synthesis	NA	2018
Miguel Elias:Jeremy Elson:Danyel Fisher:Jon Howell	The recent introduction of simple, web-based geographic visualization interfaces has unleashed a tidal wave of new geographic content now available on the Internet. There has been enormous attention on the development of data interchange standards and programming interfaces that make all this content interoperable, but far less thought about how the user experience should change when users have their choice of 10,000 maps. To inform the design of online mapping systems, we investigate the case of queries that require correlation of multiple maps---that is, discovery and synthesis of several map layers. We based our study on interviews with expert users of maps: archivists and librarians. This paper describes our user-task taxonomy distilled from these interviews, and presents MapSynthesizer, a prototype system that allows users to efficiently query, discover, and integrate many maps from a corpus of thousands.	Do I live in a flood basin?: synthesizing ten thousand maps	NA:NA:NA:NA	2018
Adam Perer:Ben Shneiderman	Although both statistical methods and visualizations have been used by network analysts, exploratory data analysis remains a challenge. We propose that a tight integration of these technologies in an interactive exploratory tool could dramatically speed insight development. To test the power of this integrated approach, we created a novel social network analysis tool, SocialAction, and conducted four long-term case studies with domain experts, each working on unique data sets with unique problems. The structured replicated case studies show that the integrated approach in SocialAction led to significant discoveries by a political analyst, a bibliometrician, a healthcare consultant, and a counter-terrorism researcher. Our contributions demonstrate that the tight integration of statistics and visualizations improves exploratory data analysis, and that our evaluation methodology for long-term case studies captures the research strategies of data analysts.	Integrating statistics and visualization: case studies of gaining clarity during exploratory data analysis	NA:NA	2018
Catalina M. Danis:Fernanda B. Viegas:Martin Wattenberg:Jesse Kriss	Many Eyes is a web site that provides collaborative visualization services, allowing users to upload data sets, visualize them, and comment on each other's visualizations. This paper describes a first interview-based study of Many Eyes users, which sheds light on user motivation for creating public visualizations. Users talked about data for many reasons, from scientific research to political advocacy to hobbies. One consistent theme across these different scenarios is the use of visualizations in communication and collaborative practices. Collaboration and conversation, however, often took place outside the site, leaving no traces on Many Eyes itself. In other words, despite spurring significant social activity, Many Eyes is not so much an online community as a "community component" which users insert into pre-existing online social systems.	Your place or mine?: visualization as a community component	NA:NA:NA:NA	2018
Patrick Baudisch	NA	Session details: Touch and Target Selection	NA	2018
Koji Yatani:Kurt Partridge:Marshall Bern:Mark W. Newman	Many mobile devices have touch-sensitive screens that people interact with using fingers or thumbs. However, such interaction is difficult because targets become occluded, and because fingers and thumbs have low input resolution. Recent research has addressed occlusion through visual techniques. However, the poor resolution of finger and thumb selection still limits selection speed. In this paper, we address the selection speed problem through a new target selection technique called Escape. In Escape, targets are selected by gestures cued by icon position and appearance. A user study shows that for targets six to twelve pixels wide, Escape performs at a similar error rate and at least 30% faster than Shift, an alternative technique, on a similar task. We evaluate Escape's performance in different circumstances, including different icon sizes, icon overlap, use of color, and gesture direction. We also describe an algorithm that assigns icons to targets, thereby improving Escape's performance.	Escape: a target selection technique using visually-cued gestures	NA:NA:NA:NA	2018
Alex Olwal:Steven Feiner:Susanna Heyman	We introduce two families of techniques, rubbing and tapping, that use zooming to make possible precise interaction on passive touch screens, and describe examples of each. Rub-Pointing uses a diagonal rubbing gesture to integrate pointing and zooming in a single-handed technique. In contrast, Zoom-Tapping is a two-handed technique in which the dominant hand points, while the non-dominant hand taps to zoom, simulating multi-touch functionality on a single-touch display. Rub-Tapping is a hybrid technique that integrates rubbing with the dominant hand to point and zoom, and tapping with the non-dominant hand to confirm selection. We describe the results of a formal user study comparing these techniques with each other and with the well-known Take-Off and Zoom-Pointing selection techniques. Rub-Pointing and Zoom-Tapping had significantly fewer errors than Take-Off for small targets, and were significantly faster than Take-Off and Zoom-Pointing. We show how the techniques can be used for fluid interaction in an image viewer and in Google Maps.	Rubbing and tapping for precise and rapid selection on touch-screen displays	NA:NA:NA	2018
Steven J. Castellucci:I. Scott MacKenzie	Unistrokes and Graffiti are stylus-based text entry techniques. While Unistrokes is recognized in academia, Graffiti is commercially prevalent in PDAs. Though numerous studies have investigated the usability of Graffiti, none exists to compare its long-term performance with that of Unistrokes. This paper presents a longitudinal study comparing entry speed, correction rate, stroke duration, and preparation (i.e., inter-stroke) time of these two techniques. Over twenty fifteen-phrase sessions, performance increased from 4.0 wpm to 11.4 wpm for Graffiti and from 4.1 wpm to 15.8 wpm for Unistrokes. Correction rates were high for both techniques. However, rates for Graffiti remained relatively consistent at 26%, while those for Unistrokes decreased from 43% to 16%.	Graffiti vs. unistrokes: an empirical comparison	NA:NA	2018
Joona Laukkanen:Poika Isokoski:Kari-Jouko Räihä	We evaluated two cursor designs in the continuum between the traditional point cursor and the bubble cursor by Grossman and Balakrishnan. The lazy bubble cursor expanded to envelop the closest target when the ratio of the distances to the closest and the second closest target was less than 1:2. In addition to this lazy behavior the cone cursor had a tail that stayed on the last enveloped target until the next target was enveloped. In an experiment with 18 participants we found that the bubble cursor was faster than our cursors that had smaller target activation areas but the difference remained very small. Of the bubble cursor variants the lazy bubble exhibited higher error rate than the other two. Thus, the winners on the objective metrics were the bubble cursor and the cone cursor. The lazy bubble cursor and the bubble cursor were preferred in subjective ratings.	The cone and the lazy bubble: two efficient alternatives between the point cursor and the bubble cursor	NA:NA:NA	2018
Eric Paulos	NA	Session details: Green Day	NA	2018
Allison Woodruff:Jay Hasbrouck:Sally Augustin	We present a qualitative study of 35 United States households whose occupants have made significant accommodations to their homes and behaviors in order to be more environmentally responsible. Our goal is to inform the design of future sustainable technologies through an exploration of existing "green" lifestyles. We describe the motivations, practices, and experiences of the participants. The participants had diverse motivations ranging from caring for the Earth to frugal minimalism, and most participants also evidenced a desire to be unique. Most participants actively and consciously managed their homes and their daily practices to optimize their environmental responsibility. Their efforts to be environmentally responsible typically required significant dedication of time, attention, and other resources. As this level of commitment and desire to be unique may not generalize readily to the broader population, we discuss the importance of interactive technologies that influence surrounding infrastructure and circumstances in order to facilitate environmental responsibility.	A bright green perspective on sustainable choices	NA:NA:NA	2018
Elaine M. Huang:Khai N. Truong	We present a qualitative study of mobile phone ownership, replacement and disposal practices geared towards identifying design opportunities towards sustainable mobile phone interfaces. Our work investigates how people understand the lifespan of their phones, what factors, such as style, service contracts, and functionality, affect how they attribute value to their phones, and their awareness and actions regarding mobile phone sustainability. Our findings reveal the complexity of the actions and decision-making processes involved in phone ownership and replacement. We use these findings to present open areas for sustainable interaction design and generate seed ideas for designs and services to provoke thought and further exploration towards more sustainable mobile phone interfaces and practices.	Breaking the disposable technology paradigm: opportunities for sustainable interaction design for mobile phones	NA:NA	2018
Kristin Hanks:William Odom:David Roedl:Eli Blevis	This paper describes the design and interprets the results of a survey of 435 undergraduate students concerning the attitudes of this mainly millennial population towards sustainability apropos of the material effects of information technologies. This survey follows from earlier work on notions of Sustainable Interaction Design (SID)---that is the perspective that sustainability can and should be a central focus within HCI. In so doing it advances to some degree the empirical resources needed to scaffold an understanding of the theory and principles of SID. The interpretations offered yield key insights about understanding different notions of what it means to be successful in a material sense to this population and specific design principles for creating interactive designs differently such that more sustainable behaviors are palatable to individuals of varying attitudes.	Sustainable millennials: attitudes towards sustainability and the material effects of interactive technologies	NA:NA:NA:NA	2018
Panos Markopoulos	NA	Session details: Kid's Stuff	NA	2018
Nathan G. Freier	This paper describes the results of a study conducted to answer two questions: (1) Do children generalize their understanding of distinctions between conventional and moral violations in human-human interactions to human-agent interactions? and (2) Does the agent's ability to make claims to its own moral standing influence children's judgments? A two condition, between- and within-subjects study was conducted in which 60 eight and nine year-old children interacted with a personified agent and observed a researcher interacting with the same agent. A semi-structured interview was conducted to investigate the children's judgments and reasoning about the observed interactions as well as hypothetical human-human interactions. Results suggest that children do distinguish between conventional and moral violations in human-agent interactions and that the ability of the agent to express harm and make claims to its own rights significantly increases children's likelihood of identifying an act against the agent as a moral violation.	Children attribute moral standing to a personified agent	NA	2018
Neema Moraveji:Taemie Kim:James Ge:Udai Singh Pawar:Kathleen Mulcahy:Kori Inkpen	Mischief is a system to support traditional classroom practices between a remote instructor and a group of collocated students. Meant for developing regions, each student in the classroom is given a mouse and these are connected to a single machine and shared display. We present observations of teaching practices in rural Chinese classrooms that led to Mischief's design. Mischief's user interface, with which scores of collocated students can interact simultaneously, supports anonymous responses, communicates focus of attention, and maintains the role of the instructor. Mischief is an extensible platform in which Microsoft PowerPoint slides, used commonly in developing regions, are made interactive. We setup a controlled environment where Mischief was used by classrooms of children with a remote math instructor. The results from the study provided insight into the usability and capacity of the system to support traditional classroom interactions. These observations were also the impetus for a redesign of several components of Mischief and are also presented. These findings contribute both a novel system for synchronous distance education in an affordable manner and design insights for creators of related systems.	Mischief: supporting remote teaching in developing regions	NA:NA:NA:NA:NA:NA	2018
Yu-Chen Chang:Jin-Ling Lo:Chao-Ju Huang:Nan-Yi Hsu:Hao-Hua Chu:Hsin-Yen Wang:Pei-Yu Chi:Ya-Lin Hsieh	This case study in UbiComp technology and design presents a "Playful Toothbrush" system for assisting parents and teachers to motivate kindergarten children to learn proper and thorough brushing skills. The system includes a vision-based motion tracker that recognizes different tooth brushing strokes and a tooth brushing game in which the child cleans a virtual, mirror picture of his/her dirty teeth by physically brushing his/her own teeth. The user study results suggest that Playful Toothbrush enhances the effectiveness of kindergarten children in brushing their teeth, as measured by number of brushing strokes, duration of brushing and thoroughness of teeth cleaning.	Playful toothbrush: ubicomp technology for teaching tooth brushing to kindergarten children	NA:NA:NA:NA:NA:NA:NA:NA	2018
Darren Gergle	NA	Session details: Collaborative User Interfaces	NA	2018
Cosmin Munteanu:Ron Baecker:Gerald Penn	One challenge in facilitating skimming or browsing through archives of on-line recordings of webcast lectures is the lack of text transcripts of the recorded lecture. Ideally, transcripts would be obtainable through Automatic Speech Recognition (ASR). However, current ASR systems can only deliver, in realistic lecture conditions, a Word Error Rate of around 45% -- above the accepted threshold of 25%. In this paper, we present the iterative design of a webcast extension that engages users to collaborate in a wiki-like manner on editing the ASR-produced imperfect transcripts, and show that this is a feasible solution for improving the quality of lecture transcripts. We also present the findings of a field study carried out in a real lecture environment investigating how students use and edit the transcripts.	Collaborative editing for improved usefulness and usability of transcript-enhanced webcasts	NA:NA:NA	2018
Tovi Grossman:Ravin Balakrishnan	Volumetric displays possess a number of unique properties which potentially make them particularly suitable for collaborative 3D applications. Because such displays have only recently become available, interaction techniques for collaborative usage have yet to be explored. In this paper, we initiate this exploration. We present a prototype collaborative 3D model viewing application, which served as a platform for our explorations. We outline three design goals, discuss the key interaction issues which were encountered, and describe a suite of new techniques in detail. In initial user observation sessions, we found that our techniques allowed users to successfully complete a variety of 3D tasks. Furthermore, interviews with experts in potential usage domains indicated that the techniques we developed can serve as a baseline for future collaborative applications for volumetric displays.	Collaborative interaction with volumetric displays	NA:NA	2018
Beryl Plimmer:Andrew Crossan:Stephen A. Brewster:Rachel Blagojevic	"McSig" is a multimodal teaching and learning environ-ment for visually-impaired students to learn character shapes, handwriting and signatures collaboratively with their teachers. It combines haptic and audio output to realize the teacher's pen input in parallel non-visual modalities. McSig is intended for teaching visually-impaired children how to handwrite characters (and from that signatures), something that is very difficult without visual feedback. We conducted an evaluation with eight visually-impaired children with a pretest to assess their current skills with a set of character shapes, a training phase using McSig and then a post-test of the same character shapes to see if there were any improvements. The children could all use McSig and we saw significant improvements in the character shapes drawn, particularly by the completely blind children (many of whom could draw almost none of the characters before the test). In particular, the blind participants all expressed enjoyment and excitement about the system and using a computer to learn to handwrite.	Multimodal collaborative handwriting training for visually-impaired people	NA:NA:NA:NA	2018
Tara Matthews	NA	Session details: Aesthetics, Awareness, and Sketching	NA	2018
Dan Cosley:Joel Lewenstein:Andrew Herman:Jenna Holloway:Jonathan Baxter:Saeko Nomura:Kirsten Boehner:Geri Gay	Technologies in museums often support learning goals, providing information about exhibits. However, museum visitors also desire meaningful experiences and enjoy the social aspects of museum-going, values ignored by most museum technologies. We present ArtLinks, a visualization with three goals: helping visitors make connections to exhibits and other visitors by highlighting those visitors who share their thoughts; encouraging visitors' reflection on the social and liminal aspects of museum-going and their expectations of technology in museums; and doing this with transparency, aligning aesthetically pleasing elements of the design with the goals of connection and reflection. Deploying ArtLinks revealed that people have strong expectations of technology as an information appliance. Despite these expectations, people valued connections to other people, both for their own sake and as a way to support meaningful experience. We also found several of our design choices in the name of transparency led to unforeseen tradeoffs between the social and the liminal.	ArtLinks: fostering social awareness and reflection in museums	NA:NA:NA:NA:NA:NA:NA:NA	2018
Richard C. Davis:Brien Colwell:James A. Landay	Because most animation tools are complex and time-consuming to learn and use, most animations today are created by experts. To help novices create a wide range of animations quickly, we have developed a general-purpose, informal, 2D animation sketching system called K-Sketch. Field studies investigating the needs of animators and would-be animators helped us collect a library of usage scenarios for our tool. A novel optimization technique enabled us to design an interface that is simultaneously fast, simple, and powerful. The result is a pen-based system that relies on users' intuitive sense of space and time while still supporting a wide range of uses. In a laboratory experiment that compared K-Sketch to a more formal animation tool (PowerPoint), participants worked three times faster, needed half the learning time, and had significantly lower cognitive load with K-Sketch.	K-sketch: a 'kinetic' sketch pad for novice animators	NA:NA:NA	2018
Leah Buechley:Mike Eisenberg:Jaime Catchen:Ali Crockett	The advent of novel materials (such as conductive fibers) combined with accessible embedded computing platforms have made it possible to re-imagine the landscapes of fabric and electronic crafts--extending these landscapes with the creative range of electronic/computational textiles or e-textiles. This paper describes the LilyPad Arduino, a fabric-based construction kit that enables novices to design and build their own soft wearables and other textile artifacts. The kit consists of a microcontroller and an assortment of sensors and actuators in stitch-able packages; these elements can be sewn to cloth substrates and each other with conductive thread to build e-textiles. This paper will introduce the latest version of the kit; reflect on its affordances; present the results of our most recent user studies; and discuss possible directions for future work in the area of personalized e-textile design and its relation to technology education.	The LilyPad Arduino: using computational textiles to investigate engagement, aesthetics, and diversity in computer science education	NA:NA:NA:NA	2018
Robin Jeffries	NA	Session details: Data Collection	NA	2018
Timothy Sohn:Kevin A. Li:William G. Griswold:James D. Hollan	Being mobile influences not only the types of information people seek but also the ways they attempt to access it. Mobile contexts present challenges of changing location and social context, restricted time for information access, and the need to share attentional resources among concurrent activities. Understanding mobile information needs and associated interaction challenges is fundamental to improving designs for mobile phones and related devices. We conducted a two-week diary study to better understand mobile information needs and how they are addressed. Our study revealed that depending on the time and resources available, as well as the situational context, people use diverse and, at times, ingenious ways to obtain needed information. We summarize key findings and discuss design implications for mobile technology.	A diary study of mobile information needs	NA:NA:NA:NA	2018
Jun H. Kim:Daniel V. Gunn:Eric Schuh:Bruce Phillips:Randy J. Pagulayan:Dennis Wixon	Automatic recording of user behavior within a system (instrumentation) to develop and test theories has a rich history in psychology and system design. Often, researchers analyze instrumented behavior in isolation from other data. The problem with collecting instrumented behaviors without attitudinal, demographic, and contextual data is that researchers have no way to answer the 'why' behind the 'what'. We have combined the collection and analysis of behavioral instrumentation with other HCI methods to develop a system for Tracking Real-Time User Experience (TRUE). Using two case studies as examples, we demonstrate how we have evolved instrumentation methodology and analysis to extensively improve the design of video games. It is our hope that TRUE is adopted and adapted by the broader HCI community, becoming a useful tool for gaining deep insights into user behavior and improvement of design for other complex systems.	Tracking real-time user experience (TRUE): a comprehensive instrumentation solution for complex systems	NA:NA:NA:NA:NA:NA	2018
Aniket Kittur:Ed H. Chi:Bongwon Suh	User studies are important for many aspects of the design process and involve techniques ranging from informal surveys to rigorous laboratory studies. However, the costs involved in engaging users often requires practitioners to trade off between sample size, time requirements, and monetary costs. Micro-task markets, such as Amazon's Mechanical Turk, offer a potential paradigm for engaging a large number of users for low time and monetary costs. Here we investigate the utility of a micro-task market for collecting user measurements, and discuss design considerations for developing remote micro user evaluation tasks. Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach.	Crowdsourcing user studies with Mechanical Turk	NA:NA:NA	2018
Dianne Murray	NA	Session details: Health and Wellness	NA	2018
Taowei David Wang:Catherine Plaisant:Alexander J. Quinn:Roman Stanchak:Shawn Murphy:Ben Shneiderman	Electronic Health Records (EHRs) and other temporal databases contain hidden patterns that reveal important cause-and-effect phenomena. Finding these patterns is a challenge when using traditional query languages and tabular displays. We present an interactive visual tool that complements query formulation by providing operations to align, rank and filter the results, and to visualize estimates of the intervals of validity of the data. Display of patient histories aligned on sentinel events (such as a first heart attack) enables users to spot precursor, co-occurring, and aftereffect events. A controlled study demonstrates the benefits of providing alignment (with a 61% speed improvement for complex tasks). A qualitative study and interviews with medical professionals demonstrates that the interface can be learned quickly and seems to address their needs.	Aligning temporal data by sentinel events: discovering patterns in electronic health records	NA:NA:NA:NA:NA:NA	2018
Andrea Grimes:Richard Harper	Food is a central part of our lives. Fundamentally, we need food to survive. Socially, food is something that brings people together-individuals interact through and around it. Culturally, food practices reflect our ethnicities and nationalities. Given the importance of food in our daily lives, it is important to understand what role technology currently plays and the roles it can be imagined to play in the future. In this paper we describe the existing and potential design space for HCI in the area of human-food interaction. We present ideas for future work on designing technologies in the area of human-food interaction that celebrate the positive interactions that people have with food as they eat and prepare foods in their everyday lives.	Celebratory technology: new directions for food research in HCI	NA:NA	2018
Lena Mamykina:Elizabeth Mynatt:Patricia Davidson:Daniel Greenblatt	In the recent years, the number of individuals engaged in self-care of chronic diseases has grown exponentially. Advances in computing technologies help individuals with chronic diseases collect unprecedented volumes of health-related data. However, engaging in reflective analysis of the collected data may be challenging for the untrained individuals. We present MAHI, a health monitoring application that assists newly diagnosed individuals with diabetes in acquiring and developing reflective thinking skills through social interaction with diabetes educators. The deployment study with twenty five newly diagnosed individuals with diabetes demonstrated that MAHI significantly contributed to individuals' achievement of their diabetes management goals (changing diet). More importantly, MAHI inspired individuals to adopt Internal Locus of Control, which often leads to persistent engagement in self-care and positive health outcomes.	MAHI: investigation of social scaffolding for reflective thinking in diabetes management	NA:NA:NA:NA	2018
Alan Blackwell	NA	Session details: I am here. Where are you?	NA	2018
Emily Troshynski:Charlotte Lee:Paul Dourish	How do mobility and presence feature as aspects of social life? Using a case study of paroled offenders tracked via Global Positioning System (GPS), we explore the ways that location-based technologies frame people's everyday experiences of space. In particular, we focus on how access and presence are negotiated outside of traditional conceptions of "privacy." We introduce the notion of accountabilities of presence and suggest that it is a more useful concept than "privacy" for understanding the relationship between presence and sociality.	Accountabilities of presence: reframing location-based systems	NA:NA:NA	2018
Louise Barkhuus:Barry Brown:Marek Bell:Scott Sherwood:Malcolm Hall:Matthew Chalmers	This paper investigates emergent practices around 'microblogging', changing and sharing status within a social group. We present results from a trial of 'Connecto', a phone based status and location sharing application that allows a group to 'tag' areas and have individuals' locations shared automatically on a mobile phone. In use the system moved beyond being an awareness tool to a way of continuing the ongoing 'story' of conversations within the group. Through sharing status and location the system supported each groups' ongoing repartee - a site for social exchange, enjoyment and friendship.	From awareness to repartee: sharing location within social groups	NA:NA:NA:NA:NA:NA	2018
Chris Harrison:Anind K. Dey	The size and resolution of computer displays has increased dramatically, allowing more information than ever to be rendered on-screen. However, items can now be so small or screens so cluttered that users need to lean forward to properly examine them. This behavior may be detrimental to a user's posture and eyesight. Our Lean and Zoom system detects a user's proximity to the display using a camera and magnifies the on-screen content proportionally. This alleviates dramatic leaning and makes items more readable. Results from a user study indicate people find the technique natural and intuitive. Most participants found on-screen content easier to read, and believed the technique would improve both their performance and comfort.	Lean and zoom: proximity-aware user interface and content magnification	NA:NA	2018
Siân E. Lindley:James Le Couteur:Nadia L. Berthouze	The recent development of controllers designed around natural body movements has altered the nature of gaming and contributed towards it being marketed as a more social activity. The study reported here compares the use of Donkey Konga bongos with a standard controller to examine how affording motion through an input device affects social interaction. Levels of engagement with the game were also measured to explore whether increases in social behaviour in the 'real world' would result in reduced involvement with the 'game world'. Social interaction was significantly higher when the bongos were used, but this did not detract from engagement. Instead, engagement was also found to increase when body movement was afforded.	Stirring up experience through movement in game play: effects on engagement and social behaviour	NA:NA:NA	2018
Bo Begole	NA	Session details: Physiological Sensing for Input	NA	2018
T Scott Saponas:Desney S. Tan:Dan Morris:Ravin Balakrishnan	We explore the feasibility of muscle-computer interfaces (muCIs): an interaction methodology that directly senses and decodes human muscular activity rather than relying on physical device actuation or user actions that are externally visible or audible. As a first step towards realizing the mu-CI concept, we conducted an experiment to explore the potential of exploiting muscular sensing and processing technologies for muCIs. We present results demonstrating accurate gesture classification with an off-the-shelf electromyography (EMG) device. Specifically, using 10 sensors worn in a narrow band around the upper forearm, we were able to differentiate position and pressure of finger presses, as well as classify tapping and lifting gestures across all five fingers. We conclude with discussion of the implications of our results for future muCI designs.	Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces	NA:NA:NA:NA	2018
Xinyong Zhang:Xiangshi Ren:Hongbin Zha	In order to improve the stability of eye cursor, we introduce three methods, force field (FF), speed reduction (SR), and warping to target center (TC) to modulate eye cursor trajectories by counteracting eye jitter, which is the main cause of destabilizing the eye cursor. We evaluate these methods using two controlled experiments. One is an attention task experiment, which indicates that both FF and SR significantly alleviate the instability of eye cursor, but TC is not as we anticipated. The other is a 2D pointing task experiment, which shows that FF and SR as well as the improved implementation of SR (iSR) indeed improve human performance in dominant dwell-based eye pointing tasks of eye-based interactions. The method iSR is especially effective to accelerate eye pointing (10.5% and 8.5%) and reduce error rate (6.1% and 2.7%) when target diameter D = 45 and 60 pixels.	Improving eye cursor's stability for eye pointing tasks	NA:NA:NA	2018
Naoto Kaneko	In this paper, we describe the design of the ear tracker. The ear tracker detects the direction to which a person is listening. We propose the technique as a new form of an input device technology, which potentially allows the user to control machines with vague intention rather than explicit commands. Our ear tracker makes the detection with the electromyogram (EMG) signals probed behind ears. We have prototyped its hardware and algorithm. In our experiment, it shows 70% accuracy for detecting whether the testee is listening to the left or right.	Detecting the direction of listening with the emg signals measured behind ears	NA	2018
Raj M. Ratwani:J. Malcolm McCurry:J. Gregory Trafton	A postcompletion error is a distinct type of procedural error where one fails to complete the final step of a task. While redesigning interfaces and providing explicit cues have been shown to be effective in reducing the postcompletion error rate, these methods are not always feasible or well liked. This paper demonstrates how specific eye movement measures can be used to predict when a user will make a postcompletion error. We describe a real-time eye gaze system that provides cues to the user if and only if there is a high probability of the user making a postcompletion error.	Predicting postcompletion errors using eye movements	NA:NA:NA	2018
Jeffrey Pierce	NA	Session details: Policy, Telemedicine, and Enterprise	NA	2018
Lujo Bauer:Lorrie Faith Cranor:Robert W. Reeder:Michael K. Reiter:Kami Vaniea	Significant effort has been invested in developing expressive and flexible access-control languages and systems. However, little has been done to evaluate these systems in practical situations with real users, and few attempts have been made to discover and analyze the access-control policies that users actually want to implement. We report on a user study in which we derive the ideal access policies desired by a group of users for physical security in an office environment. We compare these ideal policies to the policies the users actually implemented with keys and with a smartphone-based distributed access-control system. We develop a methodology that allows us to show quantitatively that the smartphone system allowed our users to implement their ideal policies more accurately and securely than they could with keys, and we describe where each system fell short.	A user study of policy creation in a flexible access-control system	NA:NA:NA:NA:NA	2018
Simon B. Larsen:Jakob E. Bardram	Many studies and concepts within CSCW deal with the temporal, spatial, social, and computational aspects of supporting collaborative work. In this paper we want to pay attention to another central aspect to the achievement of collaborative work, namely the competence of the people involved. In particular, we want to look at the dynamic quality of competences, and investigate how competence is mutually developed in coordinated work. We have termed this process competence articulation, a concept which tries to emphasize competence as well as social development of competence as part of cooperation. The concept has emerged out of a longitudinal participatory design process investigating telemedical treatment of diabetic foot ulcers using video phones. We analyze the transitions occurring with the introduction of synchronous telemedical consultations and detail how the online video facilitates communication options for competence articulation, which again improve collaboration and thus the quality of the treatment.	Competence articulation: alignment of competences and responsibilities in synchronous telemedical collaboration	NA:NA	2018
Rosta Farzan:Joan M. DiMicco:David R. Millen:Casey Dugan:Werner Geyer:Elizabeth A. Brownholtz	Success and sustainability of social networking sites is highly dependent on user participation. To encourage contribution to an opt-in social networking site designed for employees, we have designed and implemented a feature that rewards contribution with points. In our evaluation of the impact of the system, we found that employees are initially motivated to add more content to the site. This paper presents the analysis and design of the point system, the results of our experiment, and our insights regarding future directions derived from our post-experiment user interviews.	Results from deploying a participation incentive mechanism within the enterprise	NA:NA:NA:NA:NA:NA	2018
Kari-Jouko R?ih?	NA	Session details: Post-QWERTY QWERTY	NA	2018
James Clawson:Kent Lyons:Alex Rudnick:Robert A. Iannucci, Jr.:Thad Starner	By analyzing features of users' typing, Automatic Whiteout++ detects and corrects up to 32.37% of the errors made by typists while using a mini-QWERTY (RIM Blackberry style) keyboard. The system targets "off-by-one" errors where the user accidentally presses a key adjacent to the one intended. Using a database of typing from longitudinal tests on two different keyboards in a variety of contexts, we show that the system generalizes well across users, model of keyboard, user expertise, and keyboard visibility conditions. Since a goal of Automatic Whiteout++ is to embed it in the firmware of mini-QWERTY keyboards, it does not rely on a dictionary. This feature enables the system to correct errors mid-word instead of applying a correction after the word has been typed. Though we do not use a dictionary, we do examine the effect of varying levels of language context in the system's ability to detect and correct erroneous keypresses.	Automatic whiteout++: correcting mini-QWERTY typing errors using keypress timing	NA:NA:NA:NA:NA	2018
Benoît Martin:Poika Isokoski	We describe a system that informs the users of the shape of the EdgeWrite characters within the visual feedback area of EdgeWrite. We compared two versions (static and dynamic) of this design to a printed character chart in a five-session text entry experiment with three 8-participant groups. The participants were able to use EdgeWrite with the integrated help systems. There were no statistically significant differences in text entry rate between the group using the character chart and the two groups using the integrated help. However, the group with the dynamic help was faster than the group with the static help while maintaining a low corrected error rate.	EdgeWrite with integrated corner sequence help	NA:NA	2018
Shumin Zhai:Per Ola Kristensson	Shape writing is an input technology for touch-screen mobile phones and pen-tablets. To shape write text, the user spells out word patterns by sliding a finger or stylus over a graphical keyboard. The user's trace is then recognized by a pattern recognizer. In this paper we analyze and evaluate various keyboard layouts, including alphabetic, optimized (ATOMIK), QWERTY, and interlaced QWERTY for shape writing. The goodness of a layout for shape writing has two aspects. For users' initial ease of use the letters should be easy to visually locate. For long term use, however, the layout should maximize the imprecision tolerance and writing flexibility for all words. We present empirical studies for the former and mathematical analyses for the latter. Our results led to a new layout, interlaced QWERTY, which offers excellent separation of word shapes, while still maintaining a low visual search time. Many of the findings in our study also apply to traditional soft keyboards tapped with a stylus or one finger.	Interlaced QWERTY: accommodating ease of visual search and input flexibility in shape writing	NA:NA	2018
Mary-Beth Rosson	NA	Session details: Beyond End-User Programming	NA	2018
Stefan Parry Carmien:Gerhard Fischer	A significant fraction of persons with cognitive disabilities are potentially able to live more independently with the use of powerful tools embedded in their social environment. The Memory Aiding Prompting System (MAPS) provides an environment in which caregivers can create scripts that can be used by people with cognitive disabilities ("clients") to support them in carrying out tasks that they would not be able to achieve by themselves. To account for the great diversity among clients, MAPS was developed as a meta-design environment, empowering the caregivers to develop personalized prompting systems for the specific needs of individual clients.	Design, adoption, and assessment of a socio-technical environment supporting independence for persons with cognitive disabilities	NA:NA	2018
Michael Terry:Matthew Kay:Brad Van Vugt:Brandon Slack:Terry Park	Open source projects are gradually incorporating usability methods into their development practices, but there are still many unmet needs. One particular need for nearly any open source project is data that describes its user base, including information indicating how the software is actually used in practice. This paper presents the concept of open instrumentation, or the augmentation of an open source application to openly collect and publicly disseminate rich application usage data. We demonstrate the concept of open instrumentation in ingimp, a version of the open source GNU Image Manipulation Program that has been modified to collect end-user usage data. ingimp automatically collects five types of data: The commands used, high-level user interface events, overall features of the user's documents, summaries of the user's general computing environment, and users' own descriptions of their planned tasks. In the spirit of open source software, all collected data are made available for anyone to download and analyze. This paper's primary contributions lie in presenting the overall design of ingimp, with a particular focus on how the design addresses two prominent issues in open instrumentation: privacy and motivating use.	Ingimp: introducing instrumentation to an end-user open source application	NA:NA:NA:NA:NA	2018
Neeraja Subrahmaniyan:Laura Beckwith:Valentina Grigoreanu:Margaret Burnett:Susan Wiedenbeck:Vaishnavi Narayanan:Karin Bucht:Russell Drummond:Xiaoli Fern	Little is known about the strategies end-user programmers use in debugging their programs, and even less is known about gender differences that may exist in these strategies. Without this type of information, designers of end-user programming systems cannot know the "target" at which to aim, if they are to support male and female end-user programmers. We present a study investigating this issue. We asked end-user programmers to debug spreadsheets and to describe their debugging strategies. Using mixed methods, we analyzed their strategies and looked for relationships among participants' strategy choices, gender, and debugging success. Our results indicate that males and females debug in quite different ways, that opportunities for improving support for end-user debugging strategies for both genders are abundant, and that tools currently available to end-user debuggers may be especially deficient in supporting debugging strategies used by females.	Testing vs. code inspection vs. what else?: male and female end users' debugging strategies	NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
mc schraefel	NA	Session details: Dignity in Design	NA	2018
Christopher A. Le Dantec:W. Keith Edwards	Technology, it is argued, has the potential to improve everyone's life: from the workplace, to entertainment, to easing chores around the home. But what of people who have neither job nor home? We undertook a qualitative study of the homeless population in a metropolitan U.S. city to better understand what it means to be homeless and how technology--from cell phones to bus passes--affects their daily lives. The themes we identify provide an array of opportunities for technological interventions that can empower the homeless population. Our investigation also reveals the need to reexamine some of the assumptions made in HCI about the relationship people have with technology. We suggest a broader awareness of the social context of technology use as a critical component when considering design innovation for the homeless.	Designs on dignity: perceptions of technology among the homeless	NA:NA	2018
Peter Wright:John McCarthy	For a decade HCI researchers and practitioners have been developing methods, practices and designs 'for the full range of human experience'. On the one hand, a variety of approaches to design, such as aesthetic, affective, and ludic that emphasize particular qualities and contexts of experience and particular approaches to intervening in interactive experience have become focal. On the other, a variety of approaches to understanding users and user experience, based on narrative, biography, and role-play have been developed and deployed. These developments can be viewed in terms of one of the seminal commitments of HCI, 'to know the user'. Empathy has been used as a defining characteristic of designer-user relationships when design is concerned with user experience. In this article, we use 'empathy' to help position some emerging design and user-experience methodologies in terms of dynamically shifting relationships between designers, users, and artefacts.	Empathy and experience in HCI	NA:NA	2018
Kristina Höök:Anna Ståhl:Petra Sundström:Jarmo Laaksolaahti	We propose that an interactional perspective on how emotion is constructed, shared and experienced, may be a good basis for designing affective interactional systems that do not infringe on privacy or autonomy, but instead empowers users. An interactional design perspective may make use of design elements such as open-ended, ambiguous, yet familiar, interaction surfaces that users can use as a basis to make sense of their own emotions and their communication with one-another. We describe the interactional view on design for emotional communication, and provide a set of orienting design concepts and methods for design and evaluation that help translate the interactional view into viable applications. From an embodied interaction theory perspective, we argue for a non-dualistic, non-reductionist view on affective interaction design.	Interactional empowerment	NA:NA:NA:NA	2018
Joe Tullio	NA	Session details: Knowledge Elicitation	NA	2018
Ashish Kapoor:Eric Horvitz	Experience sampling has been employed for decades to collect assessments of subjects' intentions, needs, and affective states. In recent years, investigators have employed automated experience sampling to collect data to build predictive user models. To date, most procedures have relied on random sampling or simple heuristics. We perform a comparative analysis of several automated strategies for guiding experience sampling, spanning a spectrum of sophistication, from a random sampling procedure to increasingly sophisticated active learning. The more sophisticated methods take a decision-theoretic approach, centering on the computation of the expected value of information of a probe, weighing the cost of the short-term disruptiveness of probes with their benefits in enhancing the long-term performance of predictive models. We test the different approaches in a field study, focused on the task of learning predictive models of the cost of interruption.	Experience sampling for building predictive user models: a comparative study	NA:NA	2018
Kayur Patel:James Fogarty:James A. Landay:Beverly Harrison	As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.	Investigating statistical machine learning as a tool for software development	NA:NA:NA:NA	2018
Xiaolong Zhang:Yan Qu:C. Lee Giles:Piyou Song	Making sense of research literature is a complicated process that involves various information seeking and compre-hension tasks. The lack of support for sensemaking in existing systems presents important design challenges and opportunities. This research proposes the design of an integral environment to support literature search, selection, organization and comprehension. Our system prototype, CiteSense, offers lightweight interaction tools and a smooth transition among various information activities. This research deepens our understanding of the design of systems that support the sensemaking of research literature.	CiteSense: supporting sensemaking of research literature	NA:NA:NA:NA	2018
William Jones:Predrag Klasnja:Andrea Civan:Michael L. Adcock	Prototyping and evaluation combine to explore ways that an effective, integrative organization of project-related information might emerge as a by-product of a person's efforts to plan a project. The Personal Project Planner works as an extension to the file manager -- providing people with rich-text overlays to their information. Document-like project plans provide a context in which to create or reference documents, email messages, web pages, etc. that are needed to complete the plan. The user can later locate an information item such as an email message with reference to the plan (e.g., as an alternative to searching through the inbox or sent mail). Results of an interim evaluation of the Planner are very promising and suggest special directions of focus for limited available prototyping resources.	The personal project planner: planning to organize personal information	NA:NA:NA:NA	2018
Franca Garzotto	NA	Session details: Tools for Education	NA	2018
Gillian R. Hayes:Lamar M. Gardere:Gregory D. Abowd:Khai N. Truong	Identifying the function of problem behavior can lead to the development of more effective interventions. One way to identify the function is through functional behavior assessment (FBA). Teachers conduct FBA in schools. However, the task load of recording the data manually is high, and the challenge of accurately identifying antecedents and consequences is significant while interacting with students. These issues often result in imperfect information capture. CareLog allows teachers more easily to conduct FBAs and enhances the capture of relevant information. In this paper, we describe the design process that led to five design principles that governed the development of CareLog. We present results from a five-month, quasi-controlled study aimed at validating those design principles. We reflect on how various constraints imposed by special education settings impact the design and evaluation process for HCI practitioners and researchers.	CareLog: a selective archiving tool for behavior management in schools	NA:NA:NA:NA	2018
Joel Lanir:Kellogg S. Booth:Leah Findlater	Large classrooms have traditionally provided multiple blackboards on which an entire lecture could be visible. In recent decades, classrooms were augmented with a data projector and screen, allowing computer-generated slides to replace hand-written blackboard presentations and overhead transparencies as the medium of choice. Many lecture halls and conference rooms will soon be equipped with multiple projectors that provide large, high-resolution displays of comparable size to an old fashioned array of blackboards. The predominant presentation software, however, is still designed for a single medium-resolution projector. With the ultimate goal of designing rich presentation tools that take full advantage of increased screen resolution and real estate, we conducted an observational study to examine current practice with both traditional whiteboards and blackboards, and computer-generated slides. We identify several categories of observed usage, and highlight differences between traditional media and computer slides. We then present design guidelines for presentation software that capture the advantages of the old and the new and describe a working prototype based on those guidelines that more fully utilizes the capabilities of multiple displays.	Observing presenters' use of visual aids to inform the design of classroom presentation software	NA:NA:NA	2018
Alexander J. Quinn:Chang Hu:Takeshi Arisaka:Anne Rose:Benjamin B. Bederson	Displaying scanned book pages in a web browser is difficult, due to an array of characteristics of the common user's configuration that compound to yield text that is degraded and illegibly small. For books which contain only text, this can often be solved by using OCR or manual transcription to extract and present the text alone, or by magnifying the page and presenting it in a scrolling panel. Books with rich illustrations, especially children's picture books, present a greater challenge because their enjoyment is dependent on reading the text in the context of the full page with its illustrations. We have created two novel prototypes for solving this problem by magnifying just the text, without magnifying the entire page. We present the results of a user study of these techniques. Users found our prototypes to be more effective than the dominant interface type for reading this kind of material and, in some cases, even preferable to the physical book itself.	Readability of scanned books in digital libraries	NA:NA:NA:NA:NA	2018
Kenton O'Hara	NA	Session details: Sound of Music	NA	2018
Tuck Leong:Steve Howard:Frank Vetere	Many people today have access to enormous libraries of digital content. Increasingly these libraries contain personal content, consumed in support of people's non-instrumental needs. If current trends persist, these repositories will only increase. Having to choose from so much could be unpleasant especially in the absence of strong preferences. This raises some concerns for user experience (UX) design. Approaches for such interactions should not only be optimized for UX but must also support users' non-instrumental needs. People face this predicament during digital music listening and yet report positive experiences when listening in shuffle. Through an empirical study of digital music listening and close examination of people's listening practices and experiences, we argue that a shuffle-based approach--whereby people can abdicate choice to a random process while being able to modulate the randomness--not only mitigates the unpleasantness of choosing but also supports their non-instrumental needs while fostering desirable experiential outcomes.	Choice: abidcating or exercising?	NA:NA:NA	2018
Ian Simon:Dan Morris:Sumit Basu	We introduce MySong, a system that automatically chooses chords to accompany a vocal melody. A user with no musical experience can create a song with instrumental accompaniment just by singing into a microphone, and can experiment with different styles and chord patterns using interactions designed to be intuitive to non-musicians. We describe the implementation of MySong, which trains a Hidden Markov Model using a music database and uses that model to select chords for new melodies. Model parameters are intuitively exposed to the user. We present results from a study demonstrating that chords assigned to melodies using MySong and chords assigned manually by musicians receive similar subjective ratings. We then present results from a second study showing that thirteen users with no background in music theory are able to rapidly create musical accompaniments using MySong, and that these accompaniments are rated positively by evaluators.	MySong: automatic accompaniment generation for vocal melodies	NA:NA:NA	2018
Yasushi Akiyama:Sageev Oore	We present a novel interface for young children to interact with digital music. PlaceAndPlay provides an intuitive environment for children with no music creation experience. Multimodal interaction techniques and a unique approach to music layout accommodate physical and cognitive abilities of young children. The system was evaluated in user study settings at the different designing stages and the results were positive.	PlaceAndPlay: a digital tool for children to create and record music	NA:NA	2018
David Merrill:Hayes Raffle:Roberto Aimi	The Sound of Touch is a new tool for real-time capture and sensitive physical stimulation of sound samples using digital convolution. Our hand-held wand can be used to (1) record sound, then (2) play back the recording by brushing, scraping, striking or otherwise physically manipulating the wand against physical objects. During playback, the recorded sound is continuously filtered by the acoustic interaction of the wand and the material being touched. The Sound of Touch enables a physical and continuous sculpting of sound that is typical of acoustic musical instruments and interactions with natural objects and materials, but not available in GUI-based tools or most electronic music instruments. This paper reports the design of the system and observations of thousands of users interacting with it in an exhibition format. Preliminary user feedback suggests future applications to foley, professional sound design, and musical performance.	The sound of touch: physical manipulation of digital sound	NA:NA:NA	2018
Shamsi T. Iqbal	NA	Session details: Healthcare in the Developing World	NA	2018
Rowena Luk:Melissa Ho:Paul M. Aoki	Computer-mediated communication systems can be used to bridge the gap between doctors in underserved regions with local shortages of medical expertise and medical specialists worldwide. To this end, we describe the design of a prototype remote consultation system intended to provide the social, institutional and infrastructural context for sustained, self-organizing growth of a globally-distributed Ghanaian medical community. The design is grounded in an iterative design process that included two rounds of extended design fieldwork throughout Ghana and draws on three key design principles (social networks as a framework on which to build incentives within a self-organizing network; optional and incremental integration with existing referral mechanisms; and a weakly-connected, distributed architecture that allows for a highly interactive, responsive system despite failures in connectivity). We discuss initial experiences from an ongoing trial deployment in southern Ghana.	Asynchronous remote medical consultation for Ghana	NA:NA:NA	2018
Brian DeRenzi:Neal Lesh:Tapan Parikh:Clayton Sims:Werner Maokla:Mwajuma Chemba:Yuna Hamisi:David S hellenberg:Marc Mitchell:Gaetano Borriello	Every year almost 10 million children die before reaching the age of five despite the fact that two-thirds of these deaths could be prevented by effective low-cost interventions. To combat this, the World Health Organization (WHO) and UNICEF developed the Integrated Management of Childhood Illness (IMCI) treatment algorithms. In Tanzania, IMCI is the national policy for the treatment of childhood illness. This paper describes e-IMCI, a system for administering the IMCI protocol using a PDA. Our preliminary investigation in rural Tanzania suggests that e-IMCI is almost as fast as the common practice and potentially improves care by increasing adherence to the IMCI protocols. Additionally, we found clinicians could quickly be trained to use e-IMCI and were very enthusiastic about using it in the future.	E-imci: improving pediatric health care in low-income countries	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Karen G. Cheng:Francisco Ernesto:Khai N. Truong	Handheld computers have untapped potential to improve HIV/AIDS programs in sub-Saharan Africa, particularly in the collection of survey data. We conducted an experiment in three neighborhoods of Luanda, Angola to assess the impact of the technology on people's comfort and willingness to disclose sensitive personal information, such as sexual behavior. Participants were asked about their HIV/AIDS-related knowledge, attitudes, and practices by local interviewers using either handheld computers or paper surveys. T-tests showed no differences between participants' self-reported comfort across handheld and paper conditions. However, participants in the handheld condition were more likely to give socially desirable responses to the sexual behavior questions than participants in the paper condition. These results suggest that using handheld computers in data collection in sub-Saharan Africa may lead to biased reports of HIV/AIDS-related risk behaviors.	Participant and interviewer attitudes toward handheld computers in the context of HIV/AIDS programs in sub-Saharan Africa	NA:NA:NA	2018
Andy Cockburn	NA	Session details: Displayful and Displayless	NA	2018
David Dearman:Jeffery S. Pierce	The number of computing devices that people use is growing. To gain a better understanding of why and how people use multiple devices, we interviewed 27 people from academia and industry. From these interviews we distill four primary findings. First, associating a user's activities with a particular device is problematic for multiple device users because many activities span multiple devices. Second, device use varies by user and circumstance; users assign different roles to devices both by choice and by constraint. Third, users in industry want to separate work and personal activities across work and personal devices, but they have difficulty doing so in practice Finally, users employ a variety of techniques for accessing information across devices, but there is room for improvement: participants reported managing information across their devices as the most challenging aspect of using multiple devices. We suggest opportunities to improve the user experience by focusing on the user rather than the applications and devices; making devices aware of their roles; and providing lighter-weight methods for transferring information, including synchronization services that engender more trust from users.	It's on my other computer!: computing with multiple devices	NA:NA	2018
Miguel A. Nacenta:Regan L. Mandryk:Carl Gutwin	Multi-monitor displays and multi-display environments are now common. Cross-display cursor movement, in which a user moves the pointer from one display to another, occurs frequently in these settings. There are several techniques for supporting this kind of movement, and these differ in the way that they deal with displayless space (the physical space between displays). Stitching is the method used by most operating systems; in this technique, the cursor jumps from the edge of one display directly into the next display. In contrast, Mouse Ether maps the motor space of the mouse exactly to the physical space of the displays, meaning that the cursor has to travel across displayless space until it reaches the next display. To determine which of these approaches is best for cross-display movement, we carried out a study comparing Stitching, Mouse Ether, and a variant of Mouse Ether with Halo for off-screen feedback. We found that Stitching is equivalent to or faster than any variant of Mouse Ether, and that Halo improves Ether's performance (but not enough to outperform Stitching). Results also indicate that the larger the gap between displays, the longer the targeting takes --- even for Stitching. These findings provide valuable guidance for practitioners and raise new interesting questions for research.	Targeting across displayless space	NA:NA:NA	2018
Sean Gustafson:Patrick Baudisch:Carl Gutwin:Pourang Irani	To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge, a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.	Wedge: clutter-free visualization of off-screen locations	NA:NA:NA:NA	2018
Joe McCarthy	NA	Session details: Friends, Foe, and Family	NA	2018
Andrew T. Fiore:Lindsay Shaw Taylor:G.A. Mendelsohn:Marti Hearst	Online dating systems play a prominent role in the social lives of millions of their users, but little research has considered how users perceive one another through their personal profiles. We examined how users perceive attractiveness in online dating profiles, which provide their first exposure to a potential partner. Participants rated whole profiles and profile components on such qualities as how attractive, extraverted, and genuine and trustworthy they appeared. As past research in the psychology of attraction would suggest, the attractiveness and other qualities of the photograph were the strongest predictors of whole profile attractiveness, but they were not alone: the free-text component also played an important role in predicting overall attractiveness. In turn, numerous other qualities predicted the attractiveness ratings of photos and free-text components, albeit in different ways for men and women. The fixed-choice elements of a profile, however, were unrelated to attractiveness.	Assessing attractiveness in online dating profiles	NA:NA:NA:NA	2018
Irina Shklovski:Robert Kraut:Jonathon Cummings	Many observers have praised new communication technologies for providing convenient and affordable tools for maintaining relationships at a distance. Yet the precise role of mediated communication in relationship maintenance has been difficult to isolate. In this paper, we treat residential moves as natural experiments that threaten existing social relationships and often force people to rely on mediated communication to maintain their old relationships. Results from a 3-wave survey of 900 residential movers describing 1892 relationships shows that email and the telephone play different roles in social relationships. Email helps maintain social relationships, in the sense that relationships decline when email drops after the move. However increases in email are not associated with increases in the depth of the relationship or exchanges of support. In contrast, phone calls help movers grow relationships and exchange social support.	Keeping in touch by technology: maintaining friendships after a residential move	NA:NA:NA	2018
Michael J. Brzozowski:Tad Hogg:Gabor Szabo	Traditional online social network sites use a single monolithic "friends" relationship to link users. However, users may have more in common with strangers, suggesting the use of a "similarity network" to recommend content. This paper examines the usefulness of this distinction in propagating new content. Using both macroscopic and microscopic social dynamics, we present an analysis of Essembly, an ideological social network that semantically distinguishes between friends and ideological allies and nemeses. Although users have greater similarity with their allies than their friends and nemeses, surprisingly, the allies network does not affect voting behavior, despite being as large as the friends network. In contrast, users are influenced differently by their friends and nemeses, indicating that people use these networks for distinct purposes. We suggest resulting design implications for social content aggregation services and recommender systems.	Friends and foes: ideological social networking	NA:NA:NA	2018
Andrea Grimes:A.J. Brush	We present the results of our study of 15 working parents, and how they manage their life scheduling needs, that is, how they manage their personal and professional schedules across settings and calendaring tools. In particular, we discuss how their dual roles of parent and employee compel them to record personal information on their professional calendars and we detail the tensions that arise in doing so. Finally, we present suggestions for future calendaring applications that better support working parents in managing their life scheduling needs.	Life scheduling to support multiple social roles	NA:NA	2018
Mary Czerwinski	NA	Session details: Cognition, Perception, and Memory	NA	2018
Mike Wu:Jeremy Birnholtz:Brian Richards:Ronald Baecker:Mike Massimi	Individuals with cognitive deficits and their families are prime examples of collaborative "systems" that seek to perform everyday tasks together. Yet there has been little investigation into how these families communicate and coordinate in basic tasks like remembering appointments. In this paper we take a distributed cognition approach to studying ten families struggling with amnesia through nonparticipant observation and interviews. Our data show that the families work closely together as cognitive systems that must compensate for memory volatility in one of the members. We explore our participants' strategies for overcoming these difficulties and present lessons for the design of assistive technologies, highlighting the need for redundancy, easy and frequent synchronization, and awareness of updates. We conclude with implications for distributed cognition theory.	Collaborating to remember: a distributed cognition account of families coping with memory impairments	NA:NA:NA:NA:NA	2018
David Grimes:Desney S. Tan:Scott E. Hudson:Pradeep Shenoy:Rajesh P.N. Rao	A reliable and unobtrusive measurement of working memory load could be used to evaluate the efficacy of interfaces and to provide real-time user-state information to adaptive systems. In this paper, we describe an experiment we con-ducted to explore some of the issues around using an elec-troencephalograph (EEG) for classifying working memory load. Within this experiment, we present our classification methodology, including a novel feature selection scheme that seems to alleviate the need for complex drift modeling and artifact rejection. We demonstrate classification accuracies of up to 99% for 2 memory load levels and up to 88% for 4 levels. We also present results suggesting that we can do this with shorter windows, much less training data, and a smaller number of EEG channels, than reported previously. Finally, we show results suggesting that the models we construct transfer across variants of the task, implying some level of generality. We believe these findings extend prior work and bring us a step closer to the use of such technologies in HCI research.	Feasibility and pragmatics of classifying working memory load with an electroencephalograph	NA:NA:NA:NA:NA	2018
Pradeep Shenoy:Desney S. Tan	In this paper, we present Human-Aided Computing, an approach that uses an electroencephalograph (EEG) device to measure the presence and outcomes of implicit cognitive processing, processing that users perform automatically and may not even be aware of. We describe a classification system and present results from two experiments as proof-of-concept. Results from the first experiment showed that our system could classify whether a user was looking at an image of a face or not, even when the user was not explicitly trying to make this determination. Results from the second experiment extended this to animals and inanimate object categories as well, suggesting generality beyond face recognition. We further show that we can improve classification accuracies if we show images multiple times, potentially to multiple people, attaining well above 90% classification accuracies with even just ten presentations.	Human-aided computing: utilizing implicit human processing to classify images	NA:NA	2018
Maria Francesca Costabile	NA	Session details: Exploring Web Content	NA	2018
Jan Hartmann:Antonella De Angeli:Alistair Sutcliffe	Understanding the complexities of users' judgements and user experience is a prerequisite for informing HCI design. Current user experience (UX) research emphasises that, beyond usability, non-instrumental aspects of system quality contribute to overall judgement and that the user experience is subjective and variable. Based on judgement and decision-making theory, we have previously demonstrated that judgement of websites can be influenced by contextual factors. This paper explores the strength of such contextual influence by investigating framing effects on user judgement of website quality. Two experimental studies investigate how the presentation of information about a website influences the user experience and the relative importance of individual quality attributes for overall judgement. Theoretical implications for the emerging field of UX research and practical implications for design are discussed.	Framing the user experience: information biases on website quality judgement	NA:NA:NA	2018
F. Maxwell Harper:Daphne Raban:Sheizaf Rafaeli:Joseph A. Konstan	Question and answer (Q&A) sites such as Yahoo! Answers are places where users ask questions and others answer them. In this paper, we investigate predictors of answer quality through a comparative, controlled field study of responses provided across several online Q&A sites. Along with several quantitative results concerning the effects of factors such as question topic and rhetorical strategy, we present two high-level messages. First, you get what you pay for in Q&A sites. Answer quality was typically higher in Google Answers (a fee-based site) than in the free sites we studied, and paying more money for an answer led to better outcomes. Second, we find that a Q&A site's community of users contributes to its success. Yahoo! Answers, a Q&A site where anybody can answer questions, outperformed sites that depend on specific individuals to answer questions, such as library reference services.	Predictors of answer quality in online Q&A sites	NA:NA:NA:NA	2018
Christos Katsanos:Nikolaos Tselios:Nikolaos Avouris	In this paper, we describe an innovative tool that supports the design and evaluation of the information architecture of a Web site. The tool uses Latent Semantic Analysis and hierarchical clustering algorithms to provide optimal information navigation schemes in an automated manner. The proposed, tool-based, approach addresses the problem of reasonable content structuring, which established techniques such as card sorting also address. A real world case study depicted substantial effectiveness gain, without expense in the quality of results. We argue that such an approach could facilitate information-rich applications design, like most Web sites, by reducing time and resources required.	AutoCardSorter: designing the information architecture of a web site using latent semantic analysis	NA:NA:NA	2018
Anthony Tang:Mattias Finke:Michael Blackstock:Rock Leung:Meghan Deutscher:Rodger Lea	In this paper, we reflect on the design and deployment process of MAGICBoard, a public display deployed in a university setting that solicits the electronic votes and opinions of bystanders on trivial but amusing topics. We focus on the consequences of our design choices with respect to encouraging bystanders to interact with the public display. Bystanders are individuals around the large display who may never fully engage with the application itself, but are potential contributors to the system. Drawing on our recent experiences with MAGICBoard, we present a classification of bystanders, and then discuss three design themes relevant to the design of systems for bystander use: graduated proximal engagement, lowering barriers for interaction and supporting covert engagement.	Designing for bystanders: reflections on building a public digital forum	NA:NA:NA:NA:NA:NA	2018
Alistair Sutcliffe	NA	Session details: Measuring, Business, and Voting	NA	2018
Sarah P. Everett:Kristen K. Greene:Michael D. Byrne:Dan S. Wallach:Kyle Derr:Daniel Sandler:Ted Torous	In the 2006 U.S. election, it was estimated that over 66 million people would be voting on direct recording electronic (DRE) systems in 34% of the nation's counties [8]. Although these computer-based voting systems have been widely adopted, they have not been empirically proven to be more usable than their predecessors. The series of studies reported here compares usability data from a DRE with those from more traditional voting technologies (paper ballots, punch cards, and lever machines). Results indicate that there were little differences between the DRE and these older methods in efficiency or effectiveness. However, in terms of user satisfaction, the DRE was significantly better than the older methods. Paper ballots also perform well, but participants were much more satisfied with their experiences voting on the DRE. The disconnect between subjective and objective usability has potential policy ramifications.	Electronic voting machines versus traditional methods: improved preference, similar performance	NA:NA:NA:NA:NA:NA:NA	2018
Martin Schmettow:Wolfgang Vietze	Usability evaluation methods have a long history of research. Latest contributions significantly raised the validity of method evaluation studies. But there is still a measurement model lacking that incorporates the relevant factors for inspection performance and accounts for the probabilistic nature of the process. This paper transfers a modern probabilistic approach from psychometric research, known as the Item Response Theory, to the domain of measuring usability evaluation processes. The basic concepts, assumptions and several advanced procedures are introduced and related to the domain of usability inspection. The practical use of the approach is exemplified in three scenarios from research and practice. These are also made available as simulation programs.	Introducing item response theory for measuring usability inspection processes	NA:NA	2018
Kasper Hornbæk:Erik Frøkjær	The utility and impact of a usability evaluation depend on how well its results align with the business goals of the system under evaluation. However, how to achieve such alignment is not well understood. We propose a simple technique that requires active consideration of a system's business goals in planning and reporting evaluations. The technique is tested in an experiment with 44 novice evaluators using think aloud testing. The evaluators considering business goals report fewer usability problems compared to evaluators that did not use the technique. The company commissioning the evaluation, however, assesses those problems 30-42% higher on four dimensions of utility. We discuss how the findings may generalize to usability professionals, and how the technique may be used in realistic usability evaluations. More generally, we discuss how our results illustrate one of a variety of ways in which business goals and other facets of a system's context may enter into usability evaluations.	Making use of business goals in usability evaluation: an experiment with novice evaluators	NA:NA	2018
Gina Venolia	NA	Session details: Multiple and Large Displays	NA	2018
Raphael Hoffmann:Patrick Baudisch:Daniel S. Weld	An increasing number of users are adopting large, multi-monitor displays. The resulting setups cover such a broad viewing angle that users can no longer simultaneously perceive all parts of the screen. Changes outside the user's visual field often go unnoticed. As a result, users sometimes have trouble locating the active window, for example after switching focus. This paper surveys graphical cues designed to direct visual attention and adapts them to window switching. Visual cues include five types of frames and mask around the target window and four trails leading to the window. We report the results of two user studies. The first evaluates each cue in isolation. The second evaluates hybrid techniques created by combining the most successful candidates from the first study. The best cues were visually sparse --- combinations of curved frames which use color to pop-out and tapered trails with predictable origin.	Evaluating visual cues for window switching on large screens	NA:NA:NA	2018
Jacob T. Biehl:William T. Baker:Brian P. Bailey:Desney S. Tan:Kori M. Inkpen:Mary Czerwinski	We present a new interaction framework for collaborating in multiple display environments (MDEs) and report results from a field study investigating its use in an authentic work setting. Our interaction framework, IMPROMPTU, allows users to share task information across displays via off-the-shelf applications, to jointly interact with information for focused problem solving and to place information on shared displays for discussion and reflection. Our framework also includes a lightweight interface for performing these and related actions. A three week field study of our framework was conducted in the domain of face-to-face group software development. Results show that teams utilized almost every feature of the framework in support of a wide range of development-related activities. The framework was used most to facilitate opportunistic collaboration involving task information. Teams reported wanting to continue using the framework as they found value in it overall.	Impromptu: a new interaction framework for supporting collaboration in multiple display environments and its field evaluation for co-located software development	NA:NA:NA:NA:NA:NA	2018
Masatomo Kobayashi:Takeo Igarashi	We propose the "ninja cursor" to improve the performance of target acquisition, particularly on large screens. This technique uses multiple distributed cursors to reduce the average distance to targets. Each cursor moves synchronously following mouse movement. We present the design and implementation of the proposed technique, including a method to resolve the ambiguity that results when multiple cursors indicate different targets simultaneously. We also conducted an experiment to assess the performance of the ninja cursor. The results indicate that it can generally reduce movement time. However, the performance is greatly affected by the number of cursors and target density. Based on these results, we discuss how our technique can be put into practical use. In addition to presenting a novel method to improve pointing performance, our study is the first to explore a variable number of cursors for performing pointing tasks.	Ninja cursors: using multiple cursors to assist target acquisition on large screens	NA:NA	2018
James Fogarty	NA	Session details: Mixed-Initiative Interaction	NA	2018
Jeffrey Heer:Maneesh Agrawala:Wesley Willett	Selection is a fundamental task in interactive applications, typically performed by clicking or lassoing items of interest. However, users may require more nuanced forms of selection. Selecting regions or attributes may be more important than selecting individual items. Selections may be over dynamic items and selections might be more easily created by relaxing simpler selections (e.g., "select all items like this one"). Creating such selections requires that interfaces model the declarative structure of the selection, not just individually selected items. We present direct manipulation techniques that couple declarative selection queries with a query relaxation engine that enables users to interactively generalize their selections. We apply our selection techniques in both information visualization and graphics editing applications, enabling generalized selection over both static and dynamic interface objects. A controlled study finds that users create more accurate selection queries when using our generalization techniques.	Generalized selection via interactive query relaxation	NA:NA:NA	2018
Sharon Oviatt:Colin Swindells:Alex Arthur	As emphasis is placed on developing mobile, educational, and other applications that minimize cognitive load on users, it is becoming more essential to explore interfaces based on implicit engagement techniques so users can remain focused on their tasks. In this research, data were collected with 12 pairs of students who solved complex math problems using a tutorial system that they engaged over 100 times per session entirely implicitly via speech amplitude or pen pressure cues. Results revealed that users spontaneously, reliably, and substantially adapted these forms of communicative energy to designate and repair an intended interlocutor in a computer-mediated group setting. Furthermore, this behavior was harnessed to achieve system engagement accuracies of 75-86%, with accuracies highest using speech amplitude. However, students had limited awareness of their own adaptations. Finally, while continually using these implicit engagement techniques, students maintained their performance level at solving complex mathematics problems throughout a one-hour session.	Implicit user-adaptive system engagement in speech and pen interfaces	NA:NA:NA	2018
Andreas Löhr:Bernd Brügge	Controlling graphical user interfaces (GUI) by speech is slow, but proves useful for disabled persons with limitations in operating mouse and keyboard. We present conversation-and-control, a new approach for using speech as input modality for GUIs, which facilitates direct manipulation of widget functions by spoken commands. Our approach is based on a command language, which provides a unique command for each specific widget function. For managing the interaction we propose a mixed-initiative dialog model, which can be generated from widget properties. Using heuristics for inferring the meaning of a recognition result and having the ability to ask clarification questions, our approach avoids the rejection of recognition errors. We hypothesized that conversation-and-control allows for shorter task completion times than conventional command-and-control approaches, due to a reduction of the average number of required commands. The results of a user experiment, which we present and discuss, indicate a 16.8% reduction of task completion time achieved by our approach.	Mixed-initiative dialog management for speech-based interaction with graphical user interfaces	NA:NA	2018
John Karat	NA	Session details: Help Me Search	NA	2018
Brynn Evans:Stuart Card	To understand how and why individuals make use of emerging information assimilation services on the Web as part of their daily routine, we combined video recordings of online activity with targeted interviews of eleven experienced web users. From these observations, we describe their choice of systems, the goals they are trying to achieve, their information diets, the basic process they use for assimilating information, and the impact of user interface speed.	Augmented information assimilation: social and algorithmic web aids for the information long tail	NA:NA	2018
Duen Horng Chau:Brad Myers:Andrew Faulring	Sometimes people cannot remember the names or locations of things on their computer, but they can remember what other things are associated with them. We created Feldspar, the first system that fully supports this associative retrieval of personal information on the computer. Feldspar's contributions include (1) an intuitive user interface that allows users to find information by interactively and incrementally specifying multiple levels of associations as retrieval queries, such as: "find the file from the person who I met at an event in May"; and (2) algorithms for collecting the association information and for providing answers to associative queries in real-time. A user study showed that Feldspar is easy to use, and suggested that it might be faster than conventional browsing and searching for these kinds of retrieval tasks. Feldspar could be an important addition to search and browsing tools.	What to do when search fails: finding information by association	NA:NA:NA	2018
Daniel Xiaodan Zhou:Nathan Oostendorp:Michael Hess:Paul Resni k	Many sites on the web offer collaborative databases that catalog items such as bands, events, products, or software modules. Conversation pivots allow readers to navigate from pages about these items to conversations about them on the same site or elsewhere on the Internet. Double pivots allow readers to navigate from item pages to pages about other items mentioned in the same conversations. Using text mining techniques specific to the collection it is possible to find references to collected items in online conversations. We implemented conversation pivots for the CPAN archive of Perl modules, and for Drupal.org, the reference site for the Drupal content management system.	Conversation pivots and double pivots	NA:NA:NA:NA	2018
Maryam Kamvar:Shumeet Baluja	Entering search terms on mobile phones is a time consuming and cumbersome task. In this paper, we explore the usage patterns of query entry interfaces that display suggestions. Our primary goal is to build a usage model of query suggestions in order to provide user interface guidelines for mobile text prediction interfaces. We find that users who were asked to enter queries on a search interface with query suggestions rated their workload lower and their enjoyment higher. They also saved, on average, approximately half of the key presses compared to users who were not shown suggestions, despite no associated decrease in time to enter a query. Surprisingly, users also accepted suggestions when the process of doing so resulted in an increase in the number of total key presses.	Query suggestions for mobile search: understanding usage patterns	NA:NA	2018
Catalina Davis	NA	Session details: Online Social Networks	NA	2018
Ido Guy:Michal Jacovi:Elad Shahar:Noga Meshulam:Vladimir Soroka:Stephen Farrell	Web 2.0 gives people a substantial role in content and metadata creation. New interpersonal connections are formed and existing connections become evident through Web 2.0 services. This newly created social network (SN) spans across multiple services and aggregating it could bring great value. In this work we present SONAR, an API for gathering and sharing SN information. We give a detailed description of SONAR, demonstrate its potential value through user scenarios, and show results from experiments we conducted with a SONAR-based social networking application. These suggest that aggregating SN information across diverse data sources enriches the SN picture and makes it more complete and useful for the end user.	Harvesting with SONAR: the value of aggregating social network information	NA:NA:NA:NA:NA:NA	2018
Adam N. Joinson	This paper investigates the uses of social networking site Facebook, and the gratifications users derive from those uses. In the first study, 137 users generated words or phrases to describe how they used Facebook, and what they enjoyed about their use. These phrases were coded into 46 items which were completed by 241 Facebook users in Study 2. Factor analysis identified seven unique uses and gratifications: social connection, shared identities, content, social investigation, social network surfing and status updating. User demographics, site visit patterns and the use of privacy settings were associated with different uses and gratifications.	Looking at, looking up or keeping up with people?: motives and use of facebook	NA	2018
Bongwon Suh:Ed H. Chi:Aniket Kittur:Bryan A. Pendleton	Wikis are collaborative systems in which virtually anyone can edit anything. Although wikis have become highly popular in many domains, their mutable nature often leads them to be distrusted as a reliable source of information. Here we describe a social dynamic analysis tool called WikiDashboard which aims to improve social transparency and accountability on Wikipedia articles. Early reactions from users suggest that the increased transparency afforded by the tool can improve the interpretation, communication, and trustworthiness of Wikipedia articles.	Lifting the veil: improving accountability and social transparency in Wikipedia with wikidashboard	NA:NA:NA:NA	2018
Jennifer Thom-Santelli:Michael J. Muller:David R. Millen	Social tagging systems provide users with the opportunity to employ tags in a communicative manner. To explore the use of tags for communication in these systems, we report results from 33 user interviews and employ the concept of social roles to describe audience-oriented tagging, including roles of community-seeker, community-builder, evangelist, publisher, and team-leader. These roles contribute to our understanding of the motivations and rationales behind social tagging in an international company, and suggest new features and services to support social software in the enterprise.	Social tagging roles: publishers, evangelists, leaders	NA:NA:NA	2018
Carlos Jensen	NA	Session details: Am I Safe	NA	2018
Jennifer Stoll:Craig S. Tashman:W. Keith Edwards:Kyle Spafford	Non-expert users face a dilemma when making security decisions. Their security often cannot be fully automated for them, yet they generally lack both the motivation and technical knowledge to make informed security decisions on their own. To help users with this dilemma, we present a novel security user interface called Sesame. Sesame uses a concrete, spatial extension of the desktop metaphor to provide users with the security-related, visualized system-level information they need to make more informed decisions. It also provides users with actionable controls to affect a system's security state. Sesame graphically facilitates users' comprehension in making these decisions, and in doing so helps to lower the bar for motivating them to participate in the security of their system. In a controlled study, users with Sesame were found to make fewer errors than a control group which suggests that our novel security interface is a viable alternative approach to helping users with their dilemma.	Sesame: informing user security decisions with system visualization	NA:NA:NA:NA	2018
Kandha Sankarpandian:Travis Little:W. Keith Edwards	With the proliferation of computer security threats on the Internet, especially threats such as worms that automatically exploit software flaws, it is becoming more and more important that home users keep their computers secure from known software vulnerabilities. Unfortunately, keeping software up-to-date is notoriously difficult for home users. This paper introduces TALC, a system to encourage and help home users patch vulnerable software. TALC increases home users' awareness of software vulnerabilities and their motivation to patch their software; it does so by detecting unpatched software and then drawing graffiti on their computer's background wallpaper image to denote potential vulnerabilities. Users can "clean up" the graffiti by applying necessary patches, which TALC makes possible by assisting in the software patching process	Talc: using desktop graffiti to fight software vulnerability	NA:NA:NA	2018
Serge Egelman:Lorrie Faith Cranor:Jason Hong	Many popular web browsers are now including active phishing warnings after previous research has shown that passive warnings are often ignored. In this laboratory study we examine the effectiveness of these warnings and examine if, how, and why they fail users. We simulated a spear phishing attack to expose users to browser warnings. We found that 97% of our sixty participants fell for at least one of the phishing messages that we sent them. However, we also found that when presented with the active warnings, 79% of participants heeded them, which was not the case for the passive warning that we tested---where only one participant heeded the warnings. Using a model from the warning sciences we analyzed how users perceive warning messages and offer suggestions for creating more effective warning messages within the phishing context.	You've been warned: an empirical study of the effectiveness of web browser phishing warnings	NA:NA:NA	2018
Steven Drucker	NA	Session details: Search	NA	2018
Yuan-Chi Tseng:Andrew Howes	An important question for HCI is to understand how and why visual search strategy is adapted to the demands imposed by the task of searching the results of a search engine. There is emerging evidence that a key part of the answer concerns the expected information gain of each of the set of available information gathering actions. We build on previous research to show that people are acutely sensitive to differences in the spacing and in the number of items returned by the search engine. These factors cause shifts in the efficiency of the available information gathering actions. We focus on an image browsing task, and show that, as a consequence of changes to the efficiency of available actions, people make small but significant changes to eye-movement strategy.	The adaptation of visual search strategy to expected information gain	NA:NA	2018
John O'Donovan:Barry Smyth:Brynjar Gretarsson:Svetlin Bostandjiev:Tobias Höllerer	Collaborative filtering (CF) has been successfully deployed over the years to compute predictions on items based on a user's correlation with a set of peers. The black-box nature of most CF applications leave the user wondering how the system arrived at its recommendation. This note introduces PeerChooser, a collaborative recommender system with an interactive graphical explanation interface. Users are provided with a visual explanation of the CF process and opportunity to manipulate their neighborhood at varying levels of granularity to reflect aspects of their current requirements. In this manner we overcome the problem of redundant profile information in CF systems, in addition to providing an explanation interface. Our layout algorithm produces an exact, noiseless graph representation of the underlying correlations between users. PeerChooser's prediction component uses this graph directly to yield the same results as the benchmark. User's then improve on these predictions by tweaking the graph to their current requirements. We present a user-survey in which PeerChooser compares favorably against a benchmark CF algorithm.	PeerChooser: visual interactive recommendation	NA:NA:NA:NA:NA	2018
N. Sadat Shami:Kate Ehrlich:David R. Millen	Expertise locator systems have been designed to help find experts within organizations. While there are many examples of these systems in the literature, there has not been any systematic analysis of the factors that predict whether a particular expertise search result will be selected for further exploration. This paper describes a study of 67 employees from 21 countries that performed a specific expertise search to find an expert using an expertise locator system. Rank order and social connection information displayed in snippets of search results were found to significantly predict whether a user considers a particular search result for further exploration. Implications for the design of expertise location systems and future research directions are discussed.	Pick me!: link selection in expertise search results	NA:NA:NA	2018
Kate Ehrlich:N. Sadat Shami	It is well established that there is a need to find experts to get answers or advice. A variety of expertise locator tools have emerged to help locate the right person. But there is little systematic study on what people are really looking for when such systems are used and how external factors such as job role may shape that search. We conducted a study of 75 employees who were current users of an expertise locator system. An analysis of the reasons for their search revealed that people in client facing roles are primarily seeking to have a dialog with an expert, while others are just as likely to seek answers to technical questions. We also surveyed various tools for finding experts and found that corporate directories and personal networks were most often cited as alternatives to an expertise locator. We discuss the implications of these results for the design of tools for finding experts and expert knowledge.	Searching for expertise	NA:NA	2018
Oded Nov:Mor Naaman:Chen Ye	We examine tagging behavior on Flickr, a public photo-sharing website. We build on previous qualitative research that exposed a taxonomy of tagging motivations, as well as on social presence research. The motivation taxonomy suggests that motivations for tagging are tied to the intended target audience of the tags --- the users themselves, family and friends, or the general public. Using multiple data sources, including a survey and independent system data, we examine which motivations are associated with tagging level, and estimate the magnitude of their contribution. We find that the levels of the Self and Public motivations, together with social presence indicators, are positively correlated with tagging level; Family & Friends motivations are not significantly correlated with tagging. The findings and the use of survey method carry implications for designers of tagging and other social systems on the web.	What drives content tagging: the case of photos on Flickr	NA:NA:NA	2018
Gerhard Fischer	NA	Session details: Shared Authoring	NA	2018
Brian Butler:Elisabeth Joyce:Jacqueline Pike	Wikis are sites that support the development of emergent, collective infrastructures that are highly flexible and open, suggesting that the systems that use them will be egalitarian, free, and unstructured. Yet it is apparent that the flexible infrastructure of wikis allows the development and deployment of a wide range of structures. However, we find that the policies in Wikipedia and the systems and mechanisms that operate around them are multi-faceted. In this descriptive study, we draw on prior work on rules and policies in organizations to propose and apply a conceptual framework for understanding the natures and roles of policies in wikis. We conclude that wikis are capable of supporting a broader range of structures and activities than other collaborative platforms. Wikis allow for and, in fact, facilitate the creation of policies that serve a wide variety of functions.	Don't look now, but we've created a bureaucracy: the nature and roles of policies and rules in wikipedia	NA:NA:NA	2018
Eric Baumer:Mark Sueyoshi:Bill Tomlinson	Within the last decade, blogs have become an important element of popular culture, mass media, and the daily lives of countless Internet users. Despite the medium's interactive nature, most research on blogs focuses on either the blog itself or the blogger, rarely if at all focusing on the reader's impact. In order to gain a better understanding of the social practice of blogging, we must take into account the role, contributions, and significance of the reader. This paper presents the findings of a qualitative study of blog readers, including common blog reading practices, some of the dimensions along which reading practices vary, relationships between identity presentation and perception, the interpretation of temporality, and the ways in which readers feel that they are a part of the blogs they read. It also describes similarities to, and discrepancies with, previous work, and suggests a number of directions and implications for future work on blogging.	Exploring the role of the reader in the activity of blogging	NA:NA:NA	2018
Alastair J. Gill:Darren Gergle:Robert M. French:Jon Oberlander	Being able to automatically perceive a variety of emotions from text alone has potentially important applications in CMC and HCI that range from identifying mood from online posts to enabling dynamically adaptive interfaces. However, such ability has not been proven in human raters or computational systems. Here we examine the ability of naive raters of emotion to detect one of eight emotional categories from 50 and 200 word samples of real blog text. Using expert raters as a 'gold standard', naive-expert rater agreement increased with longer texts, and was high for ratings of joy, disgust, anger and anticipation, but low for acceptance and 'neutral' texts. We discuss these findings in light of theories of CMC and potential applications in HCI.	Emotion rating from short blog texts	NA:NA:NA:NA	2018
Adam D. I. Kramer:Kerry Rodden	We present a large-scale analysis of the content of weblogs dating back to the release of the Blogger program in 1999. Over one million blogs were analyzed from their conception through June 2006. These data was submitted to the Text Analysis: Word Counts program [12], which conducted a word-count analysis using Linguistic Inquiry and Word Counts (LIWC) dictionaries [20] to provide and analyze a representative sample of blogger word usage. Covariation among LIWC dictionaries suggests that blogs vary along five psychologically relevant linguistic dimensions: Melancholy, Socialness, Ranting, Metaphysicality, and Work-Relatedness. These variables and others were subjected to a cluster analysis in an attempt to extract natural usage groups to inform design of blogging systems, the results of which were mixed.	Word usage and posting behaviors: modeling blogs with unobtrusive data collection methods	NA:NA	2018
Jacob O. Wobbrock	NA	Session details: Tangibles: Input & Output	NA	2018
Amanda J. Parkes:Hayes Solos Raffle:Hiroshi Ishii	What issues arise when designing and deploying tangibles for learning in long term evaluations? This paper reports on a series of studies in which the Topobo system, a 3D tangible construction kit with the ability to record and playback motion, was provided to educators and designers to use over extended periods of time in the context of their day-to-day work. Tangibles for learning - like all educational materials - must be evaluated in relation both to the student and the teacher, but most studies of tangibles for learning focus on the student as user. Here, we focus on the conception of the educator, and their use of the tangible interface in the absence of an inventor or HCI researcher. The results of this study identify design and pedagogical issues that arise in response to distribution of a tangible for learning in different educational environments.	Topobo in the wild: longitudinal evaluations of educators appropriating a tangible interface	NA:NA:NA	2018
Kenneth Majlund Ba h:Mads Gregers Jæger:Mikael B. Skov:Nils Gram Thomassen	Car drivers are nowadays offered a wide array of in-vehicle systems i.e. route guidance systems, climate controls, music players. Such in-vehicle systems often require the driver's visual attention, but visual workload has shown significant less eyes-on-the-road time and affects driving performance. In this paper, we illustrate and compare three different interaction techniques for in-vehicle systems. We refer to them as tactile, touch, and gesture interaction. The focus of the techniques is the effects on drivers while driving cars. We evaluated the interaction techniques with 16 subjects in two settings. Our results showed that gesture interaction has a significant effect on the number of driver eye glances especially eye fixations of more seconds. However, gesture interaction still required rapid eye glances for hand/eye coordination. On the other hand, touch interaction leads to fast and efficient task completion while tactile interaction seemed inferior to the two other interaction techniques.	You can touch, but you can't look: interacting with in-vehicle systems	NA:NA:NA:NA	2018
Christian Müller-Tomfelde:Claudia Schremmer	We present new findings on commonalities and differences between touch and mouse input for co-located interaction between teams of two people who know each other. Twenty-two participants were instructed to work as co-located pairs on three sets of two concurrent digital jigsaw puzzles, displayed on a horizontal tabletop that allows for multiple concurrent input devices. They were advised to use their preference for, or any combination of, direct (touch) and indirect (mouse) input device to achieve the goal. We increased the task?s difficulty: In the second and third puzzle task, participants had to discover that pieces were mixed up between the two puzzle stacks. We used this 'hidden task' to trigger spontaneous transitions from individual to collaborative work. Based on a qualitative analysis of individual interaction trajectories of direct and indirect input devices, we discuss patterns of collaboration. This furthers scientific understanding of co-located collaboration with multiple input devices.	Touchers and mousers: commonalities and differences in co-located collaboration with multiple input devices	NA:NA	2018
Joseph H. Goldberg:Jonathan I. Helfman:Lynne Martin	Liquid layout of web browser elements enables enterprise applications to adapt to larger windows on larger displays, but guidelines are needed to define layout rules for widescreen page content. The present study considers the impact of relative portlet distance and orientation in enterprise-type tasks. Eighteen analysts completed tasks in which critical information was located in two portlets separated by defined distances and orientations. Analysis of completion times, assists, errors, and subjective scales revealed a significant advantage for wider, horizontal information layouts over narrower, vertical layouts. The difference persisted, even when accounting for the influence of vertical scrolling. Horizontal layout in these dashboard-style tasks had a 5%-25% time savings over vertical layout, as separation distances increased to 2000 pixels. Differences in horizontal and vertical eye movement accuracy and velocity could account for these results. Widescreen design guidelines should include a preference for horizontal layout as horizontal screen distances increase.	Information distance and orientation in liquid layout	NA:NA:NA	2018
Giulio Jacucci	NA	Session details: On the Move	NA	2018
Victoria Bellotti:Bo Begole:Ed H. Chi:Nicolas Ducheneaut:Ji Fang:Ellen Isaacs:Tracy King:Mark W. Newman:Kurt Partridge:Bob Price:Paul Rasmussen:Michael Roberts:Diane J. Schiano:Alan Walendowski	This paper presents a context-aware mobile recommender system, codenamed Magitti. Magitti is unique in that it infers user activity from context and patterns of user behavior and, without its user having to issue a query, automatically generates recommendations for content matching. Extensive field studies of leisure time practices in an urban setting (Tokyo) motivated the idea, shaped the details of its design and provided data describing typical behavior patterns. The paper describes the fieldwork, user interface, system components and functionality, and an evaluation of the Magitti prototype.	Activity-based serendipitous recommendations with the Magitti mobile leisure guide	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Holger Schnädelbach:Stefan Rennick Egglestone:Stuart Reeves:Steve Benford:Brendan Walker:Michael Wright	Fairground: Thrill Laboratory was a series of live events that augmented the experience of amusement rides. A wearable telemetry system captured video, audio, heart-rate and acceleration data, streaming them live to spectator interfaces and a watching audience. In this paper, we present a study of this event, which draws on video recordings and post-event interviews, and which highlights the experiences of riders, spectators and ride operators. Our study shows how the telemetry system transformed riders into performers, spectators into an audience, and how the role of ride operator began to include aspects of orchestration, with the relationship between all three roles also transformed. Critically, the introduction of a telemetry system seems to have had the potential to re-connect riders/performers back to operators/orchestrators and spectators/audience, re-introducing a closer relationship that used to be available with smaller rides. Introducing telemetry to a real-world situation also creates significant complexity, which we illustrate by focussing on a moment of perceived crisis.	Performing thrill: designing telemetry systems and spectator interfaces for amusement rides	NA:NA:NA:NA:NA:NA	2018
Kenton O'Hara	Geocaching is a location-based activity that has been practiced for a number of years. As a sustained and established activity it represents an important opportunity for understanding everyday practices and motivations that can build up around a location-based activity. We present findings from a field study of everyday geocaching behaviour. In contrast to previous work, we take a broad perspective on the activity focussing beyond the in situ consumption of these experiences. We look too at the practices and motivations surrounding participants' creation of these experiences. Further we examine these behaviours within the social context of the on-line community that provides a significant basis for many of these behaviours. We use the findings to discuss broader implications for the design of future location-based experiences	Understanding geocaching practices and motivations	NA	2018
Tiziana Catarci	NA	Session details: Web Visits in the Long	NA	2018
Eytan Adar:Jaime Teevan:Susan T. Dumais	Our work examines Web revisitation patterns. Everybody revisits Web pages, but their reasons for doing so can differ depending on the particular Web page, their topic of interest, and their intent. To characterize how people revisit Web content, we analyzed five weeks of Web interaction logs of over 612,000 users. We supplemented these findings by a survey intended to identify the intent behind the observed revisitation. Our analysis reveals four primary revisitation patterns, each with unique behavioral, content, and structural characteristics. Through our analysis we illustrate how understanding revisitation patterns can enable Web sites to provide improved navigation, Web browsers to predict users' destinations, and search engines to better support fast, fresh, and effective finding and re-finding.	Large scale analysis of web revisitation patterns	NA:NA:NA	2018
Dan Morris:Meredith Ringel Morris:Gina Venolia	Current user interfaces for Web search, including browsers and search engine sites, typically treat search as a transient activity. However, people often conduct complex, multi-query investigations that may span long durations and may be interrupted by other tasks. In this paper, we first present the results of a survey of users' search habits, which show that many search tasks span long periods of time. We then introduce SearchBar, a system for proactively and persistently storing query histories, browsing histories, and users' notes and ratings in an interrelated fashion. SearchBar supports multi-session investigations by assisting with task context resumption and information re-finding. We describe a user study comparing use of SearchBar to status-quo tools such as browser histories, and discuss our findings, which show that users find SearchBar valuable for task reacquisition. Our study also reveals the strategies employed by users of status-quo tools for handling multi-query, multi-session search tasks.	SearchBar: a search-centric web history for task resumption and information re-finding	NA:NA:NA	2018
Bonnie Ma Kay:Carolyn Watters	Users are now performing more sophisticated web tasks. In this work, we explore web tasks that require multiple web sessions to complete (multi-session tasks) to satisfy a goal. We conducted a web-based diary study and a field study that used a customized version of Firefox which logged the participants' interactions for multi-session tasks and all their web activity. We found that multi-session tasks occur frequently and that users utilize a variety of browser tools and actions to help complete these tasks.	Exploring multi-session web tasks	NA:NA	2018
George Robertson	NA	Session details: Visualization to Support Information Work	NA	2018
Petra Isenberg:Anthony Tang:Sheelagh Carpendale	To design information visualization tools for collaborative use, we need to understand how teams engage with visualizations during their information analysis process. We report on an exploratory study of individuals, pairs, and triples engaged in information analysis tasks using paper-based visualizations. From our study results, we derive a framework that captures the analysis activities of co-located teams and individuals. Comparing this framework with existing models of the information analysis process suggests that information visualization tools may benefit from providing a flexible temporal flow of analysis actions.	An exploratory study of visual information analysis	NA:NA:NA	2018
Aruna D. Balakrishnan:Susan R. Fussell:Sara Kiesler	Information visualizations can improve collaborative problem solving, but this improvement may depend on whether visualizations promote communication. In an experiment on the effect of network visualizations, remote pairs worked synchronously to identify a serial killer. They discussed disparate evidence distributed across the pair using IM. Four conditions, respectively, offered (a) spreadsheet only (controls), (b) individual unshared visualizations, (c) view-only shared visualizations, and (d) a full-access shared visualization of all evidence. We examined collaborative performance, use of the visualization tool, and communication as a function of condition. All visualization conditions improved remote collaborators' performance over the control condition. Full access to a shared visualization best facilitated remote collaboration by encouraging tool use and fostering discussion between the partners. Shared visualization without full access impaired performance somewhat and made communication even more vital to identifying the serial killer. This study provides direct evidence of visualization tool features and partner behavior that promote collaboration.	Do visualizations improve synchronous remote collaboration?	NA:NA:NA	2018
Yedendra Babu Shrinivasan:Jarke J. van Wijk	This paper presents a new information visualization framework that supports the analytical reasoning process. It consists of three views - a data view, a knowledge view and a navigation view. The data view offers interactive information visualization tools. The knowledge view enables the analyst to record analysis artifacts such as findings, hypotheses and so on. The navigation view provides an overview of the exploration process by capturing the visualization states automatically. An analysis artifact recorded in the knowledge view can be linked to a visualization state in the navigation view. The analyst can revisit a visualization state from both the navigation and knowledge views to review the analysis and reuse it to look for alternate views. The whole analysis process can be saved along with the synthesized information. We present a user study and discuss the perceived usefulness of a prototype based on this framework that we have developed.	Supporting the analytical reasoning process in information visualization	NA:NA	2018
Brad Myers	NA	Session details: Adaptation	NA	2018
Leah Findlater:Joanna McGrenere	Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.	Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces	NA:NA	2018
Krzysztof Z. Gajos:Jacob O. Wobbrock:Daniel S. Weld	We evaluate two systems for automatically generating personalized interfaces adapted to the individual motor capabilities of users with motor impairments. The first system, SUPPLE, adapts to users' capabilities indirectly by first using the ARNAULD preference elicitation engine to model a user's preferences regarding how he or she likes the interfaces to be created. The second system, SUPPLE++, models a user's motor abilities directly from a set of one-time motor performance tests. In a study comparing these approaches to baseline interfaces, participants with motor impairments were 26.4% faster using ability-based user interfaces generated by SUPPLE++. They also made 73% fewer errors, strongly preferred those interfaces to the manufacturers' defaults, and found them more efficient, easier to use, and much less physically tiring. These findings indicate that rather than requiring some users with motor impairments to adapt themselves to software using separate assistive technologies, software can now adapt itself to the capabilities of its users.	Improving the performance of motor-impaired users with automatically-generated, ability-based interfaces	NA:NA:NA	2018
Leah Findlater:Joanna McGrenere:David Modjeska	Coarse-grained approaches to customization allow the user to enable or disable groups of features at once, rather than individual features. While this may reduce the complexity of customization and encourage more users to customize, the research challenges of designing such approaches have not been fully explored. To address this limitation, we conducted an interview study with 14 professional software developers who use an integrated development environment that provides a role-based, coarse-grained approach to customization. We identify challenges of designing coarse-grained customization models, including issues of functionality partitioning, presentation, and individual differences. These findings highlight potentially critical design choices, and provide direction for future work.	Evaluation of a role-based approach for customizing a complex development environment	NA:NA:NA	2018
Krzysztof Z. Gajos:Katherine Everitt:Desney S. Tan:Mary Czerwinski:Daniel S. Weld	While proponents of adaptive user interfaces tout potential performance gains, critics argue that adaptation's unpredictability may disorient users, causing more harm than good. We present a study that examines the relative effects of predictability and accuracy on the usability of adaptive UIs. Our results show that increasing predictability and accuracy led to strongly improved satisfaction. Increasing accuracy also resulted in improved performance and higher utilization of the adaptive interface. Contrary to our expectations, improvement in accuracy had a stronger effect on performance, utilization and some satisfaction ratings than the improvement in predictability.	Predictability and accuracy in adaptive user interfaces	NA:NA:NA:NA:NA	2018
Andy Wilson	NA	Session details: Multitouch and Surface Computing	NA	2018
Tomer Moscovich:John F. Hughes	Touchpad and touchscreen interaction using multiple fingers is emerging as a valuable form of high-degree-of-freedom input. While bimanual interaction has been extensively studied, touchpad interaction using multiple fingers of the same hand is not yet well understood. We describe two experiments on user perception and control of multi-touch interaction using one and two hands. The first experiment addresses how to maintain perceptual-motor compatibility in multi-touch interaction, while the second measures the separability of control of degrees-of-freedom in the hands and fingers. Results indicate that two-touch interaction using two hands is compatible with control of two points, while twotouch interaction using one hand is compatible with control of a position, orientation, and hand-span. A slight advantage is found for two hands in separating the control of two positions.	Indirect mappings of multi-touch input using one and two hands	NA:NA	2018
Peter Peltonen:Esko Kurvinen:Antti Salovaara:Giulio Jacucci:Tommi Ilmonen:John Evans:Antti Oulasvirta:Petri Saarikko	We present data from detailed observations of CityWall, a large multi-touch display installed in a central location in Helsinki, Finland. During eight days of installation, 1199 persons interacted with the system in various social configurations. Videos of these encounters were examined qualitatively as well as quantitatively based on human coding of events. The data convey phenomena that arise uniquely in public use: crowding, massively parallel interaction, teamwork, games, negotiations of transitions and handovers, conflict management, gestures and overt remarks to co-present people, and "marking" the display for others. We analyze how public availability is achieved through social learning and negotiation, why interaction becomes performative and, finally, how the display restructures the public space. The multi-touch feature, gesture-based interaction, and the physical display size contributed differentially to these uses. Our findings on the social organization of the use of public displays can be useful for designing such systems for urban environments.	It's Mine, Don't Touch!: interactions at a large multi-touch display in a city centre	NA:NA:NA:NA:NA:NA:NA:NA	2018
Kang Shi:Pourang Irani:Sean Gustafson:Sriram Subramanian	Studies investigating user control of pressure input have reported time-accuracy trade-offs of, on average, over 30%, when interacting with a large number of pressure levels. To increase the level of control with pressure input, we designed and evaluated four different discretization functions: linear, fisheye, visual fisheye, and clustered. The fisheye discretization dynamically modifies the range of pressure values based on the position of the pressure cursor. Our results show that a fisheye function results in significantly lower error rates and a lower number of crossings than have been reported in the literature. Furthermore, the fisheye function improves control without compromising speed. We discuss the findings of our study and identify several design recommendations for integrating pressure control into common interface tasks.	PressureFish: a method to improve control of discrete pressure-based input	NA:NA:NA:NA	2018
Roderick Murray-Smith:John Williamson:Stephen Hughes:Torben Quaade	Stane is a hand-held interaction device controlled by tactile input: scratching or rubbing textured surfaces and tapping. The system has a range of sensors, including contact microphones, capacitive sensing and inertial sensing, and provides audio and vibrotactile feedback. The surface textures vary around the device, providing perceivably different textures to the user. We demonstrate that the vibration signals generated by stroking and scratching these surfaces can be reliably classified, and can be used as a very cheaply manufacturable way to control different aspects of interaction. The system is demonstrated as a control for a music player.	Stane: synthesized surfaces for tactile input	NA:NA:NA:NA	2018
Allen Cypher	NA	Session details: Activity-Based Prototyping and Software	NA	2018
Yang Li:James A. Landay	We designed an activity-based prototyping process realized in the ActivityDesigner system that combines the theoretical framework of Activity-Centered Design with traditional iterative design. This process allows designers to leverage human activities as first class objects for design and is supported in ActivityDesigner by three novel features. First, this tool allows designers to model activities based on concrete scenarios collected from everyday lives. The models form a context for design and computational constructs for creating functional prototypes. Second, it allows designers to prototype interaction behaviors based on activity streams spanning time. Third, it allows designers to easily test these prototypes with real users continuously, in situ. We have garnered positive feedback from a series of laboratory user studies and several case studies in which ActivityDesigner was used in realistic design situations. ActivityDesigner was able to effectively streamline a ubicomp design process, and it allowed creating realistic ubicomp application prototypes at a low cost and testing them in everyday lives over an extended period.	Activity-based prototyping of ubicomp applications for long-lived, everyday human activities	NA:NA	2018
James Lin:James A. Landay	Designing UIs that run across multiple devices is increasingly important. To address this, we have created a prototyping tool called Damask, which targets web UIs that run on PCs and mobile phones, and prompt-and-response style voice UIs. In Damask, designers sketch out their design for one device while using design patterns to specify higher-level concepts within their design. Damask's patterns include pre-built UI fragments that are already optimized for each device. Designers also use layers to specify which UI parts are common across devices and which are specific to one device. Damask uses the sketches and patterns to generate designs for the other devices, which the designers can refine. A study performed with 12 professional UI designers found that, in the early stages, designers using patterns and layers in Damask created cross-device UIs that are rated at least as good as those created without patterns and layers, without more time.	Employing patterns and layers for early-stage design and prototyping of cross-device user interfaces	NA:NA	2018
Joseph Lawrance:Rachel Bellamy:Margaret Burnett:Kyle Rector	In recent years, the software engineering community has begun to study program navigation and tools to support it. Some of these navigation tools are very useful, but they lack a theoretical basis that could reduce the need for ad hoc tool building approaches by explaining what is fundamentally necessary in such tools. In this paper, we present PFIS (Programmer Flow by Information Scent), a model and algorithm of programmer navigation during software maintenance. We also describe an experimental study of expert programmers debugging real bugs described in real bug reports for a real Java application. We found that PFIS' performance was close to aggregated human decisions as to where to navigate, and was significantly better than individual programmers' decisions.	Using information scent to model the dynamic foraging behavior of programmers in maintenance tasks	NA:NA:NA:NA	2018
Beverly Harrison	NA	Session details: Multidimensional Visualization	NA	2018
Niklas Elmqvist:Nathalie Henry:Yann Riche:Jean-Daniel Fekete	Interaction and navigation in large geometric spaces typically require a sequence of pan and zoom actions. This strategy is often ineffective and cumbersome, especially when trying to study several distant objects. We propose a new distortion technique that folds the intervening space to guarantee visibility of multiple focus regions. The folds themselves show contextual information and support unfolding and paging interactions. Compared to previous work, our method provides more context and distance awareness. We conducted a study comparing the space-folding technique to existing approaches, and found that participants performed significantly better with the new technique.	Melange: space folding for multi-focus interaction	NA:NA:NA:NA	2018
Emmanuel Pietriga:Caroline Appert	Focus + context techniques such as fisheye lenses are used to navigate and manipulate objects in multi-scale worlds. They provide in-place magnification of a region without requiring users to zoom the whole representation and consequently lose context. Their adoption is however hindered by usability problems mostly due to the nature of the transition between focus and context. Existing transitions are often based on a physical metaphor (magnifying glass, fisheye, rubber sheet), and are almost always achieved through a single dimension: space. We investigate how other dimensions, namely time and translucence, can be used to achieve more efficient transitions. We present an extension to Carpendale's framework for unifying presentation space accommodating these new dimensions. We define new lenses in that space, called Sigma lenses, and compare them to existing lenses through experiments based on a generic task: focus targeting. Results show that one new lens, the Speed-coupled flattening lens, significantly outperforms all others.	Sigma lenses: focus-context transitions combining space, time and translucence	NA:NA	2018
Raimund Dachselt:Mathias Frisch:Markus Weiland	Faceted browsing is a promising way to incrementally refine data sets. Current approaches do not scale well in terms of screen size and have shortcomings in interacting with hierarchical facets. This paper introduces FacetZoom, a novel multi-scale widget combining facet browsing with zoomable user interfaces. Hierarchical facets are displayed as space-filling widgets which allow a fast traversal across all levels while simultaneously maintaining context. We contribute both a seamless continuous navigation and a quick tap-and-center interaction. Two prototypes are described which successfully apply the space-structuring widget to continuous, sampled data and an information collection. A formative user study of the latter indicates that the interface scales well to small screens. FacetZoom is versatile and offers consistent searching and browsing behaviors in a multitude of applications and device settings.	FacetZoom: a continuous multi-scale widget for navigating hierarchical metadata	NA:NA:NA	2018
Hao Jiang:Daniel Wigdor:Clifton Forlines:Michelle Borkin:Jens Kauffmann:Chia Shen	The interoperability of disparate data types and sources has been a long standing problem and a hindering factor for the efficacy and efficiency in visual exploration applications. In this paper, we present a solution, called LivOlay, that enables the rapid visual overlay of live data rendered in different applications. Our tool addresses datasets in which visual registration of the information is necessary in order to allow for thorough understanding and visual analysis. We also discuss initial evaluation and user feedback of LivOlay.	LivOlay: interactive ad-hoc registration and overlapping of applications for collaborative visual exploration	NA:NA:NA:NA:NA:NA	2018
Poika Isokoski	NA	Session details: Menu and Command Selection	NA	2018
George Fitzmaurice:Justin Matejka:Azam Khan:Michael Glueck:Gordon Kurtenbach	We describe a new type of graphical user interface widget called the "PieCursor." The PieCursor is based on the Tracking Menu technique and consists of a radial cluster of command wedges, is roughly the size of a cursor, and replaces the traditional cursor. The PieCursor technique merges the normal cursor function of pointing with command selection into a single action. A controlled experiment was conducted to compare the performance of rapid command and target selection using the PieCursor against larger versions of Tracking Menus and a status quo Toolbar configuration. Results indicate that for small clusters of tools (4 and 8 command wedges) the PieCursor can outperform the toolbar by 20.8% for coarse pointing. For fine pointing, the performance of the PieCursor degrades approximately to the performance found for the Toolbar condition.	PieCursor: merging pointing and command selection for rapid in-place tool switching	NA:NA:NA:NA:NA	2018
Feng Tian:Lishuang Xu:Hongan Wang:Xiaolong Zhang:Yuanyuan Liu:Vidya Setlur:Guozhong Dai	We present a new technique called 'Tilt Menu' for better extending selection capabilities of pen-based interfaces. The Tilt Menu is implemented by using 3D orientation information of pen devices while performing selection tasks. The Tilt Menu has the potential to aid traditional one-handed techniques as it simultaneously generates the secondary input (e.g., a command or parameter selection) while drawing/interacting with a pen tip without having to use the second hand or another device. We conduct two experiments to explore the performance of the Tilt Menu. In the first experiment, we analyze the effect of parameters of the Tilt Menu, such as the menu size and orientation of the item, on its usability. Results of the first experiment suggest some design guidelines for the Tilt Menu. In the second experiment, the Tilt Menu is compared to two types of techniques while performing connect-the-dot tasks using freeform drawing mechanism. Results of the second experiment show that the Tilt Menu perform better in comparison to the Tool Palette, and is as good as the Toolglass.	Tilt menu: using the 3D orientation information of pen devices to extend the selection capability of pen-based user interfaces	NA:NA:NA:NA:NA:NA:NA	2018
Erum Tanvir:Jonathan Cullen:Pourang Irani:Andy Cockburn	Selecting items in cascading pull-down menus is a frequent task in most GUIs. These selections involve two major components: steering and selection, with the steering component being the most time-consuming and error-prone. We describe a new technique, called Adaptive Activation-Area Menu (AAMU) that eliminate corner steering. AAMUs contain an enlarged activation area which dynamically resizes itself providing a broader steering path for menu navigation. We also combined AAMUs with Force-field menus, to create Force-AAMUs. We empirically demonstrate that AAMUs and Force-AAMUs outperformed the current default menu. We also compared performances of various other menus including Enlarged activation area menus (EMUs) and Gesture based selection with mouse as an input device. Overall, users show higher satisfaction rates for AAMUs over other menu designs.	AAMU: adaptive activation area menus for improving selection in cascading pull-down menus	NA:NA:NA:NA	2018
Shouichi Matsui:Seiji Yamada	Hierarchical menus are now ubiquitous. The performance of the menu depends on many factors: structure, layout, colors and so on. There has been extensive research on novel menus, but there has been little work on improving the performance by optimizing the menu's structure. This paper proposes an algorithm based on the genetic algorithm (GA) for optimizing the performance of menus. The algorithm aims to minimize the average selection time of menu items by considering movement and decision time. We show results on a static hierarchical menu of a cellular phone where a small screen and limited input device are assumed. Our work makes several contributions: a novel mathematical optimization model for hierarchical menus; novel optimization method based on the genetic algorithm (GA).	Genetic algorithm can optimize hierarchical menus	NA:NA	2018
Jeffrey Nichols	NA	Session details: Model Interaction	NA	2018
Kevin A. Li:Patrick Baudisch:Ken Hinckley	Many mobile phones integrate services such as personal calendars. Given the social nature of the stored data, however, users often need to access such information as part of a phone conversation. In typical non-headset use, this re-quires users to interrupt their conversations to look at the screen. We investigate a counter-intuitive solution: to avoid the need for interruption we replace the visual interface with one based on auditory feedback. Surprisingly, this can be done without interfering with the phone conversation. We present blindSight, a prototype application that replaces the traditionally visual in-call menu of a mobile phone. Users interact using the phone keypad, without looking at the screen. BlindSight responds with auditory feedback. This feedback is heard only by the user, not by the person on the other end of the line. We present the results of two user studies of our prototype. The first study verifies that useful keypress accuracy can be obtained for the phone-at-ear position. The second study compares the blindSight system against a visual baseline condition and finds a preference for blindSight.	Blindsight: eyes-free access to mobile phones	NA:NA:NA	2018
Amy K. Karlson:Benjamin B. Bederson	Supporting one-handed thumb operation of touchscreen-based mobile devices presents a challenging tradeoff between visual expressivity and ease of interaction. ThumbSpace and Shift---two new application-independent, software-based interaction techniques---address this tradeoff in significantly different ways. ThumbSpace addresses distant objects while Shift addresses small object occlusion. We present two extensive, comparative user studies. The first compares ThumbSpace and Shift to peripheral hardware (directional pad and scrollwheel) and direct touchscreen input for selecting objects while standing and walking. The data favored the Shift design overall, but suggested ThumbSpace is promising for distant objects. Our second study examines the benefits and learnability of combining Shift and ThumbSpace on a device with a larger screen (3.5"). We found their combined use offered users better overall speed and accuracy in hitting small targets (3.6 mm2) than using either method alone.	One-handed touchscreen input for legacy applications	NA:NA	2018
Michael Rohs:Antti Oulasvirta	When camera phones are used as magic lenses in handheld augmented reality applications involving wall maps or posters, pointing can be divided into two phases: (1) an initial coarse physical pointing phase, in which the target can be directly observed on the background surface, and (2) a fine-control virtual pointing phase, in which the target can only be observed through the device display. In two studies, we show that performance cannot be adequately modeled with standard Fitts' law, but can be adequately modeled with a two-component modification. We chart the performance space and analyze users' target acquisition strategies in varying conditions. Moreover, we show that the standard Fitts' law model does hold for dynamic peephole pointing where there is no guiding background surface and hence the physical pointing component of the extended model is not needed. Finally, implications for the design of magic lens interfaces are considered.	Target acquisition with camera phones when used as magic lenses	NA:NA	2018
Abigail Sellen	NA	Session details: Domesticity and Design	NA	2018
Gerard Oleksik:David Frohlich:Lorna M. Brown:Abigail Sellen	This paper presents a new study of the role, importance and meaning of sound in the home. Drawing on interview data and sound recordings gathered from seven households, this study offers fresh insight into the ways in which the domestic soundscape is managed and understood. The data revealed that household members engaged in a wide variety of sound management practices to monitor and control the real-time flow of sonic information throughout the home. They also showed that families were sometimes surprised and delighted by the ability to record fragments of the soundscape for later use. These findings suggest a number of roles for technology in enhancing the domestic soundscape and its associated behaviors, which we present here in the form of example sonic interventions created in a design workshop at the end of the project.	Sonic interventions: understanding and extending the domestic soundscape	NA:NA:NA:NA	2018
William Gaver:Andy Boucher:Andy Law:Sarah Pennington:John Bowers:Jacob Beaver:Jan Humble:Tobie Kerridge:Nicholas Villar:Alex Wilkie	Threshold devices present information gathered from the home's surroundings to give new views on the domestic situation. We built two prototypes of different threshold devices and studied them in field trials with participant households. The Local Barometer displays online text and images related to the home's locality depending on the local wind conditions to give an impression of the sociocultural surroundings. The Plane Tracker tracks aircraft passing overhead and imagines their flights onscreen to resource an understanding of the home's global links. Our studies indicated that the experiences they provided were compelling, that participants could and did interpret the devices in various ways, that their form designs were appropriate for domestic environments, that using ready-made information contributed to the richness of the experiences, and that situating the information they provided with respect to the home and its locality was important for the ways people engaged with them.	Threshold devices: looking out from the home	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Marilyn Rose McGee-Lennon	The focus of this work is the requirements engineering process in the home care domain. The overall aim is to design and document a flexible methodology to facilitate the elicitation of complex, dynamic, multi-stakeholder requirements and needs. This paper details the complexity and uniqueness of the home care domain and outlines the features of home care that demand a new or tailored approach to requirements engineering. It concludes by presenting a consolidated list of features that must be available or supported in requirements engineering methods in the home care domain.	Requirements engineering for home care technology	NA	2018
Sriram Subramanian	NA	Session details: Game Zone	NA	2018
Dimitris Grammenos	This paper presents the design and evaluation of "Game Over!", which is the world's first universally inaccessible game (i.e., a game that can be played by no one). The game is meant to be used as an educational tool for disseminating and teaching game accessibility guidelines. This is achieved by providing game developers a first-hand (frustrating) experience of how it feels interacting with a game that is not accessible, due to the fact that important design rules were not considered or applied during its design. Both the overall concept and the approach followed were evaluated and validated through: (a) an on-line survey; (b) "live" feedback from players and developers; and (c) public opinions and critique collected from numerous Web sites and blogs where "Game Over!" was presented and discussed. The evaluation outcomes strongly suggest that computer games and humor constitute a perfect match for reaching out, motivating and educating the game developers' community in the subject of game accessibility.	Game over: learning by dying	NA	2018
David Pinelle:Nelson Wong:Tadeusz Stach	Most video games require constant interaction, so game designers must pay careful attention to usability issues. However, there are few formal methods for evaluating the usability of game interfaces. In this paper, we introduce a new set of heuristics that can be used to carry out usability inspections of video games. The heuristics were developed to help identify usability problems in both early and functional game prototypes. We developed the heuristics by analyzing PC game reviews from a popular gaming website, and the review set covered 108 different games and included 18 from each of 6 major game genres. We analyzed the reviews and identified twelve common classes of usability problems seen in games. We developed ten usability heuristics based on the problem categories, and they describe how common game usability problems can be avoided. A preliminary evaluation of the heuristics suggests that they help identify game-specific usability problems that can easily be overlooked otherwise.	Heuristic evaluation for games: usability principles for video game design	NA:NA:NA	2018
Christine Szentgyorgyi:Michael Terry:Edward Lank	Today's handheld gaming systems allow players to engage in multiplayer games via ad-hoc, wireless networking. They are also now sufficiently commonplace that it is possible to study how portability and ad-hoc wireless networking have affected the social gaming practices of owners of these systems. In this paper, we report findings from a qualitative study investigating the collocated multiplayer gaming practices of Nintendo DS owners. Based on interviews of nine DS owners and observations of three organized gaming events, we identified three major themes surrounding the social, multiplayer gaming practices of Nintendo DS users: renegade gaming, or the notion that users reappropriate contexts traditionally hostile to game play; pragmatic and social barriers to the formation of ad-hoc pick-up games, despite a clear desire for multiplayer, collocated gaming; and private gaming spheres, or the observation that the handheld device's form factor creates individual, privatized gaming contexts within larger social contexts. These findings lead to a set of implications for the design of future handheld gaming systems.	Renegade gaming: practices surrounding social use of the Nintendo DS handheld gaming system	NA:NA:NA	2018
Lars Erik Holmquist	NA	Session details: Visualizations	NA	2018
Robert W. Reeder:Lujo Bauer:Lorrie Faith Cranor:Michael K. Reiter:Kelli Bacon:Keisha How:Heather Strong	We introduce the Expandable Grid, a novel interaction technique for creating, editing, and viewing many types of security policies. Security policies, such as file permissions policies, have traditionally been displayed and edited in user interfaces based on a list of rules, each of which can only be viewed or edited in isolation. These list-of-rules interfaces cause problems for users when multiple rules interact, because the interfaces have no means of conveying the interactions amongst rules to users. Instead, users are left to figure out these rule interactions themselves. An Expandable Grid is an interactive matrix visualization designed to address the problems that list-of-rules interfaces have in conveying policies to users. This paper describes the Expandable Grid concept, shows a system using an Expandable Grid for setting file permissions in the Microsoft Windows XP operating system, and gives results of a user study involving 36 participants in which the Expandable Grid approach vastly outperformed the native Windows XP file-permissions interface on a broad range of policy-authoring tasks.	Expandable grids for visualizing and authoring computer security policies	NA:NA:NA:NA:NA:NA:NA	2018
Peter McLachlan:Tamara Munzner:Eleftherios Koutsofios:Stephen North	We present LiveRAC, a visualization system that supports the analysis of large collections of system management time-series data consisting of hundreds of parameters across thousands of network devices. LiveRAC provides high information density using a reorderable matrix of charts, with semantic zooming adapting each chart's visual representation to the available space. LiveRAC allows side-by-side visual comparison of arbitrary groupings of devices and parameters at multiple levels of detail. A staged design and development process culminated in the deployment of LiveRAC in a production environment. We conducted an informal longitudinal evaluation of LiveRAC to better understand which proposed visualization techniques were most useful in the target environment.	LiveRAC: interactive visual exploration of system management time-series data	NA:NA:NA:NA	2018
Theresa A. O'Connell,:Yee-Yin Choong	There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.	Metrics for measuring human interaction with interactive visualizations for information analysis	NA:NA	2018
Keith Vertanen:Per Ola Kristensson	In a typical speech dictation interface, the recognizer's best-guess is displayed as normal, unannotated text. This ignores potentially useful information about the recognizer's confidence in its recognition hypothesis. Using a confidence measure (which itself may sometimes be inaccurate), we investigated providing visual feedback about low-confidence portions of the recognition using shaded, red underlining. An evaluation showed, compared to a baseline without underlining, underlining low-confidence areas did not increase user's speed or accuracy in detecting errors. However, we found that when recognition errors were correctly underlined, they were discovered significantly more often than baseline. Conversely, when errors failed to be underlined, they were discovered less often. Our results indicate confidence visualization can be effective --- but only if the confidence measure has high accuracy. Further, since our results show that users tend to trust confidence visualization, designers should be careful in its application if a high accuracy confidence measure is not available.	On the benefits of confidence visualization in speech recognition	NA:NA	2018
Arnie Lund	NA	Session details: Character Development	NA	2018
Tomasz Miaskiewicz:Tamara Sumner:Kenneth A. Kozar	A persona represents a group of target users that share common behavioral characteristics. By using a narrative, picture, and name, a persona provides HCI practitioners with a vivid and specific design target. This research develops a new methodology for the identification and creation of personas through the application of Latent Semantic Analysis (LSA). An application of the LSA methodology is provided in the context of the design of an Institutional Repository system. The LSA methodology helps overcome some of the drawbacks of current methods for the identification and creation of personas, and makes the process less subjective, more efficient, and less reliant on specialized skills.	A latent semantic analysis methodology for the identification and creation of personas	NA:NA:NA	2018
Scott W. McQuiggan:Jonathan P. Rowe:James C. Lester	Recent years have seen a growing interest in the role that narrative can play in learning. With the emergence of narrative-centered learning environments that engage students by drawing them into rich interactions with compelling characters, we have begun to see the significant potential offered by immersive story-based learning experiences. In this paper we describe two studies that investigate the impact of empathetic characters on student perceptions of presence. A study was initially conducted with middle school students, and was then replicated with high school students. The results indicate that, for both populations, employing empathetic characters in narrative-centered learning environments significantly increases student perceptions of presence. The studies also reveal that empathetic characters contribute to a heightened sense of student involvement and control in learning situations.	The effects of empathetic virtual characters on presence in narrative-centered learning environments	NA:NA:NA	2018
Jennifer (Jen) McGinn:Nalini Kotamraju	Much has been written on creating personas --- both what they are good for, and how to create them. A common problem with personas is that they are not based on real customer data, and if they are, the data set is not of a sample size that can be considered statistically significant. In this paper, we describe a new method for creating and validating personas, based on the statistical analysis of data, which is fast and cost effective.	Data-driven persona development	NA:NA	2018
Boris de Ruyter	NA	Session details: Social Presence	NA	2018
Clint Heyer:Margot Brereton:Stephen Viller	In this paper, we introduce a prototype system designed to support mobile group socializing that has been appropriated for everyday use by 150 users over 18 months. The system supports cross-channel communication, allowing users to participate in group conversations using text messaging, instant messaging, email and the web. It does this with the "console," a uniform text-based syntax that enables the prototype to be used over a variety of mediums. We found that participants used the system mostly for ad-hoc coordination rather than chat, with pervasive, cross-channel group communication supporting an informal "half-invite" style of invitation. We examine why coordination dominates over chat, suggesting that cross-channel mobile group messaging serves a distinct role, different to traditional text messaging, instant messaging and email. Furthermore, we found differences in the content and usage habits across channels, for example messages sent from a computer were more likely to refer to time and location than those sent using a phone. We also discuss the usage of the prototype and compare it to other work.	Cross-channel mobile social software: an empirical study	NA:NA:NA	2018
Sin-Hwa Kang:James H. Watt:Sasi Kanth Ala	In this paper, we describe research exploring the effect of behavioral and visual realism of avatars on users' social copresence in emotionally engaged conversations conducted via a simulated mobile video telephone. We offer an elaborated definition of Social Copresence to better measure users' engagement with conversational partners in social interactions that do not involve specific tasks or concrete outcomes. We investigate ways to secure mobile telephone users' anonymity while preserving their most important nonverbal affective behaviors. Experimental results with 180 participants using different combinations of static and dynamic, high and low iconic (both video and graphically animated) avatars show increased Social Copresence with dynamic high-iconic (similar to the human communicator) avatars incorporating correct facial expressions, even when these are presented on the small screen of mobile telephones in such a way that individual identities are masked. The results point to an economical combination of behavioral and iconic realism of avatars that produces maximum emotional engagement in anonymous social interactions using mobile video telephones.	Social copresence in anonymous social interactions using a mobile video telephone	NA:NA:NA	2018
Werner Geyer:Casey Dugan:Joan DiMicco:David R. Millen:Beth Brownholtz:Michael Muller	Social networking sites support a variety of shared content types such as photos, videos, or music. More structured or form-based social content types are not mainstream but we have started seeing sites evolve that support them. This paper describes the design and use of structured lists in an enterprise social networking system. As a major feature of our shared lists, we introduced the ability to reuse someone else's list. We report the results on the use and reuse of shared lists based on three months of usage data from 285 users and interviews with 9 users. Our findings suggest that despite the structured nature of lists, our users socialize more around lists than photos, and use lists as a medium for self-representation.	Use and reuse of shared lists as a social content type	NA:NA:NA:NA:NA:NA	2018
James Landay	NA	Session details: Tactile and Haptic User Interfaces	NA	2018
Katri Salminen:Veikko Surakka:Jani Lylykangas:Jukka Raisamo:Rami Saarinen:Roope Raisamo:Jussi Rantala:Grigori Evreinov	A prototype of friction-based horizontally rotating fingertip stimulator was used to investigate emotional experiences and behavioral responses to haptic stimulation. The rotation style of 12 different stimuli was varied by burst length (i.e., 20, 50, 100 ms), continuity (i.e., continuous and discontinuous), and direction (e.g., forward and backward). Using these stimuli 528 stimulus pairs were presented to 12 subjects who were to distinguish if stimuli in each pair were the same or different. Then they rated the stimuli using four scales measuring the pleasantness, arousal, approachability, and dominance qualities of the 12 stimuli. The results showed that continuous forward-backward rotating stimuli were rated as significantly more unpleasant, arousing, avoidable, and dominating than other types of stimulations (e.g., discontinuous forward rotation). The reaction times to these stimuli were significantly faster than reaction times to discontinuous forward and backward rotating stimuli. The results clearly suggest that even simple haptic stimulation can carry emotional information. The results can be utilized when making use of haptics in human-technology interaction.	Emotional and behavioral responses to haptic stimulation	NA:NA:NA:NA:NA:NA:NA:NA	2018
Clifton Forlines:Ravin Balakrishnan	We present a pair of experiments that explore the effects of tactile-feedback and direct vs. indirect pen input on pointing and crossing selection tasks. While previous work has demonstrated the validity of crossing as a useful selection mechanism for pen-based computing, those experiments were conducted using an indirect input device -- one in which the pen-input and display were separated. We investigate users' performance with pointing and crossing interfaces controlled via not only an indirect input device, but also a direct input device -- one in which the pen-input and display are co-located. Results show that direct input significantly outperforms indirect input for crossing selection, but the two modalities are essentially equivalent in pointing selection. A small amount of tactile feedback is shown to be beneficial for both pointing and crossing selection, most noticeably in crossing tasks when using direct input where visual feedback is often occluded by a hand or stylus.	Evaluating tactile feedback and direct vs. indirect stylus input in pointing and crossing selection tasks	NA:NA	2018
Eve Hoggan:Stephen A. Brewster:Jody Johnston	This paper presents a study of finger-based text entry for mobile devices with touchscreens. Many devices are now coming to market that have no physical keyboards (the Apple iPhone being a very popular example). Touchscreen keyboards lack any tactile feedback and this may cause problems for entering text and phone numbers. We ran an experiment to compare devices with a physical keyboard, a standard touchscreen and a touchscreen with tactile feedback added. We tested this in both static and mobile environments. The results showed that the addition of tactile feedback to the touchscreen significantly improved finger-based text entry, bringing it close to the performance of a real physical keyboard. A second experiment showed that higher specification tactile actuators could improve performance even further. The results suggest that manufacturers should use tactile feedback in their touchscreen devices to regain some of the feeling lost when interacting on a touchscreen with a finger.	Investigating the effectiveness of tactile feedback for mobile touchscreens	NA:NA:NA	2018
Philippe Palanque	NA	Session details: Culture and Technology	NA	2018
Oliviero Stock:Massimo Zancanaro:Chaya Koren:Cesare Rocchi:Zvi Eisikovits:Dina Goren-bar:Daniel Tomasini:Patrice (Tamar) Weiss	So called intractable conflicts may benefit from more modest and socially oriented approaches than those based on classical conflict resolution techniques. This paper is inspired by theories on small group intervention in a conflict. The general claim is that participants may achieve a greater understanding of and appreciation for the other's viewpoint under conditions that support partaking in a tangible joint task and creating a shared narration. Our goal was to design a methodology wherein the extent to which technology contributes to conflict negotiation and resolution could be assessed. Specifically, a co-located interface for producing a joint narration as a tool for favouring reconciliation is presented and discussed. The results of an initial set of studies where the interface was used by Arab and Jewish youth in Israel provided insight into the usability of the various components of the technology and of the paradigm.	A co-located interface for narration to support reconciliation in a conflict: initial results from Jewish and Palestinian youth	NA:NA:NA:NA:NA:NA:NA:NA	2018
Christine Satchell	When exploring a topic as intangible as the construction of mobile social networks it is necessary to look at how relationships are formed and at the way users identify themselves through their interactions. The theoretically informed discourses within cultural theory make an ideal lens for understanding these subtle nuances of use in terms of design. This paper describes a case study where the application of abstract cultural theory concepts to the practical act of analysing qualitative data from a user study resulted in the development of The Swarm mobile phone prototypes. By signposting the intersection of cultural theory within HCI, the value of a philosophically grounded mobile phone design space is highlighted. To uncover reactions to the design we explored the blogs that sprung up critiquing an online version of The Swarm and in doing so, discovered the at times subversive values (such as the need to lie) that users place on their mobile mediated interactions.	Cultural theory and real world design: Dystopian and Utopian Outcomes	NA	2018
Eric Gilbert:Karrie Karahalios:Christian Sandvig	History repeatedly demonstrates that rural communities have unique technological needs. Yet, we know little about how rural communities use modern technologies, so we lack knowledge on how to design for them. To address this gap, our empirical paper investigates behavioral differences between more than 3,000 rural and urban social media users. Using a dataset collected from a broadly popular social network site, we analyze users' profiles, 340,000 online friendships and 200,000 interpersonal messages. Using social capital theory, we predict differences between rural and urban users and find strong evidence supporting our hypotheses. Namely, rural people articulate far fewer friends online, and those friends live much closer to home. Our results also indicate that the groups have substantially different gender distributions and use privacy features differently. We conclude by discussing design implications drawn from our findings; most importantly, designers should reconsider the binary friend-or-not model to allow for incremental trust-building.	The network in the garden: an empirical analysis of social media in rural life	NA:NA:NA	2018
Gerrit van der Veer	NA	Session details: Fitt's Law Lives	NA	2018
Jacob O. Wobbrock:Edward Cutrell:Susumu Harada:I. Scott MacKenzie	For decades, Fitts' law (1954) has been used to model pointing time in user interfaces. As with any rapid motor act, faster pointing movements result in increased errors. But although prior work has examined accuracy as the "spread of hits," no work has formulated a predictive model for error rates (0-100%) based on Fitts' law parameters. We show that Fitts' law mathematically implies a predictive error rate model, which we derive. We then describe an experiment in which target size, target distance, and movement time are manipulated. Our results show a strong model fit: a regression analysis of observed vs. predicted error rates yields a correlation of R2=.959 for N=90 points. Furthermore, we show that the effect on error rate of target size (W) is greater than that of target distance (A), indicating a departure from Fitts' law, which maintains that W and A contribute proportionally to index of difficulty (ID). Our error model can be used with Fitts' law to estimate and predict error rates along with speeds, providing a framework for unifying this dichotomy.	An error model for pointing based on Fitts' law	NA:NA:NA:NA	2018
Morgan Dixon:François Guimbretière:Nicholas Chen	We present an empirical analysis of crossing-based dialog boxes. First, we study the spatial constraints required for efficient crossing-based interactions in the case of a simple multi-parameter dialog box. Through a series of 3 tasks, we establish the minimal value of the landing margin, the takeoff margin, and the column width. We also offer an estimation of the role of stroke shape on user performance. After studying the reasons for errors during our experiment, we propose a relaxed crossing semantic that combines aspects of pointing and crossing-based interfaces. To test our design, we compare a naïve dialog box implementation with our new implementation, as well as a standard point-and-click dialog box. Our results reveal that there is not a significant difference between the naïve crossing implementation and the standard point-and-click interface and that the new crossing semantic is faster than both the naïve crossing implementation and the point-and-click interface, despite a higher error rate. Together these two experiments establish that crossing-based dialog boxes can be as spatially efficient and faster than their point-and-click counterpart. Our new semantic provides the first step towards a smooth transition from point-and-click interfaces to crossing-based interfaces.	Optimal parameters for efficient crossing-based dialog boxes	NA:NA:NA	2018
I. Scott MacKenzie:Poika Isokoski	We describe an experiment to test the hypothesis that Fitts' throughput is independent of the speed-accuracy tradeoff. Eighteen participants used a mouse in performing a total of 5,400 target selection trials. Comparing nominal, speed-emphasis, and accuracy-emphasis conditions, significant main effects were found on movement time (ms) and error rate (%), but not on throughput (bits/s). In the latter case, failure to reject the null hypothesis of "no significant difference" (i.e., .05 < p < 1) is viewed as evidence supporting the constant-throughput hypothesis.	Fitts' throughput and the speed-accuracy tradeoff	NA:NA	2018
Jacob Biehl	NA	Session details: Collaboration and Cooperation	NA	2018
Gregorio Convertino:Helena M. Mentis:Mary Beth Rosson:John M. Carroll:Aleksandra Slavkovic:Craig H. Ganoe	We study the development of common ground in an emergency management planning task. Twelve three-person multi-role teams performed the task with a paper prototype in a controlled setting; each team completed three versions of the task. We use converging measures to document the development of common ground in the teams and present an in-depth analysis of the characteristics of the common ground development process. Our findings indicate that in complex collaborative work, process common ground increases, thus diminishing the need for acts like information querying or strategy discussions about how to organize the collaborative activities. However, content common ground is created and tested throughout the three runs; in fact dialogue acts used to clarify this content increase over time. Discussion of the implications of these findings for the theory of common ground and the design of collaborative systems follows.	Articulating common ground in cooperative work: content and process	NA:NA:NA:NA:NA:NA	2018
Saleema Amershi:Meredith Ringel Morris	Web search is often viewed as a solitary task; however, there are many situations in which groups of people gather around a single computer to jointly search for information online. We present the findings of interviews with teachers, librarians, and developing world researchers that provide details about users' collaborative search habits in shared-computer settings, revealing several limitations of this practice. We then introduce CoSearch, a system we developed to improve the experience of co-located collaborative Web search by leveraging readily available devices such as mobile phones and extra mice. Finally, we present an evaluation comparing CoSearch to status quo collaboration approaches, and show that CoSearch enabled distributed control and division of labor, thus reducing the frustrations associated with shared-computer searches, while still preserving the positive aspects of communication and collaboration associated with joint computer use.	CoSearch: a system for co-located collaborative web search	NA:NA	2018
Meredith Ringel Morris	Today's Web browsers provide limited support for rich information-seeking and information-sharing scenarios. A survey we conducted of 204 knowledge workers at a large technology company has revealed that a large proportion of users engage in searches that include collaborative activities. We present the results of the survey, and then review the implications of these findings for designing new Web search interfaces that provide tools for sharing.	A survey of collaborative web search practices	NA	2018
Jeremy P. Birnholtz:Carl Gutwin:Gonzalo Ramos:Mark Watson	The initiation of interaction in face-to-face environments is a gradual process, and takes place in a rich information landscape of awareness, attention, and social signals. One of the main benefits of this process is that people can be more sensitive to issues of privacy and interruption while they are moving towards interaction. However, on-line communication tools do not provide this subtlety, and often lead to unwanted interruptions. We have developed a prototype message system called OpenMessenger (OM) that adds the idea of gradual initiation of interaction to on-line communication. OpenMessenger provides multiple levels of awareness about people, and provides notification to those about whom information is being gathered. OpenMessenger allows people to negotiate interaction in a richer fashion than is possible with any other current messaging system. Preliminary evaluation data suggest the utility of the approach, but also shows that there are a number of issues yet to be resolved in this area.	OpenMessenger: gradual initiation of interaction for distributed workgroups	NA:NA:NA:NA	2018
Emmanuel Pietriga	NA	Session details: Driving in My Car	NA	2018
Ing-Marie Jonsson:Helen Harris:Clifford Nass	Driving requires focused attention and timely decision making for appropriate maneuvers. This relies on well-timed and accurate information. Designing an in-vehicle information system it is important to ensure that the information for the driver does not negatively affect cognitive processing and driving performance. This study investigates levels of information accuracy necessary in in-vehicle information systems to elicit positive behavioral and attitudinal responses from the driver. In a 2 (gender) by 5 (accuracy: 100%, 88%, 76%, 64% and no system) between-participants study, 100 participants drove in a driving simulator for 25 minutes with an in-vehicle information system designed to inform the driver of hazard and traffic events. Results show that decreasing the accuracy of the system decreased both driving performance and trust and liking of car and in-vehicle system. Female drivers in particular benefit from the in-vehicle system and show higher tolerance of inaccuracies. Design implications for in-vehicle systems are discussed.	How accurate must an in-car information system be?: consequences of accurate and inaccurate information in cars	NA:NA:NA	2018
Gilly Leshed:Theresa Velden:Oya Rieger:Blazej Kot:Phoebe Sengers	Although in-car GPS navigation technology is proliferating, it is not well understood how its use alters the ways people interpret their environment and navigate through it. We argue that GPS-based car navigation might disengage people from their surrounding environment, but also has the potential to open up novel ways to engage with it. We present an ethnographically-informed study with GPS users, showing evidence for practices of disengagement as well as new opportunities for engagement, illustrating our findings using rich descriptions from the field. Grounded in our observations we propose design principles for GPS systems that support richer experiences of driving. We argue that for a fuller understanding of issues of disengagement and engagement with the environment we need to move beyond a focus on the (re)design of GPS devices, and point to future directions of work that embrace a broader perspective.	In-car gps navigation: engagement with and disengagement from the environment	NA:NA:NA:NA:NA	2018
Stefan Graf:Wolfgang Spiessl:Albrecht Schmidt:Anneke Winter:Gerhard Rigoll	Increasing functionality, growing media volumes and dynamic data in today's in-vehicle information systems bear new challenges for user interaction design. Traditional hierarchical and menu-based interaction can only provide limited support while new search-based approaches are promising. In this work we assess different search techniques and search-based user interfaces. In particular we compare free search across all data items with categorized search. Our experiments with functional prototypes show that free search is more efficient and easier to use than searching within categories. Tests in a driving simulator show promising results regarding safety and workload. Means for alphanumeric input appear to be essential for an efficient and safe search interaction while driving.	In-car interaction using search-based user interfaces	NA:NA:NA:NA:NA	2018
Bonnie E. John	NA	Session details: Pointing and Flicking	NA	2018
Dzimitry Aliakseyeu:Pourang Irani:Andrés Lucero:Sriram Subramanian	Multi-flick, which consists of repeated flick actions, has received popular media attention as an intuitive and natural document-scrolling technique for stylus based systems. In this paper we put multi-flick to test, by designing several flick-based scrolling techniques. We first map out the de-sign space of multi-flick and identify mapping functions that make multi-flick a natural and intuitive technique for document navigation. In the first experiment we compare several multi-flick variations for navigating lists on three different devices -- a PDA, a tabletPC, and a large table. Our study shows that compound-multi-flick (CMF) is the most preferred technique and it is at least as fast, if not faster than the traditional scrollbar. In a follow-up experiment, we evaluate multi-flick for scrolling text-based documents. Results show that all implementations of multi-flick are as good as the scrollbar for short distances while CMF is the most preferred. We discuss the implications of our findings and present several design guidelines.	Multi-flick: an evaluation of flick-based scrolling techniques for pen interfaces	NA:NA:NA:NA	2018
Xiang Cao:Jacky Jie Li:Ravin Balakrishnan	Peephole interaction occurs when a spatially aware display is moved and acts as a viewport to reveal different parts of the virtual space that cannot all fit within the display at once. We investigate pointing within this peephole metaphor, where the targets may not be initially visible on the display, but are dynamically revealed by moving the display. We develop and experimentally validate a quantitative model for peephole pointing. Our results indicate that the model accurately accounts for peephole pointing for a variety of display sizes, both with and without users' having prior knowledge of the target location.	Peephole pointing: modeling acquisition of dynamically revealed targets	NA:NA:NA	2018
Géry Casiez:Daniel Vogel	Isometric and elastic devices are most compatible with a rate control mapping. However, the effect of elastic stiffness has not been thoroughly investigated nor its interaction with control gain. In a controlled experiment, these factors are investigated along with user feedback regarding ease-of-use and fatigue. The results reveal a U-shaped profile of control gain vs. movement time, with different profiles for different stiffness levels. Using the optimum control gain for each stiffness level, performance across stiffness levels were similar. However, users preferred lower stiffness and lower control gain levels due to increased controller displacement. Based on these results, design guidelines for elastic rate control devices are given.	The effect of spring stiffness and control gain with an elastic rate control pointing device	NA:NA	2018
Margaret Burnett	NA	Session details: End-Users Sharing and Tailoring Software	NA	2018
Gilly Leshed:Eben M. Haber:Tara Matthews:Tessa Lau	Modern enterprises are replete with numerous online processes. Many must be performed frequently and are tedious, while others are done less frequently yet are complex or hard to remember. We present interviews with knowledge workers that reveal a need for mechanisms to automate the execution of and to share knowledge about these processes. In response, we have developed the CoScripter system (formerly Koala [11]), a collaborative scripting environment for recording, automating, and sharing web-based processes. We have deployed CoScripter within a large corporation for more than 10 months. Through usage log analysis and interviews with users, we show that CoScripter has addressed many user automation and sharing needs, to the extent that more than 50 employees have voluntarily incorporated it into their work practice. We also present ways people have used CoScripter and general issues for tools that support automation and sharing of how-to knowledge.	CoScripter: automating & sharing how-to knowledge in the enterprise	NA:NA:NA:NA	2018
James R. Eagan:John T. Stasko	Information awareness applications offer the exciting potential to help people to better manage the data they encounter on a routine basis, but customizing these applications is a difficult task. Most applications allow users to perform basic customizations or programmers to create advanced ones. We present an intermediate customization space and Cocoa Buzz, an application that demonstrates one way to bridge these two extremes. Cocoa Buzz runs on an extra display on the user's desktop or on a large shared display and cycles through different information sources customized by the user. We further demonstrate some of the customizations that have been made using this approach. We show some preliminary evidence to suggest that this approach may be useful at providing users with the ability to perform customizations across this spectrum.	The buzz: supporting user tailorability in awareness applications	NA:NA	2018
Matt Jones	NA	Session details: Picture Perfect	NA	2018
Mor Naaman:Rahul Nair:Vlad Kaplun	We designed and iterated on a photo browsing application for high-end mobile phones. The application, Zurfer, supports viewing of photos from the user, their contacts, and the general user population. Photos are organized using a channel metaphor, driven by multiple dimensions: social, spatial and topical. Zurfer was deployed to over 500 users; extensive user research was conducted with nine participants. The data from the deployment and the study exposes general themes of mobile application use, as well as requirements for mobile applications in the photos domain, mobile social applications, and entertainment-driven mobile applications.	Photos on the go: a mobile application case study	NA:NA:NA	2018
Sean Kandel:Andreas Paepcke:Martin Theobald:Hector Garcia-Molina:Eric Abelson	PhotoSpread is a spreadsheet system for organizing and analyzing photo collections. It extends the current spreadsheet paradigm in two ways: (a) PhotoSpread accommodates sets of objects (e.g., photos) annotated with tags (attribute-value pairs). Formulas can manipulate object sets and refer to tags. (b) Photos can be reorganized (tags and location changed) by drag-and-drop operations on the spreadsheet. The PhotoSpread design was driven by the needs of field biologists who have large collections of annotated photos. The paper describes the PhotoSpread functionality and the design choices made.	Photospread: a spreadsheet for managing photos	NA:NA:NA:NA:NA	2018
Jimmy Secretan:Nicholas Beato:David B. D Ambrosio:Adelein Rodriguez:Adam Campbell:Kenneth O. Stanley	Picbreeder is an online service that allows users to collaboratively evolve images. Like in other Interactive Evolutionary Computation (IEC) programs, users evolve images on Picbreeder by selecting ones that appeal to them to produce a new generation. However, Picbreeder also offers an online community in which to share these images, and most importantly, the ability to continue evolving others' images. Through this process of branching from other images, and through continually increasing image complexity made possible by the NeuroEvolution of Augmenting Topologies (NEAT) algorithm, evolved images proliferate unlike in any other current IEC systems. Participation requires no explicit talent from the users, thereby opening Picbreeder to the entire Internet community. This paper details how Picbreeder encourages innovation, featuring images that were collaboratively evolved.	Picbreeder: evolving pictures collaboratively online	NA:NA:NA:NA:NA:NA	2018
Catherine Plaisant	NA	Session details: Finding your way	NA	2018
Niklas Elmqvist:Mihail Eduard Tudoreanu:Philippas Tsigas	Motion constraints providing guidance for 3D navigation have recently been suggested as a way of offloading some of the cognitive effort of traversing complex 3D environments on a computer. We present findings from an evaluation of the benefits of this practice where users achieved significantly better results in memory recall and performance when given access to such a guidance method. The study was conducted on both standard desktop computers with mouse and keyboard, as well as on an immersive CAVE system. Interestingly, our results also show that the improvements were more dramatic for desktop users than for CAVE users, even outperforming the latter. Furthermore, the study indicates that allowing the users to retain local control over the navigation on the desktop platform helps them in familiarizing themselves with the 3D world.	Evaluating motion constraints for 3D wayfinding in immersive and desktop virtual environments	NA:NA:NA	2018
Nicholas Chen:Francois Guimbretiere:Morgan Dixon:Cassandra Lewis:Maneesh Agrawala	Existing e-book readers do not do a good job supporting many reading tasks that people perform, as ethnographers report that when reading, people frequently read from multiple display surfaces. In this paper we present our design of a dual display e-book reader and explore how it can be used to interact with electronic documents. Our design supports embodied interactions like folding, flipping, and fanning for local/lightweight navigation. We also show how mechanisms like Space Filling Thumbnails can use the increased display space to aid global navigation. Lastly, the detachable faces in our design can facilitate inter-document operations and flexible layout of documents in the workspace. Semi-directed interviews with seven users found that dual-displays have the potential to improve the reading experience by supporting several local navigation tasks better than a single display device. Users also identified many reading tasks for which the device would be valuable. Users did not find the embodied interface particularly useful when reading in our controlled lab setting, however.	Navigation techniques for dual-display e-book readers	NA:NA:NA:NA:NA	2018
Robin Stewart:Gregory Scott:Vladimir Zelevinsky	Traditional interfaces for information access do not fully support queries that rely on semantic relationships between terms. To better support such queries, we introduce a system that automatically extracts subject-verb-object concepts from unstructured text documents and dynamically presents them to the user as navigable refinements. This approach, which we call "idea navigation," makes subject-verb-object querying as simple as selecting successive refinements. It also supports exploratory search by providing a view of the most common ideas in the current result set. First-time users of a prototype system successfully used idea navigation to solve realistic search tasks, demonstrating its effectiveness.	Idea navigation: structured browsing for unstructured text	NA:NA:NA	2018
Sebastian Ryszard Kruk:Bill M Daniel	The growing amount of available information poses challenges not only in the process of information retrieval. The usability of the rendered search process and results can be increased by appropriate visualization techniques or new interaction paradigms, or both. In this article we present the HoneyComb™ paradigm, an information visualization style that aims to render and manage large quantities of information items. We describe the design objectives and the prototype of HC™. Finally, we present a short evaluation of the HC™ paradigm in the context of search and browsing.	Rendering navigation and information space with honeycomb™	NA:NA	2018
Joseph A. Konstan	NA	Session details: Personal Health	NA	2018
Sunny Consolvo:David W. McDonald:Tammy Toscos:Mike Y. Chen:Jon Froehlich:Beverly Harrison:Predrag Klasnja:Anthony LaMarca:Louis LeGrand:Ryan Libby:Ian Smith:James A. Landay	Recent advances in small inexpensive sensors, low-power processing, and activity modeling have enabled applications that use on-body sensing and machine learning to infer people's activities throughout everyday life. To address the growing rate of sedentary lifestyles, we have developed a system, UbiFit Garden, which uses these technologies and a personal, mobile display to encourage physical activity. We conducted a 3-week field trial in which 12 participants used the system and report findings focusing on their experiences with the sensing and activity inference. We discuss key implications for systems that use on-body sensing and activity inference to encourage physical activity.	Activity sensing in the wild: a field trial of ubifit garden	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2018
Stinne Aaløkke Ballegaard:Thomas Riisgaard Hansen:Morten Kyng	Today the design of most healthcare technology is driven by the considerations of healthcare professionals and technology companies. This has several benefits, but we argue that there is a need for a supplementary design approach on the basis the citizen and his or her everyday life. An approach where the main focus is to develop healthcare technology that fits the routines of daily life and thus allows the citizens to continue with the activities they like and have grown used to -- also with an aging body or when managing a chronic condition. Thus, with this approach it is not just a matter of fixing a health condition, more importantly is the matter of sustaining everyday life as a whole. This argument is a result from our work -- using participatory design methods -- on the development of supportive healthcare technology for elderly people and for diabetic, pregnant women.	Healthcare in everyday life: designing healthcare services for daily life	NA:NA:NA	2018