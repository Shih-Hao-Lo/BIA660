Sarah Tausch:Stephanie Ta:Heinrich Hussmann	We present a study that investigates the influence of different types of visualizations on collaboration. The visualizations present the group's performance either in a more cooperative or more competitive way. Decades of research suggest that cooperation leads to greater productivity than competition. However, most of the existing group mirror visualizations achieve an increase in productivity and better self-regulation by enabling a direct comparison of performance within the group. We conducted a repeated measures study with 12 groups that were supported by visualizations that displayed the number of ideas of a brainstorming session (1) per person (competitive condition) (2) per group (cooperative condition), (3) per person and per group (mixed condition) and (4) without visualization (baseline). Results indicate that groups that see a combination of individual and group performance (mixed condition) are more productive, more satisfied with their results and participate in a more balanced way.	A Comparison of Cooperative and Competitive Visualizations for Co-located Collaboration	NA:NA:NA	2016
Dimitar Asenov:Otmar Hilliges:Peter MÃ¼ller	Researchers often introduce visual tools to programming environments in order to facilitate program comprehension, reduce navigation times, and help developers answer difficult questions. Syntax highlighting is the main visual lens through which developers perceive their code, and yet its effects and the effects of richer code presentations on code comprehension have not been evaluated systematically. We present a rigorous user study comparing mainstream syntax highlighting to two visually-enhanced presentations of code. Our results show that: (1) richer code visualizations reduce the time necessary to answer questions about code features, and (2) contrary to the subjective perception of developers, richer code visualizations do not lead to visual overload. Based on our results we outline practical recommendations for tool designers.	The Effect of Richer Visualizations on Code Comprehension	NA:NA:NA	2016
Syed Ishtiaque Ahmed:Nicola J. Bidwell:Himanshu Zade:Srihari H. Muralidhar:Anupama Dhareshwar:Baneen Karachiwala:Cedrick N. Tandong:Jacki O'Neill	This paper contributes to the growing literature on peer-to-peer (P2P) applications through an ethnographic study of auto-rickshaw drivers in Bengaluru, India. We describe how the adoption of a P2P application, Ola, which connects passengers to rickshaws, changes drivers work practices. Ola is part of the 'peer services' phenomenon which enable new types of ad-hoc trade in labour, skills and goods. Auto-rickshaw drivers present an interesting case because prior to Ola few had used Smartphones or the Internet. Furthermore, as financially vulnerable workers in the informal sector, concerns about driver welfare become prominent. Whilst technologies may promise to improve livelihoods, they do not necessarily deliver [57]. We describe how Ola does little to change the uncertainty which characterizes an auto drivers' day. This leads us to consider how a more equitable and inclusive system might be designed.	Peer-to-peer in the Workplace: A View from the Road	NA:NA:NA:NA:NA:NA:NA:NA	2016
Renate Haeuslschmid:Bastian Pfleging:Florian Alt	In this paper we present a design space for interactive windshield displays in vehicles and discuss how this design space can support designers in creating windshield applications for drivers, passengers, and pedestrians. Our work is motivated by numerous examples in other HCI-related areas where seminal design space papers served as a valuable basis to evolve the respective field -- most notably mobile devices, automotive user interfaces, and interactive public displays. The presented design space is based on a comprehensive literature review. Furthermore we present a classification of 211 windshield applications, derived from a survey of research projects and commercial products as well as from focus groups. We showcase the utility of our work for designers of windshield applications through two scenarios. Overall, our design space can help building applications for diverse use cases. This includes apps inside and outside the car as well as applications for specific areas (fire fighters, police, ambulance).	A Design Space to Support the Development of Windshield Applications for the Car	NA:NA:NA	2016
Matthew Kay:Tara Kola:Jessica R. Hullman:Sean A. Munson	Users often rely on realtime predictions in everyday contexts like riding the bus, but may not grasp that such predictions are subject to uncertainty. Existing uncertainty visualizations may not align with user needs or how they naturally reason about probability. We present a novel mobile interface design and visualization of uncertainty for transit predictions on mobile phones based on discrete outcomes. To develop it, we identified domain specific design requirements for visualizing uncertainty in transit prediction through: 1) a literature review, 2) a large survey of users of a popular realtime transit application, and 3) an iterative design process. We present several candidate visualizations of uncertainty for realtime transit predictions in a mobile context, and we propose a novel discrete representation of continuous outcomes designed for small screens, quantile dotplots. In a controlled experiment we find that quantile dotplots reduce the variance of probabilistic estimates by ~1.15 times compared to density plots and facilitate more confident estimation by end-users in the context of realtime transit prediction scenarios.	When (ish) is My Bus?: User-centered Visualizations of Uncertainty in Everyday, Mobile Predictive Systems	NA:NA:NA:NA	2016
Ja Young Lee:Madeleine C. Gibson:John D. Lee	Human-technology interactions involving errors undermine acceptance and performance. The effect of errors and the ability to recover from them represent a particularly important consideration for design in safety-critical multitasking situations. However, few studies have considered the recovery process of errors in multitasking situations, such as their contribution to driver distraction. This paper investigates errors that drivers make interacting with an infotainment system. In this study, participants (N = 46) drove a stimulated vehicle and performed word entry tasks on a touch screen. Errors undermined driving and task performance. We also identified four different error recovery strategies and found that the accumulated information related to the driving situation and the characteristics of an infotainment system affected the choice of strategy. Implications for in-vehicle interface design, driver models, and general multitasking design are discussed.	Error Recovery in Multitasking While Driving	NA:NA:NA	2016
Daniel Miau:Steven Feiner	Maps on mobile/wearable devices often make it difficult to determine the location of a point of interest (POI). For example, a POI may exist outside the map or on a background with no meaningful cues. To address this issue, we present Personalized Compass, a self-contained compact graphical location indicator. Personalized Compass uses personal a priori POIs to establish a reference frame, within which a POI in question can then be localized. Graphically, a personalized compass combines a multi-needle compass with an abstract overview map. We analyze the characteristics of Personalized Compass and the existing Wedge technique, and report on a user study comparing them. Personalized Compass performs better for four inference tasks, while Wedge is better for a locating task. Based on our analysis and study results, we suggest the two techniques are complementary and offer design recommendations.	Personalized Compass: A Compact Visualization for Direction and Location	NA:NA	2016
Chungkuk Yoo:Inseok Hwang:Eric Rozner:Yu Gu:Robert F. Dickerson	Driven to create intuitive computing interfaces throughout our everyday space, various state-of-the-art technologies have been proposed for near-surface localization of a user's finger input such as hover or touch. However, these works require specialized hardware not commonly available, limiting the adoption of such technologies. We present SymmetriSense, a technology enabling near-surface 3-dimensional fingertip localization above arbitrary glossy surfaces using a single commodity camera device such as a smartphone. SymmetriSense addresses the localization challenges in using a single regular camera by a novel technique utilizing the principle of reflection symmetry and the fingertip's natural reflection casted upon surfaces like mirrors, granite countertops, or televisions. SymmetriSense achieves typical accuracies at sub-centimeter levels in our localization tests with dozens of volunteers and remains accurate under various environmental conditions. We hope SymmetriSense provides a technical foundation on which various everyday near-surface interactivity can be designed.	SymmetriSense: Enabling Near-Surface Interactivity on Glossy Surfaces using a Single Commodity Smartphone	NA:NA:NA:NA:NA	2016
Christian Rendl:David Kim:Patrick Parzer:Sean Fanello:Martin Zirkl:Gregor Scheipl:Michael Haller:Shahram Izadi	FlexCase is a novel flip cover for smartphones, which brings flexible input and output capabilities to existing mobile phones. It combines an e-paper display with a pressure- and bend-sensitive input sensor to augment the capabilities of a phone. Due to the form factor, FlexCase can be easily transformed into several different configurations, each with different interaction possibilities. Users can use FlexCase to perform a variety of touch, pressure, grip and bend gestures in a natural manner, much like interacting with a sheet of paper. The secondary e-paper display can act as a mechanism for providing user feedback and persisting content from the main display. In this paper, we explore the rich design space of FlexCase and present a number of different interaction techniques. Beyond, we highlight how touch and flex sensing can be combined to support a novel type of gestures, which we call Grip & Bend gestures. We also describe the underlying technology and gesture sensing algorithms. Numerous applications apply the interaction techniques in convincing real-world examples, including enhanced e-paper reading and interaction, a new copy and paste metaphor, high degree of freedom 3D and 2D manipulation, and the ability to transfer content and support input between displays in a natural and flexible manner.	FlexCase: Enhancing Mobile Interaction with a Flexible Sensing and Display Cover	NA:NA:NA:NA:NA:NA:NA:NA	2016
Ahmed Sabbir Arif:Sunjun Kim:Wolfgang Stuerzlinger:Geehyuk Lee:Ali Mazalek	We present a new smart-restorable backspace technique to facilitate correction of "overlooked" errors on touchscreen-based tablets. We conducted an empirical study to compare the new backspace technique with the conventional one. Results of the study revealed that the new technique improves the overall text entry performance, both in terms of speed and operations per character, by significantly reducing error correction efforts. In addition, results showed that most users preferred the new technique to the one they use on their tablets, and found it easy to learn and use. Most of them also felt that it improved their overall text entry performance, thus wanted to keep using it.	Evaluation of a Smart-Restorable Backspace Technique to Facilitate Text Entry Error Correction	NA:NA:NA:NA:NA	2016
Sunjun Kim:Geehyuk Lee	We introduce TapBoard 2, a touchpad-based keyboard that solves the problem of typing and pointing disambiguation. The pointing interaction design of TapBoard 2 is nearly identical to natural touchpad interaction, and its shared workspace naturally invites bimanual pointing interaction. To implement TapBoard 2, we developed a novel gesture representation scheme for a systematic design and gesture recognizer. A user evaluation showed that TapBoard 2 successfully supports collocated pointing and typing interaction. It was able to disambiguate typing and pointing actions with an accuracy of greater than 95%. In addition, the typing and pointing performance of TapBoard 2 were comparable to that of a separate keyboard and mouse. In particular, the bimanual pointing operations of TapBoard 2 are highly efficient and strongly favored by participants.	TapBoard 2: Simple and Effective Touchpad-like Interaction on a Multi-Touch Surface Keyboard	NA:NA	2016
Michael Xuelin Huang:Tiffany C.K. Kwok:Grace Ngai:Stephen C.F. Chan:Hong Va Leong	We present PACE, a Personalized, Automatically Calibrating Eye-tracking system that identifies and collects data unobtrusively from user interaction events on standard computing systems without the need for specialized equipment. PACE relies on eye/facial analysis of webcam data based on a set of robust geometric gaze features and a two-layer data validation mechanism to identify good training samples from daily interaction data. The design of the system is founded on an in-depth investigation of the relationship between gaze patterns and interaction cues, and takes into consideration user preferences and habits. The result is an adaptive, data-driven approach that continuously recalibrates, adapts and improves with additional use. Quantitative evaluation on 31 subjects across different interaction behaviors shows that training instances identified by the PACE data collection have higher gaze point-interaction cue consistency than those identified by conventional approaches. An in-situ study using real-life tasks on a diverse set of interactive applications demonstrates that the PACE gaze estimation achieves an average error of 2.56Âº, which is comparable to state-of-the-art, but without the need for explicit training or calibration. This demonstrates the effectiveness of both the gaze estimation method and the corresponding data collection mechanism.	Building a Personalized, Auto-Calibrating Eye Tracker from User Interactions	NA:NA:NA:NA:NA	2016
Keita Higuch:Ryo Yonetani:Yoichi Sato	In this work, we investigate how remote collaboration between a local worker and a remote collaborator will change if eye fixations of the collaborator are presented to the worker. We track the collaborator's points of gaze on a monitor screen displaying a physical workspace and visualize them onto the space by a projector or through an optical see-through head-mounted display. Through a series of user studies, we have found the followings: 1) Eye fixations can serve as a fast and precise pointer to objects of the collaborator's interest. 2) Eyes and other modalities, such as hand gestures and speech, are used differently for object identification and manipulation. 3) Eyes are used for explicit instructions only when they are combined with speech. 4) The worker can predict some intentions of the collaborator such as his/her current interest and next instruction.	Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks	NA:NA:NA	2016
Michael Mauderer:David R. Flatla:Miguel A. Nacenta	Using real time eye tracking, gaze-contingent displays can modify their content to represent depth (e.g., through additional depth cues) or to increase rendering performance (e.g., by omitting peripheral detail). However, there has been no research to date exploring how gaze-contingent displays can be leveraged for manipulating perceived color. To address this, we conducted two experiments (color matching and sorting) that manipulated peripheral background and object colors to influence the user's color perception. Findings from our color matching experiment suggest that we can use gaze-contingent simultaneous contrast to affect color appearance and that existing color appearance models might not fully predict perceived colors with gaze-contingent presentation. Through our color sorting experiment we demonstrate how gaze-contingent adjustments can be used to enhance color discrimination. Gaze-contingent color holds the promise of expanding the perceived color gamut of existing display technology and enabling people to discriminate color with greater precision.	Gaze-Contingent Manipulation of Color Perception	NA:NA:NA	2016
Byungjoo Lee:Olli Savisaari:Antti Oulasvirta	The paper contributes a novel technique that can improve user performance in skim reading. Users typically use a continuous-rate-based scrolling technique to skim works such as longer Web pages, e-books, and PDF files. However, visual attention is compromised at higher scrolling rates because of motion blur and extraneous objects with overly brief exposure times. In response, we present Spotlights. It complements the regular continuous technique at high speeds (2--20 pages/s). We present a novel design rule informed by theories of the human visual system for dynamically selecting objects and placing them on transparent overlays on top of the viewer. This improves the quality of visual processing at high scrolling rates by 1) limiting the number of objects, 2) ensuring minimal processing time per object, and 3) keeping objects static to avoid motion blur and facilitate gaze deployment. Spotlights was compared to continuous scrolling in two studies using long documents (200+ pages). Comprehension levels for long documents were comparable with those in continuous-rate-based scrolling, but Spotlights showed significantly better scrolling speed, gaze deployment, recall, lookup performance, and user-rated comprehension.	Spotlights: Attention-Optimized Highlights for Skim Reading	NA:NA:NA	2016
Igor Bilogrevic:Martin Ortlieb	Online services often rely on processing users' data, which can be either provided directly by the users or combined from other services. Although users are aware of the latter, it is unclear whether they are comfortable with such data combination, whether they view it as beneficial for them, or the extent to which they believe that their privacy is exposed. Through an online survey (N=918) and follow-up interviews (N=14), we show that (1) comfort is highly dependent on the type of data, type of service and on the existence of a direct relationship with a company, (2) users have a highly different opinion about the presence of benefits for them, irrespectively of the context, and (3) users perceive the combination of online data as more identifying than data related to offline and physical behavior (such as location). Finally, we discuss several strategies for companies to improve upon these issues.	"If You Put All The Pieces Together...": Attitudes Towards Data Combination and Sharing Across Services and Companies	NA:NA	2016
Janna Lynn Dupree:Richard Devries:Daniel M. Berry:Edward Lank	A primary goal of research in usable security and privacy is to understand the differences and similarities between users. While past researchers have clustered users into different groups, past categories of users have proven to be poor predictors of end-user behaviors. In this paper, we perform an alternative clustering of users based on their behaviors. Through the analysis of data from surveys and interviews of participants, we identify five user clusters that emerge from end-user behaviors-Fundamentalists, Lazy Experts, Technicians, Amateurs and the Marginally Concerned. We examine the stability of our clusters through a survey-based study of an alternative sample, showing that clustering remains consistent. We conduct a small-scale design study to demonstrate the utility of our clusters in design. Finally, we argue that our clusters complement past work in understanding privacy choices, and that our categorization technique can aid in the design of new computer security technologies.	Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security Practices	NA:NA:NA:NA	2016
Chanda Phelan:Cliff Lampe:Paul Resnick	Undergraduates interviewed about privacy concerns related to online data collection made apparently contradictory statements. The same issue could evoke concern or not in the span of an interview, sometimes even a single sentence. Drawing on dual-process theories from psychology, we argue that some of the apparent contradictions can be resolved if privacy concern is divided into two components we call intuitive concern, a "gut feeling," and considered concern, produced by a weighing of risks and benefits. Consistent with previous explanations of the so-called privacy paradox, we argue that people may express high considered concern when prompted, but in practice act on low intuitive concern without a considered assessment. We also suggest a new explanation: a considered assessment can override an intuitive assessment of high concern without eliminating it. Here, people may choose rationally to accept a privacy risk but still express intuitive concern when prompted.	It's Creepy, But it Doesn't Bother Me	NA:NA:NA	2016
T. Franklin Waddell:Joshua R. Auriemma:S. Shyam Sundar	Users often react negatively towards applications that track their personal information, even though they have consented to such tracking by hitting the "I Agree" button on the application's end user license agreement (EULA). This is because most users do not read the EULA carefully. The language and presentation of EULAs are often dull, dense and inaccessible. Researchers have proposed design options for heightening comprehension of EULA content, but the effectiveness of these suggestions is unclear. To address this gap, we conducted an experiment that examined how users' attitudes towards EULAs are affected by paraphrased and forced EULA formats. Paraphrased EULA presentations increased the time spent on reading the EULA. Moreover, they elicited more positive attitudes toward the EULA, which in turn predicted better comprehension. These findings hold implications for design of EULAs by showing that complex content displayed in simple terms across multiple windows can increase reader comprehension.	Make it Simple, or Force Users to Read?: Paraphrased Design Improves Comprehension of End User License Agreements	NA:NA:NA	2016
Serge Egelman:Marian Harbach:Eyal Peer	The Security Behavior Intentions Scale (SeBIS) measures the computer security attitudes of end-users. Because intentions are a prerequisite for planned behavior, the scale could therefore be useful for predicting users' computer security behaviors. We performed three experiments to identify correlations between each of SeBIS's four sub-scales and relevant computer security behaviors. We found that testing high on the awareness sub-scale correlated with correctly identifying a phishing website; testing high on the passwords sub-scale correlated with creating passwords that could not be quickly cracked; testing high on the updating sub-scale correlated with applying software updates; and testing high on the securement sub-scale correlated with smartphone lock screen usage (e.g., PINs). Our results indicate that SeBIS predicts certain computer security behaviors and that it is a reliable and valid tool that should be used in future research.	Behavior Ever Follows Intention?: A Validation of the Security Behavior Intentions Scale (SeBIS)	NA:NA:NA	2016
Alper T. Alan:Mike Shann:Enrico Costanza:Sarvapali D. Ramchurn:Sven Seuken	Smart energy systems that leverage machine learning techniques are increasingly integrated in all aspects of our lives. To better understand how to design user interaction with such systems, we implemented three different smart thermostats that automate heating based on users' heating preferences and real-time price variations. We evaluated our designs through a field study, where 30 UK households used our thermostats to heat their homes over a month. Our findings through thematic analysis show that the participants formed different understandings and expectations of our smart thermostat, and used it in various ways to effectively respond to real-time prices while maintaining their thermal comfort. Based on the findings, we present a number of design and research implications, specifically for designing future smart thermostats that will assist us in controlling home heating with real-time pricing, and for future intelligent autonomous systems.	It is too Hot: An In-Situ Study of Three Designs for Heating	NA:NA:NA:NA:NA	2016
Audrey Desjardins:Ron Wakkary	In this paper, we present a twenty-three months autobiographical design project of converting a Mercedes Sprinter van into a camper van. This project allows us to investigate the complexities and nuances of a case where people engage in a process of making, transforming and adapting a space they live in. This example opens a radically different and productive context for revisiting concepts that are currently at the center of human-computer interaction (HCI) research: ubiquitous computing, home automation, smart homes, and the Internet of Things. We offer six qualities characterizing the evolving relationship between the makers and the lived-in environment: the van. We conclude with a discussion on the two themes of living in a reconfigured home and prototype qualities in a reconfigured space, and a critical reflection around the theme of the invariably unfinished home.	Living In A Prototype: A Reconfigured Space	NA:NA	2016
Ewa Luger:Abigail Sellen	The past four years have seen the rise of conversational agents (CAs) in everyday life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary CAs within their software and, increasingly, conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak, the investigative concern within HCI has been upon multimodality rather than dialogue alone, and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of CAs in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems, particularly in terms of known machine intelligence, system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings for the design of future systems.	"Like Having a Really Bad PA": The Gulf between User Expectation and Experience of Conversational Agents	NA:NA	2016
Gilles Bailly:Sidharth Sahdev:Sylvain Malacria:Thomas Pietrzak	We investigate the potential benefits of actuated devices for the desktop workstation which remains the most used environment for daily office works. A formative study reveals that the desktop workstation is not a fixed environment because users manually change the position and the orientation of their devices. Based on these findings, we present the LivingDesktop, an augmented desktop workstation with devices (mouse, keyboard, monitor) capable of moving autonomously. We describe interaction techniques and applications illustrating how actuated desktop workstations can improve ergonomics, foster collaboration, leverage context and reinforce physicality. Finally, the findings of a scenario evaluation are (1) the perceived usefulness of ergonomics and collaboration applications; (2) how the LivingDesktop inspired our participants to elaborate novel accessibility and social applications; (3) the location and user practices should be considered when designed actuated desktop devices.	LivingDesktop: Augmenting Desktop Workstation with Actuated Devices	NA:NA:NA:NA	2016
Anne Marie Piper:Raymundo Cornejo:Lisa Hurwitz:Caitlin Unumb	With much of the population now online, the field of HCI faces new and pressing issues of how to help people sustain online activity throughout their lives, including through periods of disability. The onset of cognitive impairment later in life affects whether and how individuals are able to stay connected online and manage their digital information. While caregivers play a critical role in the offline lives of adults with cognitive impairments, less is known about how they support and enable online interaction. Using a constructivist grounded theory approach, data from focus groups with caregivers of adults with cognitive impairments reveal four forms of cooperative work caregivers perform in the context of supporting online activity. We find that staying active online is a way of empowering and engaging adults with cognitive impairments, yet this introduces new forms of risk, surrogacy, and cooperative technology use to the already demanding work of caregiving.	Technological Caregiving: Supporting Online Activity for Adults with Cognitive Impairments	NA:NA:NA:NA	2016
Ari H. Pollack:Uba Backonja:Andrew D. Miller:Sonali R. Mishra:Maher Khelifi:Logan Kendall:Wanda Pratt	Patients going home after a hospitalization face many challenges. This transition period exposes patients to unnecessary risks related to inadequate preparation prior to leaving the hospital, potentially leading to errors and patient harm. Although patients engaging in self-management have better health outcomes and increased self-efficacy, little is known about the processes in place to support and develop these skills for patients leaving the hospital. Through qualitative interviews and observations of 28 patients during and after their hospitalizations, we explore the challenges they face transitioning from hospital care to self-management. We identify three key elements in this process: knowledge, resources, and self-efficacy. We describe how both system and individual factors contribute to breakdowns leading to ineffective patient management. This work expands our understanding of the unique challenges faced by patients during this difficult transition and uncovers important design opportunities for supporting crucial yet unmet patient needs.	Closing the Gap: Supporting Patients' Transition to Self-Management after Hospitalization	NA:NA:NA:NA:NA:NA:NA	2016
Matthew K. Hong:Lauren Wilcox:Daniel Machado:Thomas A. Olson:Stephen F. Simoneaux	Adolescents with complex chronic illnesses, such as cancer and blood disorders, must partner with family and clinical caregivers to navigate risky procedures with life-altering implications, burdensome symptoms and lifelong treatments. Yet, there has been little investigation into how technology can support these partnerships. We conducted 38 in-depth interviews (15 with teenage adolescents with chronic forms of cancer and blood disorders, 15 with their parents, and eight with clinical caregivers) along with nine non-participant observations of clinical consultations, to better understand common challenges and needs that could be supported through design. Participants faced challenges primarily concerning: 1) teens' limited participation in their care, 2) communicating emotionally-sensitive information, and 3) managing physical and emotional responses. We draw on these findings to propose design goals for sociotechnical systems to support teens in partnering in their care, highlighting the need for design to support gradually-evolving partnerships.	Care Partnerships: Toward Technology to Support Teens' Participation in Their Health Care	NA:NA:NA:NA:NA	2016
Xiang Zhang:Hans-Frederick Brown:Anil Shankar	User Experience (UX) research teams following a user centered design approach harness personas to better understand a user's workflow by examining that user's behavior, goals, needs, wants, and frustrations. To create target personas these researchers rely on workflow data from surveys, self-reports, interviews, and user observation. However, this data not directly related to user behavior, weakly reflects a user's actual workflow in the product, is costly to collect, is limited to a few hundred responses, and is outdated as soon as a persona's workflows evolve. To address these limitations we present a quantitative bottom-up data-driven approach to create personas. First, we directly incorporate user behavior via clicks gathered automatically from telemetry data related to the actual product use in the field; since the data collection is automatic it is also cost effective. Next, we aggregate 3.5 million clicks from 2400 users into 39,000 clickstreams and then structure them into 10 workflows via hierarchical clustering; we thus base our personas on a large data sample. Finally, we use mixed models, a statistical approach that incorporates these clustered workflows to create five representative personas; updating our mixed model ensures that these personas remain current. We also validated these personas with our product's user behavior experts to ensure that workflows and the persona goals represent actual product use.	Data-driven Personas: Constructing Archetypal Users with Clickstreams and User Telemetry	NA:NA:NA	2016
Bernie Hogan:Joshua R. Melville:Gregory Lee Phillips II:Patrick Janulis:Noshir Contractor:Brian S. Mustanski:Michelle Birkett	While much social network data exists online, key network metrics for high-risk populations must still be captured through self-report. This practice has suffered from numerous limitations in workflow and response burden. However, advances in technology, network drawing libraries and databases are making interactive network drawing increasingly feasible. We describe the translation of an analog-based technique for capturing personal networks into a digital framework termed netCanvas that addresses many existing shortcomings such as: 1) complex data entry; 2) extensive interviewer intervention and field setup; 3) difficulties in data reuse; and 4) a lack of dynamic visualizations. We test this implementation within a health behavior study of a high-risk and difficult-to-reach population. We provide a within--subjects comparison between paper and touchscreens. We assert that touchscreen-based social network capture is now a viable alternative for highly sensitive data and social network data entry tasks.	Evaluating the Paper-to-Screen Translation of Participant-Aided Sociograms with High-Risk Participants	NA:NA:NA:NA:NA:NA:NA	2016
Beste F. Yuksel:Kurt B. Oleson:Lane Harrison:Evan M. Peck:Daniel Afergan:Remco Chang:Robert JK Jacob	We present Brain Automated Chorales (BACh), an adaptive brain-computer system that dynamically increases the levels of difficulty in a musical learning task based on pianists' cognitive workload measured by functional near-infrared spectroscopy. As users' cognitive workload fell below a certain threshold, suggesting that they had mastered the material and could handle more cognitive information, BACh automatically increased the difficulty of the learning task. We found that learners played with significantly increased accuracy and speed in the brain-based adaptive task compared to our control condition. Participant feedback indicated that they felt they learned better with BACh and they liked the timings of the level changes. The underlying premise of BACh can be applied to learning situations where a task can be broken down into increasing levels of difficulty.	Learn Piano with BACh: An Adaptive Learning Interface that Adjusts Task Difficulty Based on Brain State	NA:NA:NA:NA:NA:NA:NA	2016
Matthew Pike:Richard Ramchurn:Steve Benford:Max L. Wilson	This paper explores the design space of bio-responsive entertainment, in this case using a film that responds to the brain and blink data of users. A film was created with four parallel channels of footage, where blinking and levels of attention and meditation, as recorded by a commercially available EEG device, affected which footage participants saw. As a performance-led piece of research in the wild, this experience, named #Scanners, was presented at a week long national exhibition in the UK. We examined the experiences of 35 viewers, and found that these forms of partially-involuntary control created engaging and enjoyable, but sometimes distracting, experiences. We translate our findings into a two-dimensional design space between the extent of voluntary control that a physiological measure can provide against the level of conscious awareness that the user has of that control. This highlights that novel design opportunities exist when deviating from these two-dimensions - when giving up conscious control and when abstracting the affect of control. Reflection on of how viewers negotiated this space during an experience reveals novel design tactics.	#Scanners: Exploring the Control of Adaptive Films using Brain-Computer Interaction	NA:NA:NA:NA	2016
Xiao Xiao:Hiroshi Ishii	This paper introduces a new framework to guide the design of interactive music learning systems, focusing on the piano. Taking a Reflective approach, we identify the implicit assumption behind most existing systems-that learning music is learning to play correctly according to the score-and offer an alternative approach. We argue that systems should help cultivate higher levels of musicianship beyond correctness alone for students of all levels. Drawing from both pedagogical literature and the personal experience of learning to play the piano, we identify three skills central to musicianship-listening, embodied understanding, and creative imagination-which we generalize to the Inspect, Embody, Invent framework. To demonstrate how this framework translates to design, we discuss two existing interfaces from our own research-MirrorFugue and Andante-both built on a digitally controlled player piano augmented by in-situ projection. Finally, we discuss the framework's relevance toward bigger themes of embodied interactions and learning beyond the domain of music.	Inspect, Embody, Invent: A Design Framework for Music Learning and Beyond	NA:NA	2016
Sriram Karthik Badam:Jieqiong Zhao:Shivalik Sen:Niklas Elmqvist:David Ebert	We present TimeFork, an interactive prediction technique to support users predicting the future of time-series data, such as in financial, scientific, or medical domains. TimeFork combines visual representations of multiple time series with prediction information generated by computational models. Using this method, analysts engage in a back-and-forth dialogue with the computational model by alternating between manually predicting future changes through interaction and letting the model automatically determine the most likely outcomes, to eventually come to a common prediction using the model. This computer-supported prediction approach allows for harnessing the user's knowledge of factors influencing future behavior, as well as sophisticated computational models drawing on past performance. To validate the TimeFork technique, we conducted a user study in a stock market prediction game. We present evidence of improved performance for participants using TimeFork compared to fully manual or fully automatic predictions, and characterize qualitative usage patterns observed during the user study.	TimeFork: Interactive Prediction of Time Series	NA:NA:NA:NA:NA	2016
Justin Matejka:Michael Glueck:Tovi Grossman:George Fitzmaurice	Sliders and Visual Analogue Scales (VASs) are input mechanisms which allow users to specify a value within a predefined range. At a minimum, sliders and VASs typically consist of a line with the extreme values labeled. Additional decorations such as labels and tick marks can be added to give information about the gradations along the scale and allow for more precise and repeatable selections. There is a rich history of research about the effect of labelling in discrete scales (i.e., Likert scales), however the effect of decorations on continuous scales has not been rigorously explored. In this paper we perform a 2,000 user, 250,000 trial online experiment to study the effects of slider appearance, and find that decorations along the slider considerably bias the distribution of responses received. Using two separate experimental tasks, the trade-offs between bias, accuracy, and speed-of-use are explored and design recommendations for optimal slider implementations are proposed.	The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales	NA:NA:NA:NA	2016
Leilani Battle:Danyel Fisher:Robert DeLine:Mike Barnett:Badrish Chandramouli:Jonathan Goldstein	As real-time monitoring and analysis become increasingly important, researchers and developers turn to data stream management systems (DSMS's) for fast, efficient ways to pose temporal queries over their datasets. However, these systems are inherently complex, and even database experts find it difficult to understand the behavior of DSMS queries. To help analysts better understand these temporal queries, we developed StreamTrace, an interactive visualization tool that breaks down how a temporal query processes a given dataset, step-by-step. The design of StreamTrace is based on input from expert DSMS users; we evaluated the system with a lab study of programmers who were new to streaming queries. Results from the study demonstrate that StreamTrace can help users to verify that queries behave as expected and to isolate the regions of a query that may be causing unexpected results.	Making Sense of Temporal Queries with Interactive Visualization	NA:NA:NA:NA:NA:NA	2016
Muhammad Adnan:Mike Just:Lynne Baillie	Research on graphical perception of time series visualisations has focused on visual representation, and not on interaction. Even for visual representation, there has been limited study of the impact on users of visual encodings and the strengths and weaknesses of Cartesian and Polar coordinate systems. In order to address this research gap, we performed a comprehensive graphical perception study that measured the effectiveness of time series visualisations with different interactions, visual encodings and coordinate systems for several tasks. Our results show that, while positional and colour visual encodings were better for most tasks, area visual encoding performed better for data comparison. Most importantly, we identified that introducing interactivity within time series visualisations considerably enhances the user experience, without any loss of efficiency or accuracy. We believe that our findings can greatly improve the development of visual analytics tools using time series visualisations in a variety of domains.	Investigating Time Series Visualisations to Improve the User Experience	NA:NA:NA	2016
Stefania Pizza:Barry Brown:Donald McMillan:Airi Lampinen	In recent years, the smartwatch has returned as a form factor for mobile computing with some success. Yet it is not clear how smartwatches are used and integrated into everyday life differently from mobile phones. For this paper, we used wearable cameras to record twelve participants' daily use of smartwatches, collecting and analysing incidents where watches were used from over 34 days of user recording. This allows us to analyse in detail 1009 watch uses. Using the watch as a timepiece was the most common use, making up 50% of interactions, but only 14% of total watch usage time. The videos also let us examine why and how smartwatches are used for activity tracking, notifications, and in combination with smartphones. In discussion, we return to a key question in the study of mobile devices: how are smartwatches integrated into everyday life, in both the actions that we take and the social interactions we are part of?	Smartwatch in vivo	NA:NA:NA:NA	2016
Johannes Zagermann:Ulrike Pfeil:Roman RÃ¤dle:Hans-Christian Jetter:Clemens Klokmose:Harald Reiterer	Cross-device collaboration with tablets is an increasingly popular topic in HCI. Previous work has shown that tablet-only collaboration can be improved by an additional shared workspace on an interactive tabletop. However, large tabletops are costly and need space, raising the question to what extent the physical size of shared horizontal surfaces really pays off. In order to analyse the suitability of smaller-than-tabletop devices (e.g. tablets) as a low-cost alternative, we studied the effect of the size of a shared horizontal interactive workspace on users' attention, awareness, and efficiency during cross-device collaboration. In our study, 15 groups of two users executed a sensemaking task with two personal tablets (9.7") and a horizontal shared display of varying sizes (10.6", 27", and 55"). Our findings show that different sizes lead to differences in participants' interaction with the tabletop and in the groups' communication styles. To our own surprise we found that larger tabletops do not necessarily improve collaboration or sensemaking results, because they can divert users' attention away from their collaborators and towards the shared display.	When Tablets meet Tabletops: The Effect of Tabletop Size on Around-the-Table Collaboration with Personal Tablets	NA:NA:NA:NA:NA:NA	2016
Pei-Yu (Peggy) Chi:Yang Li:BjÃ¶rn Hartmann	Cross-device interactions involve input and output on multiple computing devices. Implementing and reasoning about interactions that cover multiple devices with a diversity of form factors and capabilities can be complex. To assist developers in programming cross-device interactions, we created DemoScript, a technique that automatically analyzes a cross-device interaction program while it is being written. DemoScript visually illustrates the step-by-step execution of a selected portion or the entire program with a novel, automatically generated cross-device storyboard visualization. In addition to helping developers understand the behavior of the program, DemoScript also allows developers to revise their program by interactively manipulating the cross-device storyboard. We evaluated DemoScript with 8 professional programmers and found that DemoScript significantly improved development efficiency by helping developers interpret and manage cross-device interaction; it also encourages testing to think through the script in a development process.	Enhancing Cross-Device Interaction Scripting with Interactive Illustrations	NA:NA:NA	2016
Michael Nebeling:Anind K. Dey	There is a significant gap in the body of research on cross-device interfaces. Research has largely focused on enabling them technically, but when and how users want to use cross-device interfaces is not well understood. This paper presents an exploratory user study with XDBrowser, a cross-device web browser we are developing to enable non-technical users to adapt existing single-device web interfaces for cross-device use while viewing them in the browser. We demonstrate that an end-user customization tool like XDBrowser is a powerful means to conduct user-driven elicitation studies useful for understanding user preferences and design requirements for cross-device interfaces. Our study with 15 participants elicited 144 desirable multi-device designs for five popular web interfaces when using two mobile devices in parallel. We describe the design space in this context, the usage scenarios targeted by users, the strategies used for designing cross-device interfaces, and seven concrete mobile multi-device design patterns that emerged. We discuss the method, compare the cross-device interfaces from our users and those defined by developers in prior work, and establish new requirements from observed user behavior. In particular, we identify the need to easily switch between different interface distributions depending on the task and to have more fine-grained control over synchronization.	XDBrowser: User-Defined Cross-Device Web Page Designs	NA:NA	2016
Meredith Ringel Morris:Annuska Zolyomi:Catherine Yao:Sina Bahram:Jeffrey P. Bigham:Shaun K. Kane	Social media is an increasingly important part of modern life. We investigate the use of and usability of Twitter by blind users, via a combination of surveys of blind Twitter users, large-scale analysis of tweets from and Twitter profiles of blind and sighted users, and analysis of tweets containing embedded imagery. While Twitter has traditionally been thought of as the most accessible social media platform for blind users, Twitter's increasing integration of image content and users' diverse uses for images have presented emergent accessibility challenges. Our findings illuminate the importance of the ability to use social media for people who are blind, while also highlighting the many challenges such media currently present this user base, including difficulty in creating profiles, in awareness of available features and settings, in controlling revelations of one's disability status, and in dealing with the increasing pervasiveness of image-based content. We propose changes that Twitter and other social platforms should make to promote fuller access to users with visual impairments.	"With most of it being pictures now, I rarely use it": Understanding Twitter's Evolving Accessibility to Blind Users	NA:NA:NA:NA:NA:NA	2016
Gloria Mark:Yiran Department of Informatics Wang:Melissa Niiya:Stephanie Reich	The amount of sleep college students receive has become a pressing societal concern. While studies show that information technology (IT) use affects sleep, here we examine the converse: how sleep duration might affect IT use. We conducted an in situ study, and logged computer and phone use and collected sleep diaries and daily surveys of 76 college students for seven days, all waking hours. We examined effects of sleep duration and sleep debt. Our results show that with less sleep, people report higher perceived work pressure and productivity. Also, computer focus duration is significantly shorter suggesting higher multitasking. The more sleep debt, the more Facebook use and the higher the negative mood. With less sleep, people may seek out activities requiring less attentional resources such as social media use. Our results have theoretical implications for multitasking: physiological and cognitive reasons could explain more computer activity switches: related to less sleep.	Sleep Debt in Student Life: Online Attention Focus, Facebook, and Mood	NA:NA:NA:NA	2016
Robin Brewer:Anne Marie Piper	While the majority of older adults are now active online, they are often perceived as passive consumers of online information rather than active creators of content. As a counter to this view, we examine the practices of older adult bloggers (N=20) through in-depth interviews. We study this group of older adults as a unique case of content creation and sharing. We find that the practice of creating and sharing through blogging meets several important psychological and social needs for older adults. Specifically, blogging supports the development of identity in older adulthood; fosters self-expression that supports older adults' values; provides meaningful engagement during retirement; and enables a sense of community and social interaction that is important for wellbeing in late-life. We argue for a focus on designing for late-life development and detail opportunities for online systems to better support the dynamic experience of growing older through online content creation and sharing.	"Tell It Like It Really Is": A Case of Online Content Creation and Sharing Among Older Adult Bloggers	NA:NA	2016
Venkata Rama Kiran Garimella:Abdulrahman Alfayad:Ingmar Weber	Several projects have shown the feasibility to use emph{textual} social media data to track public health concerns, such as temporal influenza patterns or geographical obesity patterns. In this paper, we look at whether geo-tagged emph{images} from Instagram also provide a viable data source. Especially for "lifestyle" diseases, such as obesity, drinking or smoking, images of social gatherings could provide information that is not necessarily shared in, say, tweets. In this study, we explore whether (i) tags provided by the users and (ii) annotations obtained via automatic image tagging are indeed valuable for studying public health. We find that both user-provided and machine-generated tags provide information that can be used to infer a county's health statistics. Whereas for most statistics user-provided tags are better features, for predicting excessive drinking machine-generated tags such as "liquid' and "glass' yield better models. This hints at the potential of using machine-generated tags to study substance abuse.	Social Media Image Analysis for Public Health	NA:NA:NA	2016
Corbin Reno:Erika S. Poole	A growing body of research has examined whether and how an individual can leverage online social networks to receive social support for health behavior change. This prior research largely focuses on attributes of the post content and the experiences and concerns of people posting. Less is known about moderators and mediators that influence whether and how one's social network will respond to a request for support. Using a factorial survey experiment, we find evidence that attitudes toward specific types of health behaviors greatly increase likelihood of response to a post, and that targeting close-tie relationships may increase effectiveness of social media based behavior change interventions, particularly related to smoking cessation.	It Matters If My Friends Stop Smoking: Social Support for Behavior Change in Social Media	NA:NA	2016
Mohammad M. Khajah:Brett D. Roads:Robert V. Lindsey:Yun-En Liu:Michael C. Mozer	We use Bayesian optimization methods to design games that maximize user engagement. Participants are paid to try a game for several minutes, at which point they can quit or continue to play voluntarily with no further compensation. Engagement is measured by player persistence, projections of how long others will play, and a post-game survey. Using Gaussian process surrogate-based optimization, we conduct efficient experiments to identify game design characteristics---specifically those influencing difficulty---that lead to maximal engagement. We study two games requiring trajectory planning, the difficulty of each is determined by a three-dimensional continuous design space. Two of the design dimensions manipulate the game in user-transparent manner (e.g., the spacing of obstacles), the third in a subtle and possibly covert manner (incremental trajectory corrections). Converging results indicate that overt difficulty manipulations are effective in modulating engagement only when combined with the covert manipulation, suggesting the critical role of a user's self-perception of competence.	Designing Engaging Games Using Bayesian Optimization	NA:NA:NA:NA:NA	2016
Madison Klarkowski:Daniel Johnson:Peta Wyeth:Mitchell McEwan:Cody Phillips:Simon Smith	The study examines the relationship of challenge-skill balance and the player experience through evaluation of competence, autonomy, presence, interest/enjoyment, and positive and negative affect states. To manipulate challenge-skill balance, three video game modes -- boredom (low challenge), balance (medium challenge), and overload (high challenge) -- were developed and experimentally tested (n = 45). The study showed that self-reported positive affect, autonomy, presence, and interest/enjoyment differed between the levels. The balance condition generally performed well in terms of positive player experiences, confirming the key role challenge-skill balance plays in designing for optimal play experiences. Interestingly, the study found significantly lower negative affect scores when playing the boredom condition. Greater feelings of competence were also reported for the boredom condition than the balance and overload conditions. Finally, some measures point to overload as a more enjoyable experience than boredom, suggesting possible player preference for challenge > skill imbalance over skill > challenge imbalance. Implications for design and future research are presented.	Operationalising and Evaluating Sub-Optimal and Optimal Play Experiences through Challenge-Skill Manipulation	NA:NA:NA:NA:NA:NA	2016
Jan D. Smeddinck:Regan L. Mandryk:Max V. Birk:Kathrin M. Gerling:Dietrich Barsilowski:Rainer Malaka	Matching game difficulty to player ability is a crucial step toward a rewarding player experience, yet making difficulty adjustments that are effective yet unobtrusive can be challenging. This paper examines the impact of automatic and player-initiated difficulty adjustment on player experience through two studies. In the first study, 40 participants played the casual game THYFTHYF either in motion-based or sedentary mode, using menu-based, embedded, or automatic difficulty adjustment. In the second study, we created an adapted version of the commercially available game fl0w to allow us to carry out a more focused study of sedentary casual play. Results from both studies demonstrate that the type of difficulty adjustment has an impact on perceived autonomy, but other player experience measures were not affected as expected. Our findings suggest that most players express a preference for manual difficulty choices, but that overall game experience was not notably impacted by automated difficulty adjustments.	How to Present Game Difficulty Choices?: Exploring the Impact on Player Experience	NA:NA:NA:NA:NA:NA	2016
Carl Gutwin:Christianne Rooke:Andy Cockburn:Regan L. Mandryk:Benjamin Lafreniere	The peak-end rule is a psychological heuristic observing that people's retrospective assessment of an experience is strongly influenced by the intensity of the peak and final moments of that experience. We examine how aspects of game player experience are influenced by peak-end manipulations to the sequence of events in games that are otherwise objectively identical. A first experiment examines players' retrospective assessments of two games (a pattern matching game based on Bejeweled and a point-and-click reaction game) when the sequence of difficulty is manipulated to induce positive, negative and neutral peak-end effects. A second experiment examines assessments of a shootout game in which the balance between challenge and skill is similarly manipulated. Results across the games show that recollection of challenge was strongly influenced by peak-end effects; however, results for fun, enjoyment, and preference to repeat were varied -- sometimes significantly in favour of the hypothesized effects, sometimes insignificant, but never against the hypothesis.	Peak-End Effects on Player Experience in Casual Games	NA:NA:NA:NA:NA	2016
Yoojung Kim:Sookyoung Ji:Hyunjeong Lee:Jeong-Whun Kim:Sooyoung Yoo:Joongseek Lee	By enabling people to track their lifestyles, including activity level, sleeping, and diet, technology helps clinicians to treat patients suffering from "lifestyle diseases." However, despite its importance compared to other lifestyle factors, it is not easy to record food intake consistently. Although researchers have attempted to solve this problem, most have not considered its applicability in the clinical context. In this paper, we aim to (1) understand food-journaling practices and (2) explore the applicability of lifestyle data in the clinical context. By observing 20 patients who recorded data including food logs, steps, and sleeping time, we found that patients recorded their food logs diligently, as they were conscious of clinicians. Clinicians were surprised by the high adherence rate of journaling and tried to overlap food data with other data, such as steps, sleeping time, etc. This paper contributes by providing qualitative insights for designing applicable strategies utilizing lifestyle data in the clinical context.	"My Doctor is Keeping an Eye on Me!": Exploring the Clinical Applicability of a Mobile Food Logger	NA:NA:NA:NA:NA:NA	2016
Daniel A. Epstein:Felicia Cordeiro:James Fogarty:Gary Hsieh:Sean A. Munson	Many people struggle with efforts to make healthy behavior changes, such as healthy eating. Several existing approaches promote healthy eating, but present high barriers and yield limited engagement. As a lightweight alternative approach to promoting mindful eating, we introduce and examine crumbs: daily food challenges completed by consuming one food that meets the challenge. We examine crumbs through developing and deploying the iPhone application Food4Thought. In a 3 week field study with 61 participants, crumbs supported engagement and mindfulness while offering opportunities to learn about food. Our 2x2 study compared nutrition versus non-nutrition crumbs coupled with social versus non-social features. Nutrition crumbs often felt more purposeful to participants, but non-nutrition crumbs increased mindfulness more than nutrition crumbs. Social features helped sustain engagement and were important for engagement with non-nutrition crumbs. Social features also enabled learning about the variety of foods other people use to meet a challenge.	Crumbs: Lightweight Daily Food Challenges to Promote Engagement and Mindfulness	NA:NA:NA:NA:NA	2016
Beenish M. Chaudhry:Christopher Schaefbauer:Ben Jelen:Katie A. Siek:Kay Connelly	Portion size estimation is important for managing dietary intake in many chronic conditions. We conducted a 6-week field study with nine varying literacy dialysis patients to explore the usability and feasibility of a dietary intake mobile application that emphasizes portion size estimation. Seven participants demonstrated sustained use of the application and improved their self-efficacy, knowledge, and ability to estimate portion sizes in pre- and post-study assessments. Participants reported moments when portion size information in the application differed from their prior understanding, challenging them to reconcile dissonant information. Although participants acquired new knowledge about portion sizes, they struggled to accurately estimate portion sizes in situ for most foods. Despite using the application consistently, rating it highly, and exhibiting learning, we found that self-efficacy and knowledge are not sufficient to support improved behaviors in everyday life.	Evaluation of a Food Portion Size Estimation Interface for a Varying Literacy Population	NA:NA:NA:NA:NA	2016
Xiaoyi Zhang:Laura R. Pina:James Fogarty	In situ self-report is widely used in human-computer interaction, ubiquitous computing, and for assessment and intervention in health and wellness. Unfortunately, it remains limited by high burdens. We examine unlock journaling as an alternative. Specifically, we build upon recent work to introduce single-slide unlock journaling gestures appropriate for health and wellness measures. We then present the first field study comparing unlock journaling with traditional diaries and notification-based reminders in self-report of health and wellness measures. We find unlock journaling is less intrusive than reminders, dramatically improves frequency of journaling, and can provide equal or better timeliness. Where appropriate to broader design needs, unlock journaling is thus an overall promising method for in situ self-report.	Examining Unlock Journaling with Diaries and Reminders for In Situ Self-Report in Health and Wellness	NA:NA:NA	2016
Panagiotis Tsiamyrtzis:Malcolm Dcosta:Dvijesh Shastri:Eswar Prasad:Ioannis Pavlidis	Electrodermal activity (EDA) is an important affective indicator, measured conventionally on the fingers with desktop sensing instruments. Recently, a new generation of wearable, battery-powered EDA devices came into being, encouraging the migration of EDA sensing to other body locations. To investigate the implications of such sensor/location shifts in psychophysiological studies we performed a validation experiment. In this experiment we used startle stimuli to instantaneously arouse the sympathetic system of n=23 subjects while sitting. Startle stimuli are standard but minimal stressors, and thus ideal for determining the sensor and location resolution limit. The experiment revealed that precise measurement of small EDA responses on the fingers and palm is feasible either with conventional or mobile EDA sensors. By contrast, precise measurement of small EDA responses on the sole is challenging, while on the wrist even detection of such responses is problematic for both EDA modalities. Given that affective wristbands have emerged as the dominant form of EDA sensing, researchers should beware of these limitations.	Delineating the Operational Envelope of Mobile and Conventional EDA Sensing on Key Body Locations	NA:NA:NA:NA:NA	2016
Mayank Goel:Elliot Saba:Maia Stiber:Eric Whitmire:Josh Fromm:Eric C. Larson:Gaetano Borriello:Shwetak N. Patel	Cost and accessibility have impeded the adoption of spirometers (devices that measure lung function) outside clinical settings, especially in low-resource environments. Prior work, called SpiroSmart, used a smartphone's built-in microphone as a spirometer. However, individuals in low- or middle-income countries do not typically have access to the latest smartphones. In this paper, we investigate how spirometry can be performed from any phone-using the standard telephony voice channel to transmit the sound of the spirometry effort. We also investigate how using a 3D printed vortex whistle can affect the accuracy of common spirometry measures and mitigate usability challenges. Our system, coined SpiroCall, was evaluated with 50 participants against two gold standard medical spirometers. We conclude that SpiroCall has an acceptable mean error with or without a whistle for performing spirometry, and advantages of each are discussed.	SpiroCall: Measuring Lung Function over a Phone Call	NA:NA:NA:NA:NA:NA:NA:NA	2016
Josua Krause:Adam Perer:Kenney Ng	Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these naÃ¯ve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why specific datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.	Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models	NA:NA:NA	2016
Joseph W. Newbold:Nadia Bianchi-Berthouze:Nicolas E. Gold:Ana Tajadura-JimÃ©nez:Amanda CdC Williams	In self-directed chronic pain physical rehabilitation it is important that the individual can progress as physical capabilities and confidence grow. However, people with chronic pain often struggle to pass what they have identified as safe boundaries. At the same time, over-activity due to the desire to progress fast or function more normally, may lead to setbacks. We investigate how musically-informed movement sonification can be used as an implicit mechanism to both avoid overdoing and facilitate progress during stretching exercises. We sonify an end target-point in a stretch exercise, using a stable sound (i.e., where the sonification is musically resolved) to encourage movements ending and an unstable sound (i.e., musically unresolved) to encourage continuation. Results on healthy participants show that instability leads to progression further beyond the target-point while stability leads to a smoother stop beyond this point. We conclude discussing how these findings should generalize to the CP population.	Musically Informed Sonification for Chronic Pain Rehabilitation: Facilitating Progress & Avoiding Over-Doing	NA:NA:NA:NA:NA	2016
Chuang-Wen You:Ya-Fang Lin:Cheng-Yuan Li:Yu-Lun Tsai:Ming-Chyi Huang:Chao-Hui Lee:Hao-Chuan Wang:Hao-Hua Chu	Ketamine is an addictive drug that has been shown to inflict considerable physical and mental damage on users. Due in part to its low cost, ketamine has become one of the most popular club drugs among young adults and teenagers in Southeast Asia. This paper proposes a phone-based support system (KeDiary) with Bluetooth-enabled device for the screening of saliva, as a means of assisting ketamine-dependent patients to self-monitor their ketamine use following acute withdrawal treatment. We also conducted a practical experiment to evaluate the feasibility of the proposed system, wherein three ketamine-dependent patients self-administered tests at least once per day over a period of three weeks. Follow-up interviews with the same users helped in the further refinement of the proposed self-monitoring system.	KeDiary: Using Mobile Phones to Assist Patients in Recovering from Drug Addiction	NA:NA:NA:NA:NA:NA:NA:NA	2016
Frank R. Bentley:Joseph 'Jofish' Kaye:David A. Shamma:John Alexis Guerra-Gomez	Temporal terms, such as 'winter', 'Christmas', or 'January' are often used in search queries for personal images. But how do people's memories and perceptions of time match with the actual dates when their images were captured? We compared the temporal terms that 74 Flickr users used to search their own photo collections, and compared them to the date captured data in the target image. We also conducted a larger study across several billion images, comparing user-applied tags for holidays and seasons to the dates the images were captured. We demonstrate that various query terms and tags can be in conflict with the actual dates photos were taken for specific types of temporal terms up to 40% of the time. We will conclude by highlighting implications for search systems where users are querying for personal content by date.	The 32 Days of Christmas: Understanding Temporal Intent in Image Search Queries	NA:NA:NA:NA	2016
Yanzhen Yue:Xiaojuan Ma:Zhenhui Jiang	Social product discovery is an emerging paradigm that enables users to seek information and inspiration from peer-contributed contents. Researchers have observed herd behaviors in social discovery, i.e., basing beliefs and decisions on what similarly situated others have done. In this paper, we explore the effects of content layout and motivation on users' herd behaviors in social discovery. We conduct an eye-tracking study with 120 participants to compare goal- and action-oriented users' behaviors on a grid versus waterfall style social discovery site. The results show that users have a higher tendency to herd on a grid-style website, more so for goal-oriented users.	Influence of Content Layout and Motivation on Users' Herd Behavior in Social Discovery	NA:NA:NA	2016
Saraschandra Karanam:Herre van Oostendorp	This study investigated the change in the content of the queries when performing reformulations in relation to age and task difficulty. Results showed that both generalization and specialization strategies were applied significantly more often for difficult tasks compared to simple tasks. Young participants were found to use specialization strategy significantly more often than old participants. Generalization strategy was also used significantly more often by young participants, especially for difficult tasks. Young participants were found to reformulate much longer than old participants. The semantic relevance of queries with the target information was found to be significantly higher for difficult tasks compared to simple tasks. It showed a decreasing trend across reformulations for old participants and remained constant for young participants, indicating that as old participants reformulated, they produced queries that were further away from the target information. Implications of these findings for design of information search systems are discussed.	Age-related Differences in the Content of Search Queries when Reformulating	NA:NA	2016
Tatyana Vasilevitsky:Amit Zoran	Many interactive devices use both machine elements and sensors, simultaneously but redundantly enabling and measuring the same physical function. We present Steel-Sense, an approach to joining these two families of elements to create a new type of HCI design primitive. We leverage recent developments in 3D printing to embed sensing in metal structures that are otherwise difficult to equip with sensors, and present four design principles, implementing (1) an electronic switch integrated within a ball bearing; (2) a voltage divider within a gear; (3) a variable capacitor embedded in a hinge; and (4) a pressure sensor within a screw. Each design demonstrates a different sensing principle, and signals its performance through (1) movement; (2) position; (3) angle (4) or stress. We mirror our elements physical performance in a virtual environment, evaluate our designs electronically and structurally, and discuss future work and implications for HCI research.	Steel-Sense: Integrating Machine Elements with Sensors by Additive Manufacturing	NA:NA	2016
Guanyun Wang:Lining Yao:Wen Wang:Jifei Ou:Chin-Yi Cheng:Hiroshi Ishii	To meet the increasing requirements of HCI researchers who are looking into using liquid-based materials (e.g., hydrogels) to create novel interfaces, we present a design strategy for HCI researchers to build and customize a liquid-based smart material printing platform with off-the-shelf or easy-to-machine parts. For the hardware, we suggest a magnetic assembly-based modular design. These modularized parts can be easily and precisely reconfigured with off-the-shelf or easy-to-machine parts that can meet different processing requirements such as mechanical mixing, chemical reaction, light activation, and solution vaporization. In addition, xPrint supports an open-source, highly customizable software design and simulation platform, which is applicable for simulating and facilitating smart material constructions. Furthermore, compared to inkjet or pneumatic syringe-based printing systems, xPrint has a large range of printable materials from synthesized polymers to natural micro-organism-living cells with a printing resolution from 10Î¼m up to 5mm (droplet size). In this paper, we will introduce the system design in detail and three use cases to demonstrate the material variability and the customizability for users with different demands (e.g., designers, scientific researchers, or artists).	xPrint: A Modularized Liquid Printer for Smart Materials Deposition	NA:NA:NA:NA:NA:NA	2016
Jifei Ou:Gershon Dublon:Chin-Yi Cheng:Felix Heibeck:Karl Willis:Hiroshi Ishii	This work presents a method for 3D printing hair-like structures on both flat and curved surfaces. It allows a user to design and fabricate hair geometries that are smaller than 100 micron. We built a software platform to let users quickly define the hair angle, thickness, density, and height. The ability to fabricate customized hair-like structures not only expands the library of 3D-printable shapes, but also enables us to design passive actuators and swipe sensors. We also present several applications that show how the 3D-printed hair can be used for designing everyday interactive objects.	Cilllia: 3D Printed Micro-Pillar Structures for Surface Texture, Actuation and Sensing	NA:NA:NA:NA:NA:NA	2016
Varun Perumal C:Daniel Wigdor	Foldem, a novel method of rapid fabrication of objects with multi-material properties is presented. Our specially formulated Foldem sheet allows users to fabricate and easily assemble objects with rigid, bendable, and flexible properties using a standard laser-cutter. The user begins by creating his designs in a vector graphics software package. A laser cutter is then used to fabricate the design by selectively ablating/vaporizing one or more layers of the Foldem sheet to achieve the desired physical properties for each joint. Herein the composition of the Foldem sheet, as well as various design considerations taken into account while building and designing the method, are described. Sample objects made with Foldem are demonstrated, each showcasing the unique attributes of Foldem. Additionally, a novel method for carefully calibrating a laser cutter for precise ablation is presented.	Foldem: Heterogeneous Object Fabrication via Selective Ablation of Multi-Material Sheets	NA:NA	2016
Bastian Pfleging:Drea K. Fekety:Albrecht Schmidt:Andrew L. Kun	In this paper, we present a proof-of-concept approach to estimating mental workload by measuring the user's pupil diameter under various controlled lighting conditions. Knowing the user's mental workload is desirable for many application scenarios, ranging from driving a car, to adaptive workplace setups. Typically, physiological sensors allow inferring mental workload, but these sensors might be rather uncomfortable to wear. Measuring pupil diameter through remote eye-tracking instead is an unobtrusive method. However, a practical eye-tracking-based system must also account for pupil changes due to variable lighting conditions. Based on the results of a study with tasks of varying mental demand and six different lighting conditions, we built a simple model that is able to infer the workload independently of the lighting condition in 75% of the tested conditions.	A Model Relating Pupil Diameter to Mental Workload and Lighting Conditions	NA:NA:NA:NA	2016
Baris Serim:Giulio Jacucci	We propose using eye tracking to support interface use with decreased reliance on visual guidance. While the design of most graphical user interfaces take visual guidance during manual input for granted, eye tracking allows distinguishing between the cases when the manual input is conducted with or without guidance. We conceptualize the latter cases as input with uncertainty that require separate handling. We describe the design space of input handling by utilizing input resources available to the system, possible actions the system can realize and various feedback techniques for informing the user. We demonstrate the particular action mechanisms and feedback techniques through three applications we developed for touch interaction on a large screen. We conducted a two stage study of positional accuracy during target acquisition with varying visual guidance, to determine the selection range around a touch point due to positional uncertainty. We also conducted a qualitative evaluation of example applications with participants to identify perceived utility and hand eye coordination challenges while using interfaces with decreased visual guidance.	Pointing while Looking Elsewhere: Designing for Varying Degrees of Visual Guidance during Manual Input	NA:NA	2016
Shahram Jalaliniya:Diako Mardanbegi	EyeGrip proposes a novel and yet simple technique of analysing eye movements for automatically detecting the user's objects of interest in a sequence of visual stimuli moving horizontally or vertically in front of the user's view. We assess the viability of this technique in a scenario where the user looks at a sequence of images moving horizontally on the display while the user's eye movements are tracked by an eye tracker. We conducted an experiment that shows the performance of the proposed approach. We also investigated the influence of the speed and maximum number of visible images in the screen, on the accuracy of EyeGrip. Based on the experiment results, we propose guidelines for designing EyeGrip-based interfaces. EyeGrip can be considered as an implicit gaze interaction technique with potential use in broad range of applications such as large screens, mobile devices and eyewear computers. In this paper, we demonstrate the rich capabilities of EyeGrip with two example applications: 1) a mind reading game, and 2) a picture selection system. Our study shows that by selecting an appropriate speed and maximum number of visible images in the screen the proposed method can be used in a fast scrolling task where the system accurately (87%) detects the moving images that are visually appealing to the user, stops the scrolling and brings the item(s) of interest back to the screen.	EyeGrip: Detecting Targets in a Series of Uni-directional Moving Objects Using Optokinetic Nystagmus Eye Movements	NA:NA	2016
Thomas Templier:Kenan Bektas:Richard H.R. Hahnloser	We introduce an image annotation approach for the analysis of volumetric electron microscopic imagery of brain tissue. The core task is to identify and link tubular objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain tissue. In our approach an individual 'flies' through the 3D data at a high speed and maintains eye gaze focus on a single neuronal fiber, aided by navigation with a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing). In a participant experiment we validate the approach by demonstrating a tracing accuracy of about the respective radiuses of the traced fibers with browsing speeds of up to 40 brain sections per second.	Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze	NA:NA:NA	2016
Sandy Claes:Karin Slegers:Andrew Vande Moere	As cycling is increasingly promoted as an environment-friendly, cheap and even fast alternative, there exists an increasing need to civically involve the potentially engaged and opinionated user group of cyclists. Therefore, we designed and evaluated Bicycle Barometer, an interactive bicycle count display that gathers the opinions from cyclists and conveys real-time, multi-dimensional data to them regarding cycling behavior. Our user-centered design process focused on optimizing the user experience by comparing several alternative cyclist-specific interaction designs, which resulted in the combination of a pressure sensitive floor mat, push button and low-resolution LED display. An in-the-wild evaluation study resulted in a set of design recommendations for cyclist-specific interaction, providing concrete insights into how a specifically targeted interaction method for public display is able to afford engagement and enthusiasm from a particular target audience.	The Bicycle Barometer: Design and Evaluation of Cyclist-Specific Interaction for a Public Display	NA:NA:NA	2016
Md. Sami Uddin:Carl Gutwin:Benjamin Lafreniere	Command selection on large multi-touch surfaces can be difficult, because the large surface means that there are few landmarks to help users build up familiarity with controls. However, people's hands and fingers are landmarks that are always present when interacting with a touch display. To explore the use of hands as landmarks, we designed two hand-centric techniques for multi-touch displays -- one allowing 42 commands, and one allowing 160 -- and tested them in an empirical comparison against standard tab widgets. We found that the small version (HandMark-Fingers) was significantly faster at all stages of use, and that the large version (HandMark-Multi) was slower at the start but equivalent to tabs after people gained experience with the technique. There was no difference in error rates, and participants strongly preferred both of the HandMark menus over tabs. We demonstrate that people's intimate knowledge of their hands can be the basis for fast and feasible interaction techniques that can improve the performance and usability of interactive tables and other multi-touch systems.	HandMark Menus: Rapid Command Selection and Large Command Sets on Multi-Touch Displays	NA:NA:NA	2016
Florian Perteneder:Eva-Maria Beatrix Grossauer:Joanne Leong:Wolfgang Stuerzlinger:Michael Haller	Ambient light is starting to be commercially used to enhance the viewing experience for watching TV. We believe that ambient light can add value in meeting and control rooms that use large vertical interactive surfaces. Therefore, we equipped a large interactive whiteboard with a peripheral ambient light display and explored its utility for different scenarios by conducting two controlled experiments. In the first experiment, we investigated how ambient light can be used for peripheral notifications, and how perception is influenced by the user's position and the type of work they are engaged in. The second experiment investigated the utility of ambient light for off-screen visualization. We condense our findings into several design recommendations that we then applied to application scenarios to show the versatility and usefulness of ambient light for large surfaces.	Glowworms and Fireflies: Ambient Light on Large Interactive Surfaces	NA:NA:NA:NA:NA	2016
Anders Markussen:Sebastian Boring:Mikkel R. Jakobsen:Kasper HornbÃ¦k	The size of information spaces often exceeds the limits of even the largest displays. This makes navigating such spaces through on-screen interactions demanding. However, if users imagine the information space extending in a plane beyond the display's boundaries, they might be able to use the space beyond the display for input. This paper investigates Off-Limits, an interaction concept extending the input space of a large display into the space beyond the screen through the use of mid-air pointing. We develop and evaluate the concept through three empirical studies in one-dimensional space: First, we explore benefits and limitations of off-screen pointing compared to touch interaction and mid-air on-screen pointing; next, we assess users' accuracy in off-screen pointing to model the distance-to-screen vs. accuracy trade-off; and finally, we show how Off-Limits is further improved by applying that model to the naÃ¯ve approach. Overall, we found that the final Off-Limits concept provides significant performance benefits over on-screen and touch pointing conditions.	Off-Limits: Interacting Beyond the Boundaries of Large Displays	NA:NA:NA:NA	2016
Lianne Kerlin:Jasmine Cox:Stephen Jolly:Michael Evans:George Green:David Regan	A physical hardware prototype--The Button was developed as a research probe to understand how radio audiences could discover, organise and consume music radio content at the touch of a physical button, the only control on a tiny handheld device. The Button allows listeners to tag tracks they like via a simple one-touch interaction method, and save them to a non-commercial online playlist service: BBC Playlister. Users can then export these tags to other music streaming platforms, such as Spotify, Deezer, etc. Following a user-centric design process, a large in-the-wild study was conducted over several weeks to investigate the value of the Button in aiding listeners' discovery of music. One group of participants was given a mobile phone app designed to facilitate tagging music heard on BBC radio stations; two other groups were given both the app and a Button (in one of two hardware versions). The findings revealed that Button users made significantly more tags on average than app users, indicating that a physical device could add significant value for radio listeners who want to tag music. Participants valued the simple one-touch interaction method, especially in situations where their smartphones were out of reach or contextual constraints meant that interaction with a complex device was undesirable or difficult.	Pressing Not Tapping: Comparing a Physical Button with a Smartphone App for Tagging Music in Radio Programmes	NA:NA:NA:NA:NA:NA	2016
Hanchuan Li:Eric Brockmeyer:Elizabeth J. Carter:Josh Fromm:Scott E. Hudson:Shwetak N. Patel:Alanson Sample	We describe techniques that allow inexpensive, ultra-thin, battery-free Radio Frequency Identification (RFID) tags to be turned into simple paper input devices. We use sensing and signal processing techniques that determine how a tag is being manipulated by the user via an RFID reader and show how tags may be enhanced with a simple set of conductive traces that can be printed on paper, stencil-traced, or even hand-drawn. These traces modify the behavior of contiguous tags to serve as input devices. Our techniques provide the capability to use off-the-shelf RFID tags to sense touch, cover, overlap of tags by conductive or dielectric (insulating) materials, and tag movement trajectories. Paper prototypes can be made functional in seconds. Due to the rapid deployability and low cost of the tags used, we can create a new class of interactive paper devices that are drawn on demand for simple tasks. These capabilities allow new interactive possibilities for pop-up books and other papercraft objects.	PaperID: A Technique for Drawing Functional Battery-Free Wireless Interfaces on Paper	NA:NA:NA:NA:NA:NA:NA	2016
Andrew Spielberg:Alanson Sample:Scott E. Hudson:Jennifer Mankoff:James McCann	RFID tags can be used to add inexpensive, wireless, batteryless sensing to objects. However, quickly and accurately estimating the state of an RFID tag is difficult. In this work, we show how to achieve low-latency manipulation and movement sensing with off-the-shelf RFID tags and readers. Our approach couples a probabilistic filtering layer with a monte-carlo-sampling-based interaction layer, preserving uncertainty in tag reads until they can be resolved in the context of interactions. This allows designers' code to reason about inputs at a high level. We demonstrate the effectiveness of our approach with a number of interactive objects, along with a library of components that can be combined to make new designs.	RapID: A Framework for Fabricating Low-Latency Interactive Objects with RFID Tags	NA:NA:NA:NA:NA	2016
Adrian A. de Freitas:Michael Nebeling:Xiang 'Anthony' Chen:Junrui Yang:Akshaye Shreenithi Kirupa Karthikeyan Ranithangam:Anind K. Dey	The ability to quickly interact with any nearby appliance from a mobile device would allow people to perform a wide range of one-time tasks (e.g., printing a document in an unfamiliar office location). However, users currently lack this capability, and must instead manually configure their devices for each appliance they want to use. To address this problem, we created Snap-To-It, a system that allows users to opportunistically interact with any appliance simply by taking a picture of it. Snap-To-It shares the image of the appliance a user wants to interact with over a local area network. Appliances then analyze this image (along with the user's location and device orientation) to see if they are being "selected," and deliver the corresponding control interface to the user's mobile device. Snap-To-It's design was informed by two technology probes that explored how users would like to select and interact with appliances using their mobile phone. These studies highlighted the need to be able to select hardware and software via a camera, and identified several novel use cases not supported by existing systems (e.g., interacting with disconnected objects, transferring settings between appliances). In this paper, we show how Snap-To-It's design is informed by our probes and how developers can utilize our system. We then show that Snap-To-It can identify appliances with over 95.3% accuracy, and demonstrate through a two-month deployment that our approach is robust to gradual changes to the environment.	Snap-To-It: A User-Inspired Platform for Opportunistic Device Interactions	NA:NA:NA:NA:NA:NA	2016
Tara Matthews:Kerwell Liao:Anna Turner:Marianne Berkovich:Robert Reeder:Sunny Consolvo	Many technologies assume a single user will use an account or device. But account and device sharing situations (when 2+ people use a single device or account) may arise during everyday life. We present results from a multiple-methods study of device and account sharing practices among household members and their relations. Among our findings are that device and account sharing was common, and mobile phones were often shared despite being considered "personal" devices. Based on our study results, we organize sharing practices into a taxonomy of six sharing types--distinct patterns of what, why, and how people shared. We also present two themes that cut across sharing types: that (1) trust in sharees and (2) convenience highly influenced sharing practices. Based on these findings, we discuss implications for study and technology design.	"She'll just grab any device that's closer": A Study of Everyday Device & Account Sharing in Households	NA:NA:NA:NA:NA:NA	2016
Joel E. Fischer:Andy Crabtree:Tom Rodden:James A. Colley:Enrico Costanza:Michael O. Jewell:Sarvapali D. Ramchurn	This paper presents findings from a co-design project that aims to augment the practices of professional energy advisors with environmental data from sensors deployed in clients' homes. Premised on prior ethnographic observations we prototyped a sensor platform to support the work of tailoring advice-giving to particular homes. We report on the deployment process and the findings to emerge, particularly the work involved in making sense of or accounting for the data in the course of advice-giving. Our ethnomethodological analysis focuses on the ways in which data is drawn upon as a resource in the home visit, and how understanding and advice-giving turns upon unpacking the indexical relationship of the data to the situated goings-on in the home. This insight, coupled with further design workshops with the advisors, shaped requirements for an interactive system that makes the sensor data available for visual inspection and annotation to support the situated sense-making that is key to giving energy advice.	"Just whack it on until it gets hot": Working with IoT Data in the Home	NA:NA:NA:NA:NA:NA:NA	2016
Daisuke Uriu:William Odom	We describe the design, implementation, and deployment of Fenestra, a domestic technology embodied in the form of a wirelessly connected round mirror, photo frame, and candle that displays photos of departed loved ones. Fenestra's interaction design, form, and materials are inspired by Japanese domestic practices of memorializing departed loved ones with a home altar called butsudan. We deployed Fenestra in three Japanese households to explore how this design artifact might support everyday domestic practices of memorialization, and where complications might potentially emerge. Findings reveal that a range of outcomes emerged across our participants' experiences of living with Fenestra--from profound remembrance to unexpected uses to unsettling encounters. These findings are interpreted to present opportunities for future research and practice initiatives in the HCI community.	Designing for Domestic Memorialization and Remembrance: A Field Study of Fenestra in Japan	NA:NA	2016
Sarah Mennicken:David Kim:Elaine May Huang	With the growing adoption of smart home technologies, inhabitants are faced with the challenge of making sense of the data that their homes can collect to configure automated behaviors that benefit their routines. Current commercial smart home interfaces usually provide information on individual devices instead of a more comprehensive overview of a home's behavior. To reduce the complexity of smart home data and integrate it better into inhabitants' lives, we turned to the familiar metaphor of a calendar and developed our smart home interface Casalendar. In order to investigate the concept and evaluate our goals to facilitate the understanding of smart home data, we created a prototype that we installed in two commercial smart homes for a month. The results we present in this paper are based on our analysis of user data from questionnaires, semi-structured interviews, participant-driven audio and screenshot feedback as well as logged interactions with our system. Our findings exposed advantages and disadvantages of this metaphor, emerging usage patterns, privacy concerns and challenges for information visualization. We further report on implications for design and open challenges we revealed through this work.	Integrating the Smart Home into the Digital Calendar	NA:NA:NA	2016
Vasiliki Tsaknaki:Ylva Fernaeus	The material foundations of computer systems and interactive technology is a topic that gained an increased interest within the HCI community during the last years. In this paper we discuss this topic through the Japanese concept of Wabi-Sabi, a philosophy that embraces three basic realities of the material world: 'nothing lasts', 'nothing is finished', and 'nothing is perfect'. We use these concepts to reflect on four unique interactive artefacts, which all in different ways embrace aspects of Wabi-Sabi, in terms of their design gestalt, materiality, but also in terms of use practices. Further, we use our analysis to articulate three high-level principles that may help addressing the long-term realities faced in physical interaction design, and for the design of interactive systems in general.	Expanding on Wabi-Sabi as a Design Resource in HCI	NA:NA	2016
Tamara Anna Efrat:Moran Mizrahi:Amit Zoran	The digital design space, unlimited by its virtual freedom, differs from traditional craft, which is bounded by a fixed set of given materials. We study how to introduce parametric design tools to craftspersons. Our hypothesis is that the arrangement of parametric design in modular representation, in the form of a catalog, can assist makers unfamiliar with this practice. We evaluate this assumption in the realm of bag design, through a Honeycomb Smocking Pattern Catalog and custom Computer-Aided Smocking (CAS) design software. We describe the technical work and designs made with our tools, present a user study that validates our assumptions, and conclude with ideas for future work developing additional tools to bridge computational design and craft.	The Hybrid Bricolage: Bridging Parametric Design with Craft through Algorithmic Modularity	NA:NA:NA	2016
Madeline Gannon:Tovi Grossman:George Fitzmaurice	There is a long tradition for crafting wearable objects directly on the body, such as garments, casts, and orthotics. However, these high-skill, analog practices have yet to be augmented by digital fabrication techniques. In this paper, we explore the use of hybrid fabrication workflows for on-body printing. We outline design considerations for creating on-body fabrication systems, and identify several human, machine, and material challenges unique to this endeavor. Based on our explorations, we present ExoSkin, a hybrid fabrication system for designing and printing digital artifacts directly on the body. ExoSkin utilizes a custom built fabrication machine designed specifically for on-body printing. We demonstrate the potential of on-body fabrication with a set of sample workflows, and share feedback from initial observation sessions.	ExoSkin: On-Body Fabrication	NA:NA:NA	2016
Hidekazu Saegusa:Thomas Tran:Daniela K. Rosner	This paper examines the collaborative process of developing Arc, a computer numerical controlled (CNC) engraving tool for ceramics that offers a new window onto traditional forms of craft. In reflecting on this case and scholarship from the social sciences, we make two contributions. First, we show that fabrication tools may integrate multiple and distinct roles (as copiers, translators and connectors) in their production of form, selectively limiting the agency of the maker and machine. Second, we situate small-scale manufacturing in a wider historical context of "mimetic machinery": machines for mechanical reproduction that draw their symbolic power from a material connection with the phenomena represented (in this case, sound and gesture). We end by sharing lessons learned for fabrication research based on this study.	Mimetic Machines: Collaborative Interventions in Digital Fabrication with Arc	NA:NA:NA	2016
Elena MÃ¡rquez Segura:Laia Turmo Vidal:Asreen Rostami:Annika Waern	Designing bodily experiences is challenging. In this paper, we propose embodied sketching as a way of practicing design that involves understanding and designing for bodily experiences early in the design process. Embodied sketching encompasses ideation methods that are grounded in, and inspired by, the lived experience and includes the social and spatial settings as design resources in the sketching. Embodied sketching is also based on harnessing play and playfulness as the principal way to elicit creative physical engagement. We present three different ways to implement and use embodied sketching in the application domain of co-located social play. These include bodystorming of ideas, co-designing with users, and sensitizing designers. The latter helps to uncover and articulate significant, as well as novel embodied experiences, whilst the first two are useful for developing a better understanding of possible design resources.	Embodied Sketching	NA:NA:NA:NA	2016
Laura Devendorf:Joanne Lo:Noura Howell:Jung Lin Lee:Nan-Wei Gong:M. Emre Karagozler:Shiho Fukuhara:Ivan Poupyrev:Eric Paulos:Kimiko Ryokai	This paper explores the role dynamic textile displays play in relation to personal style: What does it mean to wear computationally responsive clothing and why would one be motivated to do so? We developed a novel textile display technology, called Ebb, and created several woven and crochet fabric swatches that explored clothing-specific design possibilities. We engaged fashion designers and non-designers in imagining how Ebb would integrate into their design practice or personal style of dressing. Participants evaluated the appeal and utility of clothing-based displays according to a very different set of criteria than traditional screen-based computational displays. Specifically, the slowness, low-resolution, and volatility of Ebb tended to be seen as assets as opposed to technical limitations in the context of personal style. Additionally, participants envisioned various ways that ambiguous, ambient, and abstract displays of information could prompt new experiences in their everyday lives. Our paper details the complex relationships between display and personal style and offers a new design metaphor and extension of Gaver et al.'s original descriptions of ambiguity in order to guide the design of clothing-based displays for everyday life.	"I don't Want to Wear a Screen": Probing Perceptions of and Possibilities for Dynamic Displays on Clothing	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2016
Jaemyung Shin:Bumsoo Kang:Taiwoo Park:Jina Huh:Jinhan Kim:Junehwa Song	Research shows the critical role of social relationships in behavior change, and the advancement of mobile technologies brings new opportunities of using online social support for persuasive applications. In this paper, we propose Relational Norm Intervention (RNI) model for behavior change, which involves two individuals as a target user and a helper respectively. RNI model uses Negative Reinforcement and Other-Regarding Preferences as motivating factors for behavior change. The model features the passive participation of a helper who will undergo artificially generated discomforts (e.g., limited access to a mobile device) when a target user performs against a target behavior. Based on in-depth discussions from a two-phase design workshop, we designed and implemented BeUpright, a mobile application employing RNI model to correct sitting posture of a target user. Also, we conducted a two-week study to evaluate the effectiveness and user experience of BeUpright. The study showed that the RNI model has a potential to increase efficacy, in terms of behavior change, compared to conventional notification approaches. The most influential factor of RNI model in the changing the behavior of target users was the intention to avoid discomforting their helpers. RNI model also showed a potential to help unmotivated individuals in behavior change. We discuss the mechanism of the RNI model in relation to prior literature on behavior change and implications of exploiting discomfort in mobile behavior change services.	BeUpright: Posture Correction Using Relational Norm Intervention	NA:NA:NA:NA:NA:NA	2016
Sang-won Leigh:Pattie Maes	Physical interfaces with actuation capability enable the design of wearable devices that augment human physical capabilities. Extra machine joints integrated to our biological body may allow us to achieve additional skills through programmatic reconfiguration of the joints. To that end, we present a wearable multi-joint interface that offers "synergistic interactions" by providing additional fingers, structural supports, and physical user interfaces. Motions of the machine joints can be controlled via interfacing with our muscle signals, as a direct extension of our body. On the basis of implemented applications, we demonstrate our design guidelines for creating a desirable human-machine synergy -- that enhances our innate capabilities, not replacing or obstructing, and also without enforcing the augmentation. Finally we describe technical details of our muscle-based control method and implementations of the presented applications.	Body Integrated Programmable Joints Interface	NA:NA	2016
