Junfeng Yao:Xiaobiao Xie:Ming Zhang:Hui Zhang:Andy Ju An Wang	In recent years, virtual reality is experiencing a rapid development, which is also applied in plant morphology simulation. With a variety dynamic process of blooming, you are not only able to create a virtual landscape but to decorate a virtual space. In the internet, people can enjoy flowering anytime and anywhere to promote flower exhibitions and business. This paper focuses on the botanical characteristics of blooming process and creates a vivid effect based on Bezier curves and surfaces theory.	A 3-D flowering simulation based on botany characteristics and random generation algorithm	NA:NA:NA:NA:NA	2010
Shunsuke Matsuyama:Hironori Mitake:Shoichi Hasegawa	Recent progress of interactive techniques brought intuitive and physical interaction with characters in entertainment field such as console games. Conventional motion generation method requires preparing an enormous number of motion patterns in order to implement various reactions of characters. Therefore, for an easy way of implementation of various reactions, virtual creatures with sensorimotor models will become useful. Virtual creatures [Mitake et al. 2007] are characters with sensorimotor models generate motion in physics simulation environment.	A development environment for designing interactive characters with sensorimotor models	NA:NA:NA	2010
Aria Shahingohar:Roy Eagleson	The simulation of needle insertion is an important research area that has many applications in robotic and image guided brachytherapy cancer treatment, biopsies, and neurosurgery. Modeling of soft tissue plays an important role in the needle insertion simulation, but the use of Finite Element Method is complicated due to the need for remeshing in the neighbourhood of the needle tip. We are proposing to use a meshfree method for the tissue deformation modeling, in which new tissue nodes are added on the needle shaft as the needle is inserted into the tissue. In addition, we have utilized Nvidia's CUDA technology to accelerate the methods used in our framework.	A framework for GPU accelerated needle insertion simulation using meshfree methods	NA:NA	2010
Hirofumi Suda:Kentaro Yamanaka:Shigeo Morishima	We propose a skinning technique to improve expressive power of Skeleton Subspace Deformation (SSD) by adding the influence of the shape of skeletons to the deformation result by post-processing.	A skinning technique considering the shape of human skeletons	NA:NA:NA	2010
Michael Berger:Gregor Hofer:Hiroshi Shimodaira	Facial animation is difficult to do convincingly. The movements of the face are complex and subtle, and we are innately attuned to faces. It is particularly difficult and labor-intensive to accurately synchronize faces with speech. A technology-based solution to this problem is automated facial animation. There are various ways to automate facial animation, each of which drives a face from some input sequence. In performance-driven animation, the input sequence may be either facial motion capture or video of a face. In automatic lip-syncing, the input is audio (and possibly a text transcript), resulting in facial animation synchronized with that audio. In audio-visual text-to-speech synthesis (AVTTS), only text is input, and synchronous auditory and visual speech are synthesized.	Carnival: a modular framework for automated facial animation	NA:NA:NA	2010
D. Kravtsov:O. Fryazinov:V. Adzhiev:A. Pasko:P. Comninos	Polygonal models are widely used in computer animation. Static polygonal models are commonly animated using an underlying skeleton controlling the deformation of the mesh. This technique known as skeletal animation allows the artist to produce complex animation sequences in a relatively easy way. However, performing complex transitions between arbitrary animated meshes remains a challenging problem. There is a set of established techniques to perform metamorphosis (3D morphing) between static 3D meshes [Lazarus and Verroust 1998], but most of these can not be easily applied to animated meshes. The approach presented in this poster allows us to produce with great ease metamorphosing transitions between animated meshes of arbitrary topology using polygonal functional hybrids [Kravtsov et al. 2010].	Controlled metamorphosis of animated meshes using polygonal-functional hybrids	NA:NA:NA:NA:NA	2010
Hiroaki Gohara:Shiori Sugimoto:Shigeo Morishima	In anime production, some key-frames are drawn by artist precisely and then a great number of in-betweening frames are drawn by assistants' hands. However, it is seriously time-consuming and skilled work to draw many characters especially including face rotation. In this paper, we propose an automatic in-betweening technique for rotating face of hand drawn character only from a front image and a diagonal image (Fig.1). Baxter [2009] represented generating in-betweening using image morphing technique. However, their approach doesn't consider reflecting the artist's style and touch. Accordingly, we represent reflecting style and touch using morphing technique trained by his own database and introduced especially to generate a rotational in-betweening faces. This database contains center of gravity of each part (right eye, left eye, nose, mouth, eyebrow) and the contours on the facial image.	Data driven in-betweening for hand drawn rotating face	NA:NA:NA	2010
Michael J. Gourlay	Modeling continuous media such as fluids remains an elusive goal for interactive simulations. Fluids are particularly challenging because of the complexity imparted by the non-linear equations of motion, and the difficulty in creating stable simulations that retain spatial detail.	Fluid-body simulations using vortex particle operations	NA	2010
Dung A. Nguyen:Zhaoyang Wang	A 3D motion capturing and reconstructing system at high speed is presented. The system utilizes the fringe projection technique with one modified DLP projector, one camera and a computing unit to provide real-time reconstruction of forty-two 3D frames per second with the relative accuracy of 1/5000.	High speed 3D shape and motion capturing system	NA:NA	2010
Meredith McLendon:Ann McNamara:Tim McLaughlin:Ravindra Dwivedi	A digital creature's performance can be thought of as a combination of specifically defined motion and form; a combination that allows the viewer to comprehend the creature's action and intent. Computer graphics offers a variety of methods for defining motion including key-frame animation, data-driven action, rule-based and physically-based motion. However, all of these methods can be complex and time-consuming to implement. Essentially, most computer animation methods force the animator to think about motion at a low-level of abstraction. To create animation tools that simplify the process of creating expressive motion, we need to allow animators to work at a high-level of abstraction. We need determine the minimal elements of form and motion that visually communicate a maximal amount of information about an actor's identity or intentions. By attaching small reflective objects to joint pivot locations and recording at high contrast [Johansson 1973] developed a method for isolating motion from form as a collection of particles, now commonly known as a Point-Light Display (PLD). Manipulating this minimized visual information can even affect the perceived gender of PLD walkers. Cutting [1978] found that exaggerating the movement of points representing the hips and shoulders can bias gender recognition. The goal of our study was to investigate whether viewers use similar visual information to recognize expressive characteristics in animal motion PLDs as when viewing full representations and discover how it might be possible to use that visual information to influence the viewer's perception.	Lions and tigers and bears: investigating cues for expressive creature motion	NA:NA:NA:NA	2010
Gregor Hofer:Korin Richmond:Michael Berger	Talking computer animated characters are a common sight in video games and movies. Although doing the mouth animation by hand gives the best results it is not always feasible because of cost or time constraints. Therefore producing lip animation automatically is highly desirable. The problem can therefore be phrased as mapping from speech to lip animation or in other words as an acoustic inversion. In our work we propose a solution that takes a sequence of input frames of speech and maps it directly to an output sequence of animation frames. The key point is that there is no need for phonemes or visemes which cuts one step in the usual lip synchronization process.	Lip synchronization by acoustic inversion	NA:NA:NA	2010
Sriranjan Rasakatla:K. Madhava Krishna:Bipin Indurkhya	The Modular Legged robotic system [1] "Mod-Leg" presented here has been bio-inspired from a Snake's vertebrae and a caterpillar's legged structure. The system can be configured to a 4-legged robotic dog, a hexapod, a caterpillar and a Snake robot. This robot's novel design achieves compliance to the terrain using a combination of legs and electronically actuated universal spine. A unique simulator has been designed for this purpose. Some of the things we learned while developing this robotic system have been presented below.	"Mod-Leg" a modular legged robotic system	NA:NA:NA	2010
Adriana Schulz:Marcelo Cicconet:Luiz Velho	The one-way road leading music to motion has many manifestations. Choreographers build dance movements to match music features, subway passengers tap their feet following their iPod song hits, and the number one rule at any party is: if you wanna dance, dance to the music!	Motion scoring	NA:NA:NA	2010
Takeshi Miura:Kazutaka Mitobe:Takaaki Kaiga:Takashi Yukawa:Toshiyuki Taniguchi:Hideo Tamamoto:Noboru Yoshimura	It has been recognized that a technique to divide a raw motion-capture data stream of a dance into segments on the time axis is needed [Sonoda 2008]. In particular, the extraction of the higher-level information such as the hierarchical segmentation-structure is a subject of growing interest at the present time. In this study, the authors attempt to develop a method to segment dance motion in a multi-level style, namely in a hierarchical fashion.	Multi-level segmentation of dance motion by piecewise regression	NA:NA:NA:NA:NA:NA:NA	2010
Shoji Kunitomo:Shinsuke Nakamura:Shigeo Morishima	Realistic drape and motion of virtual clothing is now possible by using an up-to-date cloth simulator, but it is even difficult and time consuming to adjust and tune many parameters to achieve an authentic looking of a real particular fabric. Bhat et al. [2003] proposed a way to estimate the parameters from the video data of real fabrics. However, this projects structured light patterns on the fabrics, so it might not be possible to estimate the accurate value of the parameters if fabrics have colors and textures. In addition to the structured light patterns, they use a motion capture system to track how the fabrics move. In this paper, we will introduce a new method using only a motion capture system by attaching a few markers on fabric surface without any other devices. Moreover, animators can easily estimate the parameters of many kinds of fabrics with this method. Authentic looking and motion of simulated fabrics are realized by minimizing error function between captured motion data and synthetic motion considering both static and dynamic cloth features.	Optimization of cloth simulation parameters by considering static and dynamic features	NA:NA:NA	2010
Fiona Rivera:Phil Watten:Patrick Holroyd:Felix Beacher:Katerina Mania:Hugo Critchley	This research concentrates on providing high fidelity animation, only achievable with offline rendering solutions, for interactive fMRI-based experiments. Virtual characters are well established within the film, game and research worlds, yet much remains to be learned about which design, stylistic or behavioural factors combine to make a believable character. The definition of believability depends on context. When designing and implementing characters for entertainment, the concern is making believable characters that the audience will engage with. When using virtual characters in experiments, the aim is to create characters and synthetic spaces that people respond to in a similar manner to their real world counterparts. Research has shown that users show empathy for virtual characters. However, uncanny valley effects -- ie dips in user impressions -- can arise: behavioural fidelity expectations increase alongside increases in visual fidelity and vice versa. Often, characters used within virtual environments tend to be of fairly low fidelity due to technological constraints including rendering in real-time (Garau et al. 2003). This problem is addressed here by using non-linear playback and compositing of pre-rendered high fidelity sequences.	Real-time compositing framework for interactive stereo fMRI displays	NA:NA:NA:NA:NA:NA	2010
Cheng-Te Li:Hsun-Ping Hsieh:Tsung-Ting Kuo:Shou-De Lin	The goal of crowd simulation is to produce potential collective behaviors by simulating the movement process of a number of characters or agents. Some famous models are proposed to simulate crowd, including social force (e.g. [Helbing 2000]), cellular automata (e.g. [Chenny 2004]), and rule-based models (e.g. [Reynolds 1987]). Others use physiological (e.g. locomotion, energy level) and psychological (e.g. impatience, personality attributes) traits of agents to trigger heterogeneous behaviors [Pelechano 2007]. However, existing approaches do not consider the real-world social interactions among agents, and thus are unable to produce social-dependent scenarios. In this work, we propose to leverage the underlying social network, which captures social relationships among agents, for crowd simulation. A novel social-network-based framework, SocioCrowd, is developed (figure 1(a)) shows the virtual world). Based on SocioCrowd, we simulate three social-based scenarios, including community-guided flocking, following leading persons, and spatio-social information spreading. They display certain real-world social behaviors which are hardly modeled by existing methods. To lift the performance, our SocioCrowd is implemented by pure Java with GPU programming in ways of GSGL and JCUDA.	SocioCrowd: a social-network-based framework for crowd simulation	NA:NA:NA:NA	2010
Nobuhiko Mukai:Kentaro Ito:Masashi Nakagawa:Makoto Kosugi	One of the most challenging issues of computer graphics is to represent the behavior of fluid. Visualizing the fluid behavior requires to solve Navier-Stokes equations, which take huge amount of time so that some researches use many super computers for the simulation, and others utilize the GPU performance. The common fluid is Newtonian that can be described by a single constant value of viscosity, and there are many researches related to Newtonian. On the other hand, there is another type of fluid called non-Newtonian that cannot be described easily, and one of non-Newtonians is viscoelactic fluid. Viscoelastic fluid has the characteristics of both viscosity of fluid and elasticity of solid, and it is difficult to represent the behavior of viscoelastic fluid. [Goktekin et al. 2004] represented the behavior of viscoelastic fluid. His technique is based on Eulerian methods and added elastic terms to Navier-stokes equations, which govern fluid behavior. [Clavet et al. 2005] used particle method for representing fluid behavior. Particle method can represent fine behavior of the fluid such as rain drops, fountains, clay manipulation. Their researches could visualize many types of behavior of viscoelastic fluid, however, they cannot represent the spinnability, which has three characteristics: 1) it stretches very thin as if it is a string, 2) the radius is getting smaller gradually from the both ends and the center part has the least radius, and 3) it shrinks rapidly as if it is a rubber.	Spinnability simulation of viscoelastic fluid	NA:NA:NA:NA	2010
Daniele Federico:Damien Fagnou:Tom Reed	The creation of animation clips and the tweaking of existing character animation is often a tedious, time-consuming task, especially in large-scale CG productions. Traditionally these tasks were achieved by animators manually changing multiple keyframe values for all the relevant animation rig controls. Starting with the idea that a single animated object (e.g. a rig control) essentially defines a time-varying curve in 3D space - where the control points are defined by the keyframe values of the translation channels - we introduce a modeling approach for deforming these conceptual 3D curves. We will talk about our current implementation based on FFDs (Free Form Deformations) as described in [Sederberg and Parry 1986], but we strongly believe the same approach can have many other usages (e.g. modeling tools, collisions and obstacle avoidance).	Warping the space around an animated object	NA:NA:NA	2010
Paul D. Solt	Creating digital artwork requires a lot of time, talent, and effort from artists and programmers. It takes artists hours to design pleasing artwork and programmers even more time as they develop and debug complex graphics shaders. One way to aid in the creation of complex art is to use evolutionary computing called genetic programming. Genetic programming can be used to create mathematical expressions that can be rendered as an image. The image can be used as a texture in a 3D scene or as a starting point for additional artwork.	Artwork evolution	NA	2010
Young-Mi Kim:Jong-Soo Choi	This paper is about the study on an artwork, a black-and white drawing that has been expressed through a digital algorithm. Black-white drawings were popular during the Chosun era (1392--1910) reigned by kings and officials. The Oriental fine art, pursuing harmony with nature, is expressed in a moderate and restrained way, hence anyone would find it very soft and thus readily acceptable. Unlike the western paintings that fill the canvus to the very full, the oriental paintings treat even the blank space as a part making up a balanced painting. This artwork features Daegum, the decent traditional musical instrument which used to be played in loyal palaces or guest rooms of prestigious officials' residences, and a bamboo which was a frequent motive of gentlemen's paintings in the past. Daegum and the bamboo, expressed in a modern style in this work, make people appreciate the life that is full and rich. So, one can say they have been used here to make this "well-being art."	Breathe brush	NA:NA	2010
Daniel Tauber	I present a custom software for typing experiences that opposed to linear word processing renders visible individual writing styles on a personal computer using responsive typography in order to achieve a unique and personal representation of text analogous to handwriting.	Digital writing ductus: a visual representation of individual writing styles	NA	2010
Young-Mi Kim:Jong-Soo Choi	During the old days in the orient, people used to wipe cymbidium leaves or painted cymbidium for mental training by having a cymbidium always by their side. Through the act of wiping cymbidium leaves with utmost care, a cymbidium instilled with ancient philosophical ideas is visualized, and just as God breathed life into human nostrils and created a living life form, if a breath is breathed into a cymbidium flower, a cymbidium flower with an excellent fragrance is visualized. This work is an interactive visualization of an oriental cymbidium using modern technology which our oriental ancestors painted for mental training.	Ink-and-wash painting oriental cymbidium drawn with the tip of the fingers	NA:NA	2010
Özge Samanci:Anuj Tewari	In the digital era, the comics medium is transported from print to computer screen. Current digital comics (web comics or online comics) are confined to computer screen and use the affordances of digital medium in a limited way. GPS Comics: Seeing thru Walls is a GPS based comics story that expands the comic canvas and explores the idea of location-based comics. In Seeing thru Walls, in order to receive the meaning in a comic frame the player must experience a sensory detail (a smell, sound, breeze or an object) in her surroundings in the physical world. The concept of location-based comics is an unexplored idea and gives artists new meaning making strategies.	GPS comics: seeing thru walls	NA:NA	2010
Cem Sina Cetin	Graphic artists have a wide variety of applications to use for digital painting. Although each application has its own solution to enhance the user experience, most of them rely on the same standard feature; a single brush, which is completely dependent on user input for location. Although this is required for a fully controlled painting process, making small changes on this feature yields unpredictable results. My proposal for an alternate brush paradigm is using multiple brushes (as seen in the application "PD Particles"), which are not completely under control but rather moving within trajectories with random deviations, simultaneously. The trajectories are defined by controllable parameters and the user input. Since the rate of obedience to user input is dependant on the parameters, users can define the rate of deviation and thus switch between finger painting and generative painting, without changing the set of tools.	Musophobia	NA	2010
Tomoko Hashida:Yasuaki Kakehi:Takeshi Naemura	Drawing tools using digital technology can stimulate creativity in people. For example, the Wacky Brush tool in KidPix can produce effects (such as a line of dripping paint or a line of shapes) that cannot be obtained using ordinary paper and brushes [Hickman 1991]. This feature makes it easy for people to draw pictures having a combination of patterns. Such software, however, has so far been used only with electronic displays such as LCDs and PDPs. In this paper, we propose a mechanism that would allow the user to draw such pictures while using paper as a canvas instead of electronic displays. With this mechanism, a variety of patterns can be made to appear along lines traced out by the user by moving an electronic paint brush over paper. The advantages of using paper in this way include a high degree of freedom in shape and size as well as portability.	Photochromic canvas drawing with patterned light	NA:NA:NA	2010
Russell Deaton	Code (computer software and the technologies that it enables) is changing fundamentally how human beings interact with each other, and think about themselves and the world. It is a medium through which artists are increasingly expressing themselves. Code can serve as the tool which the artist uses to produce their work, or more interestingly, the artist takes the role of programmer and designs and implements an algorithm that generates the work of art. Thus, the artist's ideas are filtered and constrained through the filter of code, whose limitations and capabilities shape and inform the consequent artistic vision. For example, Casey Reas through his {Software} Structures takes verbal descriptions of processes to produce visual components and turns them into programs[Reas 2009]. In what follows, a Turing-universal model of some natural and manmade phenomena, Self-Assembly, is adapted to the automatic creation of visual art.	Self-assembled art	NA	2010
Shiho Hirayama:Yasuaki Kakehi	From childhood, we often play with bubbles. We find various aesthetic elements in a series of actions of soap bubbles: appearing, expanding, floating, bursting and disappearing. This time, we utilize the movements of soap bubbles as a pixel of an image and propose a novel interactive substantial display named "Shaboned Display." (see Figure 1)	Shaboned display: an interactive substantial display using soap bubbles	NA:NA	2010
Akira Nakayasu:Kiyoshi Tomimatsu	Recently there has been demand for display equipment capable of advanced expressions in spatial design. For example, there is the Adobe Interactive Wall at Union Square (New York City, 2007), and the Zero Energy Media Wall of greenPIX (Beijing, 2008) using LEDs placed on the whole facade. The simple display of information contents is becoming insufficient, and more appealing spatial designs combining information content with interactive art expression are becoming more important. In this paper, we propose a shape memory alloy motion display (SMD), a novel piece of display equipment taking advantage of the existence of an actual object. Then, we introduce an interactive art work plant based on SMD technology.	SMA motion display: plant	NA:NA	2010
Junfeng Yao:Xiaobiao Xie:Fengchun Lin:Xufa Ji:Xiaoyan Lin:Andy Ju An Wang	Recently, Xiamen University and Flying Information Technology Co., Ltd worked together and completed the development of The Online Custom-Built WEB3D Middleware System for Arts and Crafts, which will perform as a product 3D design and display center, its main features include the product demonstration background change, 3-Dimension design, 3-Dimension product display, product component reorganization and product material replacement.	The online customer-built WEB3D middleware system for arts and crafts	NA:NA:NA:NA:NA:NA	2010
Yuka Kubo:Hiroyuki Shindo:Koichi Hirota	For more than 1,300 years, beauty portraits have continued to be painted in Japan and virtually all have been stylized to a very unrealistic extent.	The Orikao Method: 3D scene reconstruction from Japanese beauty portraits	NA:NA:NA	2010
Robert B. Trempe, Jr	"24X7ATPHL: Codify" is an investigation into the novel usage of time-based animation software and procedural modeling as a method for visualizing time-based quantitative data via the construction of a qualitative, two-dimensional rendering. Treated as an experiment in the extrusion and aggregation of time-based qualitative instances, "24X7ATPHL: Codify" slows down and composites the accumulated information of seven days traffic (customer pickup and drop off) at an international airport; visualizing information in such a way as to not only notate the generations and changes in patterns, but also to show the beauty that can be found in data while unlocking the emergent potential for design. "Codify" makes use of the accumulation of NURBS geometries as a methodology for understanding the specific conditions of movement created by the interaction of existing architecture and user, the results of which are currently being used to develop everything from the design of several furniture pieces to that of a new cladding system for the Philadelphia International Airport.	[email protected]: Codify	NA	2010
Amy Martin:Wendy Ju	Bloom uses the metaphor of a desktop plant to remove task management from the already overloaded inbox and into a more human environment. When tasks in the inbox are starred, the email information is sent to an external touchscreen that then grows a flower for that specific task. The flower is activated on touch and the text of the email is displayed. Plucking the flower---touching, holding, then flicking the flower---removes that item from the task list. A large number of tools exist for managing tasks. Bloom is different in that it uses an organic, passive metaphor for visual display. Instead of having a series of piling text, whether in physical or digital form, Bloom does not visually overwhelm. A single task is as visually appealing as fifty. Additionally, although numerous email visualizations also exist much of this work has to do with overall inbox visualization and/or the display of relationships [1]. There is also precedence in using metaphor to visualize email as seen in Kjen Wilkens' Mail Garden. Bloom is distinct in both its focus on task management and our intent at full integration with existing email systems.	Bloom: an interactive, organic visualization of starred emails	NA:NA	2010
Yuki Igarashi	Line stone decoration is popular with young people. They enjoy applying line stone decorations to personal goods, such as notebook PCs, mobile phones and digital cameras. However, novices often find line stone decorations difficult to design, as the user must consider stroke length, stone width, and stone spacing. Hence, many people employ off-the-shelf design sheets or have their items decorated by an in-store professional. We have developed an interactive designing editor for line stone decoration. The user interactively draws freeform strokes on the canvas, as shown in Figure 1. The system then automatically generates a virtual line stone image (Fig. 1(b)), in which none of the stones overlap. Various off-line methods have been proposed for designing such decorations (e.g., tile mosaics [Hausner 2001]). Using our system, the user can create the designs interactively at the computer. Our system also creates a physical stencil pattern to help novice users to construct real line stone (Fig. 1 (c), (d)).	DECO: a designing editor for line stone decoration	NA	2010
Yuki Igarashi:Hiromasa Suzuki	Shape-matching toys are popular items for infants, and consist of boxes with many holes in different shapes along with corresponding blocks of the same shapes. To play with the toy, an infant finds and inserts a block matching the shape of a particular hole. It is difficult to design new shape-matching toys based on existing blocks. We assume that the user performs such design as shown in Fig. 1 (e) based on existing building blocks like those shown in Fig. 1 (a). The construction of the toy body can be roughly divided into three steps: gather the parts, lay them out on a wooden board and trace them using a pencil, and saw the wooden board. This manual method is straightforward, but errors cannot be rectified and it is also unsuitable for mass production. Accordingly, we propose the use of a laser cutter (e.g., Commax Laser System) or a cutting plotter (e.g., Craft ROBO). Today, services are available that allow the user to send a vector dataset to a company and have the corresponding wooden board returned to them.	Designing a new toy to fit other toy pieces: a shape-matching toy design based on existing building blocks	NA:NA	2010
Koh Sueda:Kazushi Kotani:Jun Rekimoto	Easy-Tagging Cam (or ETC) is a digital image recording system equipped with multiple shutter buttons. This system enables users to capture and tag photographs simultaneously. This function allows the user to be set free from tagging tasks. The users enable to develop re-useable photo storage continuously. This system also utilizes a life-log system thereby aiding the easy retrieval of information.	Easy-Tagging Cam: using social tagging to augment memory	NA:NA:NA	2010
Hiroki Yamada	Flower arrangement is one of famous traditional arts in Japan, and being enjoyed across the world now. People have been created the atmosphere in a room or represented one's mind by flower arrangement.	Floral melody: flower arrangement as music interface	NA	2010
Robert B. Trempe, Jr	"How Would You Like To Live" is a graphical articulation manifest from user sensory "wishes" supplied by an architectural client building a new home. It was crafted to help the designer in under-standing the needs of the client through emergent, patterned, non 1:1 results. Through the use of a parametrically-driven procedural network with parametric inputs supplied by the client, a graphical "depiction" of the user's hopes, dreams, and senses towards the occupation of domestic space was generated.	How would you like to live?	NA	2010
Ming Tabg:Jonathon Anderson	The name "Math-Morph" combines the notion of "mathematic" with the notion of "morphology. This project focuses on the study of "mathematic" as an embedded variability of spatial arrangement with procedural model. The influence of digital media and information technology on architectural education and practice is increasingly evident. Digital technology has reconditioned the design process that establishes new processes and techniques of fabrication. This reconditioning has influenced how we operate as architects. Today, architectural design and building construction are increasingly aided by and dependent on digital technology. These technologies allow architects to foresee the appearance and predict the performance of proposed buildings. Mathmorph proposes an interdisciplinary research in digital fabrication of unconventional 3D forms on a conceptual design level in order to explore their features in interacting with people and their potentials of being used as architectural forms. It describes an experimental approach which facilitates 3D form generation, visualization and fabrication.	Mathmorph	NA:NA	2010
Rebecca Findlay	Pixel Pusher represents a humorous symbol for all people who work with pixels on a daily basis such as teachers, students, or some other creative in the field relating them to the rigorous, time-consuming labor of a construction worker.	Rebecca Findlay's Pixel Pusher: poster abstract	NA	2010
Sophia Sobers	This architectural system explores the idea of using a parametric interface that reacts and changes based on user input while reproducing a series of affects (defined in psychology as the experience of emotion or feeling) on the user. The affects are predetermined, based on real world examples, and the system is designed in accordance. The overall premise for this project is to explore how tangible affects can be represented through parameters where the results are only visualized through the computer.	Reactive architecture	NA	2010
Kumiko Kushiyama:Tetsuaki Baba:Kouki Doi:Shinji Sasada	"Thermo-Pict neo" is a design apparatus produced by applying temperature visualization technology linked to an information display with the use of a thermograph sheet. Thermography is used to visualize the surface temperature of objects through their depiction as colors. This technology has been used primarily in the medical and research fields. Thermography display colors come in a wide range of hues and brightness that enables quick visualization of any object's surface temperature distribution. Use of this technology will be attempted as a tool in the production of design displays. [Fig.1]	Temperature design display device to use peltier elements and liquid crystal thermograph sheet: "Thermo-Pict neo"	NA:NA:NA:NA	2010
Hiroki Yamada	In this paper, the authors propose Tiny Dreamy Stories, which uses a traditional paper book as an interface to experience digital contents, so that it can keep the affordances of paper books while adding electronic augmentation. The aim of this study is to achieve both highly computer-supported contents and natural interface, e.g., highly efficient combination of physical and digital world. With Tiny Dreamy Stories, every person (especially who is not good at operating computers) can enjoy rich digital contents just by flipping pages.	Tiny Dreamy Stories: interactive paper book capable of changing the storylines	NA	2010
Jieun Kim:Carole Bouchard:Jean-Francois Omhover:Ameziane Aoussat	The TRENDS European project aimed at developing an image and text retrieval engine in order to support the activity of the designers in the early stages of their design process [TRENS 2007]. The study of the designers' activity has led us to the production of an image database in which designers will find inspirational material. A content-based image search engine has been elaborated, starting from recommendations taken from the methodology employed by the designers in their activity, to end with a complete system incorporating image retrieval technologies and various tools to extract relevant information from these images.	TRENDS: a content-based information retrieval system for designers	NA:NA:NA:NA	2010
Mary Huang	The design of typefaces is founded upon principles from the days of metal type, when creating individual fonts was a laborious process and constrained by physical requirements. Most digital type design follows those same conventions, even though fonts are now drawn with vectors and pixels. Fonts are still largely based on historical references and are created in the context of publishing.	TYPEFACE	NA	2010
Hwan-Soo Yoo:Seong-Whan Kim	We propose an Agritainment (agriculture with entertainment) framework, where users can learn how to cultivate plants and to breed livestock. To make an agricultural training joyful, we implement 3D collaborative space for training agricultural experience, which transforms monotonous training experience into realistic experience. Technical details include (1) multi-user networking, (2) realistic plant grow-up modeling, and (3) story-telling approach for immersive experience.	Agritainment: 3D collaborative space for training agricultural experience with entertainment elements	NA:NA	2010
Liliana Vega:Griselda Ledezma:Anayeli Hidalgo:Eduardo Ruiz:Omar Pinto:Ricardo Quintero:Leopoldo Zepeda	Recent results in educational research suggest the benefits of creating learning atmospheres in which students actively engage with the material as well as other classmates [1]. The idea of creating such an environment using a multiplayer mobile game represents a natural extension of the ubiquitous audio guides offered by most museums today.	Basic elements on game design for interactive museum exhibitions	NA:NA:NA:NA:NA:NA:NA	2010
David Bartle:Sam Rossoff:David Whittaker:Bruce Gooch:Kim Kerns:Jenny MacSween	Therapies that help restore abilities in individuals with brain damage are being investigated to help individuals with FAS. These methods focus on rehabilitation and exercises for the brain which improve specific cognitive capacities. We present Cognitive Carnival, a computer game therapy based on cognitive exercises, designed to improve the child's motivation and engagement of the tasks. Three minigames were developed, each based on improving one of three cognitive prinicples: executive function, continuous performance, and working memory. These minigames will be used in controlled therapy sessions with neuropsychologists for children with FAS to determine their effectiveness as a rehabilitative tool. Fetal Alcohol Syndrome (FAS) is a disorder that is caused by the ingestion of alcohol during pregnancy. Alcohol is a teratogen (substance that is toxic to the developing brain) and can result in abnormal brain development (brain damage). Children with FAS are faced with numerous obstacles, including significant problems with executive functions, attention, memory, and language. These conditions impede children with FAS from succeeding in school and living normal lives. There is estimated to be 0.5 to 2.0 children diagnosed with FAS per 1,000 births in the United States during the 1980's and 1990's [May and Gossage 2001]. It especially prevalent in remote communities. There is no cure. However, therapies that help restore abilities in individuals with brain damage are being explored to help individuals with FAS. These methods focus on rehabilitiation by means of an intervention by psychological professionals. The therapies are able to leverage the brain's plasticity to improve cognitive function [Neu 2002]. While adult brains show low levels of plasticity, children have more neurons and their brains continue to grow into their early 20's. Consequently, neurogenesis can be leveraged by supervised mental exercise. Classical therapy involves a trained therapist visiting local school, often times for a single child, to administer the therapy. The therapy itself consists of a set of exercises which the child preforms. This model of therapy, while effective, is inefficient and often times impractical for many areas. Additionally, the therapy has no builtin reward system and often times the therapist will offer the child candy or a small prize which provides little engagement with the tasks themselves. The minigames are intended for a controlled environment where a child with FAS is supervised by a neuroscientist. Over a course of weeks, the child will play each minigame, progressing through the difficulty levels as their abilities increase. A game-based therapy has multiple advantages over traditional exercises. Games tend to be more engaging than paper exercises. They also can accommodate built-in reward and motivation systems, instead of requiring the alternative of real-world incentives as the sole motivation for completing the tasks. Possibly the the most significant advantage is the ability to easily distribute the system using the Internet. This allows it to easily reach remote areas, where FAS is prevalent. Our therapy targeted three cognitive abilities: continuous performance, working memory, and executive function. Four minigames were created, each embodying at least one of the fundamental cognitive abilities affected by FAS. We decided to divide the therapy into minigames as each minigame could focus primarily on a single cognitive principle. This narrowed focus allowed neuropsychologists to measure progress on particular abilities. This also allowed for separate starting ability parameters for the children. The minigames focused on three cognitive principles typically impaired by FAS: continuous performance, working memory, and executive function. Continuous performance is the ability to sustain a consistent focus to an ongoing task continuing over an extended time period. Children without this ability may be at a major disadvantage in learning settings to their healthy counterparts. Working memory is the ability to temporarily store and manipulate information. It is an important basis for complex cognitive processes. Executive function is the ability to plan, problem solve, and make decisions. Each minigame has built-in difficulty levels, and the ability to manually adjust parameters for an individually-tailored therapy. Levels are then subdivided into repeated trials of the same parameters. The user progresses through each trial, receiving positive and negative feedback as appropriate, according to his or her performance. Upon the completion of a session, the user is presented with his or her results and a progress plot of their recent trials.	Cognitive games as therapy for children with FAS	NA:NA:NA:NA:NA:NA	2010
James R. Geraci:Erek R. Speed	Our work focuses on the area of using a high level language to improve program productivity, performance and portability. In general, this has been an area of intense research. There are a number of previous efforts including ZPL [Chamberlain and et al 2004], X10/Fortress/Chapel from IBM/SUN/Cray [Weiland 2007], Intel's CT/RapidMind [McCool 2006] and parallel VSIPL++ [Lebak and et al 2005] to name a few. However, while these languages do great things in simplifying parallel implementation of code, extensions beyond that are limited. The primary exception to this is VSIPL++ which implements several high level functions useful to the signal processing community. While most of these languages can be used to implement graphics or game related algorithms if necessary, none of them attempt to provide a platform that makes such development particularly easy. On the other hand, high level engines such as Renderman and Unreal provide the wanted abstractions but with little or no guarantees about extensibility, portability, or parallel performance. Our research focuses on adapting the parallel VSIPL++ API from the signal processing community to the graphics and game development environment.	Improving program productivity, performance and portability through a high level language for graphics and game development	NA:NA	2010
Madhuri Koushik:Eun Jung Lee:Laura Pieroni:Emily Sun:Chun-Wei Yeh	The goal of the project was to design an integrated system for the California Academy of Sciences that combined new technology (iPads in our case) with a social-networking based website to promote educational learning geared towards middle-school students. The experience begins when museum visitors create profiles on the California Academy of Sciences website. Initially they are able to personalize a limited number of characteristics of their avatars. Once they visit the museum, they play mini-games on iPad kiosks to accumulate points on their accounts. We developed five different educational mini-games, focusing on the areas of climate change, astronomy, evolution, and the food chain. The points gained on the iPad mini-games can then be redeemed at home by returning to the California Academy of Sciences website. Accessing the website from home allows the user to further personalize an avatar, learn more facts, and compare their scores on the mini-games and their avatar with those of their peers. Points can be redeemed to upgrade the avatar's available attributes and attires. By extending the museum experience to home and through increased level of social network interaction, learning is reinforced over a longer period of time. In a user testing session with 50 students of the target demographic age, 72% said they would be interested in redeeming their points online. They also had the opportunity to write a fact that they learned from the game. 67% of students that played the camouflage game (n=12) were able to state a fact that they learned from the game. Utilizing new technologies like the iPad is an opportunity to increase the number of initial users that create profiles on a new educational socialnetworking game website. Future research can focus on determining the extent of the educational effect of a system like this. For example, how might the experience of learning at the museum, enforcing that learning at home, and repeating through return visits to the website affect retention of facts?	iPad mini-games connected to an educational social networking website	NA:NA:NA:NA:NA	2010
Tetsuaki Baba:Kumiko Kushiyama:Kouki Doi	Today, many researchers reports studies about haptic, tactile or tangible art and entertainment. Particularly about temperature sensation, few interaction system has ever been presented because of it does not have good responsiveness. In this study, we shall design the video game interaction system that uses temperature sensation to users. First of all we investigate the relation of the rapidity of temperature change and user response time by using prototyped controller. Our game controller can offer temperature to users dynamically according to game situations. As a result, It was able to propose a basis of interaction system to take the temperate sensation to the game interaction.	ThermoGame: video game interaction system that offers dynamic temperature sensation to users	NA:NA:NA	2010
Kotaro Takahashi:Tomohito Yamamoto	For providing high presence, many kinds of display system have been developed [Hughes et al. 2005]. Typical examples are 3-dimensional display and multi-channel surround speaker system. Moreover, 3D movie such as "Avatar" or 3D TV have been brought to the market. However, these high realistic displays for visual, sound, or both, were usually composed of fixed and expensive equipment.	3D audio-visual display using mobile devices	NA:NA	2010
Mike Roberts:Mario Costa Sousa:Joseph Ross Mitchell	We present a novel GPU level set segmentation algorithm that is both work-efficient and step-efficient. Our algorithm has O(log n) step-complexity, in contrast to previous GPU algorithms [Lefohn et al. 2004; Jeong et al. 2009] which have O(n) step-complexity. Moreover our algorithm limits the active computational domain to the minimal set of changing elements by examining both the temporal and spatial derivatives of the level set field. We apply our algorithm to 3D medical images (Figure 1) and demonstrate that our algorithm reduces the total number of processed level set field elements by 16x and is 14x faster than previous GPU algorithms with no reduction in segmentation accuracy.	A work-efficient GPU algorithm for level set segmentation	NA:NA:NA	2010
Budirijanto Purnomo:Norman Rubin:Michael Houston	Modern GPUs have been shown to be highly efficient machines for data-parallel applications such as graphics, image, video processing, or physical simulation applications. For example, a single ATI Radeon™ HD 5870 GPU has a theoretical peak of 2.72 teraflops (1012 floating-point operations per second) with a video memory bandwidth of 153.6 GB/s. While it is not difficult to port CPU algorithms to run on GPUs, it is extremely challenging to optimize the algorithms to achieve teraflops performance on GPUs. Only a select few expert engineers with the application domain expertise, a deep understanding of the modern GPU architecture, and an intimate knowledge of shader compiler optimization can program GPUs close to their optimal capabilities. Many developers are content with several folds of improvements rather than one or several orders of magnitude acceleration compared to their optimized CPU implementations.	ATI Stream Profiler: a tool to optimize an OpenCL kernel on ATI Radeon GPUs	NA:NA:NA	2010
Yoshiharu Momonoi:Masahiro Sekine:Tatsuo Saishu:Yasunobu Yamauchi	We have proposed a flatbed autostereoscopic display using the one-dimensional (1-D) integral imaging (II) method [Hirayama 2006]. 1-D cylindrical lens array (lenticular sheet) is used in the 1D-II display, making it possible to observe a three-dimensional (3-D) image with the horizontal parallax ray. The flatbed autostereoscopic display system brought about a more effective stereoscopic experience than the conventional upright display. In the flatbed display configuration, observers perceive displayed objects as if they exist on a table, because it has real depth matching with a horizontal plane and uses bird's-eye view configuration.	Birds-eye view ray scan system for flatbed autostereoscopic displays	NA:NA:NA:NA	2010
William C. Thibault	Immersive multi-projector displays with dozens of projectors are becoming easier to build as projection technology proliferates. We envision scenarios such as a classroom of students with individual projectors, and informal groups of people with projector-equipped mobile devices, in which computer-generated imagery can be generated and displayed in real time. Ideally, the resolution of the multi-projector display should grow with the number of projectors, and support arbitrarily wide displays (to 4π steradians).	Camera-based calibration for scalable immersive rendering	NA	2010
Sriranjan Rasakatla:Kashyap Kompella:Krishna Koundinya	Here we present our idea of using a cell-phone (the Neo Freerunner) for tracking a Car's location using GPS and measuring the road's quality using the accelerometer in the cell-phone. Neo-Freerunner is an open source Linux phone by Open Moko Inc. The phone can run many flavors of linux like Android, Qt, SHR etc. Here the implementation was done in SHR.	Car tracking and vibration test rig using Neo-Freerunner	NA:NA:NA	2010
Kazuhisa Yanaka:Akifumi Momose:Masahiko Yoda	Chroma keying is a well-known technique for mixing two images in which a specific color of the foreground image is made transparent. When this technology is applied to integral photography (IP) images, each of which is a textured image in which images taken from hundreds of angles are integrated, it is very useful. IP is an ideal 3D display method because parallax in all directions can be obtained without the need for wearing special glasses. Moreover, it needs only simple hardware consisting of an LCD and a fly's eye lens. In particular, in the case of the extended fractional view (EFV) method [1][2], an inexpensive ready-made fly's eye lens can be used. Animation is also possible by displaying frames successively. However, creation of IP images is computationally intensive because multi-viewpoint rendering, in which a large number of images are observed from hundreds of viewpoints, is necessary. Therefore, we developed a chroma keying technology to reduce the processing time. By creating the foreground IP images and the background IP images separately and combining them later, the processing time could be reduced greatly, especially when the background was stationary.	Chroma keying between integral photography images	NA:NA:NA	2010
Douglas Lanman:Matthew Hirsch:Yunhee Kim:Ramesh Raskar	We optimize the performance of automultiscopic barrier-based displays, constructed by stacking a pair of LCD panels. To date, such displays have conventionally employed heuristically-determined parallax barriers, containing a fixed array of slits or pinholes, to provide view-dependent imagery. While recent methods adapt barriers to one or more viewers, we show that both layers can be adapted to the multi-view content as well. The resulting content-adaptive parallax barriers increase display brightness and frame rate. We prove that any 4D light field created by dual-stacked LCDs is the tensor product of two 2D mask functions. Thus, a pair of 1D masks only achieves a rank-1 approximation of a 2D light field. We demonstrate higher-rank approximations using temporal multiplexing.	Content-adaptive parallax barriers for automultiscopic 3D display	NA:NA:NA:NA	2010
Kip Haynes:Jacquelyn Morie:Eric Chance	Second Life (SL) is a popular 3D online virtual world designed for human interaction (also known as a MUVE, or multi-user virtual environment). It typically supports 60--70 thousand concurrent users. The assets and physical environments within SL are easy to create and use, and the environments themselves are very much part of the human interaction experience. However, the typical means of accessing SL is through a single computer screen, which lessens the immersion that is inherent in such a rich 3D world. Because of this, the SL virtual world is a good candidate for adaptation to large scale immersive displays such as a CAVE™ or other multi projector systems.	I want my virtual friends to be life size!: adapting Second Life to multi-screen projected environments	NA:NA:NA	2010
Shunsuke Yoshida:Sumio Yano:Hiroshi Ando	A tabletop is a useful shared space for diverse collaborative tasks. If the tabletop is considered to be interface, then expression through visual sensation, especially 3D images, is an important way to engage the principal human sense. Many 3D displays that can be observed from any direction have been proposed in recent years. However, some techniques force to wear special glasses and restrict the positions from which 3D images can be viewed [Kitamura et al. 2001]. Other glasses-free 3D displays employ obstructive apparatus on the table [Jones et al. 2007].	Implementation of a tabletop 3D display based on light field reproduction	NA:NA:NA	2010
Sriranjan Rasakatla	Many sensors like the laser range finder, stereo vision cameras which help in building a depth perception of the world around it in 3D are very costly. Here I present the designs and prototypes of few 3D perception sensors which have been built low cost using components off the shelf. These perception sensors use structured infrared light projection. The design is miniature compared to other 3D sensors like LIDAR, Laser scanner and Time of flight cameras.	Low cost 3D perception sensors	NA	2010
Hideaki Nii:James Teh Keng Soon:Adrian David Cheok	This paper describes the design of a parallax based Moving Slit Light Field Display (MSLFD). A MSLFD shows multi parallax images, by using vertical slits in an opaque cylinder surrounding multiple static flat panel displays. It allows viewers looking towards the cylinder to see an image from any position. Currently, various forms of 3D display have been developed and flat panel 3D display has been in practical use for some time. But commercial 3D displays only show a stereogram. On the other hand, Light Field Displays have been developed for displaying the dense ray information of the space, [Endo et al. 2005; Jones et al. 2007]. These displays use a "Parallax barrier" to control the ray direction to the observer. It shows parallax images without the use of an eye glass. We describe a system to reduce the size of the display by using two dimensional Organic Light- Emitting Diodes (OLED) and a rounding slit. OLEDs can act as the dense light source array and it can be controlled line by line. This system proposes a method to synchronize the movement of OLED's line and movement of slits. It can show many images in multi orientation (Figure 1(a)). In this paper we explain the principal method of design and how to expand the resolution and views of a MSLFD.	Moving Slit Light Field Display	NA:NA:NA	2010
Ishtiaq Rasool Khan	Two-layer encoding schemes for HDR images (and video) can not only reduce the storage requirements, but more importantly they can also ensure backward compatibility during transition from LDR to HDR age. The first layer is a tone-mapped LDR image, which can be shown on existing displays. The second layer is another LDR image and contains the residual information lost in tone-mapping, which can be used by HDR applications.	A backward compatible HDR encoding scheme	NA	2010
Chun-Te Wu:Wei-Hao Huang:Chih-Hao Liu:Wei-Jia Huang:Kai-Che Liu:Ludovic J. Angot	The new data structure, the bilateral grid, was presented by Jiawen et al. to make bilateral filter algorithm become simple implementation. Based on the data structure, the GPU CUDA-based optimization is proposed to have more efficiency in using GPU shared memory and massive multithreading. Meanwhile, a commercial application, the video 2d to 3d conversion which was presented by Ludovic et al. is also re-designed by applying the proposed CUDA-based bilateral grid three times to obtain better 3D quality in real-time. Depth map are created and modified by adjusting bilateral grid parameters.	A real-time video 2D-to-3D with the bilateral grid	NA:NA:NA:NA:NA:NA	2010
Masaru Tsuchida:Toru Takahashi:Koichi Ito:Takahito Kawanishi:Junji Yamato:Takafumi Aoki	In the digital archiving for cultural heritage preservation, in the medical field, and in some industrial fields, high-fidelity reproduction of color, gloss, texture, and shape are very important. Multiband or full-spectrum imaging technology is a solution for accurate color reproduction. Although several types of multi band camera systems have been developed [Yamaguchi 2000, Tominaga 2000, Helling 2004, Hashimoto 2008], all of them are multi-shot systems and they cannot take images of moving objects. Ohsawa et al. [2004] have developed a six-band HDTV camera system. However, the system requires very expensive customized equipment. In order to make multiband technology pervasive, equipment costs must be reduced and the systems have to be able to take images of moving objects. To meet these requirements, we developed a novel multiband image capturing system that combines multiband and stereo imaging techniques. This system can acquire both spectral color information and depth information at the same time. In this paper, we focus on the generation of six-band images from a pair of stereo image.	A stereo one-shot multi-band camera system for accurate color reproduction	NA:NA:NA:NA:NA:NA	2010
Christian Lipski:Christian Linz:Marcus Magnor	Over the last decade, considerable progress has been made on the so-called early vision problems. We present an optical flow algorithm for image morphing that incorporates recent advances in feature matching, energy minimization, stereo vision and image segmentation. At the core of our flow estimation we use Efficient Belief Propagation for energy minimization. While state-of-the-art algorithms only work on thumbnail-sized images, our novel feature downsampling scheme in combination with a simple, yet efficient data term compression can cope with high-resolution data. The incorporation of SIFT features into data term computation further resolves matching ambiguities, making long-range flows possible. We detect occluded areas by evaluating the symmetry of the flow fields, we further apply Geodesic matting to automatically inpaint these regions.	Belief propagation optical flow for high-resolution image morphing	NA:NA:NA	2010
Stavros Papastavrou:Demetris Hadjiachilleos:Georgios Stylianou	The identification of a bank note's value is a non-trivial task for the blind and the visually impaired. A popular approach adopted by many countries in order to facilitate the visually impaired, is the impression of a high-contrast, large-print region on their bank notes. Additionally, an approach used to facilitate the blind population is the impression of unique tactile marks on bank notes. However, even when tactile marks or different sizes (e.g. Euros) are used, blind and visually impaired people have practical difficulties in identifying them.	Blind-folded recognition of bank notes on the mobile phone	NA:NA:NA	2010
Xuan Dong:Yi (Amy) Pang:Jiangtao (Gene) Wen	We describe a novel and effective video enhancement algorithm for low lighting video. The algorithm works by first inverting the input low-lighting video and then applying an image de-haze algorithm on the inverted input. To facilitate faster computation and improve temporal consistency, correlations between temporally neighboring frames are utilized. Simulations using naive implementations of the algorithm show good enhancement results and 2x speed-up as compared with frame-wise enhancement algorithms, with further improvements in both quality and speed possible.	Fast efficient algorithm for enhancement of low lighting video	NA:NA:NA	2010
Lange Benoit:Rodriguez Nancy	Until now computer graphic researchers have tried to solve visualization problems introduced by the size of meshes. Modern tools produce large models and hardware is not able to render them in full resolution. For example, the digital Michelangelo project extracted a model with more than one billion polygons. One can notice hardware has become more and more powerful but meshes have also become more and more complex. To solve this issue, people have worked on many solutions. We can find solutions based on space subdivision, or based on visibility of objects like the use of a Z-buffer. But in 1976, Clark [Clark 1976] introduces the level of detail concept (LOD). The principle of LOD is the construction of several versions of the same 3D model at different resolutions. This is achieved by removing some object features. Luebke provides in [Luebke 1997] a very complete survey of LOD algorithms. The main issue with the simplification is that the mesh does not preserve appearance of the original mesh. Indeed, important features tend to disappear. For example, with the Quadric Error Metrics (QEM) algorithms and the cow mesh, the tail, horn and other characteristic points merge with the mesh at a low resolution. Our approach allows the simplified mesh to preserve important details.	LOD +: augmenting LOD with skeletons	NA:NA	2010
Shiro Ozawa:Takao Abe:Noriyuki Naruto:Toshihiro Nakae:Makoto Nakamura:Naoya Miyashita:Mitsunori Hirano:Kazuhiko Tanaka	In surface computing, one of the most important requirements is tracking an object placed on the surface and manipulating information related to that object. To recognize objects, the most popular technique is marker tracking using techniques such as RFID, tag-like TarckMate[Kumpf 2009] and so on. The issues with marker tracking are the effort required to paste the tag and the existence of objects that are difficult to mark with a tag. To recognize objects without tags, feature point tracking on the image plane is one of the most effective ways in the area of the computer vision[Lowe 2004]. Unfortunately it is difficult to extract features from images taken through the frosted glass that is often used in surface computing. In addition, one cannot extract the feature points from objects without strong texture. In this paper, we present a marker-less object recognition system using multi channel silhouettes and quantized polar coordinates.	Marker-less object recognition for surface computing	NA:NA:NA:NA:NA:NA:NA:NA	2010
Erich Marth:Guillermo Marcus	With the introduction of H.264, the complexity on video encoders has increased dramatically. As hardware based encoding solutions profit from the strict sequential design and already feature real time capabilities for high definition material, software solutions lack most of the encoding performance. More precisely, the performance of software encoders is limited due to the computation power of encoding system as well as the high level of codec-intern dependencies. As a consequence, software encoders supporting high definition needs are very rare.	Parallelization of the x264 encoder using OpenCL	NA:NA	2010
Eriko Kimura:Naoki Kawai:Kazunori Miyata	We have proposed a method called Bump Mapping onto Real Objects (BMRO)[1] for displaying the appearance of curved surface on flat media. The method converts normal vectors of modeled curved surface into directions of grooves by which anisotropic reflection occurs for displaying a curved surface. Although curved surfaces can appear on media by BMRO, it is still insufficient for practical use because the streamlines used for a pattern of grooves are often placed too closely or too sparsely to one another due to the vector plot employed for generating them. The simplest solution to avoid the non-uniformity is to divide the entire region into regular square or hexagonal cells and to fill each cell with parallel lines in a given direction instead of tracing the direction field strictly with streamlines, but this improvement causes aliasing to noticeably appear at the edges and ridges of the original model. In this article, we propose an improvement on generating cells that reduces aliasing for BMRO and makes it practical for industrial applications.	Practical 3D decoration on flat media with anisotropic reflection	NA:NA:NA	2010
Matthew Trentacoste:Rafal Mantiuk:Wolfgang Heidrich	The image quality of a digital viewfinder is considerably lower than that of a through-the-lens optical system. While the sensor may be capable of capturing 10 or 20 megapixels, the screen of the viewfinder is typically constrained to resolutions under 1 megapixel. The limited resolution makes it impossible to discern all the small details of the captured image. Small blurs and noise that are present in the full-size image can render the image unusable for certain tasks, yet these artifacts may be too small to be discernible in the downsampled version shown on the camera viewfinder.	Quality-preserving image downsizing	NA:NA:NA	2010
Zhengguo Li:Susanto Rahardja:Shiqian Wu:Zijian Zhu:Shoulie Xie	It is known that a high dynamic range (HDR) image can be produced by sequentially capturing a set of low dynamic range (LDR) images with different exposure times [Debevec and Malik 1997]. However, ghosting artifacts could be produced via this method when there are moving objects in a scene. In this poster, a similarity index is first introduced for such LDR images by using intensity mapping functions (IMFs) among them. The index is then applied to detect moving objects such that ghosting artifacts are removed from the eventual HDR image. The details are given as below.	Robust movement detection based on a new similarity index for HDR imaging	NA:NA:NA:NA:NA	2010
Thang M. Hoang	Fringe projection profilometry (FPP) is one of the most commonly used non-contact methods for retrieving the three-dimensional (3D) shape information of objects. In reality, the nonlinearity mostly caused by the gamma effect of digital otpic system, includes both projector and camera, gives inevitable intensity changes, which dramatically reduce the measurement accuracy. In this poster, a robust and simple scheme to eliminate the intensity nonlinearity induced by gamma effect. Firstly, by using phase shifting techniques, the gamma value involved in the measurement system can be detected accurately. Then, a gamma encoding process is applied to the system for future actual 3D shape measurements. With the proposed technique, high accuracy of measurement can be achieved with the traditional three-step phase-shifting algorithm.	Simple gamma correction for fringe projection profilometry system	NA	2010
Sun-Young Lee:Jong-Chul Yoon:In-Kwon Lee	Existing video matting approaches determine the alpha matte sequence frame-by-frame, which lead to flickering near the boundary of the foreground region. We reduce this effect by considering video data as a spatio-temporal cube, and extending a robust matting algorithm to a 3D solver. Our results demonstrate consistent and visually pleasing alpha mattes, and tend to preserve temporal coherence better than previous techniques.	Temporally coherent video matting	NA:NA:NA	2010
Jean-Charles Bazin:Soonkee Chung:Roger Blanco Ribera:Quang Pham:Inso Kweon	This paper introduces the new concept of virtual face sculpting. Given the images of a human face and a statue face (cf Fig 1-a and b), the goal of this application is to sculpt a virtual statue (cf Fig 1-c) as if the human face was sculpted on the statue. This problem is complicated and must face some important difficulties. For example, the virtual sculpture must verify the color and texture consistency of the original statue. Moreover, the structure of the human face must also not be modified, otherwise the person will not be recognizable.	Virtual face sculpting	NA:NA:NA:NA:NA	2010
Koki Nagano:Takeru Utsugi:Mika Hirano:Takeo Hamada:Akihiko Shirai:Masayuki Nakajima	We have enabled the superimposition of multiplexed images on the same screen at the same time with tangible and stable equipment. Our multiplex images can be seen by wearing special configured polarized glasses, and the image projection method is designed to be based on current 3D stereoscopic technology, which is now prevalent and making rapid progress, thus high compatibility with current contents industries is retained. Therefore our system enables the wide range of applications with new expressions and can easily be put into production.	A new "multiplex content" displaying system compatible with current 3D projection technology	NA:NA:NA:NA:NA:NA	2010
Seiya Matsuda:Tomohito Yamamoto	Recently, 3D movies such as "Avatar" have been popular because they can provide hyper reality. Most of these movies require special facility such as IMAX 3D. Therefore it has been difficult to introduce these movies to home environment. However, 3D TV for individual use has already been developed and is expected to become popular in a few years. In such situation, the demand of 3D contents for those systems will be higher and higher. However it is very difficult to create such contents because it requires exclusive tool, high technique and much cost.	A web system for creating and sharing 3D auditory contents	NA:NA	2010
Yuki Hirobe:Shinobu Kuroki:Katsunari Sato:Takumi Yoshida:Kouta Minamizawa:Susumu Tachi	Previously, pictures were painted using tools such as crayons or even by hand. Surfaces such as canvases or walls, provided the tactile sensations of the drawing surface while painting. However, this tactile experience has got lost because of advances in computer graphics software. Besides, a conventional multi-touch interface [1] can not provide tactile sensation. We propose a novel interactive painting interface called "Colorful Touch Palette" that may help us to rediscover our creativity. The user can touch the canvas having the electrode, select or blend tactile textures of their choice, draw a line, and experience the tactile sensations of painting as shown in Figure 1. Various tactile textures can be created by blending textures as paints. This interface can be used to design complex spatial tactile patterns for haptic-friendly products. Moreover, this system can be potentially used to create novel tactile paintings.	Colorful Touch Palette	NA:NA:NA:NA:NA:NA	2010
Yoshihiro Kuroda:Hirotoshi Ashida:Masataka Imura:Yoshiyuki Kagiyama:Osamu Oshiro	Liquid absorption affects the behavior of objects. Rain absorbed in the barrage can weaken its structure and cause the dam failure. A wet sponge ball bounces differently from a dry one. Porous media is a material that has internal pore space and is able to absorb liquid (e.g. a sponge or soil). Liquid absorption changes not only geometrical properties, e.g. volume, but also mechanical properties, e.g. elasticity. The aim of this study is to physically model the structural change of a porous media due to liquid absorption. Previous studies have focused on liquid flow inside the media[Lenaerts et al. 2008]. In contrast, this paper proposes a porous model that is able to simulate elastic change in a real sponge.	Force reflecting porous media with dynamic elasticity change	NA:NA:NA:NA:NA	2010
Michal Lech:Bozena Kostek	Nowadays, one of the main focuses of the Human-computer interaction area is controlling computers by gestures. Various gesture types provide means of controlling user interfaces and applications. However, most of them involve the front-facing camera and the user's gestures are recognized often from the static background. In addition, colorful gloves, gloves with motion sensors or infrared diodes are often used for this purpose.	Gesture controlled interactive whiteboard based on SVM and fuzzy logic	NA:NA	2010
Stephen David Beck:Shantenu Jha:Brygg Ullmer:Chris Branton:Sharath Maddineni	Laptop Orchestras (LOs) have recently become a very popular mode of musical expression. They engage groups of performers to use ordinary laptop computers as instruments and sound sources in the performance of specially created music software. By using an orchestral metaphor, LOs provide an engaging and challenging environment to experiment with human-computer interaction, network and machine latency, and sound/signal processing. While the LOs at Princeton and Stanford are perhaps the best known, LOs have now been established at many universities in the US and UK, and as private ensembles around the world. Perhaps the biggest challenge for LOs is the distribution, management and control of software across heterogeneous collections of networked computers. Software must be stored and distributed from a central repository, but launched on individual laptops immediately before performance. Each "composition" consists of unique combinations of software, user interfaces, and physical devices. Moreover, performers in a Laptop Orchestra can have a complex array of application layers to manage and launch before the start of a specific piece's performance. For example, one work written for our LO requires a bluetooth middleware application which reads gestures from a Wii-mote and converts them into OpenSoundControl [Wright and Freed 1997] messages to be forwarded to a custom Max application, all of which must be launched and configured before any performance. Combine this with the rapid turnaround from one composition to the next during a concert performance, and the problem of preparing members of the laptop orchestra with the appropriate tools for each piece becomes daunting. The GRENDL project leverages proven grid computing frameworks and approaches the Laptop Orchestra as a distributed computing platform for interactive computer music. This allows us to readily distribute software to each laptop in the orchestra depending on the laptop's internal configuration, its role in the composition, and the player assigned to that computer. Using the SAGA framework [Goodale et al.], GRENDL is able to run pre-distribution scripts on a master computer, distribute software to client computers, launch post-distribution scripts on the master computer and launch application scripts on client computers that in turn manage application environments for each composition. SAGA, the Simple API for Grid Applications, is a distributed computing middleware used to distribute, manage and process grid-based applications, typically for scientific research problems in such diverse fields as numerical relativity, computational fluid dynamics and materials science. Its functionality and stability are well regarded within the computational science community and SAGA has become a standard API for grid computing. Our initial experiments have demonstrated that SAGA can be used successfully in a concert environment. The Laptop Orchestra of Louisiana (LOLs) debut concert on April 14, 2010 used a prototype version of GRENDL to manage two of the seven works performed, and GRENDL worked flawlessly. GRENDL proposes to go further than just applying SAGA to the LO environment. We will use tangible and physical objects [Ullmer et al. 2008] to represent individuals, resources, roles and compositions such that GRENDL knows how to distribute software appropriate to the LO's environment, the individuals performing and their role in the composition. By using RFID-embeded objects [Ullmer et al. 2010], master and client computers determine who is at which computers, and what is being performed. Just as a music librarian knows where to place parts for each composition on which music stands, GRENDL will know where to send software and how to launch that software for each composition, laptop and performer. Extending SAGA to work with tangibles and in novel runtime environments, will require extensions to SAGA -- support for new interfaces and instruments -- as well as require some performance engineering in order for commands to be processed with lower latency than "traditional" distributed systems are designed to tolerate. The trans-disciplinary nature of GRENDL provides potential to shed new light on existing challenges in computational and computer science. The LO setting presents a unique perspective from which to investigate topics such as time-sensitive and dynamic job scheduling, latency-bound interaction, and effective user interfaces for grid computing environments. Some of the first iteration interaction technologies have been developed for distributed computational science applications, and some of what is learned through GRENDL will likely be applicable in that area.	GRENDL: grid enabled distribution and control for Laptop Orchestras	NA:NA:NA:NA:NA	2010
M. Cicconet:L. Velho:P. Carvalho:G. Cabral	Interfacing with the guitar using the audio signal is one of the oldest problems in Computer Music, and advances in the area were astonishing. In our days it is possible to simulate a huge range of amplifiers, apply many filter effects and evaluate the pitch of a plucked string robustly, to mention a few useful applications.	Guitar-leading band	NA:NA:NA:NA	2010
Ji-Hye An:Su-Jin Lee	Considerations of interface design have been limited to the senses of sight and hearing. However, as the sense of touch, such as haptics, began to be applied to equipment, new interaction has emerged. Due to the integrated nature of people (Goldstein, 2002), it is important for a new system that added tactile stimuli to correctly analyze and understand users' experiences. This study analyzes integrated cross modality user experiences from devices providing information on the senses of sight, hearing, and touch.	How people tend to organize sensory information into unified wholes in haptic phone?: focusing on cross modality interaction	NA:NA	2010
Kai Uwe Barthel:Sebastian Müller:David Backstein:Dirk Neumann:Klaus Jung	Internet image search systems mostly use words from the context of the web page containing the image as keywords. The performance of these search systems is rather poor, as the search systems neither know the intention of the searching user nor the semantic relationships of these images. Content-based image retrieval (CBIR) systems rely on the assumption that similar images share similar visual features. Despite intense research efforts, the results of CBIR systems have not reached the performance of text based search engines. The main problem of CBIR systems is the semantic gap between the content that can be described with low-level visual features and the description of image content that humans use with high-level semantic concepts. Some image retrieval systems have combined the keyword and the content-based visual search approach. However with this approach many images may be found that semantically do not match. In addition semantically similar images that visually look different cannot be found at all.	Image retrieval using collaborative filtering and visual navigation	NA:NA:NA:NA:NA	2010
Paulo F. U. Gotardo:Alan Price	Our research explores the use of real-time computer vision techniques and a pair of standard computer cameras to provide 3D human body awareness in an inexpensive, immersive environment system, Fig. 1. The goal is to enhance the user experience of immersion in a virtual scene that is displayed by a 3D screen. We combine stereo vision and stereo projection to allow for both the user and the virtual scene to become aware of each others 3D presence as part of a single, integrated 3D space.	Integrated space: authoring in an immersive environment with 3D body tracking	NA:NA	2010
Jae-Hee Park:Tackdon Han	Multi-touch sensing exists in a number of applications and is presently used in personal computing devices (i.e. laptops and desktop computers), mobile touch screens, kiosks, Interactive wall displays (i.e. subway station map), ATMS, and any display requiring an interactive platform. Current multi-touch sensing methods use capacitive and or resistive based touchscreens both which are expensive and difficult to make. Infrared based touchscreens is being studied as an alternative method that is effective and low-cost solution of producing equal results particularly with large interactive displays.	LLP+: multi-touch sensing using cross plane infrared laser light for interactive based displays	NA:NA	2010
Norbert Győrbíró:Henry Larkin:Michael Cohen	To remember important information, we often take pictures and arrange them into collections. Photos can also be gathered and organized via personal lifelogs and social media websites which may include contextual metadata such as location, participants, rating, and even emotional tags. However, memories and connections between places, events, and people can be difficult to recollect. Memory recall in our brain can depend on several factors: emotional level, context variability, loss of information during encoding, etc. As time passes, memories are gradually forgotten or become altered, e.g. due to collision with newly encoded information [Yi Chen 2010].	Long-term memory retention and recall of collected personal memories	NA:NA:NA	2010
Chun-Yu Tsai:Hung-Jung Lin:Tzu-Hao Kuo:Kai-Yin Cheng:I-Chao Shen:Bing-Yu Chen:Rung-Huei Liang	Hearing is one of human's five senses. In our daily life, we usually guess where we are and the surrounding conditions not only by the visual feedbacks of the surrounded scene, but also by environmental sounds. For example, subway stations usually hint people the door closing by an urgent sound. In Taiwan, the garbage trucks usually broadcast one special song, and people can judge whether the car is coming. Similarly, we usually can recognize our familiar people only by hearing the sounds they generated without actually seeing them. For example, John usually bats basketball while entering the room. Hence, before he enters the room, the familiar sounds is heard, and can be recognized. Moreover, through the sense of hearing, people can only use their peripheral attention to quickly know where they are and what happens.	MusicSpace: you "play" the music	NA:NA:NA:NA:NA:NA:NA	2010
Anusha Withana:Rika Matsui:Maki Sugimoto:Kentaro Harada:Masa Inakage	With recent advancements in digital photography, data storage and network technologies, publishing and sharing of digital images in Internet has been drastically increased. High popularity and growth of internet image libraries such as Flickr and Picasa are good examples for these trends. In order to enable easy browsing and searching, online storages store meta-data in the form of keywords to describe images. Meta-data could be a general description of the image, a specific tag or an annotation to describe spatial information within the image. In order to ease and improve the efficiency of tagging process, image processing and analysis algorithms has been combined to manual tagging systems [Yang et al. 2009]. Furthermore, meta-data can be used to create interesting presentations of images. Specially in exhibition displays, automated slide shows and digital photo frames, meta data are used to group related images and present them under different categories. However, presentations generated by most of the existing systems are limited to sequential displaying of individual images as correlated groups. In this paper we present a system that composite digital images in a narrative fashion utilizing objective and subjective tagging information. Proposed system can extract a region from one image and composite it into another image according to available meta-data. As a proof of concept we created a right to left continuous image panning application using Adobe Flash which combines different images according to their similarities and composite them together to create a narrative image presentation.	Narrative image composition using objective and subjective tagging	NA:NA:NA:NA:NA	2010
Toshihiro Nakae:Shiro Ozawa:Naoya Miyashita	We propose O-Link, a system that allows us to convey our experience by binding digital videos to a real object in order to facilitate intergenerational communications. We focus on two factors in designing our interface to build a closer relationship between grandparents and grandchildren.	O-Link: augmented object system for intergenerational communication	NA:NA:NA	2010
Frank Steinicke:Gerd Bruder:Scott Kuhl	In computer graphics one is often concerned with representing 3D objects on 2D displays, which provide often only a limited display field of view (DFOV) to the observer. Usually, planar geometric projections, in particular linear perspective projections, are applied, which make use of a straightforward mapping of graphical entities in a 3D view frustum to a 2D image plane. Corresponding to the DFOV introduced for computer screens, the aperture angle of the virtual camera is often denoted as geometric field of view (GFOV) [Kjelldahl and Prime 1995]. Projections of virtual objects on a computer screen are affected by the interplay between the GFOV that is used to render the scene, and the DFOV (see Figure 1). In this context, only little research has been conducted to identify perspective projections that appear realistic to users. Instead, graphics designers and developers often choose GFOVs that vary significantly from the DFOV [Steinicke et al. 2009].	Perception of perspective distortions of man-made virtual objects	NA:NA:NA	2010
Marcelo Cicconet:Paulo Cezar Carvalho	Computer hardware and music softwares have evolved to such a level that, in our days, it is possible to compose high quality music using only a simple laptop equipped with the proper applications.	Playing the QWERTY keyboard	NA:NA	2010
Dane M. Coffey:Daniel F. Keefe	Advances in high-performance (supercomputer) simulations are revolutionizing biomedical research. Figure 1 shows a visualiazation of data from a cutting-edge computational fluid dynamics (CFD) simulation of blood flow through a replacement heart valve. Our collaborators in medical device design hope to use these data as part of a new approach to redesigning the valve hinging mechanism, ultimately improving the longevity of these devices. Biomedical engineers face significant challenges in exploring and understanding these data.	Shadow WIM: a multi-touch, dynamic world-in-miniature interface for exploring biomedical data	NA:NA	2010
Kristian Gohlke:Michael Hlatky:Jörn Loviscach	During extended sessions with a graphical user interface (GUI), users often apply a small set of commands with high frequency. A majority of direct manipulation tasks on a GUI are carried out using the mouse, particularly when keyboard shortcuts are not provided or the user is not familiar with them. Thus, to invoke a certain command, the user is required to aim the mouse pointer at a given onscreen widget and click with the mouse. If the overall task requires a user to click on the same widget repeatedly as part of a sequence of different interleaved micro-tasks, the overall performance suffers, as each point-and-click action requires a considerable amount of time for correctly aiming at the respective control.	TapShot: screenshot snippets as GUI shortcuts	NA:NA:NA	2010
Yoichi Ochiai	Visible Breadboard is the Breadboard like interface which shows voltages of each and every hole by full color LED and enable us to make wiring by tracing with finger tips. Users could insert electrical material into the holes and make a circuit on this device. Users could understand what is happening in the circuit and correct the connections with finger tracing.	The visible electricity device: visible breadboard	NA	2010
Kumiko Kushiyama:Tetsuaki Baba:Kouki Doi:Shinji Sasada	"Thermo-Paradox" is a thermal design display device to use the thermal tactile Physiological illusions that can interactively present patterns of warm and cool temperatures. The technological success of a compact 80-pixel, 9-inch thermal display allows text information to be conveyed by temperature, which has never before been achieved, and the device compactness increases the degree of freedom in presentation methods. We propose this unprecedented tactile expression as a device that can display thermal images that interactively match a visual image, using the tactile Paradoxical sensation produced by the ability to control the temperature of each pixel. (Fig. 1)	Thermal design display device to use the thermal tactile illusions: "Thermo-Paradox"	NA:NA:NA:NA	2010
Pierre Rouanet:Pierre-Yves Oudeyer:David Filliat	Social robots are drawing an increasing interest both in scientific and economic communities and one of the main issues is the need to provide these robots with the ability to interact easily and naturally with humans. We believe that the interaction issues may have a very strong impact on the whole system and should be given more attention. Current research however focus mainly on the the visual perception and/or machine learning issues (see for example Steels and Kaplan [1]). We think that by focusing on the users and on the interface we can help them provide the learning system with very high quality learning examples.	Using mediator objects to easily and robustly teach visual objects to a robot	NA:NA:NA	2010
Patricia Codyre	Information and communication technologies (ITC) offer innovative ways to improve health services and systems. Integration of eHealth into the daily life of rural health-care workers is fast becoming a reality in developing countries. Computermediated communication systems can be used to bridge the gap between doctors in underserved regions with local shortages of medical expertise and medical specialists. eHealth for primary health-care includes applications that directly support disease prevention, patient diagnosis and patient management and care.	Using innovative ehealth interventions in a local health care context	NA	2010
Tanasai Sucontphunt:Zhigang Deng:Ulrich Neumann	Modeling a 3D face toward a specific person is a tedious and painstaking task even for skilled artists. Crafting a 3D cartoon-style or a 3D fiction-creature face to reflect a specific person likeness is even more challenging. For example, creating an ogre that keeps the actor/actress likeness or constructing a 3D avatar that reflects the person identity is an intensive process that involves high artistic skills to convey the human identity on the monster geometries. This work presents an automatic 3D face modeling system that transfers a target 3D human face identity (likeness) to any 3D character faces. This system can be used for a broad variety of a 3D face modeling such as an early stage 3D character face design or a individualized 3D avatars creation.	3D human face identity transfer using deformation gradient	NA:NA:NA	2010
Mohammed Yousef:Ahmed Hashem:Hassan Saad:Amr Gamal:Osama Galal:Khaled F. Hussain	Digital Content Creation (DCC) Applications (e.g. Blender, Autodesk 3ds Max) have long been used for the creation and editing of digital content. Due to current advancement in the field, the need for controlled automated work forced these applications to add support for small programming languages that gave power to artists without diving into many details. With time these languages developed into more mature languages and were used for more complex tasks (driving physics simulations, controlling particle systems, or even game engines). For long, these languages have been interpreted, embedded within the applications, lagging the UIs or incomparable with real programming languages (regarding Completeness, Expressiveness, Extensibility and Abstractions). Two approaches were used to implement those languages. Either build them from scratch (like MaxScript), or use an existing popular language and write a set of extensions to it and embed it (like Blender and Python). In practice, both those solutions suffer, the first method produces languages lacking being real, competitive languages and generally very inefficient, the second method has problems arising from not being dedicated in first place for that kind of applications so, they lack expressiveness facilities (like dedicated constructs) that support that particular domain, also it's very hard to optimize these languages for specific DCC situations.	A scripting language for Digital Content Creation applications	NA:NA:NA:NA:NA:NA	2010
Wael Abdelrahman:Sara Farag	Segmenting 3D meshes into distinct components is vital and necessary for more efficient processing and usability. The smaller segments are usually easier to process and can be associated with with semantics or geometric features. This can be used in 3D parametrization, 3D database creation, animation, deformation transfer and many other 3D graphics applications. However, automating such a process is challenging due to the variety and complexity of the input.	Automated 3D mesh segmentation using 2D footprints	NA:NA	2010
Olusola O. Aina:Jian Jun Zhang	Physically-based facial animation (FA) techniques are notoriously difficult to create, reuse, and art-direct. We address these shortcomings by proposing a rig-builder that automatically generates bony and soft-tissue substructures for any given head model. In an earlier work, [Aina 2009] presented a method for fitting a generic skull to any given head model as a first step toward automated rig-building. Here, we outline work done since, and give an overview of a method for creating muscles of facial expression (mimic muscles), and other soft-tissues in the gap between a given head model and a fitted generic skull.	Automatic muscle generation for physically-based facial animation	NA:NA	2010
Ergun Akleman:Jianer Chen:Yen-Lin Chen:Qing Xing	Any arbitrary twist of the edges of an extended graph rotation system induces a cyclic weaving on the corresponding surface [Akleman et al. 2009]. This recent theoretical result allows us to study generalized versions of textile weaving structures as cyclic weaving structures on arbitrary surfaces. In this work, we extend the study to twill weaving, which is used in fabrics such as denim or gabardine. Biaxial twill is a textile weave in which the weft (filling) threads pass over and under two consecutive warp threads and each row is obtained from the row above it by a shift of 1 unit to the right or to the left. The shift operation creates the characteristic diagonal pattern that makes the twill fabric visually appealing.	Cyclic twill-woven objects	NA:NA:NA:NA	2010
Kazuhiko Yamamoto:Toki Takeda:Ryoichi Ando:Syota Kawano	In this study, we propose a novel system to create vivid animated 3d creature model from user's freeform 2d stroke. The most famous technique that construct 3d model from user's 2d sketch is Teddy system[Igarashi et al. 1999]. Past teddy like system create 3D mesh from user sketched 2d-shape, only what is needed is the stroke. These approaches allow a lot of freedom of creativity to us. However, there are also the cases we need to build the identification or determine the character of contents such like most games. In these cases, although it proper to design or control the contents in advance by the developers, the past methods are too much freely to control their contents. To address this, our approach enables end-users to collaborate with product developer's design without decreasing the freedom of creativity. It creates 3d animated creature from the combination of user's freeform stroke and the primitive models that are created by contents' designer beforehand. The generated creature depend on the user's inspiration, so obtained variations are infinte, but don't lack of the identification of the contents which is designed by the creators. Furthermore, our approach makes us to animate the generated model as if it is alive much easier than past methods.	Darwin's Lake: sketch-based creature creation system enables users to collaborate with contents designers	NA:NA:NA:NA	2010
Jae-Pil Heo:Duksu Kim:Joon-Kyung Seong:Jeong-Mo Hong:Min Tang:Sung-Eui Yoon	Simulating complex phenomena such as fracture requires collision detection (CD) methods to avoid any inter-collisions among deforming models and self-collisions (i.e. intra-collisions) within each deforming model. CD is typically the main computational bottleneck of simulating such complex phenomena.	FASTCD: fracturing-aware stable collision detection	NA:NA:NA:NA:NA:NA	2010
Nuno Goncalves:Ana Catarina Nogueira	Reflectors attract the attention of people since they reflect discontinuous images of the world and often provide unexpected information of a non-direct field of view. This is why reflections still have a lot of research attention in rendering of images in computer graphics, computer vision and optics, amongst other fields.	Faster accurate reflections throught quadric mirrors	NA:NA	2010
Yasuyuki Tomita:Reiji Tsuruno	We present a new method for making wave animation from still water image. In our method, users can control the behavior of wave in the water surface intuitively and interactively. After we simulate the wave using a Spectral Method [Tessendorf 1999], we have the water surface corresponding to the projection system of static images. Previous works for animating water surface. Chuang et al [Chuang and Goldman 2005] proposed a method for generating an animating of picture using displacement mapping and warping, however, those methods are only effective for gentle and calm water surfaces. Contrarily, our method is adaptively used for large scale waves of water height field.	Motion texture animation of water surface	NA:NA	2010
Sara Farag:Wael Abdelrahman	Simulation of the interactions with deformable models is important in many applications such as medical training and tissue engineering. To physically model the 3D object, both the inner and outer segments need to be considered. This implies dealing with different materials and hence different deformation behavior. Thus, a physically-based simulation needs to augment the behavior of embedded materials when the materials are in direct physical contact, and produce a plausible net result in both visual and haptic cues.	Physical modeling of heterogeneous embedded deformable object deformation	NA:NA	2010
James Gregson:Zheng Wang	Reconstructing scanned geometry is an important operation in geometry processing. Volumetric algorithms reconstruct the object volume by transforming range images into global coordinates and using scanline algorithms to build a scalar field that can be isocontoured to obtain the surface [Curless and Levoy 1996].	Rapid surface and volume mesh generation from depth-augmented visual hulls	NA:NA	2010
Craig Reynolds	This poster describes an abstract computation model of the evolution of camouflage in nature. Evolution is represented by genetic programming. Camouflage patterns are represented by procedural texture synthesis. A 2D environment is represented by a supplied photo. A predator is represented by a human's visual perception, interacting through a graphical user interface.	Using interactive evolution to discover camouflage patterns	NA	2010
Ku-Jin Kim:Jung-Eun Lee:Nakhoon Baek	We present an interactive algorithm to compute Voronoi diagrams for protein molecules. In the research area of biochemistry, a molecule is generally represented as a set of 3D spheres with various radii. In this paper, we propose a method to compute Voronoi diagrams for a set of spheres in the 3D discrete domain. We achieved interactive construction of Voronoi diagrams through our adaptive subdivision scheme and massively parallel processing supported by current graphics hardware.	Voronoi diagram computation for protein molecules using graphics hardware	NA:NA:NA	2010
Pedro Santos:Thomas Gierlinger:Rafael Huff:Martin Ritz:André Stork	In the real world, the ratio between full brightness of the sun and complete darkness is in the range of 2.000.000.000:1. However today's projection display technology is limited to contrast ratios of approximately 10.000:1. This hinders a convincing simulation and presentation of lighting effects in professional markets such as car styling, architecture and industrial design. At the same time, High Dynamic Range Imaging (HDRI) has been developed as a new field of research resulting in breakthroughs in image based lighting. What is missing today are interactive visualisation systems that fully support HDR material and light information from the acquisition stage right through the processing stage to the display stage. Current software systems do exist to simulate the effect of light sources in virtual scenes. However, they require specialist training, they are complex to use, they cannot operate in real-time, often requiring modification and recalibration. Current systems also do not support HDRI. This means that not only do they lack the ability to simulate real lighting conditions, e.g. the position and intensity of the sun, cloudcover, but also the behaviour of materials in various light conditions.	A full HDR pipeline from acquisition to projection	NA:NA:NA:NA:NA	2010
Sudarshanram Shetty:Mike Bailey	This paper introduces a layered model for rendering human teeth, to be used in photorealistic rendering of humans for games and animations. While the lighting responses of teeth have been studied in the dental industry ([Joiner 2004], [Brodbelt et al 1981], [Zijp and ten Bosch 1993]) for the production of realistic-looking dentures, to our knowledge this is the first study of its type in computer graphics for the production of realistic renderings. Human teeth exhibit translucency and are characterized by complex light interaction. From a rendering perspective, we make use of a bank of sliders (Figure 2) to vary optical properties at runtime and achieve desired rendering effects, including aging effects as shown in Figure 1. We also make use of hand drawn distribution maps for different layers rather than texture maps to achieve diffuse coloring.	A physical rendering model for human teeth	NA:NA	2010
Shailen Agrawal:Subodh Kumar	Ambient occlusion has been tackled in many different ways to inculcate realism into renderings. Ambient occlusion is a crude approximation to global illumination. But performing a full global illumination in real-time has turned out to be computationally expensive. Combined with local rendering models, ambient occlusion can produce renderings which have increased realism.	Approximate ambient occlusion for dynamic scenes using the GPU	NA:NA	2010
Lesley Northam:Joe Istead:Craig Kaplan	Hand-drawn sketches often depict geometry, colour and texture using loose and roughly drawn lines. Many automated sketching algorithms focus on accurately depicting salient details using pen-and-ink drawings. The approach of Hertzmann et. al. [2000] sketches the contours and silhouettes of 3D meshes, while the interactive algorithm of Kalnins et. al. [2002] renders decorative lines with artistic brushes and suggestions. Other 2D algorithms render Sobel and Canny edges with artistic brushes [Orzan et al. 2007].	Artistic sketching with a painterly rendering algorithm	NA:NA:NA	2010
Borom Tunwattanapong:Abhijeet Ghosh:Paul Debevec	Traditional image-based relighting technique requires capturing a dense set of lighting directions surrounding the object and uses the linearity of light transport property together with the illumination data of the target environment to relight an object [Debevec et al. 2000]. However, this can be a very data intensive process because such datasets typically involve photographing hundreds of lighting directions. It is also difficult to modify or edit the data in post-production environments because the data is high dimensional. Adjustment has to be made in several dimensions in order to add artistic effects to the result. Difficulty in acquisition process is also one of the main problems. The capturing process typically lasts long enough to only be suitable for static objects. In this poster, we present a relighting technique which greatly reduces the number of images required for relighting, and still generate realistic results. We combine spherical harmonics with point lights to achieve efficient image based relighting. Spherical harmonics can efficiently capture smooth low frequency illumination [Ramamoorthi and Hanrahan 2001] while point lights capture high frequency directional illumination. Combining both techniques, we create relighting results which have both low and high frequency illumination data. This technique also benefits the acquisition process by reducing the number of required photographs which results in shorter capture time. In addition, fewer dimensions of the data can potentially simplify modification or editing of reflectance data.	Combining spherical harmonics and point-source illumination for efficient image-based relighting	NA:NA:NA	2010
Kyoji Matsusima:Masaki Nakamura:Sumio Nakahara:Ichiroh Kanaya	James Cameron's Avatar pioneered 3-D films in practical meaning. All audiences of the movie were happy even though their eye points were fixed when they were watching the movie. However, there are certain area that fixed eye points are not acceptable. This is why the authors focus on Computational Holography (see Fig. 1).	Computational holography: the real 3-D by fast wave-field rendering in ultra high resolution	NA:NA:NA:NA	2010
Ole Gulbrandsen	Sharply separating a diffuse surface into a light and dark side often results in unwanted details. Combining normals from the actual surface with the normals from a simplified surface we get better control of the dark side.	Controlling the dark side in toon shading	NA	2010
Tomohito Hattori:Hiroyuki Kubo:Shigeo Morishima	This paper discusses an approach for computing the ambient occlusion by curvature depended approximation of occlusion. Ambient occlusion is widely used to improve the realism of fast lighting simulation. The ambient occlusion is defined as follows.	Curvature depended local illumination approximation of ambient occlusion	NA:NA:NA	2010
Jeong-ho Ahn:Jong-Chul Yoon:In-Kwon Lee	When artists draw a picture of photorealistic scene in an image, they describe only specific parts that represent characteristic features carefully, but they express the parts about less important region roughly. In study about Non-photorealistic rendering, image abstraction research reflects such artist's character. Thus, methods about image abstraction commonly preserve image features and flatten non-feature area. Recently, Kyprianidis et al. [2009] introduced Anisotropic Kuwahara Filtering (AKF) which generates feature preserved image abstraction using the smoothed structure tensor. However since they used only color information to defining anisotropic ratio, different regions that have similar color are conquered by each other unintentionally. Hence, we propose the depth-based AKF method that considers not only color, but also depth to generate image abstraction where boundary feateures are effectively preserved.	Depth-based Anisotropic Kuwahara Filtering	NA:NA:NA	2010
Andrew Cox:Jan Kautz	Real-time applications require simple techniques that enable predictable high performance rendering, but illumination methods for GPUs tend either to be complex and fragile on the one hand or very limited and offering poor visual quality on the other. The addition of a plausible global look to an application's lighting impacts users' perceptions of its realism, and on the spectrum of existing approaches, screen space ambient occlusion (SSAO) lies at the simplest and most predictable end. We have extended screen space ambient occlusion by replacing its depth buffer comparisons with a sampling of a volumetric discretization of the scene, while still evaluating it in an image-space post-process and thus retaining its predictable performance. We show improvements in quality over depth buffer based alternatives at a reasonable additional cost.	Dynamic ambient occlusion from volumetric proxies	NA:NA	2010
Roger Hoang:Steve Koepnick:Joseph D. Mahsman:Matthew Sgambati:Cody J. White:Daniel S. Coming	Real time global illumination (GI) is a difficult and steadily researched area. Advances in the field could potentially benefit virtual reality applications by increasing users' sense of presence. In immersive virtual environments (IVE) like CAVEs, applications must support perspective-corrected stereoscopic rendering. Dmitriev et al. [2004] performed GI in a CAVE using Precomputed Radiance Transfer, which requires a static scene. Mortensen et al. [2007] also performed GI in a CAVE using Virtual Light Fields which did not allow moving lights or geometry. We present our attempt to find GI techniques that support dynamic lights and scene geometry in our 6-sided CAVE-like IVE (DRIVE6). We implemented two separate illumination techniques: GPU photon mapping (GPM) and multiresolution splatting for indirect illumination (MSII). Each technique makes trade-offs between image quality and speed, and appropriate use of each depends on the needs of the application. Anecdotal evidence suggests that these techniques increase the sense of presence, warranting formal study. A user study is planned.	Exploring global illumination for virtual reality	NA:NA:NA:NA:NA:NA	2010
Xuehui Liu:Xiaoguang Hao:Mengcheng Huang:Fang Liu:Mingquan Zhou:Hanqiu Sun:En-Hua Wu	Soft shadow generation is a challenging problem in realistic rendering. Previous methods using shadow map or shadow volume work well for point light sources but are difficult to be extended to area lights. This paper presents a new method for fast soft shadow generation under dynamic area light sources. Our algorithm encodes the depth distribution of the scene into a coarse depth grid in a preliminary pass from the light point of view. In the second pass, the scene is rendered from the camera viewpoint to capture the frontmost layer. During deferred shading, the area light is sampled and the irradiance of each shaded pixel is accumulated along the ray. Experimental results demonstrate high quality soft shadows with interactive performance for dynamic scenes and lighting.	Fast soft shadow by depth peeling	NA:NA:NA:NA:NA:NA:NA	2010
Mohammad Obaid:Ramakrishnan Mukundan:Mark Billinghurst	Facial caricature drawing exaggerates physical face features for a comical effect, and can create an entertaining, humorous, and cartoon-like description of a person's face. Recently, example-based approaches have been introduced to generate facial sketches. Most of these approaches exaggerate the caricature appearance by altering the overall facial shape based on capturing artists' exaggeration-prototypes. Rare attempts have been made to alter and control the facial expressions of the generated caricatures. Moreover, example-based approaches learn how to generate artistic sketch styles through a training phase with prototypes from artist sketches. One of the limitations to these systems is that they require a lot of manual work with a large number of training prototypes drawn by artists. In addition, the final appearance of the caricature can only be limited to the prototypes used in the training phase.	Generating and rendering expressive caricatures	NA:NA:NA	2010
Patrick Cozzi:Frank Stoner	Accurately rendering an ellipsoid is a fundamental problem for virtual globes in GIS and aerospace applications where the Earth's standard reference surface is non-spherical. The traditional approach of tessellating an ellipsoid into triangles and rendering via rasterization has several drawbacks [Miller and Gaskins 2009]. Geodetic grid tessellations oversample at the poles (2a), which leads to shading artifacts and ineffective culling. Tessellations based on subdividing an inscribed platonic solid lead to problematic triangles crossing the International Date Line and poles (2b).	GPU ray casting of virtual globes	NA:NA	2010
Christian Linz:Christian Lipski:Marcus A. Magnor	Multi-image interpolation in space and time has recently received considerable attention. Typically, the interpolated image is synthesized by adaptively blending several forward-warped images. Blending itself is a low-pass filtering operation: the interpolated images are prone to blurring and ghosting artifacts as soon as the underlying correspondence fields are imperfect. We address both issues and propose a multi-image interpolation algorithm that avoids blending. Instead, our algorithm decides for each pixel in the synthesized view from which input image to sample. Combined with a symmetrical long-range optical flow formulation for correspondence field estimation, our approach yields crisp interpolated images without ghosting artifacts.	Multi-image interpolation based on graph-cuts and symmetric optical flow	NA:NA:NA	2010
Lei Ma:Shuangjiu Xiao:Xubo Yang	We presented an multi-interfaces image based method to simulate the refraction and related light effects in real time on a normal graphic card. The multi-interfaces based representation of the refractor is obtained by hiring depth peeling ideas. This leads to significantly better results than two interfaces refraction where only the front and back face of the object was captured.	Multi-interfaces based refractive rendering	NA:NA:NA	2010
Daniel M. Tokunaga:Cléber G. Corrêa:Ricardo Nakamura:Fátima L. S. Nunes:Romero Tori	Spatial visualization of virtual contents appears to be, with the appearance of stereoscopic displays, the next step for increasing immersion in visual output. This kind of visualization can be used to facilitate the understanding of complex informations, like anatomic structures. One approach currently adopted for this purpose is the use of non-photorealisitic rendering (NPR), like proposed by Tietjen, Isenberg and Preim [2005]. However, this NPR style, which conventionally tries to simulate a 2D illustration, fused with the the stereoscopic 3D visualization can break the 3D perception of the virtual contents. This work aims to study the 3D perception of virtual contents represented using NPR techniques, in order to evaluate the influence of NPR in the 3D perception when used with stereoscopic information visualization. The stereoscopic NPR visualization was applied in VIDA, a system for the study of anatomic structures that enables the stereoscopic visualization and interaction with virtual objects [Tori et al. 2009], in order to proceed the user tests, the figure 1c show the system used in the test.	Non-photorealistic rendering in stereoscopic 3D visualization	NA:NA:NA:NA:NA	2010
Martin Eisemann:Elmar Eisemann:Hans-Peter Seidel:Marcus Magnor	We present a system to automatically construct high resolution images from an unordered set of low resolution photos. It consists of an automatic preprocessing step to establish correspondences between any given photos. The user may then choose one image and the algorithm automatically creates a higher resolution result, several octaves larger up to the desired resolution. Our recursive creation scheme allows to transfer specific details at subpixel positions of the original image. It adds plausible details to regions not covered by any of the input images and eases the acquisition for large scale panoramas spanning different resolution levels.	Photo zoom: high resolution from unordered image collections	NA:NA:NA:NA	2010
Mahdi MohammadBagher:Jan Kautz:Nicolas Holzschuch:Cyril Soler	We present an algorithm for computing Percentage-Closer Soft Shadows inside a screen-space rendering loop. Our algorithm is faster than traditional soft shadows based on percentage closer filtering, while providing soft shadows of similar visual quality. It combines naturally with a deferred shading pipeline, making it an ideal choice for video games. This algorithm is not only faster, but allows the use of larger shadow maps without dramatically affecting the rendering speed.	Screen-space Percentage-Closer Soft Shadows	NA:NA:NA:NA	2010
Tom Cuypers:Se Baek Oh:Tom Haber:Philippe Bekaert:Ramesh Raskar	Diffraction is a common phenomenon in nature when dealing with small scale occluders. It can be observed on biological surfaces, such as feathers and butterfly wings, and man--made objects like rainbow holograms. In acoustics, the effect of diffraction is even more significant due to the much longer wavelength of sound waves. In order to simulate effects such as interference and diffraction within a ray--based framework, the phase of light or sound waves needs to be integrated.	WBSDF for simulating wave effects of light and audio	NA:NA:NA:NA:NA	2010
Benjamin P. DeLillo	For more than a decade, rich 3D content on the web has only been available via external, often proprietary, browser plugins. However, a new standard has emerged to change this. WebGL, currently under development by the Khronos Group, is a standard specification for javascript bindings to OpenGL [Khronos 2009]. In September 2009 WebGL support made its way to development builds of Firefox 3.7. Since this time, WebGL has gained greater traction and visibility within developer communities. Although impressive demonstrations of WebGL are available [Vukicevic 2009], we believed that the creation of a development library would help kickstart interest in the creation of new applications.	WebGLU development library for WebGL	NA	2010
Stefan Elsen	WorldSeed introduces a fractal architecture that allows to generate and render full scale planets in real-time. Similar to existing concepts (e.g. by Szeliskit and Terzopoulos [1989] [1]) WorldSeed uses self-similar fractal subdivision to generate landscape detail. By expanding the concepts introduced by Bokeloh and Wand [2006] [2] to use triangular patches rather than rectangles, WorldSeed is capable of generating relatively distortion free spherical surfaces. 64bit integer seeds are used to generate consistent worlds, similar to a concept suggest by Teong Joo Ong et al. [2005] [3]. WorldSeed will be an integral part of a virtual reality application within the CodeVenture research project to teach basic modeling and programming skills to teenagers [4].	WorldSeed	NA	2010
Tai-Wei Kan:Chin-Hung Teng	The field of Augmented Reality (AR) has grown and progressed remarkably in recent years and many useful AR applications have been developed focusing on different areas such as game and education. However, most of these AR systems are designed for closed applications with limited number of users and restricted 3D contents. They are inappropriate for public environment with diverse 3D contents due to the following issues: (1) Limited number of markers. To ensure recognition accuracy, the number of markers is typically limited. (2) Marker registration. Pervasive AR systems often require a registration process each time a new marker is included in the systems. (3) Content management. Traditional AR systems are closed systems with all of their contents stored in a system server. This mechanism is inefficient for public systems with a huge volume of 3D contents. (4) Special Markers. The markers of traditional AR systems are often designed with particular patterns. They are not public or universal patterns.	A framework for multifunctional Augmented Reality based on 2D barcodes	NA:NA	2010
Hiroki Nishino	Markers are widely used for camera-based interaction. Yet, most of the marker tracking methods have considerable limitations in shapes and designs; they are not usually visually meaningful to the users. Such an issue on visually communicative designs can be very important to provide visual cues in a mobile/pervasive environment where a user must first notice a marker and understand its meaning before initiating interaction, unlike in an immersive environment with a head-mounted-display that keeps displaying information on the detected markers.	A shape-free, designable 6-DoF marker tracking method	NA	2010
Tej Tadi:Patrick Salamin:Frederic Vexo:Daniel Thalmann:Olaf Blanke	Over the years, different approaches have been explored to build effective learning methods in virtual reality but the design of effective 3D manipulation techniques still remains an important research problem. To this end, it is important to quantify behavioral and brain mechanisms underlying the geometrical mappings of the body with the environment and external objects, both within the virtual environments (VE), the real world and relative to each other. The successful mapping of such interactions entails the study of fundamental components of these interactions, such as the origin of the visuo-spatial perspective (1PP, 3PP) and how they contribute to the user's performance in the virtual environments. Here, we report data using a novel set-up exposing participants - during free navigation - with a scene view from either 3PP or the habitual first-person perspective (1PP).	Brain activity underlying third person and first person perspective training in virtual environments	NA:NA:NA:NA:NA	2010
Takashi Kajinami:Oribe Hayashi:Takuji Narumi:Tomohiro Tanikawa:Michitaka Hirose	In our research, we aim to construct an interactive exhibition system for museums to convey the background information about its exhibit, which today's museums need. Museums have to preserve their exhibits, and that was a limitation on the exhibition form. They cannot hold a quite new type of exhibition because it might jeopardize their exhibits. So they cannot do more than the exhibition with conventional display cases and panels, in other words a passive exhibition to convey the background information. Digital technologies untie them from this limitation. We can convey the background information effectively using CG in exhibitions, without jeopardizing real exhibits.	Digital display case: the exhibition sysytem for conveying the background information	NA:NA:NA:NA:NA	2010
Megha Davalath:Mat Sanford:Anton Agana:Ann McNamara:Frederic Parke	3D Immersive visualization systems provide a novel platform to present complex datasets and virtual environments (VEs). The objective of the research presented here is to compare user-interaction and performance between two immersive displays: a low-cost, tiled, multi-screen immersive visualization system and a more expensive, continuous, immersive visualization facility. The low cost system is designed using off-the-shelf components and constructed by arranging LCD displays in a tiled hemispherical layout. The expensive system is a Rockwell-Collins semi-rigid, rear projected, continuous curved screen. With the low cost paradigm, seams are introduced into the image where the displays are tiled. We hypothesize that the tiled system presents an equivalent visual experience, despite the seams introduced by connecting the screens. Both systems will be tested through psychophysical experimentation designed to measure aspects of human performance. Proving our hypothesis will impact lower budget organizations, currently unable to afford such displays, by providing an opportunity to work with lower cost immersive visualization systems at no sacrifice to user-experience.	Evaluating performance in immersive displays	NA:NA:NA:NA:NA	2010
Tae-Joon Kim:Yongyoung Byun:Yongjin Kim:Bochang Moon:Seungyong Lee:Sung-Eui Yoon	Ray tracing and collision detection are widely used for providing high-quality visualizations and user interactions. In these algorithms, we need to detect intersecting primitives between two input objects (e.g., a ray and a 3D object in ray tracing and two 3D objects in collision detection). In order to efficiently detect these intersecting primitives, hierarchical traversal and culling by using bounding volume hierarchies (BVHs) are commonly used.	HCCMeshes: hierarchical-culling oriented compact meshes	NA:NA:NA:NA:NA:NA	2010
Takuji Narumi:Takashi Kajinami:Tomohiro Tanikawa:Michitaka Hirose	So far, gustatory information has rarely been studied in relation to computers, even though there are lots of studies on visual, auditory, haptic and olfactory information. This scarcity of research on gustatory information has several reasons. One reason is that gustatory sensation is based on chemical signals, whose functions have not been fully understood yet. Another reason is that perception of gustatory sensation is affected by other factors, such as vision, olfaction, thermal sensation, and memories. Thus, complexity of cognition mechanism for gustatory sensation as described above makes it difficult to build up a gustatory display.	Meta cookie	NA:NA:NA:NA	2010
Tsouknidas Nikolaos:Tomimatsu Kiyoshi	Advancements in mobile technology have recently contributed to the surfacing of viable mobile augmented reality applications. Still, the main problem of mobile AR, as with all implementations of augmented reality, is the accurate and robust registration of the live camera feed and the digital contents (e.g. images, video, 3D models). So far, mobile AR applications make use of GPS and marker technology (fiducials) to solve this problem (e.g. Sekai Camera, Layar, AR-toolkit, Unifeye). The disadvantages are that, firstly, GPS can only guess the position of the device within a 5 to 10 meter radius, is subjected to weather changes, and does not work indoors. Secondly, although marker registration is very accurate, a marker has to be printed and visible by the camera in order to work.	QR-code calibration for mobile augmented reality applications: linking a unique physical location to the digital world	NA:NA	2010
Justin Ehrlich	The application of virtual reality is becoming ever more important as technology reaches new heights allowing virtual environments (VE) complete with global illumination. One successful application of virtual environments is educational interventions meant to treat individuals with autism spectrum disorder (ASD) since VEs induces pretense and presence, without the social fear of failing in the real world. Pretense and presence improves the user's ability to learn social skills and enhances perception-taking capabilities. Because of the lack of conclusive research of improving presence of individuals with ASD in a VE, this study evaluated ways of enhancing presence to improve a VE intervention for individuals with ASD. In the field of computer science visual realism, new research has surfaced linking illumination realism to presence. Since this research was limited to Neurologically Typical (NT) individuals (those without ASD), and because generalization is particularly important to individuals with ASD, this study targeted these individuals. Further, since head mounted displays (HMD) are impractical for widespread delivery of a VE intervention application and since the literature is inconclusive about the effect of VEs without HMDs on presence, this study used standard desktop displays. This work measured the extent to which visual realism induces the presence of a VE intervention, enumerated the specific characteristics of rendering that promote the sense of presence and the ability to generalize, and statistically verified the enhanced outcomes from using these techniques. After conducting a between-group study with 24 individuals with ASD, illumination realism was found to have a positive effect (effect size=0.6) on the presence felt by these individuals. This work contributes to the field of visualization and special education by providing empirical evidence supporting the claim that illumination realism increases the presence felt by users with ASD when interacting with a PVE.	The effect of desktop illumination realism on a user's sense of presence in a virtual learning environment	NA	2010
Woong Choi:Takahiro Fukumori:Kohei Furukawa:Kozaburo Hachimura:Takanobu Nishiura:Keiji Yano	Recently, extensive research has been undertaken on digital archiving of cultural properties in the field of cultural heritage. These investigations have examined the processes of recording and preserving both tangible and intangible materials through the use of digital technologies.	Virtual Yamahoko parade in virtual Kyoto	NA:NA:NA:NA:NA:NA	2010
Santi Fort	This research project is conducted by a consortium of European industrial and academic partners that include companies like: Technicolor, Digital Projection, DTS Europe, Doremi, Mediapro, Creative Wokers (CREW) and Datasat, and research centers: Barcelona Media, Joaneum research, University of Hasselt, University of Reading and Fraunhoffer. It is aimed to research, develop and demonstrate novel forms of compelling entertainment experiences based on new technologies for the capture, production, networked distribution and display of three-dimensional sound and images. 2020 3D Media research project is co-funded by the European Commission under the Seventh Framework Programme (FP7--ICT).	2020 3D media: new directions in immersive entertainment	NA	2010
Ippei Takauchi:Yuta Hara:Hiromu Saito:Ryo Asakura:Motofumi Hattori	It is becoming an important field in computer art to visualize High Dimensional Manifolds. [Banchoff 1990] [Kusabuka and AlgorithmicArt 2006] In this research, we will find the dynamics equation which express deforming motion of the α dimensional manifold r, and visualize many interesting motions of the deformed manifold r(t) by CG animation.	A mathematical model of deforming manifolds and their visualizations by CG animation	NA:NA:NA:NA:NA	2010
Dilip Banerjee:John Gross:Pradeep Reddy Gaddam:Marc Olano:William Hess:Judith Terrill:Terence Griffin:John Hagedorn:John Kelso:Steve Satterfield	In order to move away from the current prescriptive design methods towards performance based methods for the design of structures under fire, we need validated computer models. The next section describes our approach for modeling and analysis.	An integrated interactive visualization and analysis environment to study the impact of fire on building structures	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2010
Toshiki Takeuchi:Takuji Narumi:Kunihiro Nishimura:Tomohiro Tanikawa:Michitaka Hirose	Logging images, voices, etc. of one's daily life is called "lifelog". Recently, it is done research by many researchers because of rapid increasing information with a highly information-oriented society and increasing capacity and lowering price of logging device.	Forecast and visualization of future expenditure with logging and analyzing receipts	NA:NA:NA:NA:NA	2010
S. D. Laycock:M. B. Stocks:S. Hayward	A haptic feedback device enables a user to manipulate three dimensional structures and feel forces contained within complex data-sets such as those resulting from computational biology. However, as the data-set grows in size it becomes difficult to ensure that the user can easily interact with every part of it. One could scale the data-set down to fit into the haptic workspace, however, this could result in important features being missed. A secondary problem is enabling the user to select points efficiently within the three dimensional data set, where the perception of depth can be difficult. In this paper we present novel techniques to rapidly navigate large and complex data-sets with a haptic feedback device, whilst still permitting accurate and fast selection of points in three dimensional space. We have applied these techniques as part of software dedicated to studying the response of biomolecules to externally applied forces using elastic network models.	Navigation and exploration of large data-sets using a haptic feedback device	NA:NA:NA	2010
Shantanu H. Joshi:Ian Bowman:Robin Jennings:David Hasson:Zhizhong Liu:Arthur W. Toga:John D. Van Horn	Large scale neuroimaging data archival protocols are gradually becoming ubiquitous in both research as well as clinical settings. Current user-database interfaces are limited to textual searches and often require data-specific knowledge for performing queries. This is proving to be an obstacle for researchers who wish to obtain a holistic view of the data before designing pilot neuroscientific studies or even formulating statistical hypotheses. Instead of providing a restricted, unidimensional view of the data, we seek to place a multi-dimensional view of the entire neurodatabase at the user's disposal. With the aim of visual navigation of complete neuro-repositories, we introduce the concept of brain meta-spaces. The meta-space models the implicit nonlinear manifold where the neurological data resides, and encodes pair-wise dissimilarities between all individuals in a population. Additionally, the novelty in our approach lies in the user ability to simultaneously view and interact with many brains at once but doing so in a vast meta-space that encodes (dis)similarity in morphometry.	Visual mining of neuro-metaspaces	NA:NA:NA:NA:NA:NA:NA	2010
Kunihiro Nishimura:Jun'ichi Nakano:Tomohiro Tanikawa:Michitaka Hirose	The concept of this study is to collect "ant's eye view" to generate "bird's eye view". When we can collect large number of ant's eye views, we can integrate them and can generate bird's eye view. The idea of this study is an assumption that we can grasp both whole view and situations at multiple places when we can see real-time-report from various points. To achieve this idea, we focus on lifelog technology. Using a wearable computer or small devices and sensors, it is easy to get our daily-life data. We can record our photos, sounds, positions, and so on. It will be lifelog data. When we can collect multiple people's lifelog data, we can utilize them much more. In this study, we propose a visualization method for multiple people's life log data. The lifelog data is uploaded to the server, and the viewer visualizes the data that provides us to see the whole view of the data. We combined position information and sensor information of remote places, and visualized these data.	Visualization of multiple people's lifelog: collecting "Ant's-eye view" to generate "Bird's-eye view"	NA:NA:NA:NA	2010
Pedro Cruz:Penousal Machado	This is an information visualization project that narrates the decline of the British, French, Portuguese and Spanish empires during the 19th and 20th centuries. These empires were the main maritime empires in terms of land area during the referred centuries [Wikipedia]. The land area of the empires and its former colonies is continuously represented in the simulation. The size of the empires varies during the simulation as they gain, or lose, territories. The graphic representation forms were selected to attain a narrative that depicts the volatility, instability and dynamics of the expansion and decline of the empires. Furthermore, the graphic representation also aims at emphasizing the contrast between their maximum and current size, and portraying the contemporary heritage and legacy of the empires.	Visualizing empires decline	NA:NA	2010
