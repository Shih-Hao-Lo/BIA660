I. Yosun Chang	Augmented Reality (AR) Interfaces for the Internet of Things (IoT) is an implementation of a provisional universal software platform for IoT devices, created by a solo independent developer. We showcase several use-cases of being able to point one's camera-bearing device or head mounted display (HMD) to IoT objects and the appropriate interfaces that arise to read and/or control these devices, as well as the infrastructure to enable accuracy in these interactions.	Augmented reality interfaces for the internet of things: extended abstract	NA	2018
Jisun Jang:Tomasz Bednarz	The HoloSensor project aims to enhance the visualisation and visual analytics data sourced from various sensors through use of Augmented Reality (AR) technology, allowing users to anchor information throughout various locations inside a building. The output of the project is an application, that connects networked sensors (Arduino with temperature, humidity, light sensors) communicating its data though a Python-based server. Users are able to interact with this data on holograms in real-time through the Microsoft HoloLens. This integration of the immersive AR technology with Internet of Things (IoT) shows its versatile usage in all three areas of human experience: health, home and entertainment.	HoloSensor for smart home, health, entertainment	NA:NA	2018
Fangwei Lee:Janet Lin:Elliot Segal	REALITEER Corp. created a cross-platform and kid-friendly digital mirror that can be used for education and body exercise utilizing AR/VR technologies. In a gamified manner, we take users through educational research-based exercises that will not only tackle the psychiatric and physical conditions but better overall well-being.	Kid-friendly digital mirror for education and exercise	NA:NA:NA	2018
Max Reimann:Amir Semmo:Jürgen Döllner:Sebastian Pasewaldt:Mandy Klingbeil	We present MaeSTrO, a mobile app for image stylization that empowers users to direct, edit and perform a neural style transfer with creative control. The app uses iterative style transfer, multi-style generative and adaptive networks to compute and apply flexible yet comprehensive style models of arbitrary images at run-time. Compared to other mobile applications, MaeSTrO introduces an interactive user interface that empowers users to orchestrate style transfers in a two-stage process for an individual visual expression: first, initial semantic segmentation of a style image can be complemented by on-screen painting to direct sub-styles in a spatially-aware manner. Second, semantic masks can be virtually drawn on top of a content image to adjust neural activations within local image regions, and thus direct the transfer of learned sub-styles. This way, the general feed-forward neural style transfer is evolved towards an interactive tool that is able to consider composition variables and mechanisms of general artwork production, such as color, size and location-based filtering. MaeSTrO additionally enables users to define new styles directly on a device and synthesize high-quality images based on prior segmentations via a service-based implementation of compute-intensive iterative style transfer techniques.	MaeSTrO: mobile style transfer orchestration using adaptive neural networks	NA:NA:NA:NA:NA	2018
Roberto Lopez Mendez	Up to now in mobile Virtual Reality (VR), we have been able to only control the camera orientation with our head. However, premium smartphones already incorporate the essential technology to track user position. Apple ARKit and Google ARCore designed for Augmented Reality (AR) applications are already enabled in millions of phones. Both libraries can be used to achieve 6DoF mobile VR. This contribution combines head orientation tracking provided by the VR headset with the position tracking capability provided by Google ARCore to achieve 6DoF tracking in mobile VR.	Mobile inside-out VR tracking, now available on your phone: extended abstract	NA	2018
Alyn Rockwood:Kun Gao	The SuperD 3D modeling app rapidly creates high quality, sleek and intricate shapes for 3D concept design. It employs the widely known SubD interface, which facilitates learning and provides intuitive shape controls; but without any of the troublesome extraordinary points or patch clusters.. The uniquely defined surfaces are smooth (often C2, approaching Class A) and are watertight for 3D printing. SuperD is VR/AR enabled.	SuperD: conceptual 3D modeling on mobiles	NA:NA	2018
Kevin J. Bruggeman:Skylar W. Wurster	This document explains the design, concept, and purpose behind The Hiatus System. This project aims to identify the possibility of using virtual reality to enhance the effectiveness of mindfulness based stress reduction (MBSR) practice on individuals with low cognitive memory. The Hiatus System was developed from the ongoing research at The Ohio State University on Virtual Healing Spaces. Healing Spaces, a phrase coined by Dr. Esther Sternberg, is a space that promotes a stress reductive state. This virtual experience is designed to attain and maintain user attentions towards the meditative practice. The hypothesis is that the virtual environment, combined with real time biofeedback of the breath, will create a system that can effectively teach the user how to meditate and reduce stress.	The Hiatus system: virtual healing spaces: low dose mindfulness based stress reduction virtual reality application	NA:NA	2018
