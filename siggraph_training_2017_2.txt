Naoki Nozawa:Tsukasa Fukusato:Shigeo Morishima	Resizing of 3D model is necessary for computer graphics animation and application such as games and movies. In general, when users deform a target model, they built on a bounding box or a closed polygon mesh (cage) to enclose a target model. Then, the resizing is done by deforming the cage with target model. However, these approaches are not good for detailed adjustment of 3D shape because they do not preserve local information. In contrast, based on a local information (e.g., edge set and weight map), Sorkine et al. [Sorkine and Alexa 2007; Sorkine et al. 2004] can generate smooth and conformal deformation results with only a few control points. While these approaches are useful for some situations, the results depend on resolution and topology of the target model. In addition, these approaches do not consider texture (UV) information.	3D model partial-resizing via normal and texture map combination	NA:NA:NA	2017
Shinji Mizuno:Kenji Funahashi	The authors have been developing an interactive CG creation system "Amazing Sketchbook" in which, a user can create a 3DCG scene composed of many 3DCG objects interactively by drawing a picture in an ordinary physical sketchbook with ordinary physical color pens, and can interact with the 3DCG scene by touching the picture or shaking the sketchbook [Kondo et al. 2013]. "Amazing Sketchbook" does not require any drafts to color in, and a user can create 3DCG scenes from arbitrary hand-drawn pictures interactively, unlike other systems with the same concepts [Clark et al. 2011][teamLab 2013].	"Amazing sketchbook advance"	NA:NA	2017
Masanori Nakamura:Shugo Yamaguchi:Shigeo Morishima	We propose a novel font called Beautifying Font to assist learning techniques in writing Chinese calligraphy. Chinese calligraphy has various expressions but they are hard to acquire for beginners. Beautifying Font visualizes the speed and pressure of brush-strokes so that users can intuitively understand how to write.	Beautifying font: effective handwriting template for mastering expression of Chinese calligraphy	NA:NA:NA	2017
Claudio Mura:Renato Pajarola	We propose a scalable strategy for the architectural modeling of large-scale interiors from 3D point clouds. We exploit the fact that buildings are structured into different rooms to cast the modeling of a large, multi-room environment as a set of simpler and independent reconstruction problems. This drastically reduces the complexity of the computation and makes the processing of large-scale datasets feasible even without using restrictive priors that affect the precision of the final output.	Exploiting the room structure of buildings for scalable architectural modeling of interiors	NA:NA	2017
Masaki Fujita:Suguru Saito	Although 3D CG tools produce similar style animations with conventional 2D animation, conventional hand-drawn animation has advantages that cannot be substituted in animation produced by those tools. This paper introduces a new method to assist animators in creating 2D keyframe animation, which utilizes the self-shaped canvas hidden from the user. Drawing keyframes is the main input. Because the canvas has a three-dimensional shape deformed according to keyframes, inbetween animation with them mapped on it obtains depth-aware motion.	Hand-drawn animation with self-shaped canvas	NA:NA	2017
Teemu Lindborg:Philip Gifford:Oleg Fryazinov	Modern 3D modelling tools allow to create very complex scenes, however, they usually require a certain level of knowledge from users, which is not always possible for artists, especially if one needs to define internal material properties or change the parameters during the modelling process. In this paper, we present a visual, node-based approach to heterogeneous 3D modelling by using signed distance fields and material interpolation which allows for easy parametrisation of the scene with interactive rendering for a good user experience.	Interactive parameterised heterogeneous 3D modelling with signed distance fields	NA:NA:NA	2017
Yoichi Ochiai:Tatsuya Minagawa:Takayuki Hoshi:Daitetsu Sato:Satoshi Hashizume:Kazuki Takazawa:Amy Koike:Ippei Suzuki:Atsushi Shinoda:Kazuyoshi Kubokawa	Aerial manipulation of material objects is fascinating and is used in many performance situations. Many scientific demonstrations and magic shows employ these levitations. Acoustic, magnetic, electric, and superconductive levitation are used in many situations. Adding controllability and increasing the design space of these levitation methods are often studied for use in entertainment applications in graphics and HCI communities. In this study, we focus on superconductive levitation (Figure 1) because it has not been well explored for entertainment applications.	LeviFab: stabilization and manipulation of digitally fabricated objects for superconductive levitation	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2017
Hojin Choi:Seungkyu Lee	We propose a framework for novel view synthesis for a cartoon face given two images of key views such as front and side views. Due to the structure inconsistency of cartoon faces in manually drawn images, matching region detection between different views is a challenging task. We propose a local complexity based segmentation that grabs facial components such as eyes, eyebrows and mouth that are not clearly separated by contour in cartoon faces. We automatically find the matching region in the two input key images and morph them to create intermediate views.	Novel view synthesis from two cartoon face drawings	NA:NA	2017
Hei-Ting Tamar Wong:Yaozhun Huang:Sze-Chun Tsang:Miu-Ling Lam	In applications such as computational swept volume light painting, real-time contour rendering is essential to ensure shape fidelity. However, there is, at yet, no real-time and scalable solution for slicing a model in arbitrary direction. We propose a new slicing method by organizing the triangular mesh into Octree data structure. The approach can significantly reduce the computational time and improve the performance of real-time rendering. The data structure is invariant to the slicing direction, thus constructing the Octree is a one-time, offline pre-process.	Real-time model slicing in arbitrary direction using octree	NA:NA:NA:NA	2017
Austin E. MacKay:Jonathan D. Denning	We use systematic layering of variously sized layers to quickly create large, seemingly non-repeating textures. This leads to significantly more control for artists to create expansive visual scenes without the need for large teams to create massive textures. Our method maintains the visual appeal of seamless and non-repeating design, while using little memory and rendering quickly.	rpTextures: systematic layering for large texture generation	NA:NA	2017
Quentin Corker-Marin:Valery Adzhiev:Alexander Pasko	This poster describes an original approach to producing artistic shapes in a cubist style. We propose mathematical models and algorithms for adding cubist features to (or cubification of) time-variant sculptural shapes as well as a practical technological pipeline embracing all the main phases of their production. A novel method is proposed for faceting and local distortion of the given artistic shape. A new concept of a 4D cubist camera is introduced for multiple projections from 4D space-time to 3D space and combining them using space-time blending to create animated sculptures. The proposed techniques are implemented and experimental results are presented.	Space-time cubification of artistic shapes	NA:NA:NA	2017
Xin Liu:Xuan Li:Caowei Zhang:Chuqi Tang:Xiaolian Zhang:Cheng Zheng:Ye Tao:Guanyun Wang:Wenjie Xu:Cheng Yao:Fangtian Ying	Inspired by the composition characteristics of Escher's images, we noticed that regular mosaic patterns can be interconverted from background to foreground smoothly by gradually changing borders of mosaic shapes in a non-linear way. Based on this, we developed an interactive system to assist children in creating artworks of pattern evolution. In this paper, taking the child's graffti patterns as a source of inspiration, our system employed interactive GA (IGAs) to achieve the transformation and evolution of patterns as well as the positive and negative conjunction among any two or more patterns. Our developed system aims to not only help children complete the art creations for the transformation and conjunction of innovative positive and negative forms among patterns, but also inspire the development of their brain which is the original purpose of building the system.	The artwork generating system of escher-like positive and negative pattern evolution	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2017
Wataru Date:Yasuaki Kakehi	In this research we propose a new method for typeface design that incorporates the chronological change of physical materials as the algorithm, and interventions by the environment and users as variables to determine the typeface shape in the design. We have focused on physical materials and phenomena with different time scales, such as vaporization of water, oxidation of copper, discoloration of leaves, and have designed and implemented a device for forming typefaces.	Typeharvesting: a typeface design utilizing time-dependent appearance change of physical materials	NA:NA	2017
David Goodhue	Modern video game engines feature animation compression built using algorithms which offer fast runtime decompression. In comparison to other state-of-the-art industry techniques, we present new methods by which better compression ratios can be realized without significantly impacting performance. We first present a technique for reconstructing a stream of sparsely-keyed rotations from a sequence of angular velocities. Next, we encode those velocities as consecutive deltas, making it possible to use much smaller key sizes. As a final enhancement, we allow the speed component of our angular velocity to in some cases receive influence from velocity keys which do not specify an axis of rotation. Instead, the axis remains unchanged from the previous frame's velocity, yielding smaller data on those frames.	Velocity-based compression of 3D animated rotations	NA	2017
Naoki Kawai	We propose a simple method to generate new views of a scene using a sparse light field generated from a few panoramic images. We introduce a virtual sphere centered at a new viewpoint as a screen for projecting rays of the light field to get resampled images. Our method creates new views directly from a light field and thus provides a way to build virtual reality system which is more stable than using 3D modeling and rendering and less distorted than image morphing approaches.	A simple method for light field resampling	NA	2017
Hirotsugu Yamamoto:Shusei Ito:Tomoyuki Okamoto:Ryosuke Kujime:Kengo Fujii:Yoshiki Terashima:Yukihiro Takeda	We have developed a visual, thermal and acoustic floating aerial display. Our developed display forms aerial visual images over a tabletop and locally heats a part of aerial images. Furthermore, our display forms locally aerial speaker on a part of aerial images, where sound pressure locally increases. Aerial images are formed with aerial imaging by retro-reflection (AIRR), which features a wide viewing angle, scalability, and mass-productivity. The aerial heater and the aerial speaker are realized with double-layered arrays of rectangular mirror (WARM) and crossed-mirror array (CMA), respectively. In combination of these imaging methods, we have realized a multi-modal aerial display.	Aerial display with thermal and acoustic sensation	NA:NA:NA:NA:NA:NA:NA	2017
Yu-Kai Chiu:Yi-Lung Kao:Yu-Hsuan Huang:Ming Ouhyoung	Creating videos from compositing multiple footage requires the support of the robotic arm due to the camera motion model needs to be precise. It is extremely difficult to shoot the footage with hand-held camera. However, the cost of the robotic arm is extremely high. Thus, we introduce an augmented reality guiding system to replace it. In our system, we utilized augmented reality to guide the user for the camera motion and implemented an algorithm of stabilization and camera motion alignment for a hand-held camera. The system reduces the cost but remaining good quality of the result at the same time.	AR filming: augmented reality guide for compositing footage in filmmaking	NA:NA:NA:NA	2017
Molly Flexman:Ashish Panse:Benoit Mory:Christopher Martel:Atul Gupta	There is a growing awareness of the effects of radiation exposure to the patient and staff during minimally-invasive x-ray guided interventions. Augmented reality can provide real-time visualization of radiation dose during the procedure with relevant information displayed in the appropriate context.	Augmented reality for radiation dose awareness in the catheterization lab	NA:NA:NA:NA:NA	2017
Yu-Kai Chiu:Yu-Hsuan Huang:Ming Ouhyoung	The traditional method of cinematography tutorials often separates the theories from the practical experience. The theory was taught first, thus the students often need to practice on their own after that. However, cinematography equipment is costly and not affordable for most students. In this poster, we introduce a virtual reality tutorial system of cinematography. The system contains hands-on drills and simulation of cinematography equipment. Therefore, the user could learn cinematography in an immersive way through our system and gain hands-on experience at the same time. Our system are and can be adapted to assisting tools for production use, and not just for a tutorial.	Cinematography tutorials in virtual reality	NA:NA:NA	2017
Yun Suen Pai:Benjamin I. Outram:Benjamin Tag:Megumi Isogai:Daisuke Ochi:Hideaki Kimata:Kai Kunze	Layout planning is a process often used in architectural interior design, for factory production plans, and so on. We present CleaVR, a system that provides the user with an immersive virtual reality system that accurately visualizes the layout plan in three dimensions as shown in Figure 1(a). The user is able to freely orbit around the design to observe it in every angle for an accurate evaluation and assessment. The implemented gesture recognition system means that no physical buttons are required, allowing a complete immersion with intuitive controls. These controls allow the user to pan around the environment, pinch to pick and place objects, as well as swiping the view to switch into first person view, as shown in Figure 1(b). With our system, architects, engineers, designers, and even sports analysts may approach their targeted environment through a multi-user, multi-view tool with full control of the virtual environment purely by intuitive gesture controls.	CleaVR: collaborative layout evaluation and assessment in virtual reality	NA:NA:NA:NA:NA:NA:NA	2017
Mengyuan Ren:Ning Xie:Yang Yang:Heng Tao Shen	Cosmetic medical visualization has become an important application in computer graphics, especially for facial appearance visualization[Chandawarkar et al. 2013]. Recent approaches have reached very realistic results by blend shape[Ma et al. 2012], which is the most practical tool to make the facial appearance and expression animation in application domains on the entertainment industry (VFXs and games). In many role-playing games (RPGs), players enable to edit the character's facial appearance. However, it is unrealistic since arbitrary discontinuities and position relationship violations (a selected nose might be at a higher position that the bottom of the eyes selected from a different character) caused by players' manual operation. Moreover, the validity on changing facial organs has not be considered well yet.	Cosmetic-vis: sample-based 3D facial editor for cosmetic medical visualization	NA:NA:NA:NA	2017
Sheng-Kuen Huang:Hong-Shiang Lin:Ming Ouhyoung	We presents an alternative and effective method for omnistereo panorama video generation by using deformable spheres. Deformable spheres use vertex based spherical mesh to represent the depth of a scene. Meanwhile, the spherical mesh was substituted for the original 3D points cloud mesh in the rendering step. In our experiments, this approach reduces the time of omnistereo panorama generation and the result is smooth in both spatial and temporal domain.	Effective omnistereo panorama video generation by deformable spheres	NA:NA:NA	2017
Yun Suen Pai:Benjamin I. Outram:Benjamin Tag:Megumi Isogai:Daisuke Ochi:Kai Kunze	Viewing 360-degree-images and videos through head-mounted displays (HMDs) currently lacks a compelling interface to transition between them. We propose GazeSphere; a navigation system that provides a seamless transition between 360-degree-video environment locations through the use of orbit-like motion, via head rotation and eye gaze tracking. The significance of this approach is threefold: 1) It allows navigation and transition through spatially continuous 360-video environments, 2) It leverages the human's proprioceptive sense of rotation for locomotion that is intuitive and negates motion sickness, and 3) it uses eye tracking for a completely seamless, hands-free, and unobtrusive interaction. The proposed method uses an orbital motion technique for navigation in virtual space, which we demonstrate in applications such as navigation and interaction in computer aided design (CAD), data visualization, as a game mechanic, and for virtual tours.	GazeSphere: navigating 360-degree-video environments in VR using head rotation and eye gaze	NA:NA:NA:NA:NA:NA	2017
Toshikazu Ohshima:Kenzo Kojima	In this study, we propose the use of mixed reality (MR) for the purposes of biological education. Our objective is to create an interactive edutainment MR framework for users to learn about nature and human beings. MitsuDomoe, an interactive ecosystem simulator of virtual creatures in a petri dish, comprises three species of primitive artificial creatures. MitsuDomoe simulates the predation chain of the virtual creatures in the petri dish, and users can interact with this ecosystem via the petri dish interface. Users can also experience immersive observation by wearing HMD. By combining the MR petri dish and immersive virtual reality (VR) interfaces, we synergistically improve user understanding of the experience.	MitsuDomoe: ecosystem simulation of virtual creatures in mixed reality petri dish (2)	NA:NA	2017
Hiroyuki Osone:Takatoshi Yoshida:Yoichi Ochiai	Many people exercise in water. However, when they swim in the pool, they may get bored. Therefore, studies on virtural reality (VR) and augmented reality (AR) in water have been made. Aquacave[Yamashita et al. 2016] allows you to experience VR in an aquarium. The payload is low but the cost of setting up the environment is high. We cannot swim, over a wide area, and so it cannot be used by many people. Zhang, Tan, and Chen (2016) have created a head-mounted display (HMD)[Zhang et al. 2016] that can be used underwater, but in this structure, air enters the device, which greatly increases the buoyancy, making swimming uncomfortable. In Quarles (2015)[Quarles 2015], water was present in the internal structure of the HMD, but its optical impact was not discussed, the viewing angle is unknown. Therefore, we designed an optimal HMD for swimming. Because there was no air layer in the HMD, it was expected that buoyancy would not be an issue and that the HMD could easily be worn while swimming. Our study is the first to evaluate underwater VR by subject experiments.	Optimized HMD system for underwater VR experience	NA:NA:NA	2017
Yoonsik Yang:Yoonjung Park:Seungho Chae:Tack-don Han	With the development of digital technology, many researchers increasingly study projection-based augmented reality (AR) that recognizes surrounding space, considers users' situation and provides space-oriented information rather than merely providing simple, fragmentary information. However, complicated installation issues persist, such as projection system installation and space setup to provide projection under various environments. In this study, we propose a portable, ambient projection system to address such complex installation issues. We defined pervasive projection AR system that enables projection in various spaces. The system consists of a pico-projector, a depth-sensing camera, and a pan/tilting platform that supports the projector-camera system. The portable ambient projection system can be positioned at an unknown space and can extract plane information by scanning its surrounding environment as it rotates 360-degrees in a clockwise manner. Users are provided with a pervasive projection AR environment as with a simple tablet user interface to control it.	Portable ambient projection system: build your room projectable space	NA:NA:NA:NA	2017
Shoki Miyagawa:Yoshihiro Fukuhara:Fumiya Narita:Norihiro Ogata:Shigeo Morishima	Marker-based retexturing is to superimpose the texture on a target object by detecting and identifying markers from within the captured image. We propose a new marker that can be identified under a large deformation that involves self-occlusion, which was not taken into consideration in the following markers. Bradley et al. [Bradley et al. 2009] designed the independent markers, but it is difficult to recognize them under complicated occlusion. Scholz et al.[Scholz and Magnor 2006] created a circular marker with a single color selected from multiple colors. They created ID corresponding to the alignment of colors by one marker and the markers around it and identified by placing the marker so that the ID would be unique. However, when some markers are covered by self-occlusion, the positional relationship of the markers appears to be different from the original, so markers near the self-occlusion are failed to identify. Narita et al. [Narita et al. 2017] considered self-occlusion by improving the identification algorithm. They succeeded in improving the accuracy of identification by creating triangle meshes whose vertices are the center of gravity of markers and assuming that they are close to a right isosceles triangle. However, since outliers are removed using angles, identification of markers may fail in the case of the object that is likely to be deformed in the shear direction like a cloth. Therefore, we considered self-occlusion by designing hierarchical markers so that they can be refferred to in a global scope. We designed a color based marker for easy recognition even at low resolution.	Retexturing under self-occlusion using hierarchical markers	NA:NA:NA:NA:NA	2017
Akira Ishii:Masaya Tsuruta:Ippei Suzuki:Shuta Nakamae:Tatsuya Minagawa:Junichi Suzuki:Yoichi Ochiai	Virtual reality (VR) with HMD is closed experience among those who are experiencing the VR, and can only be individually experienced by the specific person. We call this "perspective gap." These perspective gaps exist in many situations. To address these problems, we present "ReverseCAVE", a system for sharing the experiences of people in VR with others (observer). As another application, it is possible to visually recognize the actual appearance of the person performing the act at the motion capture studio and the superimposed character at the same time. ReverseCAVE has four translucent screens surrounding the player. VR environment that the player is experiencing is projected onto the screens. By this, the observer can see both the physical player and the VR environment experienced by the player simultaneously. Also, in the motion capture system, when viewing the actor from the observer outside of ReverseCAVE, the character is superimposed to the actor. This makes it look as if the actor is the actual character from the observer. ReverseCAVE enhances the observers' experience.	ReverseCAVE: providing reverse perspectives for sharing VR experience	NA:NA:NA:NA:NA:NA:NA	2017
Nami Ogawa:Takuji Narumi:Michitaka Hirose	We present a multiuser, wide-angle, and naked-eye three-dimensional (3D) display technique called a "swinging 3D lamp." This technique creates 3D optical illusions of motion parallax by superimposing dynamic luminance patterns on a static two-dimensional (2D) image in a real environment. The basic idea involves combining "wiggle stereoscopy," a method of creating 3D images by exploiting motion parallax, with "dynamic luminance projection," a projection technique making static images dynamic. However, in some cases, it can be difficult to obtain sufficient depth information when combining these methods. This was overcome by adding a depth-of-field (DOF) effect on the original image. The proposed technique is useful for simple and eye-catching 3D displays in public spaces because of the fact that depth information can be presented on the RGB images of common printed media and that multiple people can perceive the depth without special glasses or equipment.	Swinging 3D lamps: a projection technique to convert a static 2D picture to 3D using wiggle stereoscopy	NA:NA:NA	2017
Ippei Suzuki:Satoshi Hashizume:Kazuki Takazawa:Ryuichiro Sasaki:Yoshikuni Hashimoto:Yoichi Ochiai	In this paper, we propose a telepresence system that is able to provide care from a remote location by implementing functions such as object recognition on a wheelchair (Figure 1 Left). In conventional remote control robots, the operator controls the system while receiving feedback from cameras mounted on the robot [Gundersen et al. 1996]. However, this operating method cannot capture the full environment around the system, even if we use wide FOV cameras, such as omnidirectional cameras. This leaves the operator with incomplete feedback. In order to utilize the telepresence system safely, it is necessary to solve the problem of the blind spot of the user. Further, human operators are limited by their attention span. The reaction time of the computer is greater than that of humans.	Telewheelchair: The intelligent electric wheelchair system towards human-machine combined environmental supports	NA:NA:NA:NA:NA:NA	2017
Ping-Hsuan Han:Yang-Sheng Chen:Han-Lei Wang:Yu-Jie Huang:Jus-Chun Hsiao:Kuan-Wen Chen:Yi-Ping Hung	In general, highly-skilled manipulation without instruction is difficult. Recently there are some works which apply the manipulating guidance by a Virtual Reality (VR) or Augmented Reality (AR) head-mounted display (HMD) to keep the user hands-free. Henderson et al. [Henderson and Feiner 2009] applied AR to armored vehicle turret maintenance. With a head-worn display, the mechanic could acquire steps in the form of texts, images and animations. Our previous work (My Tai-Chi Coaches) [Han et al. 2017] used optical see-through HMD for Tai-Chi Chuan (TCC) augmented learning tool. Although it can provide the user visual hints such as virtual coaches, the visual hints which the user can see are constrained to the small augmented FOV of the HMD.	The design of video see-through window for manipulating physical object with head-mounted display	NA:NA:NA:NA:NA:NA:NA	2017
Zikun Chen:Wei Peng:Roshan Peiris:Kouta Minamizawa	With rise in the popularity of virtual reality, head mounted displays (HMDs) have become a main piece of hardware that delivers an immersive experience to the user. As one of the approaches to further enhance the user's presence in the virtual reality environment, haptic feedback has been widely used in the current VR space.	ThermoReality: thermally enriched head mounted displays for virtual reality	NA:NA:NA:NA	2017
Chika Matsusue:Kenji Funahashi:Shinji Mizuno	In this paper, we propose a novel virtual piano system to assist composition, that corrects deviation of a position based on music theory when a user strikes a wrong key. It means that this system estimates a correct melody from deviated fingering due to the non-physical keyboard. When experienced performer comes up with a good melody, his hands usually move by themselves to play it. Our proposed VR piano does not have any physical keyboard; it estimates a correct key when user's fingering is deviated. Furthermore, if the weight of music theory is adjusted higher than the weight of the user's fingering position, this system changes to easy-playable VR piano. Even by hitting a key randomly, it will produce an appropriate melody based on music theory by taking a bit of fingering into account.	Touch-typable VR piano that corrects positional deviation of fingering based on music theory	NA:NA:NA	2017
Atsuto Inoue:Kohei Yatabe:Yasuhiro Oikawa:Yusuke Ikeda	We propose a visualization system of three-dimensional (3D) sound information using video and optical see-through head mounted displays (ST-HMDs). The Mixed Reality (MR) displays enable intuitive understanding of 3D information of a sound field which is quite difficult to project onto an ordinary two-dimensional (2D) display in an easily understandable way. As examples of the visualization, the sound intensity (a stationary vector field representing the energy flow of sound) around a speaker and a motor engine is shown.	Visualization of 3D sound field using see-through head mounted display	NA:NA:NA:NA	2017
Jia-Wei Lin:Ping-Hsuan Han:Jiun-Yu Lee:Yang-Sheng Chen:Ting-Wei Chang:Kuan-Wen Chen:Yi-Ping Hung	Recently, virtual reality (VR) becomes more and more popular and provides users an immersive experience with a head-mounted display (HMD). However, in some applications, users have to interact with physical objects while immersed in VR. With a non-see-through HMD, it is difficult to perceive visual information from the real world. Users must recall the spatial layout of the real surroundings and grope around to find the physical objects. After locating the objects, it is still inconvenient to use them without any visual feedback, which would detract the immersive experience.	Visualizing the keyboard in virtual reality for enhancing immersive experience	NA:NA:NA:NA:NA:NA:NA	2017
Ryohei Nagao:Keigo Matsumoto:Takuji Narumi:Tomohiro Tanikawa:Michitaka Hirose	In the field of virtual reality, a few methods exist that allow a user to walk up and down the stairs in a virtual environment (VE); however, most of them are based on a complicated device system that generates physical steps using actuators (e.g., [Iwata et al. 2005; Schmidt et al. 2015]). Because it is difficult for users wearing head mounted displays (HMDs) to keep track of the surrounding environment, walking on physical steps could prove to be very dangerous and lead to injuries. Further, these systems have disadvantages in that the user cannot walk naturally. Therefore, a simple and low-cost system that allows users to walk safely and freely in the vertical direction in a VE is highly desirable.	Walking up virtual stairs based on visuo-haptic interaction	NA:NA:NA:NA:NA	2017
Keigo Matsumoto:Takuji Narumi:Tomohiro Tanikawa:Michitaka Hirose	This paper proposes a novel redirected walking technique that creates the feeling of walking uphill and downhill in the virtual environment while actually walking on a flat floor in the real world. We focus on the amount of energy consumed while walking uphill and downhill. Previous studies show that walking uphill takes three times as much energy as walking on a flat ground while walking downhill takes only half as much energy. We believe that the walking feeling in the virtual environment could be improved by changing the walking distance according to the gradient and bringing it closer to the energy consumption at the actual ascending and descending walk. We conducted a preliminary experiment to confirm that the proposed method is effective and the experimental results imply that our method is efficient for walking uphill.	Walking uphill and downhill: redirected walking in the vertical direction	NA:NA:NA:NA	2017
Ergun Akleman:Fermi Perumal:Youyou Wang	In this work, we present an integrated model that can provide direct illumination, subsurface scattering and soft shadow effects in a single equation. We have implemented our model to render bas-reliefs, which are the shapes that are defined as height fields. Using our model it is possible to interactively obtain all three effects in a qualitatively consistent way. One of the most important properties of our model is that it provides cos θ for planar surfaces. Moreover, our formula is qualitatively related to exponential attenuation due to scattering and provides soft shadows. Therefore, this model provides qualitatively consistent shading for direct illuminated subsurface scattering and shadow regions.	Cos Θ shadows: an integrated model for direct illumination, subsurface scattering and shadow computation	NA:NA:NA	2017
Nahomi Maki:Toshiaki Yamanouchi:Teluhiko Hilano:Kazuhisa Yanaka	A four-plane depth-fused display (DFD) is an autostereoscopic system that can display four images at different depth positions using a single liquid crystal display and mirrors or half mirrors. This system increases the number of images in the depth direction, thereby enhancing stereoscopic effect. To date, however, the contents of proposed DFD remain limited to still images. Therefore, we introduced an animation that included object motion in the XYZ space in four planes into DFD. This approach considerably increased the sense of depth.	Creation of 3DCG animation using a four-plane depth-fused display	NA:NA:NA:NA	2017
Junho Choi:Yong Yi Lee:Yong Hwi Kim:Bilal Ahmed:Jong Hun Lee:Moon Gu Son:Junbum Kim:Kwan H. Lee	Various vision-based measurement systems have been developed to reconstruct the 3D shape and appearance of an object. To achieve this, a large number of the samples need to be captured. However, most of the existing measurement system requires a long acquisition time because of system complexity. Although some systems present effective acquisition strategy in the adaptive manner, they focus on only 2D planar samples so that they cannot handle complex 3D object and its reflectance property. In this paper, we present the multi-camera and multi-light source based measurement system that capture the 3D geometry and appearance simultaneously. We also proposed a novel curvature-aware acquisition strategy for reducing the acquisition time and data storage requirement. Since the proposed method can efficiently capture the appearance of 3D objects with complicated shape, expect to progress the digitization in the various field such as museum and industry.	Curvature-aware adaptive capture of 3D geometry and appearance	NA:NA:NA:NA:NA:NA:NA:NA	2017
Ibragim Atadjanov:Seungkyu Lee	In this work, we propose a novel light field approximation method for multi-layer light field display. Our target light field display consists of two liquid crystal panels with a uniform back-light with no time multiplexing. LCD panels are not necessarily to be parallel. For wide angle of view configuration, we introduce quadratic penalization term to alleviate ghost effects. This creates perceptually improved approximation of light field and increases the possibility of usage in design with a wider field of view configuration.	Dual-layered light field display: maximizing image perceptibility	NA:NA	2017
Daito Kakeya:Masashi Baba:Shinsaku Hiura	When synthesizing CG images with real image as a background, it is necessary to estimate the lighting environment such as intensities and directions of light sources from real images. In previous study [Baba et al. 2016], except for the high intensity area such as the sun, light source information was estimated by concerning pixels of the captured image as light sources having corresponding intensities[Debevec 1998]. For a high intensity area, the intensity of the light source was estimated from the ratio of the intensity of the shadow area and the sunshine area[Sato et al. 2003]. However, since the sun is used as one parallel light source, there is a problem that it can express only a sharp shadow and it can not be reproduced as an HDR light probe images. Figure 2(a) shows a real image. Figure 2(b) shows a rendering result by the conventional method. In the Figure 2(b), the penumbra of the upper part of the shadow can not be expressed and the shadow boundary is clear comparing with the real image.	Generation of omni-directional HDR light probe images based on the intensity distribution model around the sun	NA:NA:NA	2017
Martin Misiak:Arnulph Fuhrmann	We present a new, physically plausible, real-time approach to compute directional occlusion for dynamic objects, lit with image based lighting. For this, we partition the hemisphere into multiple sectors and pre-convolve these into separate irradiance maps. At runtime the contributions of each sector are then individually occluded and summed together.	Directional occlusion via multi-irradiance mapping	NA:NA	2017
Mehmet Ömer Özek:Engin Demir	As the GPU's processing power has been improving much faster than the CPU's. the terrain rendering algorithms have evolved to use the graphics hardware as much as possible. One of the recently developed GPU-based Level of Detail (LOD) algorithm is Continuous View Dependent Adaptive LOD using hardware tessellation. In this study, Continuous View Dependent Adaptive LOD using hardware tessellation is enhanced using three additional methods. First method is determining pixel-based LOD using occlusion query. Because of hidden surface culling, render time is reduced. Second method is determining pixel-based LOD using occlusion query that newly developed by using OpenGL and CUDA interoperability. Third method is extension of second method that includes quad-tree based query for each terrain node. Third method aims to increase rendering quality of partial rendered terrain node.	Pixel-based level of detail on hardware tessellated terrain rendering	NA:NA	2017
Antoine Toisoul:Abhijeet Ghosh	We present a novel approach for real-time rendering of realistic diffraction effects in surface reflectance under environmental illumination. Renderings in arbitrary environments require the computation of a convolution. In the case of diffraction, the convolution kernel is large due to the high frequency details contained in diffraction patterns, making computations at real time framerate impractical. We propose a low rank factorisation of the diffraction kernel that allows the computation of the convolution in two passes with smaller kernels instead of a large 2D kernel. We present renderings of the diffraction produced by several surfaces and reach a performance of 50 to 100 FPS.	Real time rendering of realistic surface diffraction with low rank factorisation	NA:NA	2017
Shohei Anraku:Fumihiko Ishiwata:Nahomi Maki:Toshiaki Yamanouchi:Kazuhisa Yanaka	To use the advanced content creation functions of a game engine and develop contents in which displaying real-time integral photography images is important, we implemented multi-viewpoint rendering and IP image synthesis functions by adding a shader and C# scripts to the game engine.	Real-time integral photography using a game engine	NA:NA:NA:NA:NA	2017
Kumar Ayush:Parag Chaudhuri	We present a generic and principled Monte Carlo raytracing approach to visualizing curved spacetime. In contrast to earlier work, our method can trace rays in curved spacetime while resolving usual ray-object intersections. This not only allows us to visualize complex cosmological phenomena, but also create plausible visualizations of what happens when a black hole or a wormhole appears in a more known environment, like a room with regular specular and diffuse surfaces.	Rendering curved spacetime in everyday scenes	NA:NA	2017
Julio Marco:Adrian Jarabo:Wojciech Jarosz:Diego Gutierrez	Accurate simulation of light transport in participating media is expensive, due to the many scattering events. However, the band-limiting effect of scattering in media makes this kind of light transport very suitable for adaptive sampling and reconstruction techniques. In this work we present a novel algorithm that adaptively samples radiance from sparse points in the medium using up-to second-order occlusion-aware derivatives to determine when interpolation is appropriate. We derive our metric from each point's incoming light field. We use a proxy triangulation-based representation of the radiance reflected by the surrounding medium and geometry to efficiently compute the first- and second-order derivatives of the radiance at the cache points while accounting for occlusion changes. We validate the quality of our approach on a self-contained two-dimensional model for light transport in media. Then we show how our results generalize to practical three-dimensional scenarios, where we show much better results while reducing computation time up to a 30% compared to previous work.	Second-order occlusion-aware volumetric radiance caching	NA:NA:NA:NA	2017
Bekir Öztürk:Ahmet Oğuz Akyüz	Light mapping is an important optimization technique, in which the lighting of a scene is precomputed into a texture during a stage known as light baking. However, the primary drawback of this technique is that lights and objects must be static. Our work relaxes several important requirements of light mapping, such as the requirement of the color, intensity, and on-off state of lights as well as the presence or absence of shadow casting objects to be static.	Semi-dynamic light maps	NA:NA	2017
Cheng Zheng:Caowei Zhang:Xuan Li:Xin Liu:Chuqi Tang:Guanyun Wang:Cheng Yao:Fan Zhang:Wenjie Xu:Fangtian Ying	Children with Autism Spectrum Disorder (ASD) have social communication difficulties partly due to unusual visual processing strategy on human faces. However, their strategies are similar on cartoon faces as normal chilren. In this paper, we present Toon-Chat, a video chat system with virtual cartoon masks to help ASD children enhance communication and emotion comprehension skills. The system is tested in a series of ABA training lessons and the results are promising.	Toon-chat: a cartoon-masked chat system for children with autism	NA:NA:NA:NA:NA:NA:NA:NA:NA:NA	2017
Jin Ryong Kim:Seunghyup Shin	We present Touch3D, an interactive mobile platform that provides realistic viewing and touching experiences through glasses-free 3D visualization with electrovibration. Touch3D is designed to take advantage of both visual and tactile illusions to maximize multimodal experience in touchscreen interaction. We seamlessly integrate two technologies: Automultiscopic 3D Display and Electrovibration Display; and weave both hardware and software into one fluid interface. Our museum application using Touch3D demonstrates important implications for the improvement of 3D perception in both visual and tactile modalities for enhanced touchscreen interaction.	Touch3D: touchscreen interaction on multiscopic 3D with electrovibration haptics	NA:NA	2017
Julio Marco:Wojciech Jarosz:Diego Gutierrez:Adrian Jarabo	Recent advances on transient imaging and their applications have opened the necessity of forward models that allow precise generation and analysis of time-resolved light transport data. However, traditional steady-state rendering techniques are not suitable for computing transient light transport due to the aggravation of inherent Monte Carlo variance over time, specially problematic in participating media. We address this problem by presenting the first photon-based method for transient rendering of participating media that performs density estimations on time-resolved precomputed photon maps. We first introduce the transient integral form of the radiative transfer equation into the computer graphics community, including transient delays on the scattering events. Based on this formulation we leverage the high density and parameterized continuity provided by photon beams algorithms to present a new transient method that allows to significantly mitigate variance and efficiently render participating media effects in transient state.	Transient photon beams	NA:NA:NA:NA	2017
Takaki Murakami:Tanner Person:Charith Lasantha Fernando:Kouta Minamizawa	In this paper, (1) we developed a fingertip haptic display with integrated force, tactile and thermal feedback in a miniature form-factor such that it can be worn easily and used with augmented reality applications without affecting the existing tracking technologies. (2) we propose the concept of "Altered Touch", where the integrated fingertip haptic display stated in (1) was used to alter the haptic properties of real objects by rendering projected visual and haptic feedback. The system consists of our own force display Gravity Grabber mechanism[Minamizawa et al. 2007] to render vertical, shearing forces, high frequency tactile vibrations, and a peltier module for thermal display. The integrated haptic display module weighs less than 50g, can be easily interfaced to a PC with just one micro USB cable, and works standalone from any other additional hardware. In this paper we use this wearable haptic actuator in several augmented reality applications to alter the softness/hardness and hot/cold sensation and several use cases have been discussed. Furthermore, the haptic display could be expanded to design a haptic glove that can interact with both virtual and augmented worlds.	Altered touch: miniature haptic display with force, thermal and tactile feedback for augmented haptics	NA:NA:NA:NA	2017
Yung-Long Chu:Hung-En Hsieh:Wen-Hsiung Lin:Hui-Ju Chen:Chien-Hsing Chou	Reading is an essential part of daily life. When reading books, drug information, textual icons on electronic devices (e.g., microwave), and information on signs and maps (e.g., location and floor level), people must be able to recognize the words to obtain the information they need. However, for foreigners or people with visual impairment, reading text can be challenging. To assist people with visual impairment in reading English books, Shilkrot et al. have designed a wearable device called the FingerReader [Shilkrot et al. 2014]. The FingerReader utilizes a text-to-speech engine to enable visually impaired users to listen to printed text. Anhong et al. developed a mobile application to assist blind people in using otherwise inaccessible interfaces [Guo et al. 2016]. Through utilizing the phone camera, the software captures the text on an interface and then interactively describes the text beneath the user's finger.	Chinese FingerReader: a wearable device to explore Chinese printed text	NA:NA:NA:NA:NA	2017
Tomoya Sasaki:MHD Yamen Saraiji:Charith Lasantha Fernando:Kouta Minamizawa:Masahiko Inami	If we could have the capability to edit or customize our body scheme by technology, could our abilities and activities be enhanced? This research proposes a novel interaction to alternate body scheme using artificial limbs substitution metamorphosis. In this work, two additional robotic arms are added to user's body, and are manipulated by legs movement. Limbs control is achieved using two sets of tracking systems: global motion tracking of legs using an optical tracker and local motion tracking for manipulation purposes using socks type device. These data are mapped into artificial limbs' arms, hands and fingers motion. Lastly, force feedback is provided to the feet and mapped to manipulator's touch sensors.	MetaLimbs: metamorphosis for multiple arms interaction using artificial limbs	NA:NA:NA:NA:NA	2017
Kazuki Takazawa:Satoshi Hashizume:Ryuichiro Sasaki:Yoshikuni Hashimoto:Yoichi Ochiai	In recent years, many materials mass-produced in industrialized societies are flat, thin, and with many squares. Within such a social context, customized machines like conventional shape-changing interfaces will take much time and labor to become popular. We aimed to overcome the weaknesses of such conventional shape-changing interfaces and make them easy to manufacture and apply even for PC users. In order to achieve this, it is necessary to revise the manufacturing method. If it is possible to prepare a flat plate which is inexpensive, available and easily processed, it becomes possible to disseminate the shape changing interface at low cost. In recent times, processing machines such as laser cutters have become more widely available so it is becoming increasingly possible to reduce the cost of estuaries. Therefore, we redesigned the manufacturing method for shape changing interfaces using flat plate which, with our method, can be produced at lower cost and with less labor. Many objects in the world are made by processing flat plates, so the processing of flat plates is an important factor. By using the manufacturing method of shape changing interfaces proposed by us, it becomes possible to embed them naturally in interiors such as furniture made from flat plate.	Morpho sculptures: digital fabrication methods of engraving flat materials into shape changing user interfaces	NA:NA:NA:NA:NA	2017
Satoshi Hashizume:Amy Koike:Takayuki Hoshi:Yoichi Ochiai	Aerial haptic feedback is a popular topic in research fields on real-world-oriented interaction, augmented reality (AR), and virtual reality (VR). Various methods such as magnetic force, ultrasound, and air vortices have been proposed for this purpose.	Sonovortex: rendering multi-resolution aerial haptics by aerodynamic vortex and focused ultrasound	NA:NA:NA:NA	2017
Yuan-Ling Feng:Charith Lasantha Fernando:Jan Rod:Kouta Minamizawa	In this paper, we present a novel method of creating a waterproof wearable fingertip haptic display "AeroFinger" that is very light and small enough to fit on the fingertip and uses no electro-mechanical actuation. The display consists of 4 miniature airbags which are made out of 3D printed Rubber-Like material so that the display size, strength and shape can be customized by the user. A small sized full range speaker is mounted on a closed air chamber where the air is transferred back and forth through a tiny nozzle to the airbag. The Speaker movements creates a difference in air pressure and translated into airbag inflation and deflation. Therefore, AeroFinger can display the low frequency vibrations as force sensation and high frequency vibrations as tactile sensation. Unlike most ungrounded haptic devices which contains electrical components such as motors or vibration actuators, AeroFinger uses no electro-mechanical actuation and thus can be completely submerged on water or could be used in magnetic resonance environments.	Submerged haptics: a 3-DOF fingertip haptic display using miniature 3D printed airbags	NA:NA:NA:NA	2017
John Kasper Svergja:Henrik Lieng	The gradient mesh tool, implemented in vector graphics software like Adobe Illustrator, is a popular tool for creating and manipulating complex colour gradients. The mesh-based tool is restricted to rectangular gradient meshes, making it hard for the user to work with more complicated shapes such as shapes with holes. We propose a new gradient mesh tool that supports non-rectangular meshes, with native support for a wide range of different shapes. A user study indicates that our tool is easier to use when drawing colour gradients inside complicated shapes.	A gradient mesh tool for non-rectangular gradient meshes	NA:NA	2017
Yuanming Hu:Yu Fang	We propose a novel asynchronous time integration scheme for the Material Point Method (MPM), which offers temporal adaptivity when objects of different stiffness or velocity coexist. We show via multiple test scenes that our asynchronous MPM leads to 6X speed up over traditional synchronous MPM without sacrificing accuracy.	An asynchronous material point method	NA:NA	2017
Marta Ortin:Adrian Jarabo:Belen Masia:Diego Gutierrez	With the increasing number of available consumer light field cameras, this new form of photography is progressively becoming more common. However, there are still very few tools for light field editing, and the interfaces to create those edits remain largely unexplored. We perform a state sequence analysis and hidden Markov-chain analysis based on the sequence of tools and interaction paradigms users employ while editing light fields. These insights can aid researchers and designers in creating new light field editing tools and interfaces, thus helping close the gap between 4D and 2D image editing.	Analyzing interfaces and workflows for light field editing	NA:NA:NA:NA	2017
Chloe LeGendre:David Krissman:Paul Debevec	We present a technique for improving the alpha matting of challenging green-screen video sequences involving hair strands. As hair strands are thin and can be semi-translucent, they are especially hard to separate from a background. However, they appear as extended lines and thus have a strong response when convolved with oriented filters, even in the presence of noise. We leverage this oriented filter response to robustly locate hair strands within each frame of an actor's performance filmed in front of a green-screen. We demonstrate using production video footage that individual hair fibers excluded from a coarse artist's matte can be located and then added to the foreground element, qualitatively improving the composite result without added manual labor.	Improved chromakey of hair strands via orientation filter convolution	NA:NA:NA	2017
Jannik Boll Nielsen:Rasmus Ramsbøl Jensen	Action cameras have allowed footage from previously unseen points of view, drones allow for innovative aerial shots, which a few years ago, were either impossible or required a helicopter, and finally DSLR video and lens adaptors have made any lens available for video production. These advances provide especially low-budget movie productions with completely new flexibility and potential.	Photon rectify: undistort any footage on the timeline	NA:NA	2017
Rahul Dey:Jason G. Doig:Christos Gatzidis	In this work we present separate procedural methods to generate features that are found in natural terrains which are difficult to reproduce with heightmap-based methods. We approximate overhangs, arches and caves using procedural functions and a reduced set of parameters. This produces visually plausible terrain feature topologies as well as a high degree of artistic control. Our approach is more intuitive and art-directable than other existing volumetric methods that are more complex to integrate into existing voxel engines, due to the framework changes necessary, or rely on automatic procedural generation, thus reducing the ability to provide creative input.	Procedural feature generation for volumetric terrains	NA:NA:NA	2017
Ippei Suzuki:Yoichi Ochiai	We present a new method to protect projected content from secret photography using high-speed projection. Protection techniques for digital copies have been discussed over many years from the viewpoint of data protection. However, content displayed by general display techniques is not only visible to the human eye but also can be captured by cameras. Therefore, projected content is, at times, secretly taken by malicious small cameras even when protection techniques for digital copies are adopted. In this study, we aim to realize a protectable projection method that allows people to observe content with their eyes but not record content with camera devices.	Unphotogenic light: high-speed projection method to prevent secret photography by small cameras	NA:NA	2017
Codruta O. Ancuti:Cosmin Ancuti:Christophe De Vleeschouwer:Rafael Garcia	In underwater the light propagation is distorted due to the absorption and scattering, which respectively affect the energy and direction of propagated light. These distortions result in scenes with foggy appearance and poor contrast. Moreover, in underwater the colors are faded because their composing wavelengths are cut according to the water depth. Since the deterioration of underwater scenes results from the combination of multiplicative and additive processes, enhancing the visibility in underwater is a challenging task. Underwater single image based techniques [Ancuti et al. 2012, 2016a] have been introduced only recently and in general have been inspired by the outdoor dehazing strategies [Ancuti et al. 2010], [He et al. 2011], [Ancuti and Ancuti 2013], [Ancuti et al. 2016b]. One of the most influential technique was introduced by He et al. [He et al. 2011] based on the Dark Channel Prior (DCP) shown to fail for underwater dehazing (see Figure 1). Indeed, underwater image restoration is more challenging since the attenuation medium factor is color dependent and higher than in aerial conditions. Even if the transmission is well estimated the result image can not be effectively restored without initial image color spectrum restoration (see UDCP result in Figure 1).	A semi-global color correction for underwater image restoration	NA:NA:NA:NA	2017
Yuhang Li:Xuejin Chen	Geo-localization, aiming at aligning images with 3D models, is a key technique to many applications, such as image-based navigation, augmented reality, 3D city modeling, etc. We present a geo-localization method based on overhead images captured in low altitudes and point clouds of buildings. With two observations that 1) vertical facades of a point cloud typically correspond to edges of building roofs in the overhead image; and 2) building roofs of different altitudes are in different scales in the overhead image due to a perspective projection, we regard this geo-localization problem as a combination of a multi-layer shape matching and a global optimization of the camera pose. We test our approach on a variety of buildings with complex shapes. The experiment results demonstrate the accuracy of our geo-localization algorithm.	Accurate geo-localization of low-altitude overhead images from 3D point clouds	NA:NA	2017
Xuan Huang:Dianna Xu	Mesh quality improvement is an important problem with a wide range of practical applications. The element quality of a mesh heavily affects the results of numerical simulation done using that mesh. In the context of finite element mesh smoothing, vertex repositioning is the primary technique employed, where we allow tangential vertex motion only and the connectivity of the mesh is unchanged. Element quality is measured either by max/min angles or aspect ratio (longest edge over shortest), or both. We investigate a smoothing method focusing on improving aspect ratio. For triangle meshes this is in theory not significantly different from angle-based smoothing methods which have been widely studied. However many focus on improving minimum angles only and we believe that aspect ratio will lead to a more balanced improvement on both the minimum and maximum angles. In addition, we are also motivated by aspect ratio improvments for quadrilateral meshes, which are unrelated to angles.	Aspect-ratio based triangular mesh smoothing	NA:NA	2017
Tiancheng Sun:Ana Serrano:Diego Gutierrez:Belen Masia	Real-world materials present a wide variety of appearances, commonly described in computer graphics with the bidirectional reflectance distribution function (BRDF). Printers, on the other hand, have a predefined set of only a few inks, which defines the printer's gamut. As a consequence of this limitation, many materials cannot be exactly reproduced by the printer, creating distortions in the printed appearance that are hard to control. Finding the best approximation of the input BRDF that falls within the printer's gamut while minimizing such distortions as much as possible is the problem known as gamut mapping. We present a novel two-step gamut mapping algorithm that allows users to specify which perceptual attribute of the original material they want to preserve. In the first step, we work in the low-dimensional intuitive appearance space recently proposed by Serrano et al. [Serrano et al. 2016], and adjust achromatic reflectance via an objective function that strives to preserve certain attributes. From such intermediate representation, we then perform an image-based optimization including color information, to bring the BRDF into gamut. We show how our method yields superior results compared to the state of the art, with the additional advantage that the user can specify which visual attributes need to be preserved. For more details we refer to the reader to the full paper [Sun et al. 2017].	Attribute-preserving gamut mapping of measured BRDFs	NA:NA:NA:NA	2017
Stefanie Gassel:Thomas Neumann:Markus Wacker	Statistical body shape modelling can be used to realistically generate complex muscle deformation effects on the skin. However, purely data-driven models still ignore the biomechanical nature of surface deformations. Reliable anatomically and biomechanically consistent predictions are barely possible. Our research aims at combining the previously separate paradigms - data-driven and simulation-driven 3D surface modeling - to a hybrid body shape model. Our first goal consists of synthesizing the skin surface from simulated biomechanical data. As a first step in this direction we show preliminary results of our model of an elbow flexion motion with separate biceps and triceps muscle bulging that exhibits believable muscular deformation effects on the skin surface while enabling singular control over specific muscle regions. Our model is separately controllable in shape and pose and extensible to a wider range of human body shapes, joint motion and muscle regions.	Combining biomechanical and data-driven body surface models	NA:NA:NA	2017
Jen Rogers:Matthieu Poyade:Frank Pollick	With advancement in research in a given field, there should be parallel development in visualisation methods to understand the data accrued. 3D visualisation and interactive visual applications can facilitate synthesis and understanding of high dimensional data. This concept has been applied within varying fields of research, though it has yet to be explored significantly in the field of functional neural mapping. This project documents the development of an interactive application for mobile and tablet devices visualising multivariate functional mapping of fMRI data within a 3D structural model of the brain. The application is developed as a proof of concept for the efficacy of interactive 3D visualisation for representing research in functional mapping, as well as the potential for Unity 3D game enginefis use as a visualisation tool for the complex data involved in the research of functional neural activity.	Constellations of movement: an interactive application to visualise research in motor imagery decoding	NA:NA:NA	2017
Naoki Hashimoto:Koki Kosaka	In this research, we propose a photometric compensation technique for deformable objects, such as a curtain that is continuously swinging. In photometric compensation, it is necessary to exactly obtain an inter-pixel correspondence and a response function between a projector and a camera. Therefore, compensation for deformable objects is a major challenge. In our proposal, we reconstruct the inter-pixel correspondence by using the uniformity of a re-estimated reflectance property of the response function. By using a fast implementation with a GPU, it is possible to provide continuous photometric compensation, even for deformable objects, without using a coaxial projector-camera system.	Continuous photometric compensation for deformable objects	NA:NA	2017
Ryuji Hirayama:Hirotaka Nakayama:Atsushi Shiraki:Takashi Kakue:Tomoyoshi Shimobaba:Tomoyoshi Ito	In this study, we present a 3D structure projecting multiple dynamic full-color images in different directions. The 3D structure is represented as a crowd of controllable color particles rendered in a cylindrical 3D crystal with a CG software. We confirmed that five images could be successfully observed from different viewpoints. Such 3D structures can be applied to information service systems including digital signage and security system.	Controllable color particles in a 3D crystal projecting multiple dynamic full-color images	NA:NA:NA:NA:NA:NA	2017
Takahiro Itazuri:Tsukasa Fukusato:Shugo Yamaguchi:Shigeo Morishima	We propose a rally-rank evaluation based on the court transition information for volleyball video summarization considering the contents of the game. Our method uses the court transition information instead of non-robust visual features such as the position of a ball and players. Experimental results demonstrate the effectiveness that our method reflects viewers' preferences over previous methods.	Court-aware volleyball video summarization	NA:NA:NA:NA	2017
Matthias Schröder:Helge Ritter	Recent advances in the development of optical head-mounted displays (HMDs), such as the Microsoft HoloLens, Google Glass, or Epson Moverio, which overlay visual information directly in the user's field of vision, have opened up new possibilities for augmented reality (AR) applications. We propose a system that uses such an optical HMD to assist the user during goal-oriented activities (e.g. manufacturing work) in an intuitive and unobtrusive way (Essig et al. 2016). To this end, our system observes and recognizes the user's actions and generates context-sensitive feedback. Figure 1 shows an overview of our approach, exemplified with the task of assembling a bird house.	Deep learning for action recognition in augmented reality assistance systems	NA:NA	2017
Amy Koike:Satoshi Hashizume:Kazuki Takazawa:Mose Sakashita:Daitetsu Sato:Keisuke Kawahara:Yoichi Ochiai	Underwater expression is attractive. It seems like underwater objects are floating like anti-gravity scape by buoyancy and it is also impressive that bubbles rise while refracting the light. In this work, we aim to combine digital fabrication with interactive technology and expand underwater expression. To achieve this, we focused on a classic science experiment called the Cartesian Diver. Because of growing interest in the materialization of computer graphics, digital fabrication technologies have recently emerged as one of the most important application fields in real-world-oriented computer graphics. In particular, research on digital fabrication that gives dynamics properties is common. Spin-it [Bächer et al. 2014] presents design method for spinning objects by optimizing rotational dynamics properties. Some studies use non-contact manipulation. For example, ZeroN [Lee et al. 2011] controls the magnetic field to manipulate the object and uses it as a floating screen and input user interface(UI). Our work connects digital fabrication and non-contact manipulation that uses the space transmission power (water pressure) around the object (the diver). [Koike et al. 2016] proposes a design and manipulation method for the diver. In this work, we updated the method and investigate stability of PID control. Furthermore, we propose some applications.	Digital fabrication and manipulation method for underwater display and entertainment	NA:NA:NA:NA:NA:NA:NA	2017
Mie Sato:Haruna Kimura	We have been developing an augmented reality (AR) system that allows a user to grasp a virtual object with a bare hand. To enhance the user's perception of grasping the virtual object, we employ multisensory integration in our AR system. Our experimental results show that presenting a virtual object with an auditory cue is statistically more effective than presenting one without an auditory cue as regards grasping, holding, translating, rotating and releasing the virtual object.	Effects of auditory cues on grasping a virtual object with a bare hand	NA:NA	2017
Samar M. Alsaleh:Angelica I. Aviles:Alicia Casals:James Hahn	The appearance of objects is significantly affected by the illumination conditions in the environment. Particularly with objects that have strong reflectivity as they suffer from more dominant specular highlights, causing information loss and discontinuity in the image domain. Many computer vision algorithms are vulnerable to errors in the presence of specular highlights because they violate the image consistency assumption and hinder the performance of many vision tasks, such as object recognition, tracking and surface reconstruction [Artusi et al. 2011]. This is further complicated when we consider video sequences with free-moving cameras or dynamic objects, which is the focus of this work.	Escaping specularity: recovering specular-free video sequences from rank-constrained data	NA:NA:NA:NA	2017
Victor Arellano:Diego Gutierrez:Adrian Jarabo	Recent works have demonstrated non-line of sight (NLOS) reconstruction by using the time-resolved signal from multiply scattered light. These works combine ultrafast imaging systems with computation, which back-projects the recorded space-time signal to build a probabilistic map of the hidden geometry. Unfortunately, this computation is slow, becoming a bottleneck as the imaging technology improves. In this work, we propose a new back-projection technique for NLOS reconstruction, which is up to a thousand times faster than previous work, with negligible quality loss.	Fast back-projection for non-line of sight reconstruction	NA:NA:NA	2017
Vlastimil Havran:Jan Hošek:Šárka Němcová:Jiří Čáp:Jiří Bittner	We present a portable instrument for on site measuring of surface reflectance represented by the bidirectional texture function (BTF) and the bidirectional reflectance distribution function (BRDF). Our device allows for measurement application scenarios outside the laboratory without the necessity to extract the measured sample from its environment because the instrument is taken to the measured sample. The concept is a rotational lightweight light stage with a compact hemispherical dome and cameras along the meridian and light emitting diode (LED) modules illuminating the sample surface. The LED modules are fixed on the hemisphere and the six cameras can move along the arc in the range of the elevation angle from 0 to 75 degrees. By rotating the hemispherical dome along its axis we can set all possible camera directions to a measured sample. We use an auto-collimator to adjust the correct perpendicular direction of the instrument against the sample. The proposed instrument is portable and fast while maintaining a high degree of accuracy achieving a quality similar to existing stationary BTF gantries that can be only used in a laboratory. The instrument design provides a good tradeoff between the accuracy of measurements and the practical applicability for measurement of locally flat samples. The instrument provides approximately 1000 HDR photographs in a minute that are necessary to capture spatially varying surface reflectance.	Lightdrum: surface reflectance measurement on site	NA:NA:NA:NA:NA	2017
Yiqun Wang:Dong-Ming Yan:Chengcheng Tang:Xiaohan Liu	In this poster, we propose a simple yet efficient algorithm for eliminating obtuse triangles for isotropic remeshing. Our method can either be applied directly on the input mesh, or be used as a post-processing step on the results from other remeshing algorithms. Our approach outperforms the state-of-the-art approaches in terms of the mesh quality.	Obtuse triangle elimination for isotropic remeshing	NA:NA:NA:NA	2017
David C. Schedl:Clemens Birklbauer:Oliver Bimber	We present an angular superresolution method for light fields captured with a sparse camera array. Our method uses local dictionaries extracted from a sampling mask for upsampling a sparse light field to a dense light field by applying compressed sensing reconstruction. We derive optimal sampling masks by minimizing the coherence for representative global dictionaries. The desired output perspectives and the number of available cameras can be arbitrarily specified. We show that our method yields qualitative improvements compared to previous techniques.	Optimized sampling for view interpolation in light fields using local dictionaries	NA:NA:NA	2017
Kouta Takeuchi:Kazuki Okami:Daisuke Ochi:Hideaki Kimata	We propose a partial plane sweep volume that can be a more suitable input format for deep-learning-based view synthesis approaches. Our approach makes it possible to synthesize higher quality images with a smaller number of learning iterations, while keeping the number of depth planes.	Partial plane sweep volume for deep learning based view synthesis	NA:NA:NA:NA	2017
Jaewon Kim:Abhijeet Ghosh	We present a novel, practical method for acquisition of optical properties of common everyday translucent liquids using a simple acquisition setup involving an LCD panel. Previous work on acquiring liquids has required specialized procedures such as dyeing with a fluorescent agent [Ihrke et al. 2005] for volumetric reconstruction of liquid flow, or dilution of liquid in a specialized water tank [Narasimhan et al. 2006] for acquiring its optical properties for rendering. In this work, we build upon the recent work of Kim et al. [2017] who employ direct transmission imaging for single-view reconstruction of axially-symmetric transparent objects such as glasses, goblets, carafes, etc. We observe that many optically interesting everyday liquids such as cocktails, juices, whiskey, wine, oil, etc., are commonly contained in such axially-symmetric transparent containers. Hence, we propose a much more natural acquisition process where we image the transmission of backlit illumination through a liquid volume contained in such a glass object to estimate its optical properties including its absorption and scattering coefficients, and refractive index. Figure 1 demonstrates renderings of various acquired translucent liquids with our proposed method separated into two types: those exhibiting only absorption (a), and those that exhibit both absorption and scattering (b).	Practical acquisition of translucent liquids using polarized transmission imaging	NA:NA	2017
Jianwei Guo:Zhanglin Cheng:Shibiao Xu:Xiaopeng Zhang	Plants are ubiquitous in the nature, and realistic plant modeling plays an important role in a variety of applications. Over the last decades, an immense amount of efforts have been dedicated to plant modeling. These approaches can be classified into two major categories: procedural modeling [Palubicki et al. 2009; Stava et al. 2014] and data-driven reconstruction approaches (e.g., photographs [Li et al. 2011; Tan et al. 2007] or scanned points [Livny et al. 2010; Xu et al. 2007]). Each approach has its own pros and cons. For example, procedural modeling approaches work well for synthesizing local branch structure details to produce botanically correct trees, but they lack the ability to control the growth of trees under certain shape constraints. While the data-driven approaches might precisely reconstruct skeletal structures, the botanical fidelity of trees are difficult to maintain.	Realistic procedural plant modeling guided by 3D point cloud	NA:NA:NA:NA	2017
Yuka Nakamura:Naoki Hashimoto	In this study, we demonstrate that it is possible to provide accurate multi-projection over a whole space using a simple procedure and commercially available cameras by arranging multiple projectors freely. Increasing research interest in projection mapping is providing growing opportunities for application of this technique, resulting in a mounting need for simple and highly accurate image projection techniques for entire spaces. Effective projection is difficult to achieve using only one projector, but the use of multiple projectors requires highly complex projection techniques. In this study, we propose a novel and effective geometric correction technique that combines the use of a fish-eye lens camera and a standard lens camera.	Simple and accurate geometric correction with multiple projectors	NA:NA	2017
